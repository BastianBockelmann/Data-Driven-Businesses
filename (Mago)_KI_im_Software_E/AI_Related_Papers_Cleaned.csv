Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier,is_ai_related
A critique of software defect prediction models,N. E. Fenton; M. Neil,"Centre for Software Reliability, London, UK; Centre for Software Reliability, London, UK",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,5,675,689,"Many organizations want to predict the number of defects (faults) in software systems, before they are deployed, to gauge the likely delivered quality and maintenance effort. To help in this numerous software metrics and statistical models have been developed, with a correspondingly large literature. We provide a critical review of this literature and the state-of-the-art. Most of the wide range of prediction models use size and complexity metrics to predict defects. Others are based on testing data, the ""quality"" of the development process, or take a multivariate approach. The authors of the models have often made heroic contributions to a subject otherwise bereft of empirical studies. However, there are a number of serious theoretical and practical problems in many studies. The models are weak because of their inability to cope with the, as yet, unknown relationship between defects and failures. There are fundamental statistical and data quality problems that undermine model validity. More significantly many prediction models tend to model only part of the underlying problem and seriously misspecify it. To illustrate these points the Goldilock's Conjecture, that there is an optimum module size, is used to show the considerable problems inherent in current defect prediction approaches. Careful and considered analysis of past and new results shows that the conjecture lacks support and that some models are misleading. We recommend holistic models for software defect prediction, using Bayesian belief networks, as alternative approaches to the single-issue models used at present. We also argue for research into a theory of ""software decomposition"" in order to test hypotheses about defect introduction and help construct a better science of software engineering.",1939-3520,,10.1109/32.815326,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=815326,,Predictive models;Bayesian methods;Software quality;Computer Society;System testing;Process design;Software maintenance;Software systems;Software metrics;Software testing,,694,15,,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
On the statistical analysis of the number of errors remaining in a software design document after inspection,N. B. Ebrahimi,"Division of Statistics, Northern Illinois University, DeKalb, IL, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1997,23,8,529,532,"Sometimes, complex software systems fail because of faults introduced in the requirements and design stages of the development process. Reviewing documents related to requirements and design by several reviewers can remove some of these faults, but often a few remain undetected until the software is developed. In this paper, we propose a procedure leading to the estimation of the number of faults which are not discovered. The main advantage of our procedure is that we do not need the standard assumption of independence among reviewers.",1939-3520,,10.1109/32.624308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=624308,,Statistical analysis;Software design;Software systems;Smoothing methods;Software engineering;Programming;Fault detection;Inspection;Parameter estimation;Phase estimation,,31,,8,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
"Comments on ""More success and failure factors in software reuse""",M. Morisio; M. Ezran; C. Tully,"Automatica e Informatica, Politecnico di Torino, Torino, Italy; Valtech S. A., Courbevoie, France; School of Computing Science, Middlesex University, London, UK",IEEE Transactions on Software Engineering,21 May 2003,2003,29,5,478,,"For original paper see ibid., p. 474. This is a clear example of how research in software engineering can progress when empirical methods are applied. Menzies and Di Stefano apply a number of data mining tools to the data set. While, inmost cases, their results are in agreement with ours, in some cases they are not. Our first and main observation is that our interpretation of the data set is based not only on the data set itself but also on the knowledge gathered during the interviews with project members. The main problem with the data set is its size: 23 data points. Although this data set is the largest one available about reuse projects, it is too limited to base analysis only on data mining techniques; data mining is usually applied to data sets with thousands if not millions of data points.",1939-3520,,10.1109/TSE.2003.1199077,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1199077,,Data mining;Predictive models;Testing;Data analysis;Human factors;Computer Society;Software engineering;Production;Association rules,,5,,2,IEEE,21 May 2003,,,IEEE,IEEE Journals,True
Ginger2: an environment for computer-aided empirical software engineering,K. Torii; K. Matsumoto; K. Nakakoji; Y. Takada; S. Takada; K. Shima,"Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Software Engineering Laboratory, Graduate School of Information Science,Nara Institute of Science and Technology, Software Research Associates, Inc., Ikoma, Nara, Japan; Development & Production HQ, Social Systems Business Group, OMRON Corporation, Kusatsu, Shiga, Japan; Department of Information and Computer Science, Faculty of Science and Technology, Keio University, Yokohama, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,4,474,492,"Empirical software engineering can be viewed as a series of actions to obtain knowledge and a better understanding about some aspects of software development, given a set of problem statements in the form of issues, questions or hypotheses. Experience has made us aware of the criticality of integrating the various types of data that are collected and analyzed as well as the criticality of integrating the various types of activities that take place, such as experiment design and the experiment itself. This has led us to develop a Computer-Aided Empirical Software Engineering (CAESE) framework to support the empirical software engineering lifecycle. The paper first presents the CAESE framework that consists of three elements: (1) a process model for the ""lifecycle"" of empirical software engineering studies, including needs analysis, experiment design, actual experimentation, and analyzing and packaging results; (2) a model that helps empirical software engineers decide how to look at the ""world"" to be studied in a coherent manner; (3) an architecture, based on which CAESE environments can be built, consisting of tool sets for each phase of the process model, a process management mechanism, and the two types of integration mechanism that are vital for handling multiple types of data: data integration and control integration. Next, the paper describes the Ginger2 environment as an instantiation of our framework. It concludes with reports on case studies using Ginger2, which dealt with a variety of empirical data types including mouse and keystrokes, eye traces, 3D movement, skin resistance level, and videotaped data.",1939-3520,,10.1109/32.799942,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=799942,,Software engineering;Programming;Software packages;Packaging;Software tools;Data engineering;Design engineering;Computer architecture;Environmental management;Engineering management,,27,,32,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Explaining software developer acceptance of methodologies: a comparison of five theoretical models,C. K. Riemenschneider; B. C. Hardgrave; F. D. Davis,"Sam M. Walton College of Business Information Systems Department, University of Arkansas, Fayetteville, AR, USA; Sam M. Walton College of Business Information Systems Department, University of Arkansas, Fayetteville, AR, USA; Sam M. Walton College of Business Information Systems Department, University of Arkansas, Fayetteville, AR, USA",IEEE Transactions on Software Engineering,6 Jan 2003,2002,28,12,1135,1145,"Many organizations attempt to deploy methodologies intended to improve software development processes. However, resistance by individual software developers against using such methodologies often obstructs their successful deployment. To better explain why individual developers accept or resist methodologies, five theoretical models of individual intentions to accept information technology tools were examined. In a field study of 128 developers in a large organization that implemented a methodology, each model explained significant variance in developers' intentions to use the methodology. Similar to findings from the tool adoption context, we found that, if a methodology is not regarded as useful by developers, its prospects for successful deployment may be severely undermined. In contrast to the typical pattern of findings in a tool context, however, we found that methodology adoption intentions are driven by: 1) the presence of an organizational mandate to use the methodology, 2) the compatibility of the methodology with how developers perform their work, and 3) the opinions of developers' coworkers and supervisors toward using the methodology. Collectively, these results provide surprising new insights into why software developers accept or resist methodologies and suggest what software engineering managers might do to overcome developer resistance.",1939-3520,,10.1109/TSE.2002.1158287,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1158287,,Programming;Information technology;Software engineering;Productivity;Resists;Software development management;Computer Society;Engineering management;Technological innovation;Production,,160,,70,IEEE,6 Jan 2003,,,IEEE,IEEE Journals,True
A controlled experiment for evaluating quality guidelines on the maintainability of object-oriented designs,L. C. Briand; C. Bunse; J. W. Daly,"Systems and Computer Engineering, Carleton University, Ottawa, Canada; Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Agilent Technologies, Inc., South Queensferry, UK",IEEE Transactions on Software Engineering,7 Aug 2002,2001,27,6,513,530,"The paper presents a controlled experiment, focusing on the impact of applying quality design principles such as the ones provided by P. Coad and E. Yourdon (1991) on the maintainability of object oriented designs. Results, which repeat the findings of a previous study, strongly suggest that such design principles have a beneficial effect on the maintainability of object oriented designs. It is argued that object oriented designs are sensitive to poor design practices because the cognitive complexity introduced becomes increasingly unmanageable. However, as our ability to generalize these results is limited, they should be considered as preliminary, i.e., it is very likely that they can only be generalized to programmers with little object oriented training and programming experience. Such programmers can, however, be commonly found on maintenance projects. As well as additional research, external replications of this study are required to confirm the results and achieve confidence in these findings.",1939-3520,,10.1109/32.926174,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=926174,,Guidelines;Programming profession;Software maintenance;Productivity;Software quality;Object oriented programming;Software systems;Design methodology;Entropy;Maintenance engineering,,129,,29,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
A choice relation framework for supporting category-partition test case generation,T. Y. Chen; Pak-Lok Poon; T. H. Tse,"School of Information Technology, Swinburne University of Technology, Hawthorn, Australia; Department of Accountancy, Hong Kong Polytechnic University, Hung Hom, China; Department of Computer Science and Information Systems, University of Hong Kong, Hong Kong, China",IEEE Transactions on Software Engineering,22 Jul 2003,2003,29,7,577,593,"We describe in this paper a choice relation framework for supporting category-partition test case generation. We capture the constraints among various values (or ranges of values) of the parameters and environment conditions identified from the specification, known formally as choices. We express these constraints in terms of relations among choices and combinations of choices, known formally as test frames. We propose a theoretical backbone and techniques for consistency checks and automatic deductions of relations. Based on the theory, algorithms have been developed for generating test frames from the relations. These test frames can then be used as the basis for generating test cases. Our algorithms take into consideration the resource constraints specified by software testers, thus maintaining the effectiveness of the test frames (and hence test cases) generated.",1939-3520,,10.1109/TSE.2003.1214323,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1214323,,Computer aided software engineering;Software testing;Software maintenance;Spine;Software algorithms;Costs;Humans;Information technology;Australia;Computer science,,43,,20,IEEE,22 Jul 2003,,,IEEE,IEEE Journals,True
A theory-based representation for object-oriented domain models,S. A. DeLoach; T. C. Hartrum,"Department of Electrical and Computer Engineering AFIT/ENG, US Air Force Institute of Technology, OH, USA; Department of Electrical and Computer Engineering AFIT/ENG, US Air Force Institute of Technology, OH, USA",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,6,500,517,"Formal software specification has long been touted as a way to increase the quality and reliability of software; however, it remains an intricate, manually intensive activity. An alternative to using formal specifications directly is to translate graphically based, semiformal specifications into formal specifications. However, before this translation can take place, a formal definition of basic object oriented concepts must be found. The paper presents an algebraic model of object orientation that defines how object oriented concepts can be represented algebraically using an object oriented algebraic specification language O-SLANG. O-SLANG combines basic algebraic specification constructs with category theory operations to capture internal object class structure, as well as relationships between classes.",1939-3520,,10.1109/32.852740,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=852740,,Object oriented modeling;Formal specifications;Software quality;Software systems;Computer Society;Specification languages;Software engineering;Formal languages;Application software;Natural languages,,18,,25,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
The domain theory for requirements engineering,A. Sutcliffe; N. Maiden,"Centre for HCI Design, School of Informatics, City University, London, UK; Centre for HCI Design, School of Informatics, City University, London, UK",IEEE Transactions on Software Engineering,6 Aug 2002,1998,24,3,174,196,"Retrieval, validation, and explanation tools are described for cooperative assistance during requirements engineering and are illustrated by a library system case study. Generic models of applications are reused as templates for modeling and critiquing requirements for new applications. The validation tools depend on a matching process which takes facts describing a new application and retrieves the appropriate generic model from the system library. The algorithms of the matcher, which implement a computational theory of analogical structure matching, are described. A theory of domain knowledge is proposed to define the semantics and composition of generic domain models in the context of requirements engineering. A modeling language and a library of models arranged in families of classes are described. The models represent the basic transaction processing or 'use case' for a class of applications. Critical difference rules are given to distinguish between families and hierarchical levels. Related work and future directions of the domain theory are discussed.",1939-3520,,10.1109/32.667878,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=667878,,Libraries;Application software;Software engineering;Knowledge engineering;Context modeling;Software tools;Computer aided software engineering;Software design;Design engineering;Buildings,,63,,72,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Categorization of common coupling and its application to the maintainability of the Linux kernel,L. Yu; S. R. Schach; K. Chen; J. Offutt,"Computer Science Department, Tennessee Technological University, Cookeville, TN, USA; Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, USA; Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, USA; Department of Information and Software Engineering, George Mason University, Fairfax, VA, USA",IEEE Transactions on Software Engineering,4 Oct 2004,2004,30,10,694,706,"Data coupling between modules, especially common coupling, has long been considered a source of concern in software design, but the issue is somewhat more complicated for products that are comprised of kernel modules together with optional nonkernel modules. This paper presents a refined categorization of common coupling based on definitions and uses between kernel and nonkernel modules and applies the categorization to a case study. Common coupling is usually avoided when possible because of the potential for introducing risky dependencies among software modules. The relative risk of these dependencies is strongly related to the specific definition-use relationships. In a previous paper, we presented results from a longitudinal analysis of multiple versions of the open-source operating system Linux. This paper applies the new common coupling categorization to version 2.4.20 of Linux, counting the number of instances of common coupling between each of the 26 kernel modules and all the other nonkernel modules. We also categorize each coupling in terms of the definition-use relationships. Results show that the Linux kernel contains a large number of common couplings of all types, raising a concern about the long-term maintainability of Linux.",1939-3520,,10.1109/TSE.2004.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1339279,Index Terms- Modularity;dependencies;common coupling;definition-use analysis;kernel-based software;open-source software;Linux.,Linux;Kernel;Open source software;Operating systems;Application software;Computer Society;Computer architecture;Database systems;Software design;System software,,43,,17,IEEE,4 Oct 2004,,,IEEE,IEEE Journals,True
Automating output size and reuse metrics in a repository-based computer-aided software engineering (CASE) environment,R. D. Banker; R. J. Kauffman; C. Wright; D. Zweig,"Carlson School of Management, University of Minnesota, Minneapolis, MN, USA; Stem School of Business, New York University, New York, NY, USA; Seer Technologies, New York, NY, USA; Department of Administrative Sciences, U.S. Naval Postgraduate School, CA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,3,169,187,"Measurement of software development productivity is needed in order to control software costs, but it is discouragingly labor-intensive and expensive. Computer-aided software engineering (CASE) technologies/spl minus/especially repository-based, integrated CASE/spl minus/have the potential to support the automation of this measurement. We discuss the conceptual basis for the development of automated analyzers for function point and software reuse measurement for object-based CASE. Both analyzers take advantage of the existence of a representation of the application system that is stored within an object repository, and that contains the necessary information about the application system. We also discuss metrics for software reuse measurement, including reuse leverage, reuse value, and reuse classification that are motivated by managerial requirements and the efforts, within industry and the IEEE, to standardize measurement. The functionality and the analytical capabilities of state-of-the-art automated software metrics analyzers are illustrated in the context of an investment banking industry application that is similar to systems deployed at the New York City-based investment bank where these tools were developed and tested.<>",1939-3520,,10.1109/32.268919,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=268919,,Software measurement;Computer aided software engineering;Application software;Investments;Programming;Productivity;Automatic control;Costs;Automation;Information analysis,,29,6,70,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Assessing staffing needs for a software maintenance project through queuing simulation,G. Antoniol; A. Cimitile; G. A. Di Lucca; M. Di Penta,"RCOST-Research Centre on Software Technology, Department of Engineering, University of Sannio, Benevento, Italy; RCOST-Research Centre on Software Technology, Department of Engineering, University of Sannio, Benevento, Italy; Computer Science Department, University of Sannio, Benevento, Italy; RCOST-Research Centre on Software Technology, Department of Engineering, University of Sannio, Benevento, Italy",IEEE Transactions on Software Engineering,19 Feb 2004,2004,30,1,43,58,"We present an approach based on queuing theory and stochastic simulation to help planning, managing, and controlling the project staffing and the resulting service level in distributed multiphase maintenance processes. Data from a Y2K massive maintenance intervention on a large COBOL/JCL financial software system were used to simulate and study different service center configurations for a geographically distributed software maintenance project. In particular, a monolithic configuration corresponding to the customer's point-of-view and more fine-grained configurations, accounting for different process phases as well as for rework, were studied. The queuing theory and stochastic simulation provided a means to assess staffing, evaluate service level, and assess the likelihood to meet the project deadline while executing the project. It turned out to be an effective staffing tool for managers, provided that it is complemented with other project-management tools, in order to prioritize activities, avoid conflicts, and check the availability of resources.",1939-3520,,10.1109/TSE.2004.1265735,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1265735,,Software maintenance;Queueing analysis;Computational modeling;Stochastic processes;Project management;Costs;Computer simulation;Software systems;Counting circuits;Computer Society,,50,,37,IEEE,19 Feb 2004,,,IEEE,IEEE Journals,True
Design and implementation of a fine-grained software inspection tool,P. Anderson; T. Reps; T. Teitelbaum,"GrammaTech, Inc., Ithaca, NY, USA; Computer Science Department, University of Wisconsin, Madison, WI, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA",IEEE Transactions on Software Engineering,26 Aug 2003,2003,29,8,721,733,"Although software inspection has led to improvements in software quality, many software systems continue to be deployed with unacceptable numbers of errors, even when software inspection is part of the development process. The difficulty of manually verifying that the software under inspection conforms to the rules is partly to blame. We describe the design and implementation of a tool designed to help alleviate this problem. The tool provides mechanisms for fine-grained inspection of software by exposing the results of sophisticated whole-program static analysis to the inspector. The tool computes many static-semantic representations of the program, including an accurate call graph and dependence graph. A whole-program pointer analysis is used to make sure that the representation is precise with respect to aliases induced by pointer usage. Views on the dependence graph and related representations are supported. Queries on the dependence graph allow an inspector to answer detailed questions about the semantics of the program. Facilities for openness and extensibility permit the tool to be integrated with many software development processes. The main challenge of the approach is to provide facilities to navigate and manage the enormous complexity of the dependence graph.",1939-3520,,10.1109/TSE.2003.1223646,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1223646,,Software tools;Inspection;Software quality;Navigation;Software systems;Software engineering;Best practices;NASA;Performance analysis;Filters,,49,10,44,IEEE,26 Aug 2003,,,IEEE,IEEE Journals,True
Using machine learning for estimating the defect content after an inspection,F. Padberg; T. Ragg; R. Schoknecht,"Fakultät fur Informatik, Universität Karlsruhe, Karlsruhe, Germany; Quantiom bioinformatics GmbH, Weingarten, Germany; Fakultät fur Informatik, Universität Karlsruhe, Karlsruhe, Germany",IEEE Transactions on Software Engineering,19 Feb 2004,2004,30,1,17,28,"We view the problem of estimating the defect content of a document after an inspection as a machine learning problem: The goal is to learn from empirical data the relationship between certain observable features of an inspection (such as the total number of different defects detected) and the number of defects actually contained in the document. We show that some features can carry significant nonlinear information about the defect content. Therefore, we use a nonlinear regression technique, neural networks, to solve the learning problem. To select the best among all neural networks trained on a given data set, one usually reserves part of the data set for later cross-validation; in contrast, we use a technique which leaves the full data set for training. This is an advantage when the data set is small. We validate our approach on a known empirical inspection data set. For that benchmark, our novel approach clearly outperforms both linear regression and the current standard methods in software engineering for estimating the defect content, such as capture-recapture. The validation also shows that our machine learning approach can be successful even when the empirical inspection data set is small.",1939-3520,,10.1109/TSE.2004.1265733,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1265733,,Machine learning;Inspection;Neural networks;Software engineering;Curve fitting;Linear regression;Software standards;Software testing;Quality assurance;Estimation error,,16,,25,IEEE,19 Feb 2004,,,IEEE,IEEE Journals,True
Success and failure factors in software reuse,M. Morisio; M. Ezran; C. Tully,"Dip. Automatica e Informatica, Politecnico di Torino, Torino, Italy; Immeuble Lavoisier, Valtech S. A., Courbevoie, France; School of Computing Science, Middlesex University, London, UK",IEEE Transactions on Software Engineering,7 Aug 2002,2002,28,4,340,357,"This paper aims at identifying some of the key factors in adopting or running a company-wide software reuse program. Key factors are derived from empirical evidence of reuse practices, as emerged from a survey of projects for the introduction of reuse in European companies: 24 such projects performed from 1994 to 1997 were analyzed using structured interviews. The projects were undertaken in both large and small companies, working in a variety of business domains, and using both object-oriented and procedural development approaches. Most of them produce software with high commonality between applications, and have at least reasonably mature processes. Despite that apparent potential for success, around one-third of the projects failed. Three main causes of failure were not introducing reuse-specific processes, not modifying nonreuse processes, and not considering human factors. The root cause was a lack of commitment by top management, or nonawareness of the importance of those factors, often coupled with the belief that using the object-oriented approach or setting up a repository seamlessly is all that is necessary to achieve success in reuse. Conversely, successes were achieved when, given a potential for reuse because of commonality among applications, management committed to introducing reuse processes, modifying nonreuse processes, and addressing human factors.",1939-3520,,10.1109/TSE.2002.995420,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=995420,,Companies;Human factors;Performance analysis;Application software,,142,,35,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Evaluating Web software reliability based on workload and failure data extracted from server logs,J. Tian; S. Rudraraju; Zhao Li,"Computer Science and Engineering Department, Southern Methodist University, Dallas, TX, USA; Intervoice, Flower Mound, TX, USA; Computer Science and Engineering Department, Southern Methodist University, Dallas, TX, USA",IEEE Transactions on Software Engineering,22 Nov 2004,2004,30,11,754,769,"We characterize usage and problems for Web applications, evaluate their reliability, and examine the potential for reliability improvement. Based on the characteristics of Web applications and the overall Web environment, we classify Web problems and focus on the subset of source content problems. Using information about Web accesses, we derive various measurements that can characterize Web site workload at different levels of granularity and from different perspectives. These workload measurements, together with failure information extracted from recorded errors, are used to evaluate the operational reliability for source contents at a given Web site and the potential for reliability improvement. We applied this approach to the Web sites www.seas.smu.edu and www.kde.org. The results demonstrated the viability and effectiveness of our approach.",1939-3520,,10.1109/TSE.2004.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359769,Index Terms- World Wide Web (WWW) and Internet;Web applications and Web server logs;quality and reliability;reliability modeling;workload measurement,Software reliability;Data mining;Application software;World Wide Web;Web server;Software systems;Software measurement;Computer Society;Internet;Web sites,,61,,21,IEEE,22 Nov 2004,,,IEEE,IEEE Journals,True
Measuring the maintainability of a communication protocol based on its formal specification,Sun-Jen Huang; R. Lai,"Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan; Department of Computer Science and Computer Engineering, La Trobe University, VIC, Australia",IEEE Transactions on Software Engineering,8 Apr 2003,2003,29,4,327,344,"It is difficult to measure the maintainability of a software system early in the development life cycle from its requirement descriptions written in a natural language because informal specifications cannot be analyzed. With the uses of formal description techniques (FDTs) in the communication protocol area since the mid-1980s, avenues have been opened up for a system to be analyzed early in the specification phase. Quantitative measures on its maintainability can then be extracted from such a formal specification, so that we can develop easily maintainable communication software systems and further reduce the increasingly high cost of software maintenance. To date, there is hardly any work done on measuring the maintainability of a system early in its specification phase. This paper presents a method for measuring the maintainability of a communication by using maintainability metrics derived from its formal specification written in Estelle. The methodology for building the Estelle maintainability metrics hierarchy is presented. We have also developed an automated tool, called PSAMS, to automate the calculation of the maintainability indices. We also found that there is a significant correlation between the specification metrics proposed and the widely adopted implementation metrics, thus demonstrating that our proposed metrics are a reliable means of measuring the maintainability of a communication protocol early in the specification phase.",1939-3520,,10.1109/TSE.2003.1191797,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191797,,Protocols;Formal specifications;Software maintenance;Software measurement;Software systems;Costs;Phase measurement;Software quality;Software metrics;Natural languages,,6,,33,IEEE,8 Apr 2003,,,IEEE,IEEE Journals,True
Cryptographic verification of test coverage claims,P. T. Devanbu; S. G. Stubblebine,"Department of Computer Science, University of California, Davis, CA, USA; New York, USA",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,2,178,192,"The market for software components is growing, driven on the ""demand side"" by the need for rapid deployment of highly functional products and, on the ""supply side"", by distributed object standards. As components and component vendors proliferate, there is naturally a growing concern about quality and the effectiveness of testing processes. White-box testing, particularly the use of coverage criteria, Is a widely used method for measuring the ""thoroughness"" of testing efforts. High levels of test coverage are used as indicators of good quality control procedures. Software vendors who can demonstrate high levels of test coverage have a credible claim to high quality. However, verifying such claims involves knowledge of the source code, test cases, build procedures, etc. In applications where reliability and quality are critical, it would be desirable to verify test coverage claims without forcing vendors to give up valuable technical secrets. In this paper, we explore cryptographic techniques that can be used to verify such claims. Our techniques have certain limitations, which we discuss in this paper. However, vendors who have done the hard work of developing high levels of test coverage can use these techniques (for a modest additional cost) to provide credible evidence of high coverage, while simultaneously reducing disclosure of intellectual property.",1939-3520,,10.1109/32.841116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=841116,,Cryptography;Costs;Application software;Software testing;Software standards;Intellectual property;Particle measurements;Quality control;Software quality;Software safety,,6,2,39,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Quantitative analysis of faults and failures in a complex software system,N. E. Fenton; N. Ohlsson,"Risk Assessment and Decision Analysis Research Group, Computer Science Department, Faculty of Informatics and Mathematical Sciences, Queen Mary and Westfield College, London, UK; GratisTel International, AB, Stockholm, Sweden",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,8,797,814,"The authors describe a number of results from a quantitative study of faults and failures in two releases of a major commercial software system. They tested a range of basic software engineering hypotheses relating to: the Pareto principle of distribution of faults and failures; the use of early fault data to predict later fault and failure data; metrics for fault prediction; and benchmarking fault data. For example, we found strong evidence that a small number of modules contain most of the faults discovered in prerelease testing and that a very small number of modules contain most of the faults discovered in operation. We found no evidence to support previous claims relating module size to fault density nor did we find evidence that popular complexity metrics are good predictors of either fault-prone or failure-prone modules. We confirmed that the number of faults discovered in prerelease testing is an order of magnitude greater than the number discovered in 12 months of operational use. The most important result was strong evidence of a counter-intuitive relationship between pre- and postrelease faults; those modules which are the most fault-prone prerelease are among the least fault-prone postrelease, while conversely, the modules which are most fault-prone postrelease are among the least fault-prone prerelease. This observation has serious ramifications for the commonly used fault density measure. Our results provide data-points in building up an empirical picture of the software development process.",1939-3520,,10.1109/32.879815,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=879815,,Failure analysis;Software systems;Density measurement;Software engineering;Software testing;Computer industry;Benchmark testing;Programming;Software metrics;Phase measurement,,442,1,46,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Toward constraint-object-oriented development,T. Bolognesi,"CNR-IEI-Istituto di Elaborazione dell''Informazione, Pisa, Italy",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,7,594,616,"In this paper, we propose to conservatively extend object-oriented decomposition by letting it affect also operations (methods). Different objects may support different parts of the same operation. The responsibility of defining an operation, in terms of enabling conditions and effects on the state, is distributed over several interacting objects, which act as constraints and express different, partial views about the system behavior. Constraint-oriented reasoning has already been explored and applied in the context of formal specification languages for concurrent and reactive systems, and is sufficiently different from object-oriented reasoning to be considered as a paradigm in itself, with its own specific advantages. Nevertheless, the paper shows that the two approaches are sufficiently compatible to be profitably integrated. We introduce a constraint-oriented style for an object-oriented programming language (JAVA).",1939-3520,,10.1109/32.859530,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=859530,,Formal specifications;Java;Programming profession;Object oriented programming;Design methodology;Computer languages;Software engineering;Engineering management;Isolation technology;Data encapsulation,,7,,36,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Evaluating the effect of a delegated versus centralized control style on the maintainability of object-oriented software,E. Arisholm; D. I. K. Sjoberg,"Simula Research Laboratory, Lysaker, Norway; Simula Research Laboratory, Lysaker, Norway",IEEE Transactions on Software Engineering,26 Jul 2004,2004,30,8,521,534,"A fundamental question in object-oriented design is how to design maintainable software. According to expert opinion, a delegated control style, typically a result of responsibility-driven design, represents object-oriented design at its best, whereas a centralized control style is reminiscent of a procedural solution, or a ""bad"" object-oriented design. We present a controlled experiment that investigates these claims empirically. A total of 99 junior, intermediate, and senior professional consultants from several international consultancy companies were hired for one day to participate in the experiment. To compare differences between (categories of) professionals and students, 59 students also participated. The subjects used professional Java tools to perform several change tasks on two alternative Java designs that had a centralized and delegated control style, respectively. The results show that the most skilled developers, in particular, the senior consultants, require less time to maintain software with a delegated control style than with a centralized control style. However, more novice developers, in particular, the undergraduate students and junior consultants, have serious problems understanding a delegated control style, and perform far better with a centralized control style. Thus, the maintainability of object-oriented software depends, to a large extent, on the skill of the developers who are going to maintain it. These results may have serious implications for object-oriented development in an industrial context: having senior consultants design object-oriented systems may eventually pose difficulties unless they make an effort to keep the designs simple, as the cognitive complexity of ""expert"" designs might be unmanageable for less skilled maintainers.",1939-3520,,10.1109/TSE.2004.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1316869,Index Terms- Design principles;responsibility delegation;control styles;object-oriented design;object-oriented programming;software maintainability;controlled experiment.,Software maintenance;Centralized control;Software design;Java;Design methodology;Unified modeling language;Business communication;Logic;Electrical equipment industry;Object oriented programming,,91,,33,IEEE,26 Jul 2004,,,IEEE,IEEE Journals,True
More success and failure factors in software reuse,T. Menzies; J. S. Di Stefano,"Lane Department of Computer Science, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science, West Virginia University, Morgantown, WV, USA",IEEE Transactions on Software Engineering,21 May 2003,2003,29,5,474,477,Numerous discrepancies exist between expert opinion and empirical data reported in Morisio et al.'s recent TSE article. The differences related to what factors encouraged successful reuse in software organizations. This note describes how those differences were detected and comments on their methodological implications.,1939-3520,,10.1109/TSE.2003.1199076,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1199076,,Data mining;Decision trees;Project management;Data analysis;Machine learning;Failure analysis;Stress;Web sites;Association rules,,17,,10,IEEE,21 May 2003,,,IEEE,IEEE Journals,True
A Markov chain model for statistical software testing,J. A. Whittaker; M. G. Thomason,"Software Engineering Technology, Inc., Knoxville, TN, USA; Department of Computer Science, University of Tennessee, Knoxville, TN, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,10,812,824,"Statistical testing of software establishes a basis for statistical inference about a software system's expected field quality. This paper describes a method for statistical testing based on a Markov chain model of software usage. The significance of the Markov chain is twofold. First, it allows test input sequences to be generated from multiple probability distributions, making it more general than many existing techniques. Analytical results associated with Markov chains facilitate informative analysis of the sequences before they are generated, indicating how the test is likely to unfold. Second, the test input sequences generated from the chain and applied to the software are themselves a stochastic model and are used to create a second Markov chain to encapsulate the history of the test, including any observed failure information. The influence of the failures is assessed through analytical computations on this chain. We also derive a stopping criterion for the testing process based on a comparison of the sequence generating properties of the two chains.<>",1939-3520,,10.1109/32.328991,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=328991,,Software testing;Statistical analysis;History;Probability distribution;Software quality;Failure analysis;Software systems;Stochastic processes;Performance evaluation,,290,3,28,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A controlled experiment in maintenance: comparing design patterns to simpler solutions,L. Prechelt; B. Unger; W. F. Tichy; P. Brossler; L. G. Votta,"Fakultät für Informatik, Universität Karlsruhe, Karlsruhe, Germany; Fakultät für Informatik, Universität Karlsruhe, Karlsruhe, Germany; Fakultät für Informatik, Universität Karlsruhe, Karlsruhe, Germany; sd&m GmbH and Co., München, Germany; Motorola Inc., Arlington Heights, IL, USA",IEEE Transactions on Software Engineering,7 Aug 2002,2001,27,12,1134,1144,"Software design patterns package proven solutions to recurring design problems in a form that simplifies reuse. We are seeking empirical evidence whether using design patterns is beneficial. In particular, one may prefer using a design pattern even if the actual design problem is simpler than that solved by the pattern, i.e., if not all of the functionality offered by the pattern is actually required. Our experiment investigates software maintenance scenarios that employ various design patterns and compares designs with patterns to simpler alternatives. The subjects were professional software engineers. In most of our nine maintenance tasks, we found positive effects from using a design pattern: either its inherent additional flexibility was achieved without requiring more maintenance time or maintenance time was reduced compared to the simpler alternative. In a few cases, we found negative effects: the alternative solution was less error-prone or required less maintenance time. Overall, we conclude that, unless there is a clear reason to prefer the simpler solution, it is probably wise to choose the flexibility provided by the design pattern because unexpected new requirements often appear. We identify several questions for future empirical research.",1939-3520,,10.1109/32.988711,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=988711,,Computer Society;Packaging;Software maintenance;Books;Delay effects;Runtime;Terminology;Testing;Solids;Guidelines,,113,,11,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Automatically checking an implementation against its formal specification,S. Antoy; D. Hamlet,"Department of Computer Science and the Center for Software Quality Research, Portland State University, Portland, OR, USA; Department of Computer Science and the Center for Software Quality Research, Portland State University, Portland, OR, USA",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,1,55,69,"We propose checking the execution of an abstract data type's imperative implementation against its algebraic specification. An explicit mapping from implementation states to abstract values is added to the imperative code. The form of specification allows mechanical checking of desirable properties such as consistency and completeness, particularly when operations are added incrementally to the data type. During unit testing, the specification serves as a test oracle. Any variance between computed and specified values is automatically detected. When the module is made part of some application, the checking can he removed, or may remain in place for further validating the implementation. The specification, executed by rewriting, can be thought of as itself an implementation with maximum design diversity, and the validation as a form of multiversion-programming comparison.",1939-3520,,10.1109/32.825766,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=825766,,Formal specifications;Application software;Java;Mechanical factors;Software testing;Computer languages;Software engineering;Software maintenance;Equations;Software prototyping,,54,1,59,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Quality improvement using a software reuse failure modes model,W. B. Frakes; C. J. Fox,"Department of Computer Science, Virginia Polytechnic Institute and State University, Falls Church, VA, USA; Computer Science Department, James Madison University, Harrisonburg, VA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1996,22,4,274,279,"The paper presents a failure modes model of parts-based software reuse, and shows how this model can be used to evaluate and improve software reuse processes. The model and the technique are illustrated using survey data about software reuse gathered from 113 people from 29 organizations.",1939-3520,,10.1109/32.491652,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=491652,,Software quality;Application software;Environmental economics;Law;Failure analysis;Software systems;Legal factors;Computer languages;Pareto analysis;Knowledge engineering,,57,,17,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
An application of artificial intelligence to object-oriented performance design for real-time systems,S. Honiden; K. Nishimura; N. Uchihira; K. Itoh,"Systems and Software Engineering Laboratory, Toshiba Corporation, Japan; Systems and Software Engineering Laboratory, Toshiba Corporation, Japan; Systems and Software Engineering Laboratory, Toshiba Corporation, Japan; Faculty of Science and Technology, Sophia University, Japan",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,11,849,867,"The paper describes an application of artificial intelligence technology to the implementation of a rapid prototyping method in object-oriented performance design (OOPD) for real-time systems. OOPD consists of two prototyping phases for real-time systems. Each of these phases consists of three steps: prototype construction, prototype execution, and prototype evaluation. We present artificial intelligence based methods and tools to be applied to the individual steps. In the prototype construction step, a rapid construction mechanism using reusable software components is implemented based on planning. In the prototype execution step, a hybrid inference mechanism is used to execute the constructed prototype described in declarative knowledge representation. MENDEL, which is a Prolog based concurrent object-oriented language, can be used as a prototype construction tool and a prototype execution tool. In the prototype evaluation step, an expert system which is based on qualitative reasoning is implemented to detect and diagnose bottlenecks and generate an improvement plan for them.<>",1939-3520,,10.1109/32.368123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=368123,,Artificial intelligence;Real time systems;Software prototyping;Prototypes;Application software;Algorithm design and analysis;Software performance;Hardware;Productivity;Paper technology,,3,,48,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A model of code sharing for estimating software failure on demand probabilities,J. H. R. May; A. D. Lunn,"Department of Computing, Open University, Milton Keynes, UK; Department of Statistics, Open University, Milton Keynes, UK",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,9,747,753,"A statistical software testing model is proposed in which white box factors have a role. The model combines test adequacy notions with statistical analysis, and in so doing provides a rudimentary treatment of dependencies between test results caused by the execution of common code during the tests. The model is used to estimate the probability of failure on demand for software performing safety shutdown functions on large plants and concerns the case where extensive test results are available on the latest version of the software, none of which have resulted in software failure. According to the model, there are circumstances in which some current statistical models for dynamic software testing are too conservative, and others are not conservative, depending on the software architecture.<>",1939-3520,,10.1109/32.464546,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=464546,,Software safety;Probability;Software testing;Software performance;Steady-state;Statistical analysis;Software reliability;Phase frequency detector;Sampling methods;Performance evaluation,,5,,22,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A methodology for feature interaction detection in the AIN 0.1 framework,F. J. Lin; Hong Liu; A. Ghosh,"Bellcore Applied Research, Morristown, NJ, USA; Bellcore Applied Research, Morristown, NJ, USA; Bellcore Applied Research, Morristown, NJ, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1998,24,10,797,817,"We propose an integrated methodology for specifying AIN (advanced intelligent networks) and switch based features and analyzing their interactions in the AIN 0.1 framework. The specification of each individual feature is tied to the AIN call model and requires only a minimum amount of information in terms of control and data for interaction analysis. Once a feature is specified, its specification is then validated for consistency with respect to control and data. Interaction analysis is conducted for a set of features based on the sharing of call variables between the SSP and the SCP. With this approach, one can detect the following interactions involving AIN features: (1) side effects, where a call variable modified by one feature is used by another feature and (2) disabling, where one feature disconnects a call, preventing another feature from execution. We also develop a theory that is based on the computation of sequences of messages exchanged between the SSP and the SCP and their call variable usage. This theory is shown to dramatically reduce the number of cases considered during the analysis. A brief overview of a tool that makes use of this methodology to aid in the task of feature interaction detection is also given.",1939-3520,,10.1109/32.729681,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=729681,,Computer vision;Logic;Telecommunication switching;Information analysis;Data analysis;Switches;Telecommunication services;Telephony;Software engineering;Packaging,,3,3,13,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
"Measuring and evaluating maintenance process using reliability, risk, and test metrics",N. F. Schneidewind,"Computer and Information Sciences and Operations Division, Naval Postgraduate School, Monterrey, CA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,6,769,781,"In analyzing the stability of a software maintenance process, it is important that it is not treated in isolation from the reliability and risk of deploying the software that result from applying the process. Furthermore, we need to consider the efficiency of the test effort that is a part of the process and a determinate of reliability and risk of deployment. The relationship between product quality and process capability and maturity has been recognized as a major issue in software engineering based on the premise that improvements in the process will lead to higher-quality products. To this end, we have been investigating an important facet of process capability-stability-as defined and evaluated by trend, change and shape metrics, across releases and within a release. Our integration of product and process measurement serves the dual purpose of using metrics to assess and predict reliability and risk and to evaluate process stability. We use the NASA Space Shuttle flight software to illustrate our approach.",1939-3520,,10.1109/32.824387,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=824387,,Stability criteria;Software maintenance;Shape;Stability analysis;Software measurement;NASA;Space shuttles;Software testing;Risk analysis;Software engineering,,37,1,20,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Integrating time domain and input domain analyses of software reliability using tree-based models,J. Tian,"Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,12,945,958,"The paper examines two existing approaches to software reliability analysis, time domain reliability growth modeling and input domain reliability analysis, and presents a new approach that combines some of their individual strengths. An analysis method called tree-based modeling is used to build models based on the combined measurement data. This new approach can be used to assess the reliability of software systems, to track reliability change over time, and to identify problematic subparts characterized by certain input states or time periods. The results can also be used to guide various remedial actions aimed at reliability improvement. This approach has been demonstrated to be applicable and effective in the testing of several large commercial software systems developed in the IBM Software Solutions Toronto Laboratory.",1939-3520,,10.1109/32.489071,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=489071,,Time domain analysis;Software reliability;Software testing;Software systems;Failure analysis;Laboratories;System testing;Programming;Data analysis;Sampling methods,,40,1,29,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Optimal test distributions for software failure cost estimation,W. J. Gutjahr,"Department of Statistics, Operations Research and Computer Science, University of Technology, Vienna, Vienna, Austria",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,3,219,228,"We generalize the input domain based software reliability measures by E.C. Nelson (1973) and by S.N. Weiss and E.J. Weyuker (1988), introducing expected failure costs under the operational distribution as a measure for software unreliability. This approach incorporates in the reliability concept a distinction between different degrees of failure severity. It is shown how to estimate the proposed quantity by means of random testing, using the Importance Sampling technique from Rare Event Simulation. A test input distribution that yields an unbiased estimator with minimum variance is determined. The practical application of the presented method is outlined, and a detailed numerical example is given.<>",1939-3520,,10.1109/32.372149,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=372149,,Software testing;Cost function;Software reliability;Software measurement;Application software;Fault detection;Reliability theory;Monte Carlo methods;Discrete event simulation;Yield estimation,,28,,23,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A domain-specific software architecture for adaptive intelligent systems,B. Hayes-Roth; K. Pfleger; P. Lalanda; P. Morignot; M. Balabanovic,"Knowledge Systems Laboratory, Computer Science Department, University of Stanford, Palo Alto, CA, USA; Knowledge Systems Laboratory, Computer Science Department, University of Stanford, Palo Alto, CA, USA; Knowledge Systems Laboratory, Computer Science Department, University of Stanford, Palo Alto, CA, USA; Knowledge Systems Laboratory, Computer Science Department, University of Stanford, Palo Alto, CA, USA; Knowledge Systems Laboratory, Computer Science Department, University of Stanford, Palo Alto, CA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,4,288,301,"A good software architecture facilitates application system development, promotes achievement of functional requirements, and supports system reconfiguration. We present a domain-specific software architecture (DSSA) that we have developed for a large application domain of adaptive intelligent systems (AISs). The DSSA provides: (a) an AIS reference architecture designed to meet the functional requirements shared by applications in this domain, (b) principles for decomposing expertise into highly reusable components, and (c) an application configuration method for selecting relevant components from a library and automatically configuring instances of those components in an instance of the architecture. The AIS reference architecture incorporates features of layered, pipe and filter, and blackboard style architectures. We describe three studies demonstrating the utility of our architecture in the subdomain of mobile office robots and identify software engineering principles embodied in the architecture.<>",1939-3520,,10.1109/32.385968,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=385968,,Software architecture;Computer architecture;Application software;Decision support systems;Adaptive systems;Intelligent systems;Software libraries;Filters;Teleworking;Mobile robots,,76,9,39,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A domain-specific language for regular sets of strings and trees,N. Klarlund; M. I. Schwartzbach,"AT and T Research Laboratories, USA; Department of Computer Science, Ny Munkegaardsgade, University of Aarhus, Aarhus, Denmark",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,3,378,386,"We propose a novel high level programming notation, called FIDO, that we have designed to concisely express regular sets of strings or trees. In particular, it can be viewed as a domain-specific language for the expression of finite state automata on large alphabets (of sometimes astronomical size). FIDO is based on a combination of mathematical logic and programming language concepts. This combination shares no similarities with usual logic programming languages. FIDO compiles into finite state string or tree automata, so there is no concept of run-time. It has already been applied to a variety of problems of considerable complexity and practical interest. We motivate the need for a language like FIDO, and discuss our design and its implementation. Also, we briefly discuss design criteria for domain-specific languages that we have learned from the work with FIDO. We show how recursive data types, unification, implicit coercions, and subtyping can be merged with a variation of predicate logic, called the Monadic Second-order Logic (M2L) on trees. FIDO is translated first into pure M2L via suitable encodings, and finally into finite state automata through the MONA tool.",1939-3520,,10.1109/32.798326,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798326,,Domain specific languages;Logic programming;Encoding;Application software;Computer languages;Runtime;Learning automata;Software systems;Embedded computing;Tree graphs,,6,,12,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Machine learning approaches to estimating software development effort,K. Srinivasan; D. Fisher,"Personal Computer Consultants, Inc., Washington D.C., DC, USA; Department of Computer Science, Vanderbilt University, Nashville, TN, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,2,126,137,"Accurate estimation of software development effort is critical in software engineering. Underestimates lead to time pressures that may compromise full functional development and thorough testing of software. In contrast, overestimates can result in noncompetitive contract bids and/or over allocation of development resources and personnel. As a result, many models for estimating software development effort have been proposed. This article describes two methods of machine learning, which we use to build estimators of software development effort from historical data. Our experiments indicate that these techniques are competitive with traditional estimators on one dataset, but also illustrate that these methods are sensitive to the data on which they are trained. This cautionary note applies to any model-construction strategy that relies on historical data. All such models for software effort estimation should be evaluated by exploring model sensitivity on a variety of historical data.<>",1939-3520,,10.1109/32.345828,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=345828,,Machine learning;Programming;Contracts;Integrated circuit modeling;Software testing;Personnel;Regression tree analysis;Software development management;Costs;Machine learning algorithms,,307,2,25,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Hierarchical modeling of availability in distributed systems,S. Hariri; H. Mutlu,"Department of Electrical and Computer Engineering, Syracuse University, Syracuse, NY, USA; Mutek, Inc.",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,1,50,56,"Distributed computing systems are attractive due to the potential improvement in availability, fault-tolerance, performance, and resource sharing. Modeling and evaluation of such computing systems is an important step in the design process of distributed systems. We present a two-level hierarchical model to analyze the availability of distributed systems. At the higher level (user level), the availability of the tasks (processes) is analyzed using a graph-based approach. At the lower level (component level), detailed Markov models are developed to analyze the component availabilities. These models take into account the hardware/software failures, congestion and collisions in communication links, allocation of resources, and the redundancy level. A systematic approach is developed to apply the two-level hierarchical model to evaluate the availability of the processes and the services provided by a distributed computing environment. This approach is then applied to analyze some of the distributed processes of a real distributed system, Unified Workstation Environment (UWE), that is currently being implemented at AT&T Bell Laboratories.<>",1939-3520,,10.1109/32.341847,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=341847,,Availability;Distributed computing;Resource management;Fault tolerant systems;Time sharing computer systems;Throughput;Reliability engineering;Design engineering;Steady-state;Fault trees,,22,,18,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Mawl: a domain-specific language for form-based services,D. L. Atkins; T. Ball; G. Bruns; K. Cox,"Software Production Research Department, Bell Laboratories, Lucent Technologies, Inc., Naperville, IL, USA; Software Production Research Department, Bell Laboratories, Lucent Technologies, Inc., Naperville, IL, USA; Software Production Research Department, Bell Laboratories, Lucent Technologies, Inc., Naperville, IL, USA; Software Production Research Department, Bell Laboratories, Lucent Technologies, Inc., Naperville, IL, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,3,334,346,"A form-based service is one in which the flow of data between service and user is described by a sequence of query/response interactions, or forms. Mawl is a domain-specific language for programming form-based services in a device-independent manner. We focus on Mawl's form abstraction, which is the means for separating service logic from user interface description, and show how this simple abstraction addresses seven issues in service creation, analysis, and maintenance: compile-time guarantees, implementation flexibility, rapid prototyping, testing and validation, support for multiple devices, composition of services, and usage analysis.",1939-3520,,10.1109/32.798323,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798323,,Domain specific languages;DSL;Web services;Telephony;User interfaces;HTML;Software engineering;Logic testing;Computer languages;Computer Society,,38,49,23,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
An experiment measuring the effects of personal software process (PSP) training,L. Prechelt; B. Unger,"AbaXX Technology AG, Stuttgart, Germany; AbaXX Technology AG, Stuttgart, Germany",IEEE Transactions on Software Engineering,7 Aug 2002,2001,27,5,465,472,"The personal software process is a process improvement methodology aimed at individual software engineers. It claims to improve software quality (in particular defect content), effort estimation capability, and process adaptation and improvement capabilities. We have tested some of these claims in an experiment comparing the performance of participants who had just previously received a PSP course to a different group of participants who had received other technical training instead. Each participant of both groups performed the same task. We found the following positive effects: the PSP group estimated their productivity (though not their effort) more accurately, made fewer trivial mistakes, and their programs performed more careful error-checking; further, the performance variability was smaller in the PSP group in various respects. However, the improvements are smaller than the PSP proponents usually assume, possibly due to the low actual usage of PSP techniques in the PSP group. We conjecture that PSP training alone does not automatically realize the PSP's potential benefits (as seen in some industrial PSP success stories) when programmers are left alone with motivating themselves to actually use the PSP techniques.",1939-3520,,10.1109/32.922716,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=922716,,Software measurement;Software quality;Productivity;Testing;Industrial training;Coordinate measuring machines;Data analysis;Management training;Programming profession;Quality management,,34,,12,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Experience with the accuracy of software maintenance task effort prediction models,M. Jorgensen,"Oslo Univ., Norway",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,8,674,681,"The paper reports experience from the development and use of eleven different software maintenance effort prediction models. The models were developed applying regression analysis, neural networks and pattern recognition and the prediction accuracy was measured and compared for each model type. The most accurate predictions were achieved applying models based on multiple regression and on pattern recognition. We suggest the use of prediction models as instruments to support the expert estimates and to analyse the impact of the maintenance variables on the maintenance process and product. We believe that the pattern recognition based models evaluated, i.e., the prediction models based on the Optimized Set Reduction method, show potential for such use.<>",1939-3520,,10.1109/32.403791,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=403791,,Software maintenance;Predictive models;Programming;Pattern recognition;Application software;Neural networks;Regression analysis;Instruments;Optimization methods;Software measurement,,188,,23,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Predicting maintenance performance using object-oriented design complexity metrics,R. K. Bandi; V. K. Vaishnavi; D. E. Turk,"Quantitative Methods and Information Systems Department, Indian Institute of Management, Bangalore, India; Department of Computer Information Systems, Georgia State University, Atlanta, GA, USA; Computer Information Systems Department, Colorado State University, Fort Collins, CO, USA",IEEE Transactions on Software Engineering,22 Jan 2003,2003,29,1,77,87,"The Object-Oriented (OO) paradigm has become increasingly popular in recent years. Researchers agree that, although maintenance may turn out to be easier for OO systems, it is unlikely that the maintenance burden will completely disappear. One approach to controlling software maintenance costs is the utilization of software metrics during the development phase, to help identify potential problem areas. Many new metrics have been proposed for OO systems, but only a few of them have been validated. The purpose of this research is to empirically explore the validation of three existing OO design complexity metrics and, specifically, to assess their ability to predict maintenance time. This research reports the results of validating three metrics, Interaction Level (IL), Interface Size (IS), and Operation Argument Complexity (OAC). A controlled experiment was conducted to investigate the effect of design complexity (as measured by the above metrics) on maintenance time. Each of the three metrics by itself was found to be useful in the experiment in predicting maintenance performance.",1939-3520,,10.1109/TSE.2003.1166590,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1166590,,Software maintenance;Costs;Software metrics;Time measurement;Object oriented programming;Data encapsulation;Software systems;Object oriented modeling;Message passing,,99,,50,IEEE,22 Jan 2003,,,IEEE,IEEE Journals,True
Hierarchical GUI test case generation using automated planning,A. M. Memon; M. E. Pollack; M. L. Soffa,"Department of Computer Science, University of Pittsburgh, Pittsburgh, PA, USA; Intelligent Systems Program; Department of Computer Science, University of Pittsburgh, Pittsburgh, PA",IEEE Transactions on Software Engineering,7 Aug 2002,2001,27,2,144,155,"The widespread use of GUIs for interacting with software is leading to the construction of more and more complex GUIs. With the growing complexity come challenges in testing the correctness of a GUI and its underlying software. We present a new technique to automatically generate test cases for GUIs that exploits planning, a well-developed and used technique in artificial intelligence. Given a set of operators, an initial state, and a goal state, a planner produces a sequence of the operators that will transform the initial state to the goal state. Our test case generation technique enables efficient application of planning by first creating a hierarchical model of a GUI based on its structure. The GUI model consists of hierarchical planning operators representing the possible events in the GUI. The test designer defines the preconditions and effects of the hierarchical operators, which are input into a plan-generation system. The test designer also creates scenarios that represent typical initial and goal states for a GUI user. The planner then generates plans representing sequences of GUI interactions that a user might employ to reach the goal state from the initial state. We implemented our test case generation system, called Planning Assisted Tester for Graphical User Interface Systems (PATHS) and experimentally evaluated its practicality and effectiveness. We describe a prototype implementation of PATHS and report on the results of controlled experiments to generate test cases for Microsoft's WordPad.",1939-3520,,10.1109/32.908959,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=908959,,Graphical user interfaces;Automatic testing;Computer aided software engineering;Software testing;System testing;Artificial intelligence;Prototypes;Software measurement;Path planning;Automatic generation control,,173,18,30,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Two controlled experiments assessing the usefulness of design pattern documentation in program maintenance,L. Prechelt; B. Unger-Lamprecht; M. Philippsen; W. F. Tichy,"AbaXX Technology AG, Stuttgart, Germany; SD and M, Germany; Fakultät für Informatik, Universität Karlsruhe, Karlsruhe, Germany; Fakultät für Informatik, Universität Karlsruhe, Karlsruhe, Germany",IEEE Transactions on Software Engineering,7 Aug 2002,2002,28,6,595,606,Using design patterns is claimed to improve programmer productivity and software quality. Such improvements may manifest both at construction time (in faster and better program design) and at maintenance time (in faster and more accurate program comprehension). The paper focuses on the maintenance context and reports on experimental tests of the following question: does it help the maintainer if the design patterns in the program code are documented explicitly (using source code comments) compared to a well-commented program without explicit reference to design patterns? Subjects performed maintenance tasks on two programs ranging from 360 to 560 LOC including comments. The experiments tested whether pattern comment lines (PCL) help during maintenance if patterns are relevant and sufficient program comments are already present. This question is a challenge for the experimental methodology: A setup leading to relevant results is quite difficult to find. We discuss these issues in detail and suggest a general approach to such situations. A conservative analysis of the results supports the hypothesis that pattern-relevant maintenance tasks were completed faster or with fewer errors if redundant design pattern information was provided. The article provides the first controlled experiment results on design pattern usage and it presents a solution approach to an important class of experiment design problems for experiments regarding documentation.,1939-3520,,10.1109/TSE.2002.1010061,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1010061,,Documentation;Computer Society;Programming profession;Testing;Productivity;Software design;Software tools;Software quality;Lab-on-a-chip;Java,,104,,31,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Partition testing vs. random testing: the influence of uncertainty,W. J. Gutjahr,"Department of Statistics, Operations Research and Computer Science, University of Technology, Vienna, Vienna, Austria",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,5,661,674,"This paper compares partition testing and random testing on the assumption that program failure rates are not known with certainty before testing and are, therefore, modeled by random variables. It is shown that under uncertainty, partition testing compares more favorably to random testing than suggested by prior investigations concerning the deterministic case: the restriction to failure rates that are known with certainty systematically favors random testing. In particular, we generalize a result by Weyuker and Jeng (1991) stating equal fault detection probabilities for partition testing and random testing in the case where the failure rates in the subdomains defined by the partition are equal. It turns out that for independent random failure rates with equal expectation, the case above is a boundary case (the worst case for partition testing), and the fault detection probability of partition testing can be up to k times higher than that of random testing, where k is the number of subdomains. Also in a related model for dependent failure rates, partition testing turns out to be consistently better than random testing. The dominance can also be verified for the expected (weighted) number of detected faults as an alternative comparison criterion.",1939-3520,,10.1109/32.815325,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=815325,,Uncertainty;Fault detection;Software testing;Acoustic testing;System testing;Random variables;Genetic mutations;Partitioning algorithms;Pain,,90,,27,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Domain-specific languages: from design to implementation application to video device drivers generation,S. A. Thibault; R. Marlet; C. Consel,"IRISA/INRIA-Université de Rennes 1, Rennes, France; IRISA/INRIA-Université de Rennes 1, Rennes, France; IRISA/INRIA-Université de Rennes 1, Rennes, France",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,3,363,377,"Domain-specific languages (DSL) have many potential advantages in terms of software engineering, ranging from increased productivity to the application of formal methods. Although they have been used in practice for decades, there has been little study of methodology or implementation tools for the DSL approach. We present our DSL approach and its application to a realistic domain: the generation of video display device drivers. The article focuses on the validation of our proposed framework for domain-specific languages, from design to implementation. The framework leads to a flexible design and structure, and provides automatic generation of efficient implementations of DSL programs. Additionally, we describe an example of a complete DSL for video display adaptors and the benefits of the DSL approach for this application. This demonstrates some of the generally claimed benefits of using DSLs: increased productivity, higher-level abstraction, and easier verification. This DSL has been fully implemented with our approach and is available. Compose project URL: http://www.irisa.fr/compose/gal.",1939-3520,,10.1109/32.798325,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798325,,Domain specific languages;DSL;Application software;Productivity;Software engineering;Displays;Graphics;Uniform resource locators;Telephony;Switching systems,,44,1,,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A Bayesian analysis of the logarithmic-Poisson execution time model based on expert opinion and failure data,S. Campodonico; N. D. Singpurwalla,"Res. and Test Dept., Assoc. of American Railroads, Washington, DC, USA; Departments of Operations Research and of Statistics, George Washington University, DC, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,9,677,683,"We propose a Bayesian approach for predicting the number of failures in a piece of software, using the logarithmic-Poisson model, a nonhomogeneous Poisson process (NHPP) commonly used for describing software failures. A similar approach can be applied to other forms of the NHPP. The key feature of the approach is that now we are able to use, in a formal manner, expert knowledge on software testing, as for example, published information on the empirical experiences of other researchers. This is accomplished by treating such information as expert opinion in the construction of a likelihood function which leads us to a joint distribution. The procedure is computationally intensive, but for the case of the logarithmic-Poisson model has been codified for use on a personal computer. We illustrate the working of the approach via some real live data on software testing. The aim is not to propose another model for software reliability assessment. Rather, we present a methodology that can be invoked with existing software reliability models.<>",1939-3520,,10.1109/32.317426,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=317426,,Bayesian methods;Failure analysis;Software reliability;Predictive models;Software testing;Statistics;Microcomputers;Stochastic processes;Relays,,28,,18,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Estimation and prediction metrics for adaptive maintenance effort of object-oriented systems,F. Fioravanti; P. Nesi,"Department of Systems and Informatics, University of Florence, Florence, Italy; Department of Systems and Informatics, University of Florence, Florence, Italy",IEEE Transactions on Software Engineering,7 Aug 2002,2001,27,12,1062,1084,"Many software systems built in recent years have been developed using object-oriented technology and, in some cases, they already need adaptive maintenance in order to satisfy market and customer needs. In most cases, the estimation and prediction of maintenance effort is performed with difficulty due to the lack of metrics and suitable models. In this paper, a model and metrics for estimation/prediction of adaptive maintenance effort are presented and compared with some other solutions taken from the literature. The model proposed can be used as a general approach for adopting well-known metrics (typically used for the estimation of development effort) for the estimation/prediction of adaptive maintenance effort. The model and metrics proposed have been validated against real data by using multilinear regression analysis. The validation has shown that several well-known metrics can be profitably employed for the estimation/prediction of maintenance effort.",1939-3520,,10.1109/32.988708,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=988708,,Costs;Object oriented modeling;Predictive models;Control systems;Software performance;Performance evaluation;Software systems;Regression analysis;Software maintenance;Tree data structures,,84,3,44,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
A highly available local leader election service,C. Fetzer; F. Cristian,"AT and T Research Laboratories, Florham Park, NJ, USA; Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,5,603,618,"We define the highly available local leader election problem (G. LeLann, 1977), a generalization of the leader election problem for partitionable systems. We propose a protocol that solves the problem efficiently and give some performance measurements of our implementation. The local leader election service has been proven useful in the design and implementation of several fail-aware services for partitionable systems.",1939-3520,,10.1109/32.815321,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=815321,,Nominations and elections;Protocols;Broadcasting;Measurement;Bridges;Local area networks;Availability;Clocks;Synchronization,,35,2,24,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Identification of dynamic comprehension processes during large scale maintenance,A. Von Mayrhauser; A. M. Vans,"The Department of Computer Science, Colorado State University, Fort Collins, CO, USA; The Department of Computer Science, Colorado State University, Fort Collins, CO, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1996,22,6,424,437,We present results of observing professional maintenance engineers working with industrial code at actual maintenance tasks. Protocol analysis is used to explore how code understanding might differ for small versus large scale code. The experiment confirms that cognition processes work at all levels of abstraction simultaneously as programmers build a mental model of the code. Analysis focused on dynamic properties and processes of code understanding. Cognition processes emerged at three levels of aggregation representing lower and higher level strategies of understanding. They show differences in what triggers them and how they achieve their goals. Results are useful for defining information which maintenance engineers need for their work and for documentation and development standards.,1939-3520,,10.1109/32.508315,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=508315,,Large-scale systems;Cognition;Protocols;Software maintenance;Programming profession;Switches;Maintenance engineering;Cognitive science;Documentation;Standards development,,81,5,34,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Formal development and verification of a distributed railway control system,A. E. Haxthausen; J. Peleska,"Deptartment of Information Technology, Technical University of Denmark, Kongens Lyngby, Denmark; FB-3 Informatik, Universität Bremen, Bremen, Germany",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,8,687,701,"The authors introduce the concept for a distributed railway control system and present the specification and verification of the main algorithm used for safe distributed control. Our design and verification approach is based on the RAISE method, starting with highly abstract algebraic specifications which are transformed into directly implementable distributed control processes by applying a series of refinement and verification steps. Concrete safety requirements are derived from an abstract version that can be easily validated with respect to soundness and completeness. Complexity is further reduced by separating the system model into a domain model and a controller model. The domain model describes the physical system in absence of control and the controller model introduces the safety-related control mechanisms as a separate entity monitoring observables of the physical system to decide whether it is safe for a train to move or for a point to be switched.",1939-3520,,10.1109/32.879808,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=879808,,Rail transportation;Distributed control;Control systems;Communication system control;Switches;Railway safety;Centralized control;Formal specifications;Mobile communication;Concrete,,82,,12,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Incremental design of a power transformer station controller using a controller synthesis methodology,H. Marchand; M. Samaan,"IRISA/INRIA, Rennes, France; EDF, Uniteé National Technique Système, Saint-Denis, France",IEEE Transactions on Software Engineering,6 Aug 2002,2000,26,8,729,741,"The authors describe the incremental specification of a power transformer station controller using a controller synthesis methodology. They specify the main requirements as simple properties, named control objectives, that the controlled plant has to satisfy. Then, using algebraic techniques, the controller is automatically derived from this set of control objectives. In our case, the plant is specified at a high level, using the data-flow synchronous SIGNAL language, and then by its logical abstraction, called polynomial dynamical system. The control objectives are specified as invariance, reachability, ...properties, as well as partial order relations to be checked by the plant. The control objectives equations are synthesized using algebraic transformations.",1939-3520,,10.1109/32.879811,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=879811,,Power transformers;Automatic control;Signal synthesis;Polynomials;Optimal control;Equations;Control system synthesis;Data structures;Boolean functions;Circuit faults,,30,,20,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Time domain analysis of non-Markovian stochastic Petri nets with PRI transitions,A. Horvath; M. Telek,"Department of Telecommunications, Budapest University슠of슠Technology슠and슠Economics, Hungary; Department of Telecommunications, Budapest University슠of슠Technology슠and슠Economics, Hungary",IEEE Transactions on Software Engineering,10 Dec 2002,2002,28,10,933,943,"The time domain analysis of non-Markovian stochastic Petri nets with pre-emptive repeat identical (PRI) type transitions is considered in this paper. The set of ""time domain"" equations describing the evolution of the marking process is provided. The relation of the time domain and formerly available transform domain description is discussed. Based on the time domain description of the process, a simple numerical procedure is provided to analyze the transient behavior. Two examples are calculated to illustrate the proposed numerical method.",1939-3520,,10.1109/TSE.2002.1041050,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1041050,,Time domain analysis;Stochastic processes;Petri nets;Transient analysis;Terminology;Steady-state;Laplace equations;Transforms;Queueing analysis,,3,,18,IEEE,10 Dec 2002,,,IEEE,IEEE Journals,True
Model-checking algorithms for continuous-time Markov chains,C. Baier; B. Haverkort; H. Hermanns; J. . -P. Katoen,"Institut für Informatik I, University of Bonn, Bonn, Germany; Department of Computer Science, University of Twente, Enschede, Netherlands; Department of Computer Science, University of Twente, Enschede, Netherlands; Department of Computer Science, University of Twente, Enschede, Netherlands",IEEE Transactions on Software Engineering,20 Jun 2003,2003,29,6,524,541,"Continuous-time Markov chains (CTMCs) have been widely used to determine system performance and dependability characteristics. Their analysis most often concerns the computation of steady-state and transient-state probabilities. This paper introduces a branching temporal logic for expressing real-time probabilistic properties on CTMCs and presents approximate model checking algorithms for this logic. The logic, an extension of the continuous stochastic logic CSL of Aziz et al. (1995, 2000), contains a time-bounded until operator to express probabilistic timing properties over paths as well as an operator to express steady-state probabilities. We show that the model checking problem for this logic reduces to a system of linear equations (for unbounded until and the steady-state operator) and a Volterra integral equation system (for time-bounded until). We then show that the problem of model-checking time-bounded until properties can be reduced to the problem of computing transient state probabilities for CTMCs. This allows the verification of probabilistic timing properties by efficient techniques for transient analysis for CTMCs such as uniformization. Finally, we show that a variant of lumping equivalence (bisimulation), a well-known notion for aggregating CTMCs, preserves the validity of all formulas in the logic.",1939-3520,,10.1109/TSE.2003.1205180,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1205180,,Steady-state;Stochastic processes;Probabilistic logic;Transient analysis;System performance;Timing;Integral equations;Performance analysis;Throughput;Production systems,,526,,72,IEEE,20 Jun 2003,,,IEEE,IEEE Journals,True
KLAIM: a kernel language for agents interaction and mobility,R. De Nicola; G. L. Ferrari; R. Pugliese,"Dipartimento di Sistemie Informatica, Università di Fienze, Florence, Italy; Dipartimento di Informatica, Università di Pisa, Pisa, Italy; Dipartimento di Sistemie Informatica, Università di Fienze, Florence, Italy",IEEE Transactions on Software Engineering,6 Aug 2002,1998,24,5,315,330,"We investigate the issue of designing a kernel programming language for mobile computing and describe KLAIM, a language that supports a programming paradigm where processes, like data, can be moved from one computing environment to another. The language consists of a core Linda with multiple tuple spaces and of a set of operators for building processes. KLAIM naturally supports programming with explicit localities. Localities are first-class data (they can be manipulated like any other data), but the language provides coordination mechanisms to control the interaction protocols among located processes. The formal operational semantics is useful for discussing the design of the language and provides guidelines for implementations. KLAIM is equipped with a type system that statically checks access right violations of mobile agents. Types are used to describe the intentions (read, write, execute, etc.) of processes in relation to the various localities. The type system is used to determine the operations that processes want to perform at each locality, and to check whether they comply with the declared intentions and whether they have the necessary rights to perform the intended operations at the specific localities. Via a series of examples, we show that many mobile code programming paradigms can be naturally implemented in our kernel language. We also present a prototype implementation of KLAIM in Java.",1939-3520,,10.1109/32.685256,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=685256,,Kernel;Computer languages;Mobile computing;Buildings;Access protocols;Guidelines;Permission;Mobile agents;Prototypes;Java,,370,1,41,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Specifying timing constraints and composite events: an application in the design of electronic brokerages,A. K. Mok; P. Konana; Guangtian Liu; Chan-Gun Lee; Honguk Woo,"Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA; Department of Management Science and Information Systems, Graduate School of Business, University of Texas, Austin, Austin, TX, USA; SBC Technology Resources, 슠Inc., Austin, TX, USA; Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA; Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA",IEEE Transactions on Software Engineering,10 Jan 2005,2004,30,12,841,858,"Increasingly, business applications need to capture consumers' complex preferences interactively and monitor those preferences by translating them into event-condition-action (ECA) rules and syntactically correct processing specification. An expressive event model to specify primitive and composite events that may involve timing constraints among events is critical to such applications. Relying on the work done in active databases and real-time systems, this research proposes a new composite event model based on real-time logic (RTL). The proposed event model does not require fixed event consumption policies and allows the users to represent the exact correlation of event instances in defining composite events. It also supports a wide-range of domain-specific temporal events and constraints, such as future events, time-constrained events, and relative events. This event model is validated within an electronic brokerage architecture that unbundles the required functionalities into three separable components - business rule manager, ECA rule manager, and event monitor - with well-defined interfaces. A proof-of-concept prototype was implemented in the Java programming language to demonstrate the expressiveness of the event model and the feasibility of the architecture. The performance of the composite event monitor was evaluated by varying the number of rules, event arrival rates, and type of composite events.",1939-3520,,10.1109/TSE.2004.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1377184,Index Terms- Active databases;real-time databases;electronic brokerages;event specification;timing constraints.,Timing;Event detection;Databases;Monitoring;Real time systems;Logic design;Prototypes;Java;Computer languages;Process control,,12,,43,IEEE,10 Jan 2005,,,IEEE,IEEE Journals,True
A test generation strategy for pairwise testing,Kuo-Chung Tai; Yu Lei,"Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",IEEE Transactions on Software Engineering,7 Aug 2002,2002,28,1,109,111,"Pairwise testing is a specification-based testing criterion which requires that for each pair of input parameters of a system, every combination of valid values of these two parameters be covered by at least one test case. The authors propose a novel test generation strategy for pairwise testing.",1939-3520,,10.1109/32.979992,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=979992,,Testing,,214,2,5,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Realism in assessment of effort estimation uncertainty: it matters how you ask,M. Jorgensen,"Simula Research Laboratory, Lysaker, Norway",IEEE Transactions on Software Engineering,22 Mar 2004,2004,30,4,209,217,"Traditionally, software professionals are requested to provide minimum-maximum intervals to indicate the uncertainty of their effort estimates. We claim that the traditional request is not optimal and leads to overoptimistic views about the level of estimation uncertainty. Instead, we propose that it is better to frame the request for uncertainty assessment: ""How likely is it that the actual effort will be more than/less than X?"" Our claim is based on the results of a previously reported-experiment and field studies in two companies. The two software companies were instructed to apply the traditional and our alternative framing on random samples of their projects. In total, we collected information about 47 projects applying the traditional-framing and 23 projects applying the alternative framing.",1939-3520,,10.1109/TSE.2004.1274041,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1274041,,Uncertainty;Amplitude shift keying;Project management;Risk management;Psychology;Contingency management;Costs;Humans,,51,,16,IEEE,22 Mar 2004,,,IEEE,IEEE Journals,True
Teapot: a domain-specific language for writing cache coherence protocols,S. Chandra; B. Richards; J. R. Larus,"Bell Laboratories, Lucent Technologies, Inc., Naperville, IL, USA; Department of Computer Science, Vassar College, Poughkeepsie, NY, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,3,317,333,"In this paper, we describe Teapot, a domain-specific language for writing cache coherence protocols. Cache coherence is of concern when parallel and distributed systems make local replicas of shared data to improve scalability and performance. In both distributed shared memory systems and distributed file systems, a coherence protocol maintains agreement among the replicated copies as the underlying data are modified by programs running on the system. Cache coherence protocols are notoriously difficult to implement, debug, and maintain. Moreover, protocols are not off-the-shelf, reusable components, because their details depend on the requirements of the system under consideration. The complexity of engineering coherence protocols can discourage users from experimenting with new, potentially more efficient protocols. We have designed and implemented Teapot, a domain-specific language that attempts to address this complexity. Teapot's language constructs, such as a state-centric control structure and continuations, are better suited to expressing protocol code than those of a typical systems programming language. Teapot also facilitates automatic verification of protocols, so hard to find protocol bugs, such as deadlocks, can be detected and fixed before encountering them on an actual execution. We describe the design rationale of Teapot, present an empirical evaluation of the language using two case studies, and relate the lessons that we learned in building a domain-specific language for systems programming.",1939-3520,,10.1109/32.798322,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=798322,,Domain specific languages;Writing;Protocols;Scalability;File systems;Maintenance engineering;Automatic control;Control systems;Computer languages;Computer bugs,,22,4,29,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
On the expected number of failures detected by subdomain testing and random testing,T. Y. Chen; Y. T. Yu,"Department of Computer Science, University of Melbourne, Parkville, Australia; Department of Computer Science, University of Melbourne, Parkville, Australia",IEEE Transactions on Software Engineering,6 Aug 2002,1996,22,2,109,119,"We investigate the efficacy of subdomain testing and random testing using the expected number of failures detected (the E-measure) as a measure of effectiveness. Simple as it is, the E-measure does provide a great deal of useful information about the fault detecting capability of testing strategies. With the E-measure, we obtain new characterizations of subdomain testing, including several new conditions that determine whether subdomain testing is more or less effective than random testing. Previously, the efficacy of subdomain testing strategies has been analyzed using the probability of detecting at least one failure (the P-measure) for the special case of disjoint subdomains only. On the contrary, our analysis makes use of the E-measure and considers also the general case in which subdomains may or may not overlap. Furthermore, we discover important relations between the two different measures. From these relations, we also derive corresponding characterizations of subdomain testing in terms of the P-measure.",1939-3520,,10.1109/32.485221,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=485221,,Software testing;System testing;Failure analysis;Computer science;Electronic mail;Fault detection,,97,,18,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Use of sequencing constraints for specification-based testing of concurrent programs,R. H. Carver; Kuo-Chung Tai,"Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1998,24,6,471,490,"This paper presents and evaluates a specification-based methodology for testing concurrent programs. This methodology requires sequencing constraints, which specify restrictions on the allowed sequences of synchronization events. Sequencing constraints for a concurrent program can be derived from the program's formal or informal specification. Details of the proposed testing methodology based on the use of Constraints on Succeeding and Preceding Events (CSPE) are given. How to achieve coverage and detect violations of CSPE constraints for a concurrent program, according to deterministic and nondeterministic testing of this program, are described. A coverage criterion for CSPE-based testing is defined and analyzed. The results of empirical studies of CSPE-based testing for four concurrent problems are reported. These results indicate that the use of sequencing constraints for specification-based testing of concurrent programs is a promising approach.",1939-3520,,10.1109/32.689403,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=689403,,Software testing;Automata;Explosions;Computer science;Sequential analysis;Fault detection;Protocols;Event detection,,60,2,42,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A decomposition of a formal specification: an improved constraint-oriented method,Kentaro Go; N. Shiratori,"Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Research Institute of Electrical Communication Graduate School of Information Sciences, University of Tohoku, Sendai, Japan",IEEE Transactions on Software Engineering,6 Aug 2002,1999,25,2,258,273,"In this paper, the authors propose a decomposition method for a formal specification that divides the specification into two subspecifications composed by a parallel operator. To make these specification behaviors equivalent before and after decomposition, the method automatically synthesizes an additional control specification, which contains the synchronization information of the decomposed subspecifications. The authors prove that a parallel composition of the decomposed subspecifications synchronized with the control specification is strongly equivalent with the original (monolithic) specification. The authors also write formal specifications of the OSI application layer's association-control service and decompose it using their method as an example of decomposition of a practical specification. Their decomposition method can be applied to top-down system development based on stepwise refinement.",1939-3520,,10.1109/32.761449,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=761449,,Formal specifications;Automatic control;Open systems;Protocols;Computer Society;System analysis and design;Costs;Collaborative software;Collaborative work;Productivity,,4,,17,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
The location-based paradigm for replication: Achieving efficiency and availability in distributed systems,P. Triantafillou; D. J. Taylor,"School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; Department of Computer Science, University of Waterloo, Waterloo, ONT, Canada",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,1,1,18,"Replication techniques for transaction-based distributed systems generally achieve increased availability but with a significant performance penalty. We present a new replication paradigm, the location-based paradigm, which addresses availability and other performance issues. It provides availability similar to quorum-based replication protocols but with transaction-execution delays similar to one-copy systems. The paradigm further exploits replication to improve performance in two instances. First, it takes advantage of local or nearby replicas to further improve the response time of transactions, achieving smaller execution delays than one-copy systems. Second, it takes advantage of replication to facilitate the independent crash recovery of replica sites-a goal which is unattainable in one-copy systems. In addition to the above the location-based paradigm avoids bottlenecks, facilitates load balancing, and minimizes the disruption of service when failures and recoveries occur. In this paper we present the paradigm, a formal proof of correctness, and a detailed simulation study comparing our paradigm to one-copy systems and to other approaches to replication control.<>",1939-3520,,10.1109/32.341843,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=341843,,Availability;Protocols;Computer crashes;Costs;Concurrency control;Distributed computing;Collaboration;Delay systems;Delay effects;Load management,,18,1,29,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Timing constraint Petri nets and their application to schedulability analysis of real-time system specifications,J. J. P. Tsai; S. Jennhwa Yang; Yao-Hsiung Chang,"Department of Electrical Engineering and Computer Science, University of Illinois, Chicago, Chicago, IL, USA; Department of Electrical Engineering and Computer Science, University of Illinois, Chicago, Chicago, IL, USA; LEADWELL CNC Machines Manufacturing Corporation, Taiwan",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,1,32,49,"We present timing constraint Petri nets (or TCPN's for short) and describe how to use them to model a real-time system specification and determine whether the specification is schedulable with respect to imposed timing constraints. The strength of TCPN's over other time-related Petri nets is in the modeling and analysis of conflict structures. Schedulability analysis is conducted in three steps: specification modeling, reachability simulation, and timing analysis. First, we model a real-time system by transforming its system specification along with its imposed timing constraints into a TCPN; we call this net N/sub s/. Then we simulate the reachability of N/sub s/ to verify whether a marking, M/sub n/, is reachable from an initial marking, M/sub o/. It is important to note that a reachable marking in Petri nets is not necessarily reachable in TCPN's due to the imposed timing constraints, Therefore, in the timing analysis step, a reachable marking M/sub n/, found in the reachability simulation step is analyzed to verify whether M/sub n/, is reachable with the timing constraints. M/sub n/ is said to be reachable in the TCPN's if and only if we can find at least one firing sequence /spl sigma/ so that all transitions in /spl sigma/ are strongly schedulable with respect to M/sub o/ under the timing constraints. If such M/sub n/ can be found, then we can assert that the specification is schedulable under the imposed timing constraints, otherwise the system specification needs to be modified or the timing constraints need to be relaxed. We also present a synthesis method for determining the best approximation of the earliest fire beginning time (EFBT) and the latest fire ending time (LFET) of each strongly schedulable transition.<>",1939-3520,,10.1109/32.341845,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=341845,,Timing;Petri nets;Real time systems;Job shop scheduling;Monitoring;Analytical models;Fires;Runtime;Logic;Time factors,,83,,28,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Simplifying and isolating failure-inducing input,A. Zeller; R. Hildebrandt,"Lehrstuhl für Softwaretechnik, Universtät des Saarlandes, Saarbruecken, Germany; DeTeLine-Deutsche Telekom Kommunikationsnetze GmbH, Berlin, Germany",IEEE Transactions on Software Engineering,7 Aug 2002,2002,28,2,183,200,"Given some test case, a program fails. Which circumstances of the test case are responsible for the particular failure? The delta debugging algorithm generalizes and simplifies the failing test case to a minimal test case that still produces the failure. It also isolates the difference between a passing and a failing test case. In a case study, the Mozilla Web browser crashed after 95 user actions. Our prototype implementation automatically simplified the input to three relevant user actions. Likewise, it simplified 896 lines of HTML to the single line that caused the failure. The case study required 139 automated test runs or 35 minutes on a 500 MHz PC.",1939-3520,,10.1109/32.988498,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=988498,,Vehicle crash testing;Debugging;Automatic testing;HTML;Computer crashes;Computer Society;Prototypes;Databases;Computer bugs;Turning,,670,9,14,IEEE,7 Aug 2002,,,IEEE,IEEE Journals,True
Maisie: a language for the design of efficient discrete-event simulations,R. L. Bagrodia; Wen-Toh Liao,"Department of Computer Science, University of California, Los Angeles, CA, USA; Department of Computer Science, University of California, Los Angeles, CA, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,4,225,238,"Maisie is a C-based discrete-event simulation language that was designed to cleanly separate a simulation model from the underlying algorithm (sequential or parallel) used for the execution of the model. With few modifications, a Maisie program may be executed by using a sequential simulation algorithm, a parallel conservative algorithm or a parallel optimistic algorithm. The language constructs allow the run-time system to implement optimizations that reduce recomputation and state saving overheads for optimistic simulations and synchronization overheads for conservative implementations. This paper presents the Maisie simulation language, describes a set of optimizations, and illustrates the use of the language in the design of efficient parallel simulations.<>",1939-3520,,10.1109/32.277572,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=277572,,Computational modeling;Discrete event simulation;Computer simulation;Algorithm design and analysis;Parallel architectures;Protocols;Design optimization;Concurrent computing;Distributed computing;Computer science,,112,1,35,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A characterization of independence for competing Markov chains with applications to stochastic Petri nets,R. J. Boucherie,"Department of Econometrics, Universiteit van Amsterdam, Amsterdam, Netherlands",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,7,536,544,This paper shows that some of the recently obtained product form results for stochastic Petri nets can be obtained as a special case of a simple exclusion mechanism for the product process of a collection of Markov chains.<>,1939-3520,,10.1109/32.297942,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=297942,,Stochastic processes;Petri nets;Resource management;Routing;Fires;Fellows;Traffic control;Equations;Sufficient conditions,,43,,23,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Automatic detection and exploitation of branch constraints for timing analysis,C. A. Healy; D. B. Whalley,"Computer Science Department, Furman University, Greenville, SC, USA; Computer Science Department, Florida State University, Tallahassee, FL, USA",IEEE Transactions on Software Engineering,7 Nov 2002,2002,28,8,763,781,"Predicting the worst-case execution time (WCET) and best-case execution time (BCET) of a real-time program is a challenging task. Though much progress has been made in obtaining tighter timing predictions by using techniques that model the architectural features of a machine, significant overestimations of WCET and underestimations of GCET can still occur. Even with perfect architectural modeling, dependencies on data values can constrain the outcome of conditional branches and the corresponding set of paths that can be taken in a program. While branch constraint information has been used in the past by some timing analyzers, it has typically been specified manually, which is both tedious and error prone. This paper describes efficient techniques for automatically detecting branch constraints by a compiler and automatically exploiting these constraints within a timing analyzer. The result is significantly tighter timing analysis predictions without requiring additional interaction with a user.",1939-3520,,10.1109/TSE.2002.1027799,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1027799,,Timing;Automatic control;Performance analysis;Information analysis;Real time systems;Computer Society;Predictive models;Time measurement;Programming profession;Pipelines,,31,,25,IEEE,7 Nov 2002,,,IEEE,IEEE Journals,True
Derivation of data intensive algorithms by formal transformation: the Schnorr-Waite graph marking algorithm,M. Ward,"Computer Science Department,Science Laboratories, University of Durham, Durham, UK",IEEE Transactions on Software Engineering,6 Aug 2002,1996,22,9,665,686,"Considers a particular class of algorithms which present certain difficulties to formal verification. These are algorithms which use a single data structure for two or more purposes, which combine program control information with other data structures or which are developed as a combination of a basic idea with an implementation technique. Our approach is based on applying proven semantics-preserving transformation rules in a wide spectrum language. Starting with a set theoretical specification of ""reachability"", we are able to derive iterative and recursive graph marking algorithms using the ""pointer switching"" idea of Schorr and Waite (1967). There have been several proofs of correctness of the Schorr-Waite algorithm, and a small number of transformational developments of the algorithm. The great advantage of our approach is that we can derive the algorithm from its specification using only general-purpose transformational rules, without the need for complicated induction arguments. Our approach applies equally well to several more complex algorithms which make use of the pointer switching strategy, including a hybrid algorithm which uses a fixed length stack, switching to the pointer switching strategy when the stack runs out.",1939-3520,,10.1109/32.541437,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=541437,,Iterative algorithms;Data structures;Formal verification;Logic;Computer bugs;Computer science,,18,,49,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Compiling real-time programs with timing constraint refinement and structural code motion,R. Gerber; Seongsoo Hong,"Department of Computer Science, University of Maryland College Park, College Park, MD, USA; Department of Computer Science, University of Maryland College Park, College Park, MD, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1995,21,5,389,404,"We present a programming language called TCEL (Time-Constrained Event Language), whose semantics are based on time-constrained relationships between observable events. Such a semantics infers only those timing constraints necessary to achieve real-time correctness, without overconstraining the system. Moreover, an optimizing compiler can exploit this looser semantics to help tune the code, so that its worst-case execution time is consistent with its real-time requirements. In this paper we describe such a transformation system, which works in two phases. First, the TCEL source code is translated into an intermediate representation. Then an instruction-scheduling algorithm rearranges selected unobservable operations and synthesizes tasks guaranteed to respect the original event-based constraints.<>",1939-3520,,10.1109/32.387469,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=387469,,Timing;Computer languages;Equations;Optimizing compilers;Program processors;Delay;Scheduling algorithm;Motion analysis;Real time systems;Time factors,,16,1,28,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
Modular algebraic nets to specify concurrent systems,E. Battiston; F. De Cindio; G. Mauri,"Dipartimento di Scienze dell' Informmione, Universita Degli Studi di Milano, Milan, Italy; Dipartimento di Scienze dell' Informmione, Universita degli Studi di Milano, Milan, Italy; Dipartimento di Scienze dell' Informmione, Universita degli Studi di Milano, Milan, Italy",IEEE Transactions on Software Engineering,6 Aug 2002,1996,22,10,689,705,"The authors present the basic features of a specification language for concurrent distributed systems, developed at the Department of Information Sciences of the University of Milan, Italy. The language is based on a class of modular algebraic high-level nets, OBJSA nets, which result from the synthesis of superposed automata (SA) nets and of the algebraic specification language OBJ. It is supported by the OBJSA Net Environment (ONE). OBJSA nets stress the possibility of building the system model by composing its components and encourage the incremental development of the specification and its reusability. An OBJSA net consists of an SA net inscribed with terms of an OBJ module. The ONE environment supports the user in producing and executing a specification, hiding from her/him, as much as possible, the technical details of the algebraic part of the specification. The paper provides a complete presentation of OBJSA nets, including a user-oriented introduction, the definition of OBJSA nets (as subclass of SPEC-inscribed nets), of their occurrence rule (the semantics) and of the composition operation. In addition it presents the kernel of the support environment.",1939-3520,,10.1109/32.544348,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=544348,,Petri nets;Specification languages;Concurrent computing;Automata;Stress;Kernel;Carbon capture and storage;Algebra,,14,,63,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
On a unified framework for the evaluation of distributed quorum attainment protocols,D. A. Menasce; Y. Yesha; K. Kalpakis,"Department of Computer Science, George Mason University, Fairfax, VA, USA; Computer Science Department, University of Maryland Baltimore County, MD, USA; Computer Science Department, University of Maryland Baltimore County, MD, USA",IEEE Transactions on Software Engineering,6 Aug 2002,1994,20,11,868,884,"Quorum attainment protocols are an important part of many mutual exclusion algorithms. Assessing the performance of such protocols in terms of number of messages, as is usually done, may be less significant than being able to compute the delay in attaining the quorum. Some protocols achieve higher reliability at the expense of increased message cost or delay. A unified analytical model which takes into account the network delay and its effect on the time needed to obtain a quorum is presented. A combined performability metric, which takes into account both availability and delay, is defined, and expressions to calculate its value are derived for two different reliable quorum attainment protocols: D. Agrawal and A. El Abbadi's (1991) and Majority Consensus algorithms (R.H. Thomas, 1979). Expressions for the primary site approach are also given as upper bound on performability and lower bound on delay. A parallel version of the Agrawal and El Abbadi protocol is introduced and evaluated. This new algorithm is shown to exhibit lower delay at the expense of a negligible increase in the number of messages exchanged. Numerical results derived from the model are discussed.<>",1939-3520,,10.1109/32.368122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=368122,,Availability;Delay effects;Performance analysis;Access protocols;Computer science;Time measurement;Costs;Analytical models;Upper bound;Fault tolerant systems,,4,,20,IEEE,6 Aug 2002,,,IEEE,IEEE Journals,True
A Realistic Empirical Evaluation of the Costs and Benefits of UML in Software Maintenance,W. J. Dzidek; E. Arisholm; L. C. Briand,"Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway",IEEE Transactions on Software Engineering,3 Jun 2008,2008,34,3,407,432,"The Unified Modeling Language (UML) is the de facto standard for object-oriented software analysis and design modeling. However, few empirical studies exist that investigate the costs and evaluate the benefits of using UML in realistic contexts. Such studies are needed so that the software industry can make informed decisions regarding the extent to which they should adopt UML in their development practices. This is the first controlled experiment that investigates the costs of maintaining and the benefits of using UML documentation during the maintenance and evolution of a real, non-trivial system, using professional developers as subjects, working with a state-of-the-art UML tool during an extended period of time. The subjects in the control group had no UML documentation. In this experiment, the subjects in the UML group had on average a practically and statistically significant 54% increase in the functional correctness of changes (p=0.03), and an insignificant 7% overall improvement in design quality (p=0.22) - though a much larger improvement was observed on the first change task (56%) - at the expense of an insignificant 14% increase in development time caused by the overhead of updating the UML documentation (p=0.35).",1939-3520,,10.1109/TSE.2008.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4459340,Maintainability;Distribution;Maintenance;and Enhancement;Software Engineering;Software/Software Engi;Design notations and documentation;Object-Oriented Programming;Maintainability;Distribution;Maintenance;and Enhancement;Software Engineering;Software/Software Engi;Design notations and documentation;Object-Oriented Programming,Unified modeling language;Software maintenance;Documentation;Costs;Software standards;Software design;Object oriented modeling;Computer industry;Electrical equipment industry;Control systems,,101,,49,IEEE,3 Jun 2008,,,IEEE,IEEE Journals,True
Toward a Formalism for Conservative Claims about the Dependability of Software-Based Systems,P. Bishop; R. Bloomfield; B. Littlewood; A. Povyakalo; D. Wright,"Centre for Software Reliability, City University, London, UK; Centre for Software Reliability, City University, London, UK; Centre for Software Reliability, City University, London, UK; Centre for Software Reliability, City University, London, UK; Centre for Software Reliability, City University, London, UK",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,708,717,"In recent work, we have argued for a formal treatment of confidence about the claims made in dependability cases for software-based systems. The key idea underlying this work is ""the inevitability of uncertainty"": It is rarely possible to assert that a claim about safety or reliability is true with certainty. Much of this uncertainty is epistemic in nature, so it seems inevitable that expert judgment will continue to play an important role in dependability cases. Here, we consider a simple case where an expert makes a claim about the probability of failure on demand (pfd) of a subsystem of a wider system and is able to express his confidence about that claim probabilistically. An important, but difficult, problem then is how such subsystem (claim, confidence) pairs can be propagated through a dependability case for a wider system, of which the subsystems are components. An informal way forward is to justify, at high confidence, a strong claim, and then, conservatively, only claim something much weaker: ""I'm 99 percent confident that the pfd is less than 10-5, so it's reasonable to be 100 percent confident that it is less than 10-3."" These conservative pfds of subsystems can then be propagated simply through the dependability case of the wider system. In this paper, we provide formal support for such reasoning.",1939-3520,,10.1109/TSE.2010.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492693,Bayesian probability;safety case;software reliability.,Uncertainty;Software reliability;Phase frequency detector;Battery powered vehicles;Software systems;Software safety;Programming;Power engineering computing;Reliability engineering;Power engineering and energy,,33,,24,IEEE,28 Jun 2010,,,IEEE,IEEE Journals,True
Common Trends in Software Fault and Failure Data,M. Hamill; K. Goseva-Popstojanova,"Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,484,496,"The benefits of the analysis of software faults and failures have been widely recognized. However, detailed studies based on empirical data are rare. In this paper, we analyze the fault and failure data from two large, real-world case studies. Specifically, we explore: 1) the localization of faults that lead to individual software failures and 2) the distribution of different types of software faults. Our results show that individual failures are often caused by multiple faults spread throughout the system. This observation is important since it does not support several heuristics and assumptions used in the past. In addition, it clearly indicates that finding and fixing faults that lead to such software failures in large, complex systems are often difficult and challenging tasks despite the advances in software development. Our results also show that requirement faults, coding faults, and data problems are the three most common types of software faults. Furthermore, these results show that contrary to the popular belief, a significant percentage of failures are linked to late life cycle activities. Another important aspect of our work is that we conduct intra- and interproject comparisons, as well as comparisons with the findings from related studies. The consistency of several main trends across software systems in this paper and several related research efforts suggests that these trends are likely to be intrinsic characteristics of software faults and failures rather than project specific.",1939-3520,,10.1109/TSE.2009.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4760152,Software faults and failures;fault location;fault types;software fault distribution;software reliability;empirical studies.,Failure analysis;Software quality;Programming;Software systems;Fault location;Software reliability;Fault detection;Humans;Terminology;Computer bugs,,99,,26,IEEE,23 Jan 2009,,,IEEE,IEEE Journals,True
The Use of Multilegged Arguments to Increase Confidence in Safety Claims for Software-Based Systems: A Study Based on a BBN Analysis of an Idealized Example,B. Littlewood; D. Wright,"The Centre for Software Reliability, City University, London, UK; The Centre for Software Reliability, City University, London, UK",IEEE Transactions on Software Engineering,23 Apr 2007,2007,33,5,347,365,"The work described here concerns the use of so-called multilegged arguments to support dependability claims about software-based systems. The informal justification for the use of multilegged arguments is similar to that used to support the use of multiversion software in pursuit of high reliability or safety. Just as a diverse 1-out-of-2 system might be expected to be more reliable than each of its two component versions, so might a two-legged argument be expected to give greater confidence in the correctness of a dependability claim (for example, a safety claim) than would either of the argument legs alone. Our intention here is to treat these argument structures formally, in particular, by presenting a formal probabilistic treatment of ""confidence,? which will be used as a measure of efficacy. This will enable claims for the efficacy of the multilegged approach to be made quantitatively, answering questions such as, ""How much extra confidence about a system's safety will I have if I add a verification argument leg to an argument leg based upon statistical testing?? For this initial study, we concentrate on a simplified and idealized example of a safety system in which interest centers upon a claim about the probability of failure on demand. Our approach is to build a ""Bayesian Belief Network? (BBN) model of a two-legged argument and manipulate this analytically via parameters that define its node probability tables. The aim here is to obtain greater insight than what is afforded by the more usual BBN treatment, which involves merely numerical manipulation. We show that the addition of a diverse second argument leg can indeed increase confidence in a dependability claim; in a reasonably plausible example, the doubt in the claim is reduced to one-third of the doubt present in the original single leg. However, we also show that there can be some unexpected and counterintuitive subtleties here; for example, an entirely supportive second leg can sometimes undermine an original argument, resulting, overall, in less confidence than what came from this original argument. Our results are neutral on the issue of whether such difficulties will arise in real life?that is, when real experts judge real systems.",1939-3520,,10.1109/TSE.2007.1002,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4160972,Safety claims;safety arguments;software safety;software reliability;Bayesian belief networks.,Leg;Software safety;Uncertainty;Battery powered vehicles;Particle measurements;System testing;Probability;Software reliability;Bayesian methods;Control systems,,58,,26,IEEE,23 Apr 2007,,,IEEE,IEEE Journals,True
The impact of UML documentation on software maintenance: an experimental evaluation,E. Arisholm; L. C. Briand; S. E. Hove; Y. Labiche,"Department of Software Engineering, Simula Research Laboratory, Lysaker, Norway; Department of Software Engineering, Simula Research Laboratory, Lysaker, Norway; Department of Software Engineering, Simula Research Laboratory, Lysaker, Norway; Department of Systems and Computer Engineering Software Quality Engineering Laboratory, Carleton University, Ottawa, ONT, Canada",IEEE Transactions on Software Engineering,5 Jul 2006,2006,32,6,365,381,"The Unified Modeling Language (UML) is becoming the de facto standard for software analysis and design modeling. However, there is still significant resistance to model-driven development in many software organizations because it is perceived to be expensive and not necessarily cost-effective. Hence, it is important to investigate the benefits obtained from modeling. As a first step in this direction, this paper reports on controlled experiments, spanning two locations, that investigate the impact of UML documentation on software maintenance. Results show that, for complex tasks and past a certain learning curve, the availability of UML documentation may result in significant improvements in the functional correctness of changes as well as the quality of their design. However, there does not seem to be any saving of time. For simpler tasks, the time needed to update the UML documentation may be substantial compared with the potential benefits, thus motivating the need for UML tools with better support for software maintenance",1939-3520,,10.1109/TSE.2006.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1650213,Maintenance;UML;experiment.,Unified modeling language;Documentation;Software maintenance;Object oriented modeling;Programming;Software standards;Software design;Software systems;Costs;Design engineering,,100,,36,IEEE,5 Jul 2006,,,IEEE,IEEE Journals,True
A Study of Uncertainty in Software Cost and Its Impact on Optimal Software Release Time,B. Yang; H. Hu; L. Jia,"Department of Industrial Engineering, School of Mechatronics Engineering, University of Electronic Science and Technology, Chengdu, Sichuan, China; Department of Industrial Engineering, School of Mechatronics Engineering, University of Electronic Science and Technology, Chengdu, Sichuan, China; School of Electrical Engineering, Xi''an Jiaotong University, Xi'an, Shaanxi, China",IEEE Transactions on Software Engineering,12 Dec 2008,2008,34,6,813,825,"For a development software project, management often faces the dilemma of when to stop testing the software and release it for operation, which requires careful decision-making as it has great impact on both software reliability and project cost. In most existing research on optimal software release problem, the cost considered was the expected cost (EC) of the project. However, what management concerns is the actual cost (AC) of the project rather than the EC. Treatment (such as minimization) of the EC may not ensure a desired low level of the AC, due to the uncertainty (variability) involved in the AC. In this paper, we study the uncertainty in software cost and its impact on optimal software release time in detail. The uncertainty is quantified by the variance of the AC and several risk functions. A risk-control approach to optimal software release problem is proposed. New formulations of the problem which are extensions of current formulations are developed, and solution procedures are established. Several examples are presented. Results reveal that it seems crucial to take account of the uncertainty in software cost in optimal software release problem, otherwise unsafe decision may be reached which could be a false dawn to management.",1939-3520,,10.1109/TSE.2008.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4553721,Cost estimation;Time estimation;Project control and modeling;Reliability;Cost estimation;Time estimation;Project control and modeling;Reliability,Uncertainty;Cost function;Software testing;Programming;Project management;Decision making;Software reliability;Software safety;Software development management;Software quality,,49,,36,IEEE,27 Jun 2008,,,IEEE,IEEE Journals,True
"An Exploratory Study of How Developers Seek, Relate, and Collect Relevant Information during Software Maintenance Tasks",A. J. Ko; B. A. Myers; M. J. Coblenz; H. H. Aung,"Human-Computer Interaction Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Human-Computer Interaction Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Human-Computer Interaction Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Human-Computer Interaction Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",IEEE Transactions on Software Engineering,30 Nov 2006,2006,32,12,971,987,"Much of software developers' time is spent understanding unfamiliar code. To better understand how developers gain this understanding and how software development environments might be involved, a study was performed in which developers were given an unfamiliar program and asked to work on two debugging tasks and three enhancement tasks for 70 minutes. The study found that developers interleaved three activities. They began by searching for relevant code both manually and using search tools; however, they based their searches on limited and misrepresentative cues in the code, environment, and executing program, often leading to failed searches. When developers found relevant code, they followed its incoming and outgoing dependencies, often returning to it and navigating its other dependencies; while doing so, however, Eclipse's navigational tools caused significant overhead. Developers collected code and other information that they believed would be necessary to edit, duplicate, or otherwise refer to later by encoding it in the interactive state of Eclipse's package explorer, file tabs, and scroll bars. However, developers lost track of relevant code as these interfaces were used for other tasks, and developers were forced to find it again. These issues caused developers to spend, on average, 35 percent of their time performing the mechanics of navigation within and between source files. These observations suggest a new model of program understanding grounded in theories of information foraging and suggest ideas for tools that help developers seek, relate, and collect information in a more effective and explicit manner.",1939-3520,,10.1109/TSE.2006.116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4016573,Program investigation;program understanding;program comprehension;empirical software engineering;information foraging;information scent.,Software maintenance;Programming;Navigation;Software engineering;Software tools;Performance gain;Debugging;Encoding;Packaging;Bars,,418,1,51,IEEE,30 Nov 2006,,,IEEE,IEEE Journals,True
Enhancing an Application Server to Support Available Components,A. I. Kistijantoro; G. Morgan; S. K. Shrivastava; M. C. Little,"School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia; School of Computing Science, University of Newcastle, UK; School of Computing Science, University of Newcastle, UK; Red Hat UK Limited, Berkshire, UK",IEEE Transactions on Software Engineering,1 Aug 2008,2008,34,4,531,545,"Three-tier middleware architecture is commonly used for hosting enterprise-distributed applications. Typically, the application is decomposed into three layers: front end, middle tier, and back end. Front end (""Web server"") is responsible for handling user interactions and acts as a client of the middle tier, while back end provides storage facilities for applications. Middle tier (""application server"") is usually the place where all computations are performed. One of the benefits of this architecture is that it allows flexible management of a cluster of computers for performance and scalability; further, availability measures, such as replication, can be introduced in each tier in an application-specific manner. However, incorporation of availability measures in a multitier system poses challenging system design problems of integrating open, nonproprietary solutions to transparent failover, exactly once execution of client requests, nonblocking transaction processing, and an ability to work with clusters. This paper describes how replication for availability can be incorporated within the middle and back-end tiers, meeting all these challenges. This paper develops an approach that requires enhancements to the middle tier only for supporting replication of both the middleware back-end tiers. The design, implementation, and performance evaluation of such a middle-tier-based replication scheme for multidatabase transactions on a widely deployed open source application server (JBoss) are presented.",1939-3520,,10.1109/TSE.2008.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4528966,Software engineering for Internet projects;Distributed objects;Software engineering for Internet projects;Distributed objects,Middleware;Availability;Application software;Computer architecture;Java;Scalability;Fault tolerance;Transaction databases;Containers;Distributed computing,,11,1,38,IEEE,23 May 2008,,,IEEE,IEEE Journals,True
An approach to developing domain requirements as a core asset based on commonality and variability analysis in a product line,Mikyeong Moon; Keunhyuk Yeom; Heung Seok Chae,"Department of Computer Science and Engineering, Pusan National University, Busan, South Korea; Department of Computer Science and Engineering, Pusan National University, Busan, South Korea; Department of Computer Science and Engineering, Pusan National University, Busan, South Korea",IEEE Transactions on Software Engineering,8 Aug 2005,2005,31,7,551,569,"The methodologies of product line engineering emphasize proactive reuse to construct high-quality products more quickly that are less costly. Requirements engineering for software product families differs significantly from requirements engineering for single software products. The requirements for a product line are written for the group of systems as a whole, with requirements for individual systems specified by a delta or an increment to the generic set. Therefore, it is necessary to identify and explicitly denote the regions of commonality and points of variation at the requirements level. In this paper, we suggest a method of producing requirements that will be a core asset in the product line. We describe a process for developing domain requirements where commonality and variability in a domain are explicitly considered. A CASE environment, named DREAM, for managing commonality and variability analysis of domain requirements is also described. We also describe a case study for an e-travel system domain where we found that our approach to developing domain requirements based on commonality and variability analysis helped to produce domain requirements as a core asset for product lines.",1939-3520,,10.1109/TSE.2005.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492371,Index Terms- Requirement engineering;product-line;core asset;commonality;variability;domain analysis;reuse.,Design engineering;Computer architecture;Moon;Computer Society;Computer aided software engineering;Environmental management;Software systems;Control systems;Testing;Costs,,88,,29,IEEE,8 Aug 2005,,,IEEE,IEEE Journals,True
Locating Need-to-Externalize Constant Strings for Software Internationalization with Generalized String-Taint Analysis,X. Wang; L. Zhang; T. Xie; H. Mei; J. Sun,"Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, and the Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, and the Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, and the Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, and the Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,516,536,"Nowadays, a software product usually faces a global market. To meet the requirements of different local users, the software product must be internationalized. In an internationalized software product, user-visible hard-coded constant strings are externalized to resource files so that local versions can be generated by translating the resource files. In many cases, a software product is not internationalized at the beginning of the software development process. To internationalize an existing product, the developers must locate the user-visible constant strings that should be externalized. This locating process is tedious and error-prone due to 1) the large number of both user-visible and non-user-visible constant strings and 2) the complex data flows from constant strings to the Graphical User Interface (GUI). In this paper, we propose an automatic approach to locating need-to-externalize constant strings in the source code of a software product. Given a list of precollected API methods that output values of their string argument variables to the GUI and the source code of the software product under analysis, our approach traces from the invocation sites (within the source code) of these methods back to the need-to-externalize constant strings using generalized string-taint analysis. In our empirical evaluation, we used our approach to locate need-to-externalize constant strings in the uninternationalized versions of seven real-world open source software products. The results of our evaluation demonstrate that our approach is able to effectively locate need-to-externalize constant strings in uninternationalized software products. Furthermore, to help developers understand why a constant string requires translation and properly translate the need-to-externalize strings, we provide visual representation of the string dependencies related to the need-to-externalize strings.",1939-3520,,10.1109/TSE.2012.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216383,Software internationalization;need-to-externalize constant strings;string-taint analysis,Software;Graphical user interfaces;Prototypes;Java;Libraries;Production;Globalization,,10,,31,IEEE,12 Jun 2012,,,IEEE,IEEE Journals,True
Comparing uniform and flexible policies for software maintenance and replacement,Y. Tan; V. S. Mookerjee,"Business School, University of Washington, Seattle, WA, USA; School of Management, University of Texas, Dallas, Richardson, TX, USA",IEEE Transactions on Software Engineering,25 Apr 2005,2005,31,3,238,255,"The importance of software maintenance in managing the life-cycle costs of a system cannot be overemphasized. Beyond a point, however, it is better to replace a system rather than maintain it. We derive model and operating policy that reduces the sum of maintenance and replacement costs in the useful life of a software system. The main goal is to compare uniform (occurring at fixed time intervals) versus flexible (occurring at varying, planned time intervals) polices for maintenance and replacement. The model draws from the empirical works of earlier researchers to consider 1) inclusion of user requests for maintenance, 2) scale economies in software maintenance, 3) efficiencies derived from replacing old software technology with new software technology, and 4) the impact of software reuse on replacement and maintenance. Results from our model show that the traditional practice of maintaining or replacing a software system at uniform time intervals may not be optimal. We also find that an increase in software reuse leads to more frequent replacement, but the number of maintenance activities is not significantly impacted.",1939-3520,,10.1109/TSE.2005.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1423995,Index Terms- Software maintenance and replacement;cost models;optimal scheduling.,Software maintenance;Software systems;Application software;Cost function;Environmental economics;Optimal scheduling;Computer industry;Software performance;Personnel;Java,,34,,57,IEEE,25 Apr 2005,,,IEEE,IEEE Journals,True
"Pair Programming and Software Defects--A Large, Industrial Case Study",E. di Bella; I. Fronza; N. Phaphoom; A. Sillitti; G. Succi; J. Vlasenko,"Department of Economics Quantitative Methods, University of Genova, Genova, Italy; Center for Applied Software Engineering (CASE), Free University of Bozen-Bolzano, Bolzano, Italy; Center for Applied Software Engineering (CASE), Free University of Bozen-Bolzano, Bolzano, Italy; Center for Applied Software Engineering (CASE), Free University of Bozen-Bolzano, Bolzano, Italy; Center for Applied Software Engineering (CASE), Free University of Bozen-Bolzano, Bolzano, Italy; Center for Applied Software Engineering (CASE), Free University of Bozen-Bolzano, Bolzano, Italy",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,930,953,"In the last decade, there has been increasing interest in pair programming (PP). However, despite the existing work, there is still a lack of substantial evidence of the effects of PP in industrial environments. To address this issue, we have analyzed the work of a team of 17 industrial developers for 14 months. The team is part of the IT department of a large Italian manufacturing company; it adopts a customized version of extreme programming (XP). We have investigated the effects of PP on software quality in five different scenarios. The results show that PP appears to provide a perceivable but small effect on the reduction of defects in these settings.",1939-3520,,10.1109/TSE.2012.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331491,Pair programming;software defects;case study,Programming;Software,,51,,94,IEEE,16 Oct 2012,,,IEEE,IEEE Journals,True
Coordination Breakdowns and Their Impact on Development Productivity and Software Failures,M. Cataldo; J. D. Herbsleb,"Research and Technology Center, Robert Bosch LLC, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,343,360,"The success of software development projects depends on carefully coordinating the effort of many individuals across the multiple stages of the development process. In software engineering, modularization is the traditional technique intended to reduce the interdependencies among modules that constitute a system. Reducing technical dependencies, the theory argues, results in a reduction of work dependencies between teams developing interdependent modules. Although that research stream has been quite influential, it considers a static view of the problem of coordination in engineering activities. Building on a dynamic view of coordination, we studied the relationship between socio-technical congruence and software quality and development productivity. In order to investigate the generality of our findings, our analyses were performed on two large-scale projects from two companies with distinct characteristics in terms of product and process maturity. Our results revealed that the gaps between coordination requirements and the actual coordination activities carried out by the developers significantly increased software failures. Our analyses also showed that higher levels of congruence are associated with improved development productivity. Finally, our results showed the congruence between dependencies and coordinative actions is critical both in mature development settings as well as in novel and dynamic development contexts.",1939-3520,,10.1109/TSE.2012.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6205767,Metrics/measurement;productivity;organizational management and coordination;quality analysis and evaluation,Productivity;Programming;Software quality;Context;Complexity theory;Organizations,,101,,78,IEEE,29 May 2012,,,IEEE,IEEE Journals,True
Exploiting Dynamic Information in IDEs Improves Speed and Correctness of Software Maintenance Tasks,D. Rothlisberger; M. Harry; W. Binder; P. Moret; D. Ansaloni; A. Villazon; O. Nierstrasz,"Software Composition Group, Institut für Informatik, Universität Bern, Bern, Switzerland; Software Composition Group, Institut für Informatik, Universität Bern, Bern, Switzerland; Faculty of Informatics, University of Lugano, Lugano, Switzerland; Faculty of Informatics, University of Lugano, Lugano, Switzerland; Faculty of Informatics, University of Lugano, Lugano, Switzerland; Centro de Investigaciones de Nuevas Tecnologías Informáticas (CINTI), Universidad Privada Boliviana, Cochabamba, Bolivia; Software Composition Group, Institut für Informatik, Universität Bern, Bern, Switzerland",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,579,591,"Modern IDEs such as Eclipse offer static views of the source code, but such views ignore information about the runtime behavior of software systems. Since typical object-oriented systems make heavy use of polymorphism and dynamic binding, static views will miss key information about the runtime architecture. In this paper, we present an approach to gather and integrate dynamic information in the Eclipse IDE with the goal of better supporting typical software maintenance activities. By means of a controlled experiment with 30 professional developers, we show that for typical software maintenance tasks, integrating dynamic information into the Eclipse IDE yields a significant 17.5 percent decrease of time spent while significantly increasing the correctness of the solutions by 33.5 percent. We also provide a comprehensive performance evaluation of our approach.",1939-3520,,10.1109/TSE.2011.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178187,Object-oriented programming;integrated environments;restructuring;reverse engineering;reengineering;complexity measures;performance measures.,Runtime;Measurement;Java;Context;Software maintenance;Concrete;Weaving,,27,,35,IEEE,5 Apr 2012,,,IEEE,IEEE Journals,True
Modeling Product Line Software Assets Using Domain-Specific Kits,N. I. Altintas; S. Cetin; A. H. Dogru; H. Oguztuzun,"Sabanci Center, Akbank T.A.S., Istanbul, Turkey; Cybersoft Information Technologies Company, Istanbul, Turkey; Department of Computer Engineering, Middle East Technical University, Ankara, Turkey; Department of Computer Engineering, Middle East Technical University, Ankara, Turkey",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1376,1402,"Software Product Line Engineering (SPLE) is a prominent paradigm for the assembly of a family of products using product line core assets. The modeling of software assets that together form the actual products is critical for achieving the strategic benefits of Software Product Lines (SPLs). We propose a feature-based approach to software asset modeling based on abstractions provided by Domain-Specific Kits (DSKs). This approach involves a software Asset Metamodel (AMM) used to derive Asset Modeling Languages (AMLs) that define reusable software assets in domain-specific terms. The approach also prescribes a roadmap for modeling these software assets in conjunction with the product line reference architecture. Asset capabilities can be modeled using feature diagrams as the external views of the software assets. Internal views can be expressed in terms of Domain-Specific Artifacts (DSAs) with Variability Points (VPs), where the domain-specific artifacts are created using Domain-Specific Kits. This approach produces loosely coupled and highly cohesive software assets that are reusable for multiple product lines. The approach is validated by assessing software asset reuse in two different product lines in the finance domain. We also evaluated the productivity gains in large-scale complex projects, and found that the approach yielded a significant reduction in the total project effort.",1939-3520,,10.1109/TSE.2011.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065739,Asset modeling;domain-specific kits;feature models;reuse;software asset;software product lines,Software reliability;Computer architecture;Productivity;Programming;Complexity theory;Systematics,,8,,86,IEEE,1 Nov 2011,,,IEEE,IEEE Journals,True
Change Distilling:Tree Differencing for Fine-Grained Source Code Change Extraction,B. Fluri; M. Wursch; M. PInzger; H. Gall,"Department of Informatics University of Zurich, Zürich, Switzerland; Univ. of Zurich, Zurich; Department of Informatics University of Zurich, Zürich, Switzerland; Department of Informatics University of Zurich, Zürich, Switzerland",IEEE Transactions on Software Engineering,8 Oct 2007,2007,33,11,725,743,"A key issue in software evolution analysis is the identification of particular changes that occur across several versions of a program. We present change distilling, a tree differencing algorithm for fine-grained source code change extraction. For that, we have improved the existing algorithm of Chawathe et al. for extracting changes in hierarchically structured data. Our algorithm detects changes by finding a match between nodes of the compared two abstract syntax trees and a minimum edit script. We can identify change types between program versions according to our taxonomy of source code changes. We evaluated our change distilling algorithm with a benchmark we developed that consists of 1,064 manually classified changes in 219 revisions from three different open source projects. We achieved significant improvements in extracting types of source code changes: our algorithm approximates the minimum edit script by 45% better than the original change extraction approach by Chawathe et al. We are able to find all occurring changes and almost reach the minimum conforming edit script, i.e., we reach a mean absolute percentage error of 34%, compared to 79% reached by the original algorithm. The paper describes both the change distilling and the results of our evaluation.",1939-3520,,10.1109/TSE.2007.70731,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4339230,Source code change extraction;tree differencing algorithms;software repositories;software evolution analysis,Data mining;Taxonomy;Software maintenance;Programming profession;Software algorithms;Algorithm design and analysis;Software tools;Maintenance engineering;Software systems;History,,452,5,47,IEEE,8 Oct 2007,,,IEEE,IEEE Journals,True
"Software Dependencies, Work Dependencies, and Their Impact on Failures",M. Cataldo; A. Mockus; J. A. Roberts; J. D. Herbsleb,"Research and Technology Center, Robert Bosch Limited Liability Company, Pittsburgh, PA, USA; Avaya Laboratories Research, NJ, USA; Palumbo Donahue School of Business, Duquesne University, Pittsburg, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,864,878,"Prior research has shown that customer-reported software faults are often the result of violated dependencies that are not recognized by developers implementing software. Many types of dependencies and corresponding measures have been proposed to help address this problem. The objective of this research is to compare the relative performance of several of these dependency measures as they relate to customer-reported defects. Our analysis is based on data collected from two projects from two independent companies. Combined, our data set encompasses eight years of development activity involving 154 developers. The principal contribution of this study is the examination of the relative impact that syntactic, logical, and work dependencies have on the failure proneness of a software system. While all dependencies increase the fault proneness, the logical dependencies explained most of the variance in fault proneness, while workflow dependencies had more impact than syntactic dependencies. These results suggest that practices such as rearchitecting, guided by the network structure of logical dependencies, hold promise for reducing defects.",1939-3520,,10.1109/TSE.2009.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5166450,Distribution/maintenance/enhancement;metrics/measurement;organizational management and coordination;quality analysis and evaluation.,Software systems;Predictive models;Quality management;Software engineering;Humans;Software development management;Programming,,178,2,48,IEEE,17 Jul 2009,,,IEEE,IEEE Journals,True
Incremental Maintenance of Software Artifacts,S. P. Reiss,"Department of Computer Science, Brown University, Providence, RI, USA",IEEE Transactions on Software Engineering,9 Oct 2006,2006,32,9,682,697,"Software is multidimensional, but the tools that support it are not. This lack of tool support causes the software artifacts representing different dimensions to evolve independently and to become inconsistent over time. In order to properly support the evolution of software, one must ensure that the different dimensions evolve concurrently. We have built a software development tool, CLIME that uses constraints implemented as database queries to ensure just this. Our approach makes the tool responsible for detecting inconsistencies between software design, specifications, documentation, source code, test cases, and other artifacts without requiring any of these to be a primary representation. The tool works incrementally as the software evolves, without imposing a particular methodology or process. It includes a front end that lets the user explore and fix current inconsistencies. This paper describes the basis for CLIME, the techniques underlying the tool, the interface provided to the programmer, the incremental maintenance of constraints between these artifacts, and our experiences",1939-3520,,10.1109/TSE.2006.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707667,Software maintenance;evolution;programming tools.,Software maintenance;Documentation;Programming profession;Software systems;System testing;Multidimensional systems;Software tools;Software testing;Databases;Software design,,36,,64,IEEE,9 Oct 2006,,,IEEE,IEEE Journals,True
A Controlled Experiment for Evaluating the Impact of Coupling on the Maintainability of Service-Oriented Software,M. Perepletchikov; C. Ryan,"School of Computer Science and IT, RMIT University, Melbourne, Australia; School of Computer Science and IT, RMIT University, Melbourne, Australia",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,449,465,"One of the goals of Service-Oriented Computing (SOC) is to improve software maintainability as businesses become more agile, and thus underlying processes and rules change more frequently. This paper presents a controlled experiment examining the relationship between coupling in service-oriented designs, as measured using a recently proposed suite of SOC-specific coupling metrics and software maintainability in terms of the specific subcharacteristics of analyzability, changeability, and stability. The results indicate a statistically significant causal relationship between the investigated coupling metrics and the maintainability of service-oriented software. As such, the investigated metrics can facilitate coupling related design decisions with the aim of producing more maintainable service-oriented software products.",1939-3520,,10.1109/TSE.2010.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482590,Services systems;design concepts;maintainability;product metrics;empirical studies.,Software maintenance;Programming;Software measurement;Logic;Software design;Stability analysis;Product design;Application software;Costs;Software metrics,,33,,48,IEEE,7 Jun 2010,,,IEEE,IEEE Journals,True
"Conservative Reasoning about the Probability of Failure on Demand of a 1-out-of-2 Software-Based System in Which One Channel Is ""Possibly Perfect""",B. Littlewood; A. Povyakalo,"Centre for Software Reliability, City University London, London, United Kingdom; Centre for Software Reliability, City University London, London, United Kingdom",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1521,1530,"In earlier work, [11] (henceforth LR), an analysis was presented of a 1-out-of-2 software-based system in which one channel was “possibly perfect”. It was shown that, at the aleatory level, the system pfd (probability of failure on demand) could be bounded above by the product of the pfd of channel A and the pnp (probability of nonperfection) of channel B. This result was presented as a way of avoiding the well-known difficulty that for two certainly-fallible channels, failures of the two will be dependent, i.e., the system pfd cannot be expressed simply as a product of the channel pfds. A price paid in this new approach for avoiding the issue of failure dependence is that the result is conservative. Furthermore, a complete analysis requires that account be taken of epistemic uncertainty-here concerning the numeric values of the two parameters pfdA and pnpB. Unfortunately this introduces a different difficult problem of dependence: estimating the dependence between an assessor's beliefs about the parameters. The work reported here avoids this problem by obtaining results that require only an assessor's marginal beliefs about the individual channels, i.e., they do not require knowledge of the dependence between these beliefs. The price paid is further conservatism in the results.",1939-3520,,10.1109/TSE.2013.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574864,Software reliability;fault tolerance;software perfection;probability of failure;epistemic uncertainty;software diversity;multiversion software,Phase frequency detector;Uncertainty;Cognition;Software reliability;Software;Safety,,5,,15,IEEE,5 Aug 2013,,,IEEE,IEEE Journals,True
Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings,S. Lessmann; B. Baesens; C. Mues; S. Pietsch,"Institute of Information Systems, University of Hamburg, Hamburg, Germany; Institute of Information Systems, University of Hamburg, Hamburg, Germany; Department of Applied Economic Sciences, Katholieke Universiteit Leuven, Leuven, Belgium; School of Management, University of Southampton, Southampton, UK",IEEE Transactions on Software Engineering,1 Aug 2008,2008,34,4,485,496,"Software defect prediction strives to improve software quality and testing efficiency by constructing predictive classification models from code attributes to enable a timely identification of fault-prone modules. Several classification models have been evaluated for this task. However, due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of metric-based classification in general, more research is needed to improve convergence across studies and further advance confidence in experimental results. We consider three potential sources for bias: comparing classifiers over one or a small number of proprietary data sets, relying on accuracy indicators that are conceptually inappropriate for software defect prediction and cross-study comparisons, and, finally, limited use of statistical testing procedures to secure empirical findings. To remedy these problems, a framework for comparative software defect prediction experiments is proposed and applied in a large-scale empirical comparison of 22 classifiers over 10 public domain data sets from the NASA Metrics Data repository. Overall, an appealing degree of predictive accuracy is observed, which supports the view that metric-based classification is useful. However, our results indicate that the importance of the particular classification algorithm may be less than previously assumed since no significant performance differences could be detected among the top 17 classifiers.",1939-3520,,10.1109/TSE.2008.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4527256,Complexity measures;Data mining;Formal methods;Statistical methods;Complexity measures;Data mining;Formal methods;Statistical methods,Predictive models;Software quality;Software testing;Statistical analysis;Large-scale systems;NASA;Software systems;Benchmark testing;Fault diagnosis;Convergence,,849,1,67,IEEE,23 May 2008,,,IEEE,IEEE Journals,True
Uncertainty Analysis in Software Reliability Modeling by Bayesian Analysis with Maximum-Entropy Principle,Y. -S. Dai; M. Xie; Q. Long; S. -H. Ng,"Department of Electrical Engineering and Computer Science, Department of Industrial and Information Engineering, University of Tennessee, Knoxville, Knoxville, TN, USA; Industrial and Systems Engineering Department, National University of Singapore, Singapore; Industrial and Systems Engineering Department, National University of Singapore, Singapore; Industrial and Systems Engineering Department, National University of Singapore, Singapore",IEEE Transactions on Software Engineering,8 Oct 2007,2007,33,11,781,795,"In software reliability modeling, the parameters of the model are typically estimated from the test data of the corresponding component. However, the widely used point estimators are subject to random variations in the data, resulting in uncertainties in these estimated parameters. Ignoring the parameter uncertainty can result in grossly underestimating the uncertainty in the total system reliability. This paper attempts to study and quantify the uncertainties in the software reliability modeling of a single component with correlated parameters and in a large system with numerous components. Another characteristic challenge in software testing and reliability is the lack of available failure data from a single test, which often makes modeling difficult. This lack of data poses a bigger challenge in the uncertainty analysis of the software reliability modeling. To overcome this challenge, this paper proposes utilizing experts' opinions and historical data from previous projects to complement the small number of observations to quantify the uncertainties. This is done by combining the maximum-entropy principle (MEP) into the Bayesian approach. This paper further considers the uncertainty analysis at the system level, which contains multiple components, each with its respective model/parameter/ uncertainty, by using a Monte Carlo approach. Some examples with different modeling approaches (NHPP, Markov, Graph theory) are illustrated to show the generality and effectiveness of the proposed approach. Furthermore, we illustrate how the proposed approach for considering the uncertainties in various components improves a large-scale system reliability model.",1939-3520,,10.1109/TSE.2007.70739,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4339233,Software Reliability;Uncertainty analysis;Bayesian method;Monte Carlo;Markov model;Graph theory,Uncertainty;Software reliability;Bayesian methods;Parameter estimation;Software testing;Uncertain systems;Monte Carlo methods;Graph theory;Reliability theory;Predictive models,,58,,35,IEEE,8 Oct 2007,,,IEEE,IEEE Journals,True
Effects of Personality on Pair Programming,J. E. Hannay; E. Arisholm; H. Engvik; D. I. K. Sjoberg,"Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway; Department of Psychology, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,61,80,"Personality tests in various guises are commonly used in recruitment and career counseling industries. Such tests have also been considered as instruments for predicting the job performance of software professionals both individually and in teams. However, research suggests that other human-related factors such as motivation, general mental ability, expertise, and task complexity also affect the performance in general. This paper reports on a study of the impact of the Big Five personality traits on the performance of pair programmers together with the impact of expertise and task complexity. The study involved 196 software professionals in three countries forming 98 pairs. The analysis consisted of a confirmatory part and an exploratory part. The results show that: (1) Our data do not confirm a meta-analysis-based model of the impact of certain personality traits on performance and (2) personality traits, in general, have modest predictive value on pair programming performance compared with expertise, task complexity, and country. We conclude that more effort should be spent on investigating other performance-related predictors such as expertise, and task complexity, as well as other promising predictors, such as programming skill and learning. We also conclude that effort should be spent on elaborating on the effects of personality on various measures of collaboration, which, in turn, may be used to predict and influence performance. Insights into such malleable, rather than static, factors may then be used to improve pair programming performance.",1939-3520,,10.1109/TSE.2009.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5089333,Pair programming;personality;Big Five;expertise;task complexity;performance.,Programming profession;Collaborative work;Keyboards;Books;Recruitment;Engineering profession;Employee welfare;Software testing;Instruments;Software performance,,87,,121,IEEE,19 Jun 2009,,,IEEE,IEEE Journals,True
A Study of Variability Models and Languages in the Systems Software Domain,T. Berger; S. She; R. Lotufo; A. Wasowski; K. Czarnecki,"Rued Langgaards Vej 7, IT University of Copenhagen, Copenhagen, Denmark; Department of Electrical & Computer Engineering, University of Waterloo, University Ave; Department of Electrical & Computer Engineering, University of Waterloo, University Ave; Rued Langgaards Vej 7, IT University of Copenhagen, Copenhagen, Denmark; Department of Electrical & Computer Engineering, University of Waterloo, University Ave",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1611,1640,"Variability models represent the common and variable features of products in a product line. Since the introduction of FODA in 1990, several variability modeling languages have been proposed in academia and industry, followed by hundreds of research papers on variability models and modeling. However, little is known about the practical use of such languages. We study the constructs, semantics, usage, and associated tools of two variability modeling languages, Kconfig and CDL, which are independently developed outside academia and used in large and significant software projects. We analyze 128 variability models found in 12 open--source projects using these languages. Our study 1) supports variability modeling research with empirical data on the real-world use of its flagship concepts. However, we 2) also provide requirements for concepts and mechanisms that are not commonly considered in academic techniques, and 3) challenge assumptions about size and complexity of variability models made in academic papers. These results are of interest to researchers working on variability modeling and analysis techniques and to designers of tools, such as feature dependency checkers and interactive product configurators.",1939-3520,,10.1109/TSE.2013.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6572787,Empirical software engineering;software product lines;variability modeling;feature modeling;configuration;open source,Biological system modeling;Software products;Product line;Analytical models;Computational modeling;Semantics;Computer architecture,,108,,88,IEEE,31 Jul 2013,,,IEEE,IEEE Journals,True
Frameworks Generate Domain-Specific Languages: A Case Study in the Multimedia Domain,X. Amatriain; P. Arumi,"Telefonica Research and Development, Barcelona, Spain; Barcelona Media, Barcelona, Spain",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,544,558,"We present an approach to software framework development that includes the generation of domain-specific languages (DSLs) and pattern languages as goals for the process. Our model is made of three workflows-framework, metamodel, and patterns-and three phases-inception, construction, and formalization. The main conclusion is that when developing a framework, we can produce with minimal overhead-almost as a side effect-a metamodel with an associated DSL and a pattern language. Both outputs will not only help the framework evolve in the right direction, but will also be valuable in themselves. In order to illustrate these ideas, we present a case study in the multimedia domain. For several years, we have been developing a multimedia framework. The process has produced a full-fledged domain-specific metamodel for the multimedia domain, with an associated DSL and a pattern language.",1939-3520,,10.1109/TSE.2010.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5441292,Domain-specific architectures;visual programming;life cycle;CASE.,Domain specific languages;DSL;Unified modeling language;Vocabulary;Concrete;Software engineering;Computer aided software engineering;Natural languages;Metamodeling;Best practices,,8,,37,IEEE,1 Apr 2010,,,IEEE,IEEE Journals,True
"A style-aware architectural middleware for resource-constrained, distributed systems",S. Malek; M. Mikic-Rakic; N. Medvidovic,"Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Google, Inc., Santa Monica, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA",IEEE Transactions on Software Engineering,25 Apr 2005,2005,31,3,256,272,"A recent emergence of small, resource-constrained, and highly mobile computing platforms presents numerous new challenges for software developers. We refer to development in this new setting as programming-in-the-small-and-many (Prism). This paper provides a description and evaluation of Prism-MW, a middleware platform intended to support software architecture-based development in the Prism setting. Prism-MW provides efficient and scalable implementation-level support for the key aspects of Prism application architectures, including their architectural styles. Additionally, Prism-MW is extensible to support different application requirements suitable for the Prism setting. Prism-MW has been applied in a number of applications and used as an educational tool in graduate-level software architecture and embedded systems courses. Recently, Prism-MW has been successfully evaluated by a major industrial organization for use in one of their key distributed embedded systems. Our experience with the middleware indicates that the principles of architecture-based software development can be successfully, and flexibly, applied in the Prism setting.",1939-3520,,10.1109/TSE.2005.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1423996,Index Terms- Software architecture;architectural style;middleware;Prism-MW.,Middleware;Computer architecture;Software architecture;Application software;Software systems;Guidelines;Mobile computing;Embedded system;Software engineering;Connectors,,71,14,42,IEEE,25 Apr 2005,,,IEEE,IEEE Journals,True
Event Logs for the Analysis of Software Failures: A Rule-Based Approach,M. Cinque; D. Cotroneo; A. Pecchia,"Dipartimento di Informatica e Sistemistica (DIS), Università degli Studi di Napoli Federico II, Naples, Italy; Dipartimento di Informatica e Sistemistica (DIS), Università degli Studi di Napoli Federico II, Naples, Italy; Dipartimento di Informatica e Sistemistica (DIS), Università degli Studi di Napoli Federico II, Naples, Italy",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,806,821,"Event logs have been widely used over the last three decades to analyze the failure behavior of a variety of systems. Nevertheless, the implementation of the logging mechanism lacks a systematic approach and collected logs are often inaccurate at reporting software failures: This is a threat to the validity of log-based failure analysis. This paper analyzes the limitations of current logging mechanisms and proposes a rule-based approach to make logs effective to analyze software failures. The approach leverages artifacts produced at system design time and puts forth a set of rules to formalize the placement of the logging instructions within the source code. The validity of the approach, with respect to traditional logging mechanisms, is shown by means of around 12,500 software fault injection experiments into real-world systems.",1939-3520,,10.1109/TSE.2012.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6320555,Event log;logging mechanism;rule-based logging;error detection;software failures,Unified modeling language;Failure analysis;Analytical models;Systematics;Proposals;Software systems,,80,,52,IEEE,3 Oct 2012,,,IEEE,IEEE Journals,True
Evidence-based guidelines for assessment of software development cost uncertainty,M. Jorgensen,"Simula Research Laboratory, Lysaker, Norway",IEEE Transactions on Software Engineering,12 Dec 2005,2005,31,11,942,954,"Several studies suggest that uncertainty assessments of software development costs are strongly biased toward overconfidence, i.e., that software cost estimates typically are believed to be more accurate than they really are. This overconfidence may lead to poor project planning. As a means of improving cost uncertainty assessments, we provide evidence-based guidelines for how to assess software development cost uncertainty, based on results from relevant empirical studies. The general guidelines provided are: 1) Do not rely solely on unaided, intuition-based uncertainty assessment processes, 2) do not replace expert judgment with formal uncertainty assessment models, 3) apply structured and explicit judgment-based processes, 4) apply strategies based on an outside view of the project, 5) combine uncertainty assessments from different sources through group work, not through mechanical combination, 6) use motivational mechanisms with care and only if greater effort is likely to lead to improved assessments, and 7) frame the assessment problem to fit the structure of the relevant uncertainty information and the assessment process. These guidelines are preliminary and should be updated in response to new evidence.",1939-3520,,10.1109/TSE.2005.128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1556553,Index Terms- Cost estimation;management;software psychology;uncertainty of software development cost.,Guidelines;Programming;Uncertainty;Cost function;Humans;Software development management;Psychology;Process planning;Estimation error;Terminology,,42,,75,IEEE,12 Dec 2005,,,IEEE,IEEE Journals,True
Generating Test Data from OCL Constraints with Search Techniques,S. Ali; M. Zohaib Iqbal; A. Arcuri; L. C. Briand,"Certus Software V&V Center, Simula Research Laboratory, Norway; National University of Computer and Emerging Sciences - Lahore Campus, Lahore, PK; Certus Software V&V Center, Simula Research Laboratory, Norway; Faculté des Sciences, de la Technologie et de la Communicat, University of Luxembourg, Luxembourg, Luxembourg",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1376,1402,"Model-based testing (MBT) aims at automated, scalable, and systematic testing solutions for complex industrial software systems. To increase chances of adoption in industrial contexts, software systems can be modeled using well-established standards such as the Unified Modeling Language (UML) and the Object Constraint Language (OCL). Given that test data generation is one of the major challenges to automate MBT, we focus on test data generation from OCL constraints in this paper. This endeavor is all the more challenging given the numerous OCL constructs and operations that are designed to facilitate the definition of constraints. Though search-based software testing has been applied to test data generation for white-box testing (e.g., branch coverage), its application to the MBT of industrial software systems has been limited. In this paper, we propose a set of search heuristics targeted to OCL constraints to guide test data generation and automate MBT in industrial applications. We evaluate these heuristics for three search algorithms: Genetic Algorithm, (1+1) Evolutionary Algorithm, and Alternating Variable Method. We empirically evaluate our heuristics using complex artificial problems, followed by empirical analyses of the feasibility of our approach on one industrial system in the context of robustness testing. Our approach is also compared with the most widely referenced OCL solver (UMLtoCSP) in the literature and shows to be significantly more efficient.",1939-3520,,10.1109/TSE.2013.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6491405,OCL;search-based testing;test data generation;empirical evaluation;search-based software engineering;model-based testing,Unified modeling language;Search problems;Software algorithms;Genetic algorithms;Standards;Software testing,,98,,75,IEEE,1 Apr 2013,,,IEEE,IEEE Journals,True
Improving Fault Detection Capability by Selectively Retaining Test Cases during Test Suite Reduction,D. Jeffrey; N. Gupta,"Department of Computer Science, University of Arizona Tucson, Tucson, AZ, USA; Department of Computer Science, University of Arizona Tucson, Tucson, AZ, USA",IEEE Transactions on Software Engineering,8 Jan 2007,2007,33,2,108,123,"Software testing is a critical part of software development. As new test cases are generated over time due to software modifications, test suite sizes may grow significantly. Because of time and resource constraints for testing, test suite minimization techniques are needed to remove those test cases from a suite that, due to code modifications over time, have become redundant with respect to the coverage of testing requirements for which they were generated. Prior work has shown that test suite minimization with respect to a given testing criterion can significantly diminish the fault detection effectiveness (FDE) of suites. We present a new approach for test suite reduction that attempts to use additional coverage information of test cases to selectively keep some additional test cases in the reduced suites that are redundant with respect to the testing criteria used for suite minimization, with the goal of improving the FDE retention of the reduced suites. We implemented our approach by modifying an existing heuristic for test suite minimization. Our experiments show that our approach can significantly improve the FDE of reduced test suites without severely affecting the extent of suite size reduction",1939-3520,,10.1109/TSE.2007.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4052586,Software testing;testing criteria;test suite minimization;test suite reduction;fault detection effectiveness.,Fault detection;Software testing;Programming;Time factors;Life testing;Resource management;Software development management;Polynomials,,113,,31,IEEE,8 Jan 2007,,,IEEE,IEEE Journals,True
The Effects of Time Constraints on Test Case Prioritization: A Series of Controlled Experiments,H. Do; S. Mirarab; L. Tahvildari; G. Rothermel,"Department of Computer Science 2740, North Dakota State University, Fargo, ND, USA; IBM, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ONT, Canada; Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,593,617,"Regression testing is an expensive process used to validate modified software. Test case prioritization techniques improve the cost-effectiveness of regression testing by ordering test cases such that those that are more important are run earlier in the testing process. Many prioritization techniques have been proposed and evidence shows that they can be beneficial. It has been suggested, however, that the time constraints that can be imposed on regression testing by various software development processes can strongly affect the behavior of prioritization techniques. If this is correct, a better understanding of the effects of time constraints could lead to improved prioritization techniques and improved maintenance and testing processes. We therefore conducted a series of experiments to assess the effects of time constraints on the costs and benefits of prioritization techniques. Our first experiment manipulates time constraint levels and shows that time constraints do play a significant role in determining both the cost-effectiveness of prioritization and the relative cost-benefit trade-offs among techniques. Our second experiment replicates the first experiment, controlling for several threats to validity including numbers of faults present, and shows that the results generalize to this wider context. Our third experiment manipulates the number of faults present in programs to examine the effects of faultiness levels on prioritization and shows that faultiness level affects the relative cost-effectiveness of prioritization techniques. Taken together, these results have several implications for test engineers wishing to cost-effectively regression test their software systems. These include suggestions about when and when not to prioritize, what techniques to employ, and how differences in testing processes may relate to prioritization cost--effectiveness.",1939-3520,,10.1109/TSE.2010.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482587,Regression testing;test case prioritization;cost-benefits;Bayesian networks;empirical studies.,Time factors;Software testing;Automatic testing;Maintenance engineering;Programming;System testing;Computer Society;Software systems;Bayesian methods;Software quality,,112,,62,IEEE,7 Jun 2010,,,IEEE,IEEE Journals,True
Empirical Principles and an Industrial Case Study in Retrieving Equivalent Requirements via Natural Language Processing Techniques,D. Falessi; G. Cantone; G. Canfora,"Certus Software V&V Center, Simula Research Laboratory, Norway; Department of Informatics, Systems, and Production engineering (DISP), University of Rome “TorVergata,”, Rome, Italy; University of Sannio, Benevento, Italy",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,18,44,"Though very important in software engineering, linking artifacts of the same type (clone detection) or different types (traceability recovery) is extremely tedious, error-prone, and effort-intensive. Past research focused on supporting analysts with techniques based on Natural Language Processing (NLP) to identify candidate links. Because many NLP techniques exist and their performance varies according to context, it is crucial to define and use reliable evaluation procedures. The aim of this paper is to propose a set of seven principles for evaluating the performance of NLP techniques in identifying equivalent requirements. In this paper, we conjecture, and verify, that NLP techniques perform on a given dataset according to both ability and the odds of identifying equivalent requirements correctly. For instance, when the odds of identifying equivalent requirements are very high, then it is reasonable to expect that NLP techniques will result in good performance. Our key idea is to measure this random factor of the specific dataset(s) in use and then adjust the observed performance accordingly. To support the application of the principles we report their practical application to a case study that evaluates the performance of a large number of NLP techniques for identifying equivalent requirements in the context of an Italian company in the defense and aerospace domain. The current application context is the evaluation of NLP techniques to identify equivalent requirements. However, most of the proposed principles seem applicable to evaluating any estimation technique aimed at supporting a binary decision (e.g., equivalent/nonequivalent), with the estimate in the range [0,1] (e.g., the similarity provided by the NLP), when the dataset(s) is used as a benchmark (i.e., testbed), independently of the type of estimator (i.e., requirements text) and of the estimation method (e.g., NLP).",1939-3520,,10.1109/TSE.2011.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112783,Empirical software engineering;traceability recovery;natural language processing;equivalent requirements;metrics and measurement,Natural language processing;Context;Semantics;Measurement;Matrix decomposition;Monitoring;Thesauri,,75,,116,IEEE,27 Dec 2011,,,IEEE,IEEE Journals,True
Provable Protection against Web Application Vulnerabilities Related to Session Data Dependencies,L. Desmet; P. Verbaeten; W. Joosen; F. Piessens,"Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium",IEEE Transactions on Software Engineering,31 Jan 2008,2008,34,1,50,64,"Web applications are widely adopted and their correct functioning is mission critical for many businesses. At the same time, Web applications tend to be error prone and implementation vulnerabilities are readily and commonly exploited by attackers. The design of countermeasures that detect or prevent such vulnerabilities or protect against their exploitation is an important research challenge for the fields of software engineering and security engineering. In this paper, we focus on one specific type of implementation vulnerability, namely, broken dependencies on session data. This vulnerability can lead to a variety of erroneous behavior at runtime and can easily be triggered by a malicious user by applying attack techniques such as forceful browsing. This paper shows how to guarantee the absence of runtime errors due to broken dependencies on session data in Web applications. The proposed solution combines development-time program annotation, static verification, and runtime checking to provably protect against broken data dependencies. We have developed a prototype implementation of our approach, building on the JML annotation language and the existing static verification tool ESC/Java2, and we successfully applied our approach to a representative J2EE-based e-commerce application. We show that the annotation overhead is very small, that the performance of the fully automatic static verification is acceptable, and that the performance overhead of the runtime checking is limited.",1939-3520,,10.1109/TSE.2007.70742,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359468,Software/Program Verification;Security;Security and Protection;Reliability;Data sharing;Web-based services;Web technologies;Software/Program Verification;Security;Security and Protection;Reliability;Data sharing;Web-based services;Web technologies,Protection;Runtime;Application software;Data security;Computer bugs;Computer errors;Software engineering;Databases;Computer crime;Information retrieval,,4,1,48,IEEE,31 Jan 2008,,,IEEE,IEEE Journals,True
State-Density Functions over DBM Domains in the Analysis of Non-Markovian Models,L. Carnevali; L. Grassi; E. Vicario,"Dipartimento di Sistemi e Informatica, Università di Firenze, Florence, Italy; Dipartimento di Sistemi e Informatica, Università di Firenze, Florence, Italy; Dipartimento di Sistemi e Informatica, Università di Firenze, Florence, Italy",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,178,194,"Quantitative evaluation of models with generally-distributed transitions requires analysis of non-Markovian processes that may be not isomorphic to their underlying untimed models and may include any number of concurrent non-exponential timers. The analysis of stochastic Time Petri Nets copes with the problem by covering the state space with stochastic-classes, which extend Difference Bounds Matrices (DBM) with a state probability density function. We show that the state-density function accepts a continuous piecewise representation over a partition in DBM-shaped sub-domains. We then develop a closed-form symbolic calculus of state-density functions assuming that model transitions have expolynomial distributions. The calculus shows that within each sub-domain the state-density function is a multivariate expolynomial function and makes explicit how this form evolves through subsequent transitions. This enables an efficient implementation of the analysis process and provides the formal basis that supports introduction of an approximate analysis based on Bernstein Polynomials. The approximation attacks practical and theoretical limits in the applicability of stochastic state-classes, and devises a new approach to the analysis of non Markovian models, relying on approximations in the state space rather than in the structure of the model.",1939-3520,,10.1109/TSE.2008.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711059,Software Engineering;Tools;Validation;Software and System Safety;Software/Program Verification;Formal methods;Reliability;Automata;Parallelism and concurrency;Approximation;Markov processes;Renewal theory;Stochastic processes;Software Engineering;Tools;Validation;Software and System Safety;Software/Program Verification;Formal methods;Reliability;Automata;Parallelism and concurrency;Approximation;Markov processes;Renewal theory;Stochastic processes,Stochastic processes;Function approximation;State-space methods;Petri nets;Density functional theory;Calculus;Polynomials;Software safety;Timing;Encoding,,33,,39,IEEE,12 Dec 2008,,,IEEE,IEEE Journals,True
Toward formalizing domain modeling semantics in language syntax,J. Evermann; Y. Wand,"School of Information Management, Victoria University of Wellington, Wellington, New Zealand; Sauder School of Business, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,14 Feb 2005,2005,31,1,21,37,"Information systems are situated in and are representations of some business or organizational domain. Hence, understanding the application domain is critical to the success of information systems development. To support domain understanding, the application domain is represented in conceptual models. The correctness of conceptual models can affect the development outcome and prevent costly rework during later development stages. This paper proposes a method to restrict the syntax of a modeling language to ensure that only possible configurations of a domain can be modeled, thus increasing the likelihood of creating correct domain models. The proposed method, based on domain ontologies, captures relationships among domain elements via constraints on the language metamodel, thus restricting the set of statements about the domain that can be generated with the language. In effect, this method creates domain specific modeling languages from more generic ones. The method is demonstrated using the Unified Modeling Language (UML). Specifically, it is applied to the subset of UML dealing with object behavior and its applicability is demonstrated on a specific modeling example.",1939-3520,,10.1109/TSE.2005.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1392718,Index Terms- Analysis;methodologies;specification;object-oriented design methods;design concepts;CASE;ontology.,Object oriented modeling;Context modeling;Unified modeling language;Software design;Application software;Ontologies;Design methodology;Information systems;Computer aided software engineering;Software systems,,51,,62,IEEE,14 Feb 2005,,,IEEE,IEEE Journals,True
Evaluating Pair Programming with Respect to System Complexity and Programmer Expertise,E. Arisholm; H. Gallis; T. Dyba; D. I. K. Sjoberg,"Simula Research Laboratory, Lysaker, Norway; Simula Research Laboratory, Lysaker, Norway; Simula Research Laboratory, SINTEF Information and Communication Technology, Trondheim, Norway; Simula Research Laboratory, Lysaker, Norway",IEEE Transactions on Software Engineering,8 Jan 2007,2007,33,2,65,86,"A total of 295 junior, intermediate, and senior professional Java consultants (99 individuals and 98 pairs) from 29 international consultancy companies in Norway, Sweden, and the UK were hired for one day to participate in a controlled experiment on pair programming. The subjects used professional Java tools to perform several change tasks on two alternative Java systems with different degrees of complexity. The results of this experiment do not support the hypotheses that pair programming in general reduces the time required to solve the tasks correctly or increases the proportion of correct solutions. On the other hand, there is a significant 84 percent increase in effort to perform the tasks correctly. However, on the more complex system, the pair programmers had a 48 percent increase in the proportion of correct solutions but no significant differences in the time taken to solve the tasks correctly. For the simpler system, there was a 20 percent decrease in time taken but no significant differences in correctness. However, the moderating effect of system complexity depends on the programmer expertise of the subjects. The observed benefits of pair programming in terms of correctness on the complex system apply mainly to juniors, whereas the reductions in duration to perform the tasks correctly on the simple system apply mainly to intermediates and seniors. It is possible that the benefits of pair programming will exceed the results obtained in this experiment for larger, more complex tasks and if the pair programmers have a chance to work together over a longer period of time",1939-3520,,10.1109/TSE.2007.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4052584,Empirical software engineering;pair programming;extreme programming;design principles;control styles;object-oriented programming;software maintainability;quasi-experiment.,Programming profession;Time measurement;Java;Software engineering;Software maintenance;Keyboards;Cost function;Power measurement;Computer industry,,176,,50,IEEE,8 Jan 2007,,,IEEE,IEEE Journals,True
"DESSERT: a DividE-and-conquer methodology for identifying categorieS, choiceS, and choicE Relations for Test case generation",T. Y. Chen; P. -L. Poon; S. -F. Tang; T. H. Tse,"Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, Australia; School of Accounting and Finance, Hong Kong Polytechnic University, Hong Kong, China; Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, Australia; Department of Computer Science, University of Hong Kong, Hong Kong, China",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,794,809,"This paper extends the choce relation framework, abbreviated as choc'late, which assists software testers in the application of category/choice methods to testing. choc'late assumes that the tester is able to construct a single choice relation table from the entire specification; this table then forms the basis for test case generation using the associated algorithms. This assumption, however, may not hold true when the specification is complex and contains many specification components. For such a specification, the tester may construct a preliminary choice relation table from each specification component, and then consolidate all the preliminary tables into a final table to be processed by choc'late for test case generation. However, it is often difficult to merge these preliminary tables because such merging may give rise to inconsistencies among choice relations or overlaps among choices. To alleviate this problem, we introduce a DividE-and-conquer methodology for identifying categorieS, choiceS, and choicE Relations for Test case generation, abbreviated as dessert. The theoretical framework and the associated algorithms are discussed. To demonstrate the viability and effectiveness of our methodology, we describe case studies using the specifications of three real-life commercial software systems.",1939-3520,,10.1109/TSE.2011.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963695,Black-box testing;category-partition method;choice relation framework;choice relation table;software testing;test case generation,Awards activities;Electronic mail;Software systems;Encoding;Software testing,,13,,18,IEEE,28 Jul 2011,,,IEEE,IEEE Journals,True
Quantifying the Effect of Code Smells on Maintenance Effort,D. I. K. Sjøberg; A. Yamashita; B. C. D. Anda; A. Mockus; T. Dybå,"Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway; Avaya Laboratories Research, Basking Ridge, NJ, USA; Universitetet i Oslo, Oslo, NO",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1144,1156,"Context: Code smells are assumed to indicate bad design that leads to less maintainable code. However, this assumption has not been investigated in controlled studies with professional software developers. Aim: This paper investigates the relationship between code smells and maintenance effort. Method: Six developers were hired to perform three maintenance tasks each on four functionally equivalent Java systems originally implemented by different companies. Each developer spent three to four weeks. In total, they modified 298 Java files in the four systems. An Eclipse IDE plug-in measured the exact amount of time a developer spent maintaining each file. Regression analysis was used to explain the effort using file properties, including the number of smells. Result: None of the 12 investigated smells was significantly associated with increased effort after we adjusted for file size and the number of changes; Refused Bequest was significantly associated with decreased effort. File size and the number of changes explained almost all of the modeled variation in effort. Conclusion: The effects of the 12 smells on maintenance effort were limited. To reduce maintenance effort, a focus on reducing code size and the work practices that limit the number of changes may be more beneficial than refactoring code smells.",1939-3520,,10.1109/TSE.2012.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392174,Maintainability;object-oriented design;product metrics;code churn,Maintenance engineering;Java;Software;Surgery;Time measurement;Context;Electronic mail,,234,,46,IEEE,21 Dec 2012,,,IEEE,IEEE Journals,True
The Impact of Lessons-Learned Sessions on Effort Estimation and Uncertainty Assessments,M. Jørgensen; T. M. Gruschke,"Simula Research Laboratory, University of Oslo, Strommen, Norway; KnowIT Objectnet, Oslo, Norway",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,368,383,"Inaccurate estimates of software development effort is a frequently reported cause of IT-project failures. We report results from a study that investigated the effect of introducing lessons-learned sessions on estimation accuracy and the assessment of uncertainty. Twenty software professionals were randomly allocated to a Learning group or a Control group and instructed to estimate and complete the same five development tasks. Those in the Learning group but not those in the Control group were instructed to spend at least 30 minutes on identifying, analyzing, and summarizing their effort estimation and uncertainty assessment experience after completing each task. We found that the estimation accuracy and the realism of the uncertainty assessment were not better in the Learning group than in the Control group. A follow-up study with 83 software professionals was completed to better understand this lack of improvement from lessons-learned sessions. The follow-up study found that receiving feedback about other software professionals' estimation performance led to more realistic uncertainty assessments than receiving the same feedback of one's own estimates. Lessons-learned sessions, not only in estimation contexts, have to be carefully designed to avoid wasting resources on learning processes that stimulate rather than reduce learning biases.",1939-3520,,10.1109/TSE.2009.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4752843,Cost estimation;process implementation and change;review and evaluation;software psychology.,Uncertainty;Yield estimation;Feedback;Programming;Software performance;Psychology;Software engineering;Computer industry;Acoustic reflection;Databases,,57,,42,IEEE,19 Jan 2009,,,IEEE,IEEE Journals,True
Goal-Directed Reasoning for Specification-Based Data Structure Repair,B. Demsky; M. C. Rinard,"Department of Electrical Engineering and Computer Science, University of California, Irvine, Irvine, CA, USA; Computer Science and Artificial Intelligence Laboratory, The Stata Center, MIT, Cambridge, MA, USA",IEEE Transactions on Software Engineering,30 Nov 2006,2006,32,12,931,951,"Software errors and hardware failures can cause data structures in running programs to violate key data structure consistency properties. As a result of this violation, the program may produce unacceptable results or even fail. We present a new data structure repair system. This system accepts a specification of data structure consistency properties stated in terms of an abstract set-and relation-based model of the data structures in the running program. It then automatically generates a repair algorithm that, during the execution of the program, detects and repairs any violations of these constraints. The goal is to enable the program to continue to execute acceptably in the face of otherwise crippling data structure corruption errors. We have applied our system to repair inconsistent data structures in five applications: CTAS (an air traffic control system), AbiWord (an open source word processing program), Freeciv (an interactive multiplayer game), a parallel x86 emulator, and a simplified Linux file system. Our results indicate that the generated repair algorithms can effectively repair inconsistent data structures in these applications to enable the applications to continue to operate successfully in cases where the original application would have failed. Without repair, all of the applications fail",1939-3520,,10.1109/TSE.2006.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4016571,Testing and debugging;language constructs and features.,Data structures;Application software;Software systems;Error correction codes;Hardware;Face detection;Air traffic control;Text processing;Linux;File systems,,32,,56,IEEE,30 Nov 2006,,,IEEE,IEEE Journals,True
Shallow knowledge as an aid to deep understanding in early phase requirements engineering,P. Sawyer; P. Rayson; K. Cosh,"Computing Department, Lancaster University, Lancaster, UK; Computing Department, Lancaster University, Lancaster, UK; Payap University, Chiang Mai, Thailand",IEEE Transactions on Software Engineering,12 Dec 2005,2005,31,11,969,981,"Requirements engineering's continuing dependence on natural language description has made it the focus of several efforts to apply language engineering techniques. The raw textual material that forms an input to early phase requirements engineering and which informs the subsequent formulation of the requirements is inevitably uncontrolled and this makes its processing very hard. Nevertheless, sufficiently robust techniques do exist that can be used to aid the requirements engineer provided that the scope of what can be achieved is understood. In this paper, we show how combinations of lexical and shallow semantic analysis techniques developed from corpus linguistics can help human analysts acquire the deep understanding needed as the first step towards the synthesis of requirements.",1939-3520,,10.1109/TSE.2005.129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1556555,Index Terms- Specification;elicitation methods;tools;linguistic processing;document analysis.,Knowledge engineering;Humans;Computer Society;Frequency;Natural languages;Information analysis;Speech analysis;Raw materials;Robustness;Text analysis,,65,5,53,IEEE,12 Dec 2005,,,IEEE,IEEE Journals,True
Generating Domain-Specific Visual Language Tools from Abstract Visual Specifications,J. C. Grundy; J. Hosking; K. N. Li; N. M. Ali; J. Huh; R. L. Li,"Centre for Computing and Engineering Software Systems, Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, VIC, Australia; College of Engineering and Computer Science, Australian National University, Canberra, ACT, Australia; SolNet Solutions Limited, Wellington, New Zealand; Faculty of Computer Science and Information Technology, Universiti Putra Malaysia, Serdang, Selangor, Malaysia; Centre for Software Innovation, Computer Science Department, and Auckland UniServices, University of Auckland, Auckland, New Zealand; Beef and Lamb New Zealand, Wellington, New Zealand",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,487,515,"Domain-specific visual languages support high-level modeling for a wide range of application domains. However, building tools to support such languages is very challenging. We describe a set of key conceptual requirements for such tools and our approach to addressing these requirements, a set of visual language-based metatools. These support definition of metamodels, visual notations, views, modeling behaviors, design critics, and model transformations and provide a platform to realize target visual modeling tools. Extensions support collaborative work, human-centric tool interaction, and multiplatform deployment. We illustrate application of the metatoolset on tools developed with our approach. We describe tool developer and cognitive evaluations of our platform and our exemplar tools, and summarize key future research directions.",1939-3520,,10.1109/TSE.2012.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6205768,Metatool;domain-specific visual language;software tool;visual specification;model-driven engineering,Visualization;Unified modeling language;Software;Computational modeling;Business;Abstracts;Electronic mail,,25,3,79,IEEE,29 May 2012,,,IEEE,IEEE Journals,True
A Systematic Review of the Application and Empirical Investigation of Search-Based Test Case Generation,S. Ali; L. C. Briand; H. Hemmati; R. K. Panesar-Walawege,"Simula Research Laboratory, University of Oslo, Lysaker, Norway; Simula Research Laboratory, University of Oslo, Lysaker, Norway; Simula Research Laboratory, University of Oslo, Lysaker, Norway; Simula Research Laboratory, University of Oslo, Lysaker, Norway",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,742,762,"Metaheuristic search techniques have been extensively used to automate the process of generating test cases, and thus providing solutions for a more cost-effective testing process. This approach to test automation, often coined “Search-based Software Testing” (SBST), has been used for a wide variety of test case generation purposes. Since SBST techniques are heuristic by nature, they must be empirically investigated in terms of how costly and effective they are at reaching their test objectives and whether they scale up to realistic development artifacts. However, approaches to empirically study SBST techniques have shown wide variation in the literature. This paper presents the results of a systematic, comprehensive review that aims at characterizing how empirical studies have been designed to investigate SBST cost-effectiveness and what empirical evidence is available in the literature regarding SBST cost-effectiveness and scalability. We also provide a framework that drives the data collection process of this systematic review and can be the starting point of guidelines on how SBST techniques can be empirically assessed. The intent is to aid future researchers doing empirical studies in SBST by providing an unbiased view of the body of empirical evidence and by guiding them in performing well-designed and executed empirical studies.",1939-3520,,10.1109/TSE.2009.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5210118,Evolutionary computing and genetic algorithms;frameworks;heuristics design;review and evaluation;test generation;testing strategies;validation.,System testing;Automatic testing;Software testing;Automation;Costs;Logic testing;Scalability;Guidelines;Genetic algorithms;Algorithm design and analysis,,304,,55,IEEE,21 Aug 2009,,,IEEE,IEEE Journals,True
Constructing Interaction Test Suites for Highly-Configurable Systems in the Presence of Constraints: A Greedy Approach,M. B. Cohen; M. B. Dwyer; J. Shi,"Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA; Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA; Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA",IEEE Transactions on Software Engineering,30 Sep 2008,2008,34,5,633,650,"Researchers have explored the application of combinatorial interaction testing (CIT) methods to construct samples to drive systematic testing of software system configurations. Applying CIT to highly-configurable software systems is complicated by the fact that, in many such systems, there are constraints between specific configuration parameters that render certain combinations invalid. Many CIT algorithms lack a mechanism to avoid these. In recent work, automated constraint solving methods have been combined with search-based CIT construction methods to address the constraint problem with promising results. However, these techniques can incur a non-trivial overhead. In this paper, we build upon our previous work to develop a family of greedy CIT sample generation algorithms that exploit calculations made by modern Boolean satisfiability (SAT) solvers to prune the search space of the CIT problem. We perform a comparative evaluation of the cost-effectiveness of these algorithms on four real-world highly-configurable software systems and on a population of synthetic examples that share the characteristics of those systems. In combination our techniques reduce the cost of CIT in the presence of constraints to 30 percent of the cost of widely-used unconstrained CIT methods without sacrificing the quality of the solutions.",1939-3520,,10.1109/TSE.2008.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4564473,Testing strategies;Testing tools;Testing strategies;Testing tools,System testing;Software systems;Software testing;Costs;Application software;Logic testing;Logic arrays;Production;Cameras;Computer Society,,236,4,45,IEEE,15 Jul 2008,,,IEEE,IEEE Journals,True
"Input Domain Reduction through Irrelevant Variable Removal and Its Effect on Local, Global, and Hybrid Search-Based Structural Test Data Generation",P. McMinn; M. Harman; K. Lakhotia; Y. Hassoun; J. Wegener,"Regent Court, University of Sheffield, Sheffield, UK; CREST, University College London, London, UK; CREST, University College London, London, UK; King's College, London, UK; Berner and Mattner Systemtechnik GmbH, Berlin, Germany",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,453,477,"Search-Based Test Data Generation reformulates testing goals as fitness functions so that test input generation can be automated by some chosen search-based optimization algorithm. The optimization algorithm searches the space of potential inputs, seeking those that are “fit for purpose,” guided by the fitness function. The search space of potential inputs can be very large, even for very small systems under test. Its size is, of course, a key determining factor affecting the performance of any search-based approach. However, despite the large volume of work on Search-Based Software Testing, the literature contains little that concerns the performance impact of search space reduction. This paper proposes a static dependence analysis derived from program slicing that can be used to support search space reduction. The paper presents both a theoretical and empirical analysis of the application of this approach to open source and industrial production code. The results provide evidence to support the claim that input domain reduction has a significant effect on the performance of local, global, and hybrid search, while a purely random search is unaffected.",1939-3520,,10.1109/TSE.2011.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710949,Search-based software testing;evolutionary testing;automated test data generation;input domain reduction.,Input variables;Software testing;Optimization;Algorithm design and analysis;Search problems;Software algorithms,,42,,52,IEEE,10 Feb 2011,,,IEEE,IEEE Journals,True
Genetic Algorithms for Randomized Unit Testing,J. H. Andrews; T. Menzies; F. C. H. Li,"Department of Computer Science, University of Western Ontario, London, ONT, Canada; Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Department of Computer Science, University of Western Ontario, London, ONT, Canada",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,80,94,"Randomized testing is an effective method for testing software units. The thoroughness of randomized unit testing varies widely according to the settings of certain parameters, such as the relative frequencies with which methods are called. In this paper, we describe Nighthawk, a system which uses a genetic algorithm (GA) to find parameters for randomized unit testing that optimize test coverage. Designing GAs is somewhat of a black art. We therefore use a feature subset selection (FSS) tool to assess the size and content of the representations within the GA. Using that tool, we can reduce the size of the representation substantially while still achieving most of the coverage found using the full representation. Our reduced GA achieves almost the same results as the full system, but in only 10 percent of the time. These results suggest that FSS could significantly optimize metaheuristic search-based software engineering tools.",1939-3520,,10.1109/TSE.2010.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704237,Software testing;randomized testing;genetic algorithms;feature subset selection;search-based optimization;testing tools.,Testing;Biological cells;Gallium;Receivers;Software;Java;Optimization,,57,,42,IEEE,28 Jan 2011,,,IEEE,IEEE Journals,True
A Machine Learning Approach to Software Requirements Prioritization,A. Perini; A. Susi; P. Avesani,"Fondazione Bruno Kessler, CIT-IRST, Trento, Italy; Fondazione Bruno Kessler, CIT-IRST, Trento, Italy; Fondazione Bruno Kessler, CIT-IRST, Trento, Italy",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,445,461,"Deciding which, among a set of requirements, are to be considered first and in which order is a strategic process in software development. This task is commonly referred to as requirements prioritization. This paper describes a requirements prioritization method called Case-Based Ranking (CBRank), which combines project's stakeholders preferences with requirements ordering approximations computed through machine learning techniques, bringing promising advantages. First, the human effort to input preference information can be reduced, while preserving the accuracy of the final ranking estimates. Second, domain knowledge encoded as partial order relations defined over the requirement attributes can be exploited, thus supporting an adaptive elicitation process. The techniques CBRank rests on and the associated prioritization process are detailed. Empirical evaluations of properties of CBRank are performed on simulated data and compared with a state-of-the-art prioritization method, providing evidence of the method ability to support the management of the tradeoff between elicitation effort and ranking accuracy and to exploit domain knowledge. A case study on a real software project complements these experimental measurements. Finally, a positioning of CBRank with respect to state-of-the-art requirements prioritization methods is proposed, together with a discussion of benefits and limits of the method.",1939-3520,,10.1109/TSE.2012.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249686,Requirements management;requirements prioritization;machine learning,Approximation methods;Accuracy;Software;Humans;Data models;Boosting,,109,,42,IEEE,26 Jul 2012,,,IEEE,IEEE Journals,True
A Model-Based Approach to Families of Embedded Domain-Specific Languages,J. Sanchez Cuadrado; J. G. Molina,"Department of Computers and Systems, Facultad de Informática, University of Murcia, Murcia, Spain; Department of Computers and Systems, Facultad de Informática, University of Murcia, Murcia, Spain",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,825,840,"With the emergence of model-driven engineering (MDE), the creation of domain-specific languages (DSLs) is becoming a fundamental part of language engineering. The development cost of a DSL should be modest compared to the cost of developing a general-purpose programming language. Reducing the implementation effort and providing reuse techniques are key aspects for DSL approaches to be really effective. In this paper, we present an approach to build embedded domain-specific languages applying the principles of model-driven engineering. On the basis of this approach, we will tackle reuse of DSLs by defining families of DSLs, addressing reuse both from the DSL developer and user point of views. A family of DSLs will be built up by composing several DSLs, so we will propose composition mechanisms for the abstract syntax, concrete syntax, and model transformation levels of a DSL's definition. Finally, we contribute a software framework to support our approach, and we illustrate the paper with a case study to demonstrate its practical applicability.",1939-3520,,10.1109/TSE.2009.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4782971,Domain-specific languages;model-driven development;families of DSLs;DSL composition.,Domain specific languages;DSL;Model driven engineering;Object oriented modeling;Costs;Computer languages;Concrete;Metamodeling;Proposals;Software engineering,,26,,38,IEEE,13 Feb 2009,,,IEEE,IEEE Journals,True
Session Reliability of Web Systems under Heavy-Tailed Workloads: An Approach Based on Design and Analysis of Experiments,N. Janevski; K. Goseva-Popstojanova,"Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1157,1178,"While workload characterization and performance of web systems have been studied extensively, reliability has received much less attention. In this paper, we propose a framework for session reliability modeling which integrates the user view represented by the session layer and the system view represented by the service layer. A unique characteristic of the session layer is that, in addition to the user navigation patterns, it incorporates the session length in number of requests and allows us to account for heavy-tailed workloads shown to exist in real web systems. The service layer is focused on the request reliability as it is observed at the service provider side. It considers the multifier web server architecture and the way components interact in serving each request. Within this framework, we develop a session reliability model and solve it using simulation. Instead of the traditional one-factor-at-a-time sensitivity analysis, we use statistical design and analysis of experiments, which allow us to identify the factors and interactions that have statistically significant effect on session reliability. Our findings indicate that session reliability, which accounts for the distribution of failed requests within sessions, provides better representation of the user perceived quality than the request-based reliability.",1939-3520,,10.1109/TSE.2013.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6409359,Reliability;statistical methods;modeling and prediction;simulation;web servers;Internet applications,Software reliability;Availability;Navigation;Web servers;Reliability engineering;Analytical models,,5,,58,IEEE,10 Jan 2013,,,IEEE,IEEE Journals,True
Supporting Domain Analysis through Mining and Recommending Features from Online Product Listings,N. Hariri; C. Castro-Herrera; M. Mirakhorli; J. Cleland-Huang; B. Mobasher,"Google Inc., Chicago, IL; Google Inc., Chicago, IL; Google Inc., Chicago, IL; DePaul University, School of Computing; Google Inc., Chicago, IL",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1736,1752,"Domain analysis is a labor-intensive task in which related software systems are analyzed to discover their common and variable parts. Many software projects include extensive domain analysis activities, intended to jumpstart the requirements process through identifying potential features. In this paper, we present a recommender system that is designed to reduce the human effort of performing domain analysis. Our approach relies on data mining techniques to discover common features across products as well as relationships among those features. We use a novel incremental diffusive algorithm to extract features from online product descriptions, and then employ association rule mining and the (k)-nearest neighbor machine learning method to make feature recommendations during the domain analysis process. Our feature mining and feature recommendation algorithms are quantitatively evaluated and the results are presented. Also, the performance of the recommender system is illustrated and evaluated within the context of a case study for an enterprise-level collaborative software suite. The results clearly highlight the benefits and limitations of our approach, as well as the necessary preconditions for its success.",1939-3520,,10.1109/TSE.2013.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6582404,Domain analysis;recommender systems;clustering;association rule mining;k-nearest neighbor,Feature extraction;Recommender systems;Clustering algorithms;Domain analysis;Data mining;Algorithm design and analysis;Electronic mail;Nearest neighbor search;Clustering,,74,,52,IEEE,16 Aug 2013,,,IEEE,IEEE Journals,True
A Systematic Study of Failure Proximity,C. Liu; X. Zhang; J. Han,"Microsoft Research, One Microsoft Way, Redmond, WA, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, University of Illinois, Urbana, IL, USA",IEEE Transactions on Software Engineering,12 Dec 2008,2008,34,6,826,843,"Software end-users are the best testers, who keep revealing bugs in software that has undergone rigorous in-house testing. In order to leverage their testing efforts, failure reporting components have been widely deployed in released software. Many utilities of the collected failure data depend on an effective failure indexing technique, which, at the optimal case, would index all failures due to the same bug together. Unfortunately, the problem of failure proximity, which underpins the effectiveness of an indexing technique, has not been systematically studied. This article presents the first systematic study of failure proximity. A failure proximity consists of two components: a fingerprinting function that extracts signatures from failures, and a distance function that calculates the likelihood of two failures being due to the same bug. By considering different instantiations of the two functions, we study an array of six failure proximities (two of them are new) in this article. These proximities range from the simplest approach that checks failure points to the most sophisticated approach that utilizes fault localization algorithms to extract failure signatures. Besides presenting technical details of each proximity, we also study the properties of each proximity and tradeoffs between proximities. These altogether deliver a systematic view of failure proximity.",1939-3520,,10.1109/TSE.2008.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4589219,Debugging aids;Dumps;Debugging aids;Dumps,Indexing;Failure analysis;Software maintenance;Software testing;Computer bugs;Software quality;Feedback;Debugging;Chaos;System testing,,35,2,65,IEEE,8 Aug 2008,,,IEEE,IEEE Journals,True
Size-Constrained Regression Test Case Selection Using Multicriteria Optimization,S. Mirarab; S. Akhlaghi; L. Tahvildari,"Department of Computer Science, University of Texas, Austin, Austin, TX, USA; Engineering Department, Shahed University, Tehran, Iran; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ONT, Canada",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,936,956,"To ensure that a modified software system has not regressed, one approach is to rerun existing test cases. However, this is a potentially costly task. To mitigate the costs, the testing effort can be optimized by executing only a selected subset of the test cases that are believed to have a better chance of revealing faults. This paper proposes a novel approach for selecting and ordering a predetermined number of test cases from an existing test suite. Our approach forms an Integer Linear Programming problem using two different coverage-based criteria, and uses constraint relaxation to find many close-to-optimal solution points. These points are then combined to obtain a final solution using a voting mechanism. The selected subset of test cases is then prioritized using a greedy algorithm that maximizes minimum coverage in an iterative manner. The proposed approach has been empirically evaluated and the results show significant improvements over existing approaches for some cases and comparable results for the rest. Moreover, our approach provides more consistency compared to existing approaches.",1939-3520,,10.1109/TSE.2011.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928351,Software regression testing;test case selection;integer programming;Pareto optimality,Testing;Software;Time factors;Fault detection;Optimization;Estimation;IP networks,,58,1,61,IEEE,23 Jun 2011,,,IEEE,IEEE Journals,True
Forecasting Risk Impact on ERP Maintenance with Augmented Fuzzy Cognitive Maps,J. L. Salmeron; C. Lopez,"School of Engineering, University Pablo de Olavide, Seville, Spain; School of Engineering, University Pablo de Olavide, Seville, Spain",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,439,452,"Worldwide, firms have made great efforts to implement Enterprise Resource Planning (ERP) systems. Despite these efforts, ERP adoption success is not guaranteed. Successful adoption of an ERP system also depends on proper system maintenance. For this reason, companies should follow a maintenance strategy that drives the ERP system toward success. However, in general, ERP maintenance managers do not know what conditions they should target to successfully maintain their ERP systems. Furthermore, numerous risks threaten these projects, but they are normally dealt with intuitively. To date, there has been limited literature published regarding ERP maintenance risks or ERP maintenance success. To address this need, we have built a dynamic simulation tool that allows ERP managers to foresee the impact of risks on maintenance goals. This research would help professionals manage their ERP maintenance projects. Moreover, it covers a significant gap in the literature.",1939-3520,,10.1109/TSE.2011.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680917,ERP;fuzzy cognitive maps;risk management;simulation;software maintenance.,Decision support systems,,71,,111,IEEE,6 Jan 2011,,,IEEE,IEEE Journals,True
Solving the Class Responsibility Assignment Problem in Object-Oriented Analysis with Multi-Objective Genetic Algorithms,M. Bowman; L. C. Briand; Y. Labiche,"Department of Systems and Computer Engineering, Carleton University, Ottawa, ONT, Canada; Simula Research Laboratory, University of Oslo, Lysaker, Norway; Department of Systems and Computer Engineering, Carleton University, Ottawa, ONT, Canada",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,817,837,"In the context of object-oriented analysis and design (OOAD), class responsibility assignment is not an easy skill to acquire. Though there are many methodologies for assigning responsibilities to classes, they all rely on human judgment and decision making. Our objective is to provide decision-making support to reassign methods and attributes to classes in a class diagram. Our solution is based on a multi-objective genetic algorithm (MOGA) and uses class coupling and cohesion measurement for defining fitness functions. Our MOGA takes as input a class diagram to be optimized and suggests possible improvements to it. The choice of a MOGA stems from the fact that there are typically many evaluation criteria that cannot be easily combined into one objective, and several alternative solutions are acceptable for a given OO domain model. Using a carefully selected case study, this paper investigates the application of our proposed MOGA to the class responsibility assignment problem, in the context of object-oriented analysis and domain class models. Our results suggest that the MOGA can help correct suboptimal class responsibility assignment decisions and perform far better than simpler alternative heuristics such as hill climbing and a single-objective GA.",1939-3520,,10.1109/TSE.2010.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5530324,Object-oriented analysis and design;class responsibility assignment;UML;genetic algorithm.,Algorithm design and analysis;Genetic algorithms;Object oriented modeling;Context modeling;Unified modeling language;Decision making;Humans;Software quality;Genetic engineering;Laboratories,,76,,40,IEEE,29 Jul 2010,,,IEEE,IEEE Journals,True
GenProg: A Generic Method for Automatic Software Repair,C. Le Goues; T. Nguyen; S. Forrest; W. Weimer,"Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,54,72,"This paper describes GenProg, an automated method for repairing defects in off-the-shelf, legacy programs without formal specifications, program annotations, or special coding practices. GenProg uses an extended form of genetic programming to evolve a program variant that retains required functionality but is not susceptible to a given defect, using existing test suites to encode both the defect and required functionality. Structural differencing algorithms and delta debugging reduce the difference between this variant and the original program to a minimal repair. We describe the algorithm and report experimental results of its success on 16 programs totaling 1.25 M lines of C code and 120K lines of module code, spanning eight classes of defects, in 357 seconds, on average. We analyze the generated repairs qualitatively and quantitatively to demonstrate that the process efficiently produces evolved programs that repair the defect, are not fragile input memorizations, and do not lead to serious degradation in functionality.",1939-3520,,10.1109/TSE.2011.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035728,Automatic programming;corrections;testing and debugging.,Maintenance engineering;Encoding;Computer bugs;Automatic programming;Debugging;Syntactics,,718,7,75,IEEE,6 Oct 2011,,,IEEE,IEEE Journals,True
Goal-Centric Traceability: Using Virtual Plumblines to Maintain Critical Systemic Qualities,J. Cleland-Huang; W. Marrero; B. Berenbach,"School of Computing, De Paul University, Chicago, IL, USA; School of Computing, De Paul University, Chicago, IL, USA; Siemens AG Corporate Research and Development, Princeton, NJ, USA",IEEE Transactions on Software Engineering,30 Sep 2008,2008,34,5,685,699,"Successful software development involves the elicitation, implementation, and management of critical systemic requirements related to qualities such as security, usability, and performance. Unfortunately, even when such qualities are carefully incorporated into the initial design and implemented code, there are no guarantees that they will be consistently maintained throughout the lifetime of the software system. Even though it is well known that system qualities tend to erode as functional and environmental changes are introduced, existing regression testing techniques are primarily designed to test the impact of change upon system functionality rather than to evaluate how it might affect more global qualities. The concept of using goal-centric traceability to establish relationships between a set of strategically placed assessment models and system goals is introduced. This paper describes the process, algorithms, and techniques for utilizing goal models to establish executable traces between goals and assessment models, detect change impact points through the use of automated traceability techniques, propagate impact events, and assess the impact of change upon systemic qualities. The approach is illustrated through two case studies.",1939-3520,,10.1109/TSE.2008.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4553719,Management;Maintenance management;Management;Maintenance management,Usability;System testing;Programming;Quality management;Software development management;Security;Software systems;Change detection algorithms;Event detection;Real time systems,,21,,59,IEEE,27 Jun 2008,,,IEEE,IEEE Journals,True
Empirical Studies of Pair Programming for CS/SE Teaching in Higher Education: A Systematic Literature Review,N. Salleh; E. Mendes; J. Grundy,"Department of Computer Science, International Islamic University Malaysia, Kuala Lumpur, Malaysia; Computer Science Department, University of Auckland, Auckland, New Zealand; Faculty of Information & Communication Technologies, Swinburne University of Technology, Hawthorn, VIC, Australia",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,509,525,"The objective of this paper is to present the current evidence relative to the effectiveness of pair programming (PP) as a pedagogical tool in higher education CS/SE courses. We performed a systematic literature review (SLR) of empirical studies that investigated factors affecting the effectiveness of PP for CS/SE students and studies that measured the effectiveness of PP for CS/SE students. Seventy-four papers were used in our synthesis of evidence, and 14 compatibility factors that can potentially affect PP's effectiveness as a pedagogical tool were identified. Results showed that students' skill level was the factor that affected PP's effectiveness the most. The most common measure used to gauge PP's effectiveness was time spent on programming. In addition, students' satisfaction when using PP was overall higher than when working solo. Our meta-analyses showed that PP was effective in improving students' grades on assignments. Finally, in the studies that used quality as a measure of effectiveness, the number of test cases succeeded, academic performance, and expert opinion were the quality measures mostly applied. The results of this SLR show two clear gaps in this research field: 1) a lack of studies focusing on pair compatibility factors aimed at making PP an effective pedagogical tool and 2) a lack of studies investigating PP for software design/modeling tasks in conjunction with programming tasks.",1939-3520,,10.1109/TSE.2010.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482588,Empirical studies;pair programming;systematic review.,Programming profession;Education;Educational programs;Computer science;Performance evaluation;Time measurement;Testing;Software design;Collaborative work;Algorithm design and analysis,,205,,75,IEEE,7 Jun 2010,,,IEEE,IEEE Journals,True
WASP: Protecting Web Applications Using Positive Tainting and Syntax-Aware Evaluation,W. Halfond; A. Orso; P. Manolios,"College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; College of Computer and Information Science, Northeastern University, Boston, MA, USA",IEEE Transactions on Software Engineering,31 Jan 2008,2008,34,1,65,81,"Many software systems have evolved to include a web-based component that makes them available to the public via the Internet and can expose them to a variety of web-based attacks. One of these attacks is SQL injection, which can give attackers unrestricted access to the databases underlying web applications and has become increasingly frequent and serious. This paper presents a new, highly automated approach for protecting web applications against SQL injection that has both conceptual and practical advantages over most existing techniques. From a conceptual standpoint, the approach is based on the novel idea of positive tainting and on the concept of syntax-aware evaluation. From a practical standpoint, our technique is precise and efficient and has minimal deployment requirements. We also present an extensive empirical evaluation of our approach performed using WASP, a tool that implements our technique. In the evaluation, we used WASP to protect a wide range of web applications while subjecting them to a large and varied set of attacks and legitimate accesses. WASP was able to stop all attacks and did not generate any false positives. Our studies also show that the overhead imposed by WASP was negligible in most cases.",1939-3520,,10.1109/TSE.2007.70748,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4359474,Protection mechanisms;Security and Protection;Protection mechanisms;Security and Protection,Protection;Databases;Application software;Computer Society;Internet;Runtime;Data security;Information security;Software systems;Performance evaluation,,91,2,31,IEEE,31 Jan 2008,,,IEEE,IEEE Journals,True
The Effect of Pairs in Program Design Tasks,K. M. Lui; K. C. C. Chan; J. Nosek,"Department of Computing, Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong, China; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA",IEEE Transactions on Software Engineering,31 Mar 2008,2008,34,2,197,211,"Pair programming involves-two developers simultaneously collaborating with each other on the same programming task to design and code a solution. Algorithm design and its implementation are normally interwoven in that implementation often provides feedback to enhance the design. Previous controlled pair programming experiments did not explore the efficacy of pairs versus individuals in program design-related tasks separately from coding. Variations in programmer skills in a particular language or an integrated development environment and the understanding of programming instructions can mask the skill of subjects in program design-related tasks. Programming aptitude tests (PATs) have been shown to correlate with programming performance. PATs do not require understanding of programming instructions and do not require a skill in any specific computer language. Two controlled experiments were conducted, with full-time professional programmers being the subjects who worked on increasingly complex programming aptitude tasks related to problem solving and algorithmic design. In both experiments, pairs significantly outperformed individuals, providing evidence of the value of pairs in program design-related tasks.",1939-3520,,10.1109/TSE.2007.70755,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378344,Experimental design;Programming teams;Experimental design;Programming teams,Programming profession;Algorithm design and analysis;Dynamic programming;Testing;Collaborative software;Collaborative work;Switches;Productivity;Time measurement;Collaboration,,29,,62,IEEE,31 Mar 2008,,,IEEE,IEEE Journals,True
Balancing Privacy and Utility in Cross-Company Defect Prediction,F. Peters; T. Menzies; L. Gong; H. Zhang,"Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1054,1068,"Background: Cross-company defect prediction (CCDP) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support CCDP, data must be shared. Such shared data must be privatized, but that privatization could severely damage the utility of the data. Aim: To enable effective defect prediction from shared data while preserving privacy. Method: We explore privatization algorithms that maintain class boundaries in a dataset. CLIFF is an instance pruner that deletes irrelevant examples. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. CLIFF+MORPH are tested in a CCDP study among 10 defect datasets from the PROMISE data repository. Results: We find: 1) The CLIFFed+MORPHed algorithms provide more privacy than the state-of-the-art privacy algorithms; 2) in terms of utility measured by defect prediction, we find that CLIFF+MORPH performs significantly better. Conclusions: For the OO defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction.",1939-3520,,10.1109/TSE.2013.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6419712,Privacy;classification;defect prediction,Testing;Software;Genetic algorithms;Sociology;Statistics;Search problems;Arrays,,117,,58,IEEE,24 Jan 2013,,,IEEE,IEEE Journals,True
Mutable Protection Domains: Adapting System Fault Isolation for Reliability and Efficiency,G. Parmer; R. West,"Department of Computer Science, George Washington University, Washington DC, DC, USA; Department of Computer Science, Boston University, Boston, MA, USA",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,875,888,"As software systems are becoming increasingly complex, the likelihood of faults and unexpected behaviors will naturally increase. Today, mobile devices to large-scale servers feature many millions of lines of code. Compile-time checks and offline verification methods are unlikely to capture all system states and control flow interactions of a running system. For this reason, many researchers have developed methods to contain faults at runtime by using software and hardware-based techniques to define protection domains. However, these approaches tend to impose isolation boundaries on software components that are static, and thus remain intact while the system is running. An unfortunate consequence of statically structured protection domains is that they may impose undue overhead on the communication between separate components. This paper proposes a new runtime technique that trades communication cost for fault isolation. We describe Mutable Protection Domains (MPDs) in the context of our Composite operating system. MPD dynamically adapts hardware isolation between interacting software components, depending on observed communication “hot-paths,” with the purpose of maximizing fault isolation where possible. In this sense, MPD naturally tends toward a system of maximal component isolation, while collapsing protection domains where costs are prohibitive. By increasing isolation for low-cost interacting components, MPD limits the scope of impact of future unexpected faults. We demonstrate the utility of MPD using a webserver, and identify different hot-paths for different workloads that dictate adaptations to system structure. Experiments show up to 40 percent improvement in throughput compared to a statically organized system, while maintaining high-fault isolation.",1939-3520,,10.1109/TSE.2011.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928356,Component-based;operating systems;reliability;fault isolation;performance,Kernel;Reliability;Hardware;Servers;Switches,,7,1,40,IEEE,23 Jun 2011,,,IEEE,IEEE Journals,True
Local versus Global Lessons for Defect Prediction and Effort Estimation,T. Menzies; A. Butcher; D. Cok; A. Marcus; L. Layman; F. Shull; B. Turhan; T. Zimmermann,"Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; GrammaTech, Inc., Ithaca, NY, USA; Wayne State University, Detroit, MI, USA; Fraunhofer Center, University of Maryland, College Park, MD, USA; Fraunhofer Center, University of Maryland, College Park, MD, USA; Department of Information Processing Science, University of Oulu, Oulu, Finland; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,822,834,"Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.",1939-3520,,10.1109/TSE.2012.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363444,Data mining;clustering;defect prediction;effort estimation,Estimation;Data models;Context;Java;Telecommunications;Measurement;Software,,201,,71,IEEE,29 Nov 2012,,,IEEE,IEEE Journals,True
Identifying Failure Causes in Java Programs: An Application of Change Impact Analysis,Xiaoxia Ren; O. C. Chesley; B. G. Ryder,"Division of Computer and Information Sciences, Rutgers University, Piscataway, NJ, USA; Division of Computer and Information Sciences, Rutgers University, Piscataway, NJ, USA; Division of Computer and Information Sciences, Rutgers University, Piscataway, NJ, USA",IEEE Transactions on Software Engineering,9 Oct 2006,2006,32,9,718,732,"During program maintenance, a programmer may make changes that enhance program functionality or fix bugs in code. Then, the programmer usually will run unit/regression tests to prevent invalidation of previously tested functionality. If a test fails unexpectedly, the programmer needs to explore the edit to find the failure-inducing changes for that test. Crisp uses results from Chianti, a tool that performs semantic change impact analysis [1], to allow the programmer to examine those parts of the edit that affect the failing test. Crisp then builds a compilable intermediate version of the program by adding a programmer-selected partial edit to the original code, augmenting the selection as necessary to ensure compilation. The programmer can reexecute the test on the intermediate version in order to locate the exact reasons for the failure by concentrating on the specific changes that were applied. In nine initial case studies on pairs of versions from two real Java programs, Daikon [2] and Eclipse jdt compiler [3], we were able to use Crisp to identify the failure-inducing changes for all but 1 of 68 failing tests. On average, 33 changes were found to affect each failing test (of the 67), but only 1-4 of these changes were found to be actually failure-inducing.",1939-3520,,10.1109/TSE.2006.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1707669,Fault localization;semantic change impact analysis;edit change dependence;regression testing;intermediate versions of programs.,Java;Failure analysis;Testing;Programming profession;Application software;Performance evaluation;Performance analysis;Prototypes;Computer Society;Computer bugs,,40,1,33,IEEE,9 Oct 2006,,,IEEE,IEEE Journals,True
Pert: The Application-Aware Tailoring of Java Object Persistence,P. Liu; C. Zhang,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,909,922,"Persistence is a widely used technique which allows the objects that represent the results of lengthy computations to outlive the process that creates it in order to considerably speed up subsequent program executions. We observe that conventional persistence techniques usually do not consider the application contexts of the persistence operations, where not all of the object states need to be persisted. Leveraging this observation, we have designed and implemented a framework called Pert, which first performs static program analysis to estimate the actual usage of the persisted object, given the context of its usage in the program. The Pert runtime uses the statically computed information to efficiently make tailoring decisions to prune the redundant and unused object states during the persistence operations. Our evaluation result shows that the Pert-based optimization can speed up the conventional persistence operations by 1 to 45 times. The amount of persisted data is also dramatically reduced, as the result of the application-aware tailoring.",1939-3520,,10.1109/TSE.2011.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963692,Object persistence;program analysis;performance optimization,Runtime;Anodes;Optimization;Context;Libraries;Java;Algorithm design and analysis,,2,,20,IEEE,28 Jul 2011,,,IEEE,IEEE Journals,True
Discovering Documentation for Java Container Classes,J. Henkel; C. Reichenbach; A. Diwan,"Google, Inc., Mountain View, CA, USA; Department of Computer Science, University of Colorado, Boulder, CO, USA; Department of Computer Science, University of Colorado, Boulder, CO, USA",IEEE Transactions on Software Engineering,9 Jul 2007,2007,33,8,526,543,"Modern programs make extensive use of reusable software libraries. For example, we found that 17% to 30% of the classes in a number of large Java applications use the container classes from the java.util package. Given this extensive code reuse in Java programs, it is important for the reusable interfaces to have clear and unambiguous documentation. Unfortunately, most documentation is expressed in English, and therefore does not always satisfy these requirements. Worse yet, there is no way of checking that the documentation is consistent with the associated code. Formal specifications present an alternative which does not suffer from these problems; however, formal specifications are notoriously hard to write. To alleviate this difficulty, we have implemented a tool which automatically derives documentation in the form of formal specifications. Our tool probes Java classes by invoking them on dynamically generated tests and captures the information observed during their execution as algebraic axioms. While the tool is not complete or correct from a formal perspective we demonstrate that it discovers many useful axioms when applied to container classes. These axioms then form an initial formal documentation of the class they describe.",1939-3520,,10.1109/TSE.2007.70705,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4267024,,Documentation;Java;Containers;Formal specifications;Libraries;Packaging;Probes;Testing;Data structures;Natural languages,,30,,60,IEEE,9 Jul 2007,,,IEEE,IEEE Journals,True
Exception Handling for Repair in Service-Based Processes,G. Friedrich; M. G. Fugini; E. Mussi; B. Pernici; G. Tagni,"Alpen-Adria-Universität Klagenfurt, Klagenfurt, Austria; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milan, Italy; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milan, Italy; Department of Artificial Intelligence, Faculty of Sciences, Vrije Universiteit Amsterdam, Amsterdam, Netherlands",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,198,215,"This paper proposes a self-healing approach to handle exceptions in service-based processes and to repair the faulty activities with a model-based approach. In particular, a set of repair actions is defined in the process model, and repairability of the process is assessed by analyzing the process structure and the available repair actions. During execution, when an exception arises, repair plans are generated by taking into account constraints posed by the process structure, dependencies among data, and available repair actions. The paper also describes the main features of the prototype developed to validate the proposed repair approach for composed Web services; the self-healing architecture for repair handling and the experimental results are illustrated.",1939-3520,,10.1109/TSE.2010.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383376,Exception handling;failures;faults;repair;self-healing processes;Web services;process management.,Web services;Prototypes;Service oriented architecture;Logic design;Proposals,,80,,60,IEEE,15 Jan 2010,,,IEEE,IEEE Journals,True
Model Checking Markov Chains with Actions and State Labels,C. Baier; L. Cloth; B. R. Haverkort; M. Kuntz; M. Siegle,"Institute for Theoretical Computer Science, Technische Universität Dresden, Dresden, Germany; EWI/DACS, University of Twente, Enschede, Netherlands; EWI/DACS, University of Twente, Enschede, Netherlands; EWI/DACS, University of Twente, Enschede, Netherlands; Fakultät für Informatik, Universität der Bundeswehr Munich, Neubiberg, Germany",IEEE Transactions on Software Engineering,12 Mar 2007,2007,33,4,209,224,"In the past, logics of several kinds have been proposed for reasoning about discrete-time or continuous-time Markov chains. Most of these logics rely on either state labels (atomic propositions) or on transition labels (actions). However, in several applications it is useful to reason about both state properties and action sequences. For this purpose, we introduce the logic as CSL which provides a powerful means to characterize execution paths of Markov chains with actions and state labels. asCSL can be regarded as an extension of the purely state-based logic CSL (continuous stochastic logic). In asCSL, path properties are characterized by regular expressions over actions and state formulas. Thus, the truth value of path formulas depends not only on the available actions in a given time interval, but also on the validity of certain state formulas in intermediate states. We compare the expressive power of CSL and asCSL and show that even the state-based fragment of asCSL is strictly more expressive than CSL if time intervals starting at zero are employed. Using an automaton-based technique, an asCSL formula and a Markov chain with actions and state labels are combined into a product Markov chain. For time intervals starting at zero, we establish a reduction of the model checking problem for asCSL to CSL model checking on this product Markov chain. The usefulness of our approach is illustrated with an elaborate model of a scalable cellular communication system, for which several properties are formalized by means of asCSL formulas and checked using the new procedure",1939-3520,,10.1109/TSE.2007.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4123324,Protocol verification;performance of systems;model checking;automata;Markov processes.,Stochastic processes;Probabilistic logic;Algebra;Power system modeling;Law;Legal factors;Automata;Markov processes;Embedded system;Petri nets,,41,,33,IEEE,12 Mar 2007,,,IEEE,IEEE Journals,True
Domain-Specific Service Selection for Composite Services,O. Moser; F. Rosenberg; S. Dustdar,"Distributed Systems Group, Information Systems Institute, University of Technology, Vienna, Vienna, Austria; T.J. Watson Research Center, IBM, Hawthorne, NY, USA; Distributed Systems Group, Information Systems Institute, University of Technology, Vienna, Vienna, Austria",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,828,843,"We propose a domain-specific service selection mechanism and system implementation to address the issue of runtime adaptation of composite services that implement mission-critical business processes. To this end, we leverage quality of service (QoS) as a means to specify rigid dependability requirements. QoS does not include only common attributes such as availability or response time but also attributes specific to certain business domains and processes. Therefore, we combine both domain-agnostic and domain-specific QoS attributes in an adaptive QoS model. For specifying the service selection strategy, we propose a domain-specific language called VieDASSL to specify so-called selectors. This language can be used to specify selector implementations based on the available QoS attributes. Both the QoS model implementation and the selectors can be adapted at runtime to deal with changing business and QoS requirements. Our approach is implemented on top of an existing WS-BPEL engine. We demonstrate its feasibility by implementing a case study from the telecommunication domain.",1939-3520,,10.1109/TSE.2011.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6231591,Service composition;quality of service;monitoring;service selection;domain specific languages,Quality of service;Runtime;Business;Adaptation models;Time factors;Availability;Engines,,28,,56,IEEE,3 Jul 2012,,,IEEE,IEEE Journals,True
Backward Bisimulation in Markov Chain Model Checking,J. Sproston; S. Donatelli,"Dipartimento di Informatica, Universita di Torino, Torino, Italy; Dipartimento di Informatica, Universita di Torino, Torino, Italy",IEEE Transactions on Software Engineering,18 Sep 2006,2006,32,8,531,546,"Equivalence relations can be used to reduce the state space of a system model, thereby permitting more efficient analysis. We study backward stochastic bisimulation in the context of model checking continuous-time Markov chains against continuous stochastic logic (CSL) properties. While there are simple CSL properties that are not preserved when reducing the state space of a continuous-time Markov chain using backward stochastic bisimulation, we show that the equivalence can nevertheless be used in the verification of a practically significant class of CSL properties. We consider an extension of these results to Markov reward models and continuous stochastic reward logic. Furthermore, we identify the logical properties for which the requirement on the equality of state-labeling sets (normally imposed on state equivalences in a model-checking context) can be omitted from the definition of the equivalence, resulting in a better state-space reduction",1939-3520,,10.1109/TSE.2006.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1703385,Markov processes;model checking;temporal logic;verification.,State-space methods;Stochastic processes;Logic;Stochastic systems;Context modeling;Petri nets;Algebra;Biological system modeling;Computer Society;System recovery,,23,,38,IEEE,18 Sep 2006,,,IEEE,IEEE Journals,True
Analyzing the Effect of Gain Time on Soft-Task Scheduling Policies in Real-Time Systems,L. Búrdalo; A. Terrasa; A. Espinosa; A. García-Fornes,"Universitat Politèecnica de València, Valencia; Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, Valencia, Spain; Departamento de Sistemas Informáticos y Computación, Universitat Politècnica de València, Valencia, Spain; Universitat Politèecnica de València, Valencia",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1305,1318,"In hard real-time systems, gain time is defined as the difference between the Worst Case Execution Time (WCET) of a hard task and its actual processor consumption at runtime. This paper presents the results of an empirical study about how the presence of a significant amount of gain time in a hard real-time system questions the advantages of using the most representative scheduling algorithms or policies for aperiodic or soft tasks in fixed-priority preemptive systems. The work presented here refines and complements many other studies in this research area in which such policies have been introduced and compared. This work has been performed by using the authors' testing framework for soft scheduling policies, which produces actual, synthetic, randomly generated applications, executes them in an instrumented Real-Time Operating System (RTOS), and finally processes this information to obtain several statistical outcomes. The results show that, in general, the presence of a significant amount of gain time reduces the performance benefit of the scheduling policies under study when compared to serving the soft tasks in background, which is considered the theoretical worst case. In some cases, this performance benefit is so small that the use of a specific scheduling policy for soft tasks is questionable.",1939-3520,,10.1109/TSE.2011.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025357,Real-time systems;RT-Linux;scheduling policies,Real time systems;Servers;Time factors;Generators;Scheduling;Heuristic algorithms;Decision support systems,,3,,31,IEEE,23 Sep 2011,,,IEEE,IEEE Journals,True
Guest Editorial: Special Issue on Software Maintenance and Evolution,M. Harman; B. Korel; P. K. Linos,"Department of Computer Science, Kings College London, Software Engineering Group, London, UK; Computer Science Department, Illinois Institute of Technology, Chicago, IL, USA; Fairbanks Center for Communications and Technology, Department of Computer Science and Software Engineering, Butler University, Indianapolis, IN, USA",IEEE Transactions on Software Engineering,21 Nov 2005,2005,31,10,801,803,"In systems developed without aspect-oriented programming, code implementing a crosscutting concern may be spread over many different parts of a system. Identifying such code automatically could be of great help during maintenance of the system. First of all, it allows a developer to more easily find the places in the code that must be changed when the concern changes and, thus, makes such changes less time consuming and less prone to errors. Second, it allows the code to be refactored to an aspect-oriented solution, thereby improving its modularity. In this paper, we evaluate the suitability of clone detection as a technique for the identification of crosscutting concerns. To that end, we manually identify five specific crosscutting concerns in an industrial C system and analyze to what extent clone detection is capable of finding them. We consider our results as a stepping stone toward an automated ""aspect miner” based on clone detection.",1939-3520,,10.1109/TSE.2005.113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542063,Index Terms- Clone detection;reverse engineering;aspect-oriented programming;crosscutting concerns;aspect mining.,Software maintenance;Conferences;Computer science;Software engineering;Software algorithms;Programming;Cloning;Software systems;Costs;Humans,,1,,,IEEE,21 Nov 2005,,,IEEE,IEEE Journals,True
Guest Editors' Introduction to the Special Section on Exception Handling: From Requirements to Software Maintenance,A. Garcia; A. Romanovsky; V. Issarny,"Infomatics Department, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Rio de Janeiro, Brazil; School of Computing Science, University of Newcastle, Newcastle-upon-Tyne, UK; Paris-Rocquencourt, INRIA UR Rocquencourt Domaine de Voluceau, INRIA, Chesney, France",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,147,149,The four papers in this special section focus on topics related to exception handling.,1939-3520,,10.1109/TSE.2010.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5439569,,Software maintenance;Application software;Software systems;Computer languages;Programming;Software quality;Software engineering;Protection;Pressing;Reflection,,,,70,IEEE,29 Mar 2010,,,IEEE,IEEE Journals,True
Guest Editors' Introduction to the Special Section from the International Conference on Software Maintenance,G. Canfora; L. Tahvildari; H. A. Muller,"Department of Engineering, University of Sannio, Benevento, Italy; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ONT, Canada; Department of Computer Science, Engineering Computer Science Building (ECS), University of Victoria, Victoria, BC, Canada",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,450,451,"The two papers in this special section are extended and enhanced versions of ones presented at the International Conference on Software Maintenance (ICSM), held in Paris, France, on 2-5 October 2007.",1939-3520,,10.1109/TSE.2009.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5186362,,Software maintenance;Computer Society;Conferences;Computer science;Software testing;Tagging;Programming profession;Navigation;Cities and towns;Sections,,,,,IEEE,31 Jul 2009,,,IEEE,IEEE Journals,True
"Small Errors in ""Toward Formalizing Domain Modeling Semantics in Language Syntax'",R. J. Botting,"Computer Science Department, California State University, San Bernardino, San Bernardino, CA, USA",IEEE Transactions on Software Engineering,21 Nov 2005,2005,31,10,911,911,A recent paper on domain modeling had State Charts with semantic errors.,1939-3520,,10.1109/TSE.2005.116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1542071,Index Terms- UML;semantics;state charts.,Computer errors;Rails;Computer science,,,,2,IEEE,21 Nov 2005,,,IEEE,IEEE Journals,True
"Errata for ""Discovering Documentation for Java Container Classes"" [Aug 07 526-543]",J. Henkel; C. Reichenbach; A. Diwan,"Department of Computer Science, University of Colorado, Boulder, CO; Department of Computer Science, University of Colorado, Boulder, CO; Department of Computer Science, University of Colorado, Boulder, CO",IEEE Transactions on Software Engineering,31 Mar 2008,2008,34,2,303,303,"In the above titled paper (ibid., vol. 33, no. 8, pp. 526-543, Aug 07), there were several mistakes. The corrections are presented here.",1939-3520,,10.1109/TSE.2008.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4476755,,Documentation;Java;Containers;Equations;Computer science,,,,1,IEEE,31 Mar 2008,,,IEEE,IEEE Journals,True
IEEE Computer Society Magazines and Transactions available in ePUB format [advertisement],,,IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,878,878,Advertisement: IEEE Computer Society Magazines and Transactions in ePUB format.,1939-3520,,10.1109/TSE.2011.117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095282,,,,,,,IEEE,5 Dec 2011,,,IEEE,IEEE Journals,True
How does Machine Learning Change Software Development Practices?,Z. Wan; X. Xia; D. Lo; G. C. Murphy,"College of Computer Science and Technology, Ningbo Research Institute, Zhejiang University, Hangzhou, China; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Information Systems, Singapore Management University, Singapore",IEEE Transactions on Software Engineering,16 Sep 2021,2021,47,9,1857,1871,"Adding an ability for a system to learn inherently adds uncertainty into the system. Given the rising popularity of incorporating machine learning into systems, we wondered how the addition alters software development practices. We performed a mixture of qualitative and quantitative studies with 14 interviewees and 342 survey respondents from 26 countries across four continents to elicit significant differences between the development of machine learning systems and the development of non-machine-learning systems. Our study uncovers significant differences in various aspects of software engineering (e.g., requirements, design, testing, and process) and work characteristics (e.g., skill variety, problem solving and task identity). Based on our findings, we highlight future research directions and provide recommendations for practitioners.",1939-3520,,10.1109/TSE.2019.2937083,National Key Research and Development Program of China(grant numbers:2018YFB1003904); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812912,Software engineering;machine learning;practitioner;empirical study,Software;Interviews;Data models;Machine learning;Testing;Task analysis;Software engineering,,73,,40,IEEE,26 Aug 2019,,,IEEE,IEEE Journals,True
Researcher Bias: The Use of Machine Learning in Software Defect Prediction,M. Shepperd; D. Bowes; T. Hall,"Brunel University, Uxbridge, Middlesex, United Kingdom; Science and Technology Research Institute, University of Hertfordshire, Hatfield, Hertfordshire, United Kingdom; Brunel University, Uxbridge, Middlesex, United Kingdom",IEEE Transactions on Software Engineering,16 Jun 2014,2014,40,6,603,616,"Background. The ability to predict defect-prone software components would be valuable. Consequently, there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect onpredictive performance. Method. We conduct a meta-analysis of all relevant, high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build arandom effects ANOVA model to examine the relative contribution of four model building factors (classifier, data set, input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion.  To overcome this high level of researcher bias, defect prediction researchers should (i) conduct blind analysis, (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly, research is required to determine whether this bias is prevalent in other applications domains.",1939-3520,,10.1109/TSE.2014.2322358,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824804,Software defect prediction;meta-analysis;researcher bias,Software;Predictive models;Correlation;Data models;Buildings;Software engineering;Measurement,,259,,53,IEEE,3 Jun 2014,,,IEEE,IEEE Journals,True
Authors’ Reply to “Comments on ‘Researcher Bias: The Use of Machine Learning in Software Defect Prediction’”,M. Shepperd; T. Hall; D. Bowes,"Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; University of Hertfordshire, Hatfield, United Kingdom",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1129,1131,"In 2014 we published a meta-analysis of software defect prediction studies [1] . This suggested that the most important factor in determining results was Research Group, i.e., who conducts the experiment is more important than the classifier algorithms being investigated. A recent re-analysis [2] sought to argue that the effect is less strong than originally claimed since there is a relationship between Research Group and Dataset. In this response we show (i) the re-analysis is based on a small (21 percent) subset of our original data, (ii) using the same re-analysis approach with a larger subset shows that Research Group is more important than type of Classifier and (iii) however the data are analysed there is compelling evidence that who conducts the research has an effect on the results. This means that the problem of researcher bias remains. Addressing it should be seen as a matter of priority amongst those of us who conduct and publish experiments comparing the performance of competing software defect prediction systems.",1939-3520,,10.1109/TSE.2017.2731308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990255,Software quality assurance;defect prediction;researcher bias,Software;NASA;Measurement;Analysis of variance;Data models;Predictive models;Analytical models,,8,,5,IEEE,24 Jul 2017,,,IEEE,IEEE Journals,True
Impact of Introducing Domain-Specific Modelling in Software Maintenance: An Industrial Case Study,N. Mellegård; A. Ferwerda; K. Lind; R. Heldal; M. R. V. Chaudron,"Electromobility Group at the Research Institute Viktoria Swedish ICT, Gothenburg, Sweden; Centric, Gouda, The Netherlands; Electromobility Group at the Research Institute Viktoria Swedish ICT, Gothenburg, Sweden; Software Engineering Division at the joint Department of Computer Science and Engineering, Chalmers and Gothenborg University, Gothenburg, Sweden; Software Engineering Division at the joint Department of Computer Science and Engineering, Chalmers and Gothenborg University, Gothenburg, Sweden",IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,245,260,"Domain-specific modelling (DSM) is a modern software development technology that aims at enhancing productivity. One of the claimed advantages of DSM is increased maintainability of software. However, current empirical evidence supporting this claim is lacking. In this paper, we contribute evidence from a case study conducted at a software development company. We study how the introduction of DSM affected the maintenance of a legacy system. We collected data about the maintenance phase of a system that was initially developed using manual programming, but which was gradually replaced by DSM development. We performed statistical analyses of the relation between the use of DSM and the time needed to resolve defects, the defect density, and the phase in which defects were detected. The results show that after introducing DSM the defect density is lower, that defects are found earlier, but resolving defects takes longer. Other observed benefits are that the number of developers and the number of person-hours needed for maintaining the system decreased, and the portability to new platforms increased. Our findings are useful for organizations that consider introducing DSM and would like to know which benefits can be realized in software maintenance.",1939-3520,,10.1109/TSE.2015.2479221,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270333,Empirical investigation;software maintenance;maintenance measurement;process measurement;productivity;Empirical investigation;software maintenance;maintenance measurement;process measurement;productivity,DSL;Maintenance engineering;Unified modeling language;Business;Software maintenance;Productivity,,11,,42,IEEE,16 Sep 2015,,,IEEE,IEEE Journals,True
Impact of Discretization Noise of the Dependent Variable on Machine Learning Classifiers in Software Engineering,G. K. Rajbahadur; S. Wang; Y. Kamei; A. E. Hassan,"Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Principles of Software Languages (POSL) Lab, Graduate School and Faulty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,16 Jul 2021,2021,47,7,1414,1430,"Researchers usually discretize a continuous dependent variable into two target classes by introducing an artificial discretization threshold (e.g., median). However, such discretization may introduce noise (i.e., discretization noise) due to ambiguous class loyalty of data points that are close to the artificial threshold. Previous studies do not provide a clear directive on the impact of discretization noise on the classifiers and how to handle such noise. In this paper, we propose a framework to help researchers and practitioners systematically estimate the impact of discretization noise on classifiers in terms of its impact on various performance measures and the interpretation of classifiers. Through a case study of 7 software engineering datasets, we find that: 1) discretization noise affects the different performance measures of a classifier differently for different datasets; 2) Though the interpretation of the classifiers are impacted by the discretization noise on the whole, the top 3 most important features are not affected by the discretization noise. Therefore, we suggest that practitioners and researchers use our framework to understand the impact of discretization noise on the performance of their built classifiers and estimate the exact amount of discretization noise to be discarded from the dataset to avoid the negative impact of such noise.",1939-3520,,10.1109/TSE.2019.2924371,JSPS KAKENHI(grant numbers:JP18H03222); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744330,Discretization noise;discretization;classifiers;feature importance analysis;performance;random forest;logistic regression;decision trees;KNN,Software engineering;Computer bugs;Noise measurement;Software;Machine learning;Regression tree analysis;Logistics,,17,,76,IEEE,24 Jun 2019,,,IEEE,IEEE Journals,True
A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction,Q. Song; Y. Guo; M. Shepperd,"Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science, Brunel University, Uxbridge, United Kingdom",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1253,1269,"Context: Software defect prediction (SDP) is an important challenge in the field of software engineering, hence much research work has been conducted, most notably through the use of machine learning algorithms. However, class-imbalance typified by few defective components and many non-defective ones is a common occurrence causing difficulties for these methods. Imbalanced learning aims to deal with this problem and has recently been deployed by some researchers, unfortunately with inconsistent results. Objective: We conduct a comprehensive experiment to explore (a) the basic characteristics of this problem; (b) the effect of imbalanced learning and its interactions with (i) data imbalance, (ii) type of classifier, (iii) input metrics and (iv) imbalanced learning method. Method: We systematically evaluate 27 data sets, 7 classifiers, 7 types of input metrics and 17 imbalanced learning methods (including doing nothing) using an experimental design that enables exploration of interactions between these factors and individual imbalanced learning algorithms. This yields 27 × 7 × 7 × 17 = 22491 results. The Matthews correlation coefficient (MCC) is used as an unbiased performance measure (unlike the more widely used F1 and AUC measures). Results: (a) we found a large majority (87 percent) of 106 public domain data sets exhibit moderate or low level of imbalance (imbalance ratio <; 10; median = 3.94); (b) anything other than low levels of imbalance clearly harm the performance of traditional learning for SDP; (c) imbalanced learning is more effective on the data sets with moderate or higher imbalance, however negative results are always possible; (d) type of classifier has most impact on the improvement in classification performance followed by the imbalanced learning method itself. Type of input metrics is not influential. (e) only 52% of the combinations of Imbalanced Learner and Classifier have a significant positive effect. Conclusion: This paper offers two practical guidelines. First, imbalanced learning should only be considered for moderate or highly imbalanced SDP data sets. Second, the appropriate combination of imbalanced method and classifier needs to be carefully chosen to ameliorate the imbalanced learning problem for SDP. In contrast, the indiscriminate application of imbalanced learning can be harmful.",1939-3520,,10.1109/TSE.2018.2836442,"National Natural Science Foundation of China(grant numbers:61373046,61210004); Brunel University London; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359087,Software defect prediction;bug prediction;imbalanced learning;imbalance ratio;effect size,Software measurement;Boosting;Machine learning algorithms;Bagging;Computer bugs,,187,,92,IEEE,15 May 2018,,,IEEE,IEEE Journals,True
The Role of Method Chains and Comments in Software Readability and Comprehension—An Experiment,J. Börstler; B. Paech,"Department of Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Computer Science, Heidelberg University, Heidelberg, Germany",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,886,898,"Software readability and comprehension are important factors in software maintenance. There is a large body of research on software measurement, but the actual factors that make software easier to read or easier to comprehend are not well understood. In the present study, we investigate the role of method chains and code comments in software readability and comprehension. Our analysis comprises data from 104 students with varying programming experience. Readability and comprehension were measured by perceived readability, reading time and performance on a simple cloze test. Regarding perceived readability, our results show statistically significant differences between comment variants, but not between method chain variants. Regarding comprehension, there are no significant differences between method chain or comment variants. Student groups with low and high experience, respectively, show significant differences in perceived readability and performance on the cloze tests. Our results do not show any significant relationships between perceived readability and the other measures taken in the present study. Perceived readability might therefore be insufficient as the sole measure of software readability or comprehension. We also did not find any statistically significant relationships between size and perceived readability, reading time and comprehension.",1939-3520,,10.1109/TSE.2016.2527791,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404062,Software readability;software comprehension;software measurement;comments;method chains;experiment,Software;Guidelines;Software measurement;Software engineering;Programming;Complexity theory;Object oriented modeling,,30,,57,OAPA,11 Feb 2016,,,IEEE,IEEE Journals,True
Asymmetric Release Planning: Compromising Satisfaction against Dissatisfaction,M. Nayebi; G. Ruhe,"Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada; Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada",IEEE Transactions on Software Engineering,17 Sep 2019,2019,45,9,839,857,"Maximizing satisfaction from offering features as part of the upcoming release(s) is different from minimizing dissatisfaction gained from not offering features. This asymmetric behavior has never been utilized for product release planning. We study Asymmetric Release Planning (ARP) by accommodating asymmetric feature evaluation. We formulated and solved ARP as a bi-criteria optimization problem. In its essence, it is the search for optimized trade-offs between maximum stakeholder satisfaction and minimum dissatisfaction. Different techniques including a continuous variant of Kano analysis are available to predict the impact on satisfaction and dissatisfaction with a product release from offering or not offering a feature. As a proof of concept,we validated the proposed solution approach called Satisfaction-Dissatisfaction Optimizer (SDO) via a real-world case study project. From running three replications with varying effort capacities, we demonstrate that SDO generates optimized trade-off solutions being (i) of a different value profile and different structure, (ii) superior to the application of random search and heuristics in terms of quality and completeness, and (iii) superior to the usage of manually generated solutions generated from managers of the case study company. A survey with 20 stakeholders evaluated the applicability and usefulness of the generated results.",1939-3520,,10.1109/TSE.2018.2810895,Natural Sciences and Engineering Research Council of Canada(grant numbers:250343-12); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307259,Release planning;bi-objective optimization;stakeholder satisfaction;stakeholder dissatisfaction;case study;empirical evaluation,Planning;Stakeholders;Software engineering;Software;Streaming media;Mathematical model;Optimization,,13,,79,IEEE,6 Mar 2018,,,IEEE,IEEE Journals,True
On the Multiple Sources and Privacy Preservation Issues for Heterogeneous Defect Prediction,Z. Li; X. -Y. Jing; X. Zhu; H. Zhang; B. Xu; S. Ying,"State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, China; College of Automation, Nanjing University of Posts and Telecommunications, Nanjing, China; School of Computer and Information Engineering, Henan University, Kaifeng, China; School of Electrical Engineering and Computing, University of Newcastle, Callaghan, NSW, Australia; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, China",IEEE Transactions on Software Engineering,16 Apr 2019,2019,45,4,391,411,"Heterogeneous defect prediction (HDP) refers to predicting defect-proneness of software modules in a target project using heterogeneous metric data from other projects. Existing HDP methods mainly focus on predicting target instances with single source. In practice, there exist plenty of external projects. Multiple sources can generally provide more information than a single project. Therefore, it is meaningful to investigate whether the HDP performance can be improved by employing multiple sources. However, a precondition of conducting HDP is that the external sources are available. Due to privacy concerns, most companies are not willing to share their data. To facilitate data sharing, it is essential to study how to protect the privacy of data owners before they release their data. In this paper, we study the above two issues in HDP. Specifically, to utilize multiple sources effectively, we propose a multi-source selection based manifold discriminant alignment (MSMDA) approach. To protect the privacy of data owners, a sparse representation based double obfuscation algorithm is designed and applied to HDP. Through a case study of 28 projects, our results show that MSMDA can achieve better performance than a range of baseline methods. The improvement is 3.4-15.3 percent in g-measure and 3.0-19.1 percent in AUG.",1939-3520,,10.1109/TSE.2017.2780222,"General Technology Fundamental Research United Fund(grant numbers:U1736211); National Key Research and Development Program of China(grant numbers:2017YFB0202001); National Natural Science Foundation of China(grant numbers:61373038,61672392,61472178,61672208,U1404618,41571417); Science and Technology Program in Henan province(grant numbers:1721102410064); Science and Technique Development Program of Henan(grant numbers:172102210186); Province-School-Region Project of Henan University(grant numbers:2016S11); Research Foundation of Henan University(grant numbers:2015YBZR024); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168387,Heterogeneous defect prediction;multiple sources;privacy preservation;utility;source selection;manifold discriminant alignment,Measurement;Software;Data privacy;Privacy;Predictive models;Training data;Companies,,67,,101,IEEE,6 Dec 2017,,,IEEE,IEEE Journals,True
The Use of Summation to Aggregate Software Metrics Hinders the Performance of Defect Prediction Models,F. Zhang; A. E. Hassan; S. McIntosh; Y. Zou,"School of Computing, Queen's University, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,12 May 2017,2017,43,5,476,491,"Defect prediction models help software organizations to anticipate where defects will appear in the future. When training a defect prediction model, historical defect data is often mined from a Version Control System (VCS, e.g., Subversion), which records software changes at the file-level. Software metrics, on the other hand, are often calculated at the class- or method-level (e.g., McCabe's Cyclomatic Complexity). To address the disagreement in granularity, the class- and method-level software metrics are aggregated to file-level, often using summation (i.e., McCabe of a file is the sum of the McCabe of all methods within the file). A recent study shows that summation significantly inflates the correlation between lines of code (Sloc) and cyclomatic complexity (Cc) in Java projects. While there are many other aggregation schemes (e.g., central tendency, dispersion), they have remained unexplored in the scope of defect prediction. In this study, we set out to investigate how different aggregation schemes impact defect prediction models. Through an analysis of 11 aggregation schemes using data collected from 255 open source projects, we find that: (1) aggregation schemes can significantly alter correlations among metrics, as well as the correlations between metrics and the defect count; (2) when constructing models to predict defect proneness, applying only the summation scheme (i.e., the most commonly used aggregation scheme in the literature) only achieves the best performance (the best among the 12 studied configurations) in 11 percent of the studied projects, while applying all of the studied aggregation schemes achieves the best performance in 40 percent of the studied projects; (3) when constructing models to predict defect rank or count, either applying only the summation or applying all of the studied aggregation schemes achieves similar performance, with both achieving the closest to the best performance more often than the other studied aggregation schemes; and (4) when constructing models for effort-aware defect prediction, the mean or median aggregation schemes yield performance values that are significantly closer to the best performance than any of the other studied aggregation schemes. Broadly speaking, the performance of defect prediction models are often underestimated due to our community's tendency to only use the summation aggregation scheme. Given the potential benefit of applying additional aggregation schemes, we advise that future defect prediction models should explore a variety of aggregation schemes.",1939-3520,,10.1109/TSE.2016.2599161,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539677,Defect prediction;aggregation scheme;software metrics,Predictive models;Correlation;Software metrics;Indexes;Software;Data models,,62,,87,IEEE,10 Aug 2016,,,IEEE,IEEE Journals,True
Developer Micro Interaction Metrics for Software Defect Prediction,T. Lee; J. Nam; D. Han; S. Kim; H. Peter In,"Korea University, Seoul, South Korea; University of Waterloo, ON, Canada; University Colleage London, London, United Kingdom; Hong Kong University of Science and Technology, Hong Kong, China; Korea University, Seoul, South Korea",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1015,1035,"To facilitate software quality assurance, defect prediction metrics, such as source code metrics, change churns, and the number of previous defects, have been actively studied. Despite the common understanding that developer behavioral interaction patterns can affect software quality, these widely used defect prediction metrics do not consider developer behavior. We therefore propose micro interaction metrics (MIMs), which are metrics that leverage developer interaction information. The developer interactions, such as file editing and browsing events in task sessions, are captured and stored as information by Mylyn, an Eclipse plug-in. Our experimental evaluation demonstrates that MIMs significantly improve overall defect prediction accuracy when combined with existing software measures, perform well in a cost-effective manner, and provide intuitive feedback that enables developers to recognize their own inefficient behaviors during software development.",1939-3520,,10.1109/TSE.2016.2550458,"Next-Generation Information Computing Development Program; National Research Foundation of Korea; Ministry of Education, Science and Technology(grant numbers:2012M3C4A7033345); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447797,Defect prediction;software quality;software metrics;developer interaction;Mylyn,Software quality;Software metrics;Quality assurance;Complexity theory,,45,,66,OAPA,5 Apr 2016,,,IEEE,IEEE Journals,True
Automatic Repair of Timestamp Comparisons,G. Liva; M. T. Khan; M. Pinzger; F. Spegni; L. Spalazzi,"Department of Software Engineering, Alpen-Adria Universität Klagenfurt, Klagenfurt, Austria; School of Computing and Mathematical Sciences, University of Greenwich, London, United Kingdom; Department of Software Engineering, Alpen-Adria Universität Klagenfurt, Klagenfurt, Austria; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2369,2381,"Automated program repair has the potential to reduce the developers’ effort to fix errors in their code. In particular, modern programming languages, such as Java, C, and C#, represent time as integer variables that suffer from integer overflow, introducing subtle errors that are hard to discover and repair. Recent researches on automated program repair rely on test cases to discover failures to correct, making them suitable only for regression errors. We propose a new strategy to automatically repair programs that suffer from timestamp overflows that are manifested in comparison expressions. It unifies the benefits of static analysis and automatic program repair avoiding dependency on testing to identify and correct defected code. Our approach performs an abstract analysis over the time domain of a program using a Time Type System to identify the problematic comparison expressions. The repairing strategy rewrites the timestamp comparisons exploiting the binary representation of machine numbers to correct the code. We have validated the applicability of our approach with 20 open source Java projects. The results show that it is able to correctly repair all 246 identified errors. To further validate the reliability of our approach, we have proved the soundness of both, type system and repairing strategy. Furthermore, several patches for three open source projects have been acknowledged and accepted by their developers.",1939-3520,,10.1109/TSE.2019.2948351,Austrian Research Promotion Agency(grant numbers:850757); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877769,Software/program verification;formal methods;error handling and recovery,Maintenance engineering;Java;Semantics;Static analysis;Software;Testing,,2,,52,IEEE,21 Oct 2019,,,IEEE,IEEE Journals,True
Requirements Elicitation and Specification Using the Agent Paradigm: The Case Study of an Aircraft Turnaround Simulator,T. Miller; B. Lu; L. Sterling; G. Beydoun; K. Taveter,"Department of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria, Autralia; Department of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria, Autralia; Faculty of ICT, Swinburne University of Technology, Melbourne, Victoria, Autralia; Faculty of Informatics, University of Wollongong, Wollongong, NSW 2522, Australia; Institute of Informatics, Tallinn University of Technology, Tallinn, EU, Estonia",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,1007,1024,"In this paper, we describe research results arising from a technology transfer exercise on agent-oriented requirements engineering with an industry partner. We introduce two improvements to the state-of-the-art in agent-oriented requirements engineering, designed to mitigate two problems experienced by ourselves and our industry partner: (1) the lack of systematic methods for agent-oriented requirements elicitation and modelling; and (2) the lack of prescribed deliverables in agent-oriented requirements engineering. We discuss the application of our new approach to an aircraft turnaround simulator built in conjunction with our industry partner, and show how agent-oriented models can be derived and used to construct a complete requirements package. We evaluate this by having three independent people design and implement prototypes of the aircraft turnaround simulator, and comparing the three prototypes. Our evaluation indicates that our approach is effective at delivering correct, complete, and consistent requirements that satisfy the stakeholders, and can be used in a repeatable manner to produce designs and implementations. We discuss lessons learnt from applying this approach.",1939-3520,,10.1109/TSE.2014.2339827,Australian Research Council Linkage(grant numbers:LP0882140); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6860260,Agent-oriented software engineering;agent-oriented modelling;technology transfer,Object oriented modeling;Aircraft;Atmospheric modeling;Software;Industries;Analytical models;Educational institutions,,39,,46,IEEE,18 Jul 2014,,,IEEE,IEEE Journals,True
The Impact of Automated Parameter Optimization on Defect Prediction Models,C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto,"School of Computer Science, University of Adelaide, Adelaide, SA, Australia; Department of Electrical and Computer Engineering, McGill University, Montréal, Quebec, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Takayamacho, Japa",IEEE Transactions on Software Engineering,16 Jul 2019,2019,45,7,683,711,"Defect prediction models-classifiers that identify defect-prone software modules-have configurable parameters that control their characteristics (e.g., the number of trees in a random forest). Recent studies show that these classifiers underperform when default settings are used. In this paper, we study the impact of automated parameter optimization on defect prediction models. Through a case study of 18 datasets, we find that automated parameter optimization: (1) improves AUC performance by up to 40 percentage points; (2) yields classifiers that are at least as stable as those trained using default settings; (3) substantially shifts the importance ranking of variables, with as few as 28 percent of the top-ranked variables in optimized classifiers also being top-ranked in non-optimized classifiers; (4) yields optimized settings for 17 of the 20 most sensitive parameters that transfer among datasets without a statistically significant drop in performance; and (5) adds less than 30 minutes of additional computation to 12 of the 26 studied classification techniques. While widely-used classification techniques like random forest and support vector machines are not optimization-sensitive, traditionally overlooked techniques like C5.0 and neural networks can actually outperform widely-used techniques after optimization is applied. This highlights the importance of exploring the parameter space when using parameter-sensitive classification techniques.",1939-3520,,10.1109/TSE.2018.2794977,JSPS Program for Advancing Strategic International Networks to Accelerate the Circulation of Talented Researchers(grant numbers:16J03360); Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263202,Software defect prediction;search-based software engineering;experimental design;classification techniques;parameter optimization;grid search;random search;genetic algorithm;differential evolution,Optimization;Predictive models;Computational modeling;Software;Neural networks;Computational efficiency;Power system stability,,238,,154,IEEE,18 Jan 2018,,,IEEE,IEEE Journals,True
You Are the Only Possible Oracle: Effective Test Selection for End Users of Interactive Machine Learning Systems,A. Groce; T. Kulesza; C. Zhang; S. Shamasunder; M. Burnett; W. -K. Wong; S. Stumpf; S. Das; A. Shinsel; F. Bice; K. McIntosh,"School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; Centre for HCI Design, School of Informatics, City University London, London, United Kingdom; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,307,323,"How do you test a program when only a single user, with no expertise in software testing, is able to determine if the program is performing correctly? Such programs are common today in the form of machine-learned classifiers. We consider the problem of testing this common kind of machine-generated program when the only oracle is an end user: e.g., only you can determine if your email is properly filed. We present test selection methods that provide very good failure rates even for small test suites, and show that these methods work in both large-scale random experiments using a “gold standard” and in studies with real users. Our methods are inexpensive and largely algorithm-independent. Key to our methods is an exploitation of properties of classifiers that is not possible in traditional software testing. Our results suggest that it is plausible for time-pressured end users to interactively detect failures-even very hard-to-find failures-without wading through a large number of successful (and thus less useful) tests. We additionally show that some methods are able to find the arguably most difficult-to-detect faults of classifiers: cases where machine learning algorithms have high confidence in an incorrect result.",1939-3520,,10.1109/TSE.2013.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682887,Machine learning;end-user testing;test suite size,Testing;Software;Training;Training data;Electronic mail;Software algorithms;Machine learning algorithms,,43,,63,IEEE,12 Dec 2013,,,IEEE,IEEE Journals,True
The Assessor's Dilemma: Improving Bug Repair via Empirical Game Theory,C. Gavidia-Calderon; F. Sarro; M. Harman; E. T. Barr,"Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom",IEEE Transactions on Software Engineering,14 Oct 2021,2021,47,10,2143,2161,"Priority inflation occurs when a Quality-Assurance (QA) engineer or a project manager requesting a feature inflates the priority of their task so that developers deliver the fix or the new functionality more quickly. We survey developers and show that priority inflation occurs and misallocates developer time. We are the first to apply empirical game-theoretic analysis (EGTA) to a software engineering problem, specifically priority inflation. First, we extract prioritisation strategies from 42,620 issues from Apache's JIRA, then use TaskAssessor, our EGTA-based modelling approach, to confirm conventional wisdom and show that the common process of a QA engineer assigning priority labels is susceptible to priority inflation. We then show that the common mitigation strategy of having a bug triage team assigning priorities does not resolve priority inflation and slows development. We then use mechanism design to devise assessor-throttling, a new, lightweight prioritization process, immune to priority inflation. We show that assessor-throttling resolves 97 percent of high priority tasks, 69 percent better than simply relying on those filing tasks to assign priorities. Finally, we present The Fed, a browser extension for Chrome that supports assessor-throttling.",1939-3520,,10.1109/TSE.2019.2944608,Dynamic Adaptive Automated Software Engineering Programme(grant numbers:EP/J017515); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852726,Software process;game theory;bug report;priority inflation,Task analysis;Computer bugs;Logic gates;Games;Nash equilibrium;Software,,6,,87,IEEE,30 Sep 2019,,,IEEE,IEEE Journals,True
Comments on “Researcher Bias: The Use of Machine Learning in Software Defect Prediction”,C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto,"Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1092,1094,"Shepperd et al. find that the reported performance of a defect prediction model shares a strong relationship with the group of researchers who construct the models. In this paper, we perform an alternative investigation of Shepperd et al.'s data. We observe that (a) research group shares a strong association with other explanatory variables (i.e., the dataset and metric families that are used to build a model); (b) the strong association among these explanatory variables makes it difficult to discern the impact of the research group on model performance; and (c) after mitigating the impact of this strong association, we find that the research group has a smaller impact than the metric family. These observations lead us to conclude that the relationship between the research group and the performance of a defect prediction model are more likely due to the tendency of researchers to reuse experimental components (e.g., datasets and metrics). We recommend that researchers experiment with a broader selection of datasets and metrics to combat any potential bias in their results.",1939-3520,,10.1109/TSE.2016.2553030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450669,Software quality assurance;defect prediction;researcher bias,Measurement;Interference;Analysis of variance;Predictive models;Analytical models;NASA;Data models,,61,,18,IEEE,11 Apr 2016,,,IEEE,IEEE Journals,True
MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction,K. E. Bennin; J. Keung; P. Phannachitta; A. Monden; S. Mensah,"Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, Thailand; Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong",IEEE Transactions on Software Engineering,12 Jun 2018,2018,44,6,534,550,"Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.",1939-3520,,10.1109/TSE.2017.2731766,"General Research Fund of the Research Grants Council of Hong Kong(grant numbers:11208017,11214116); City University of Hong Kong(grant numbers:7004683,7004474); JSPS KAKENHI(grant numbers:17K00102); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990590,Software defect prediction;class imbalance learning;synthetic sample generation;data sampling methods;classification problems,Biological cells;Software;Predictive models;Animals;Electronic mail;Sampling methods,,210,,44,IEEE,25 Jul 2017,,,IEEE,IEEE Journals,True
On the Costs and Profit of Software Defect Prediction,S. Herbold,"Institute of Computer Science, University of Goettingen, Goettingen, Germany",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2617,2631,"Defect prediction can be a powerful tool to guide the use of quality assurance resources. However, while lots of research covered methods for defect prediction as well as methodological aspects of defect prediction research, the actual cost saving potential of defect prediction is still unclear. Within this article, we close this research gap and formulate a cost model for software defect prediction. We derive mathematically provable boundary conditions that must be fulfilled by defect prediction models such that there is a positive profit when the defect prediction model is used. Our cost model includes aspects like the costs for quality assurance, the costs of post-release defects, the possibility that quality assurance fails to reveal predicted defects, and the relationship between software artifacts and defects. We initialize the cost model using different assumptions, perform experiments to show trends of the behavior of costs on real projects. Our results show that the unrealistic assumption that defects only affect a single software artifact, which is a standard practice in the defect prediction literature, leads to inaccurate cost estimations. Moreover, the results indicate that thresholds for machine learning metrics are also not suited to define success criteria for software defect prediction.",1939-3520,,10.1109/TSE.2019.2957794,DFG(grant numbers:402774445); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924628,Defect prediction;costs;return on investment,Predictive models;Software;Quality assurance;Measurement;Mathematical model;Machine learning;Computational modeling,,22,,47,IEEE,5 Dec 2019,,,IEEE,IEEE Journals,True
An Improved SDA Based Defect Prediction Framework for Both Within-Project and Cross-Project Class-Imbalance Problems,X. -Y. Jing; F. Wu; X. Dong; B. Xu,"State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,321,339,"Background. Solving the class-imbalance problem of within-project software defect prediction (SDP) is an important research topic. Although some class-imbalance learning methods have been presented, there exists room for improvement. For cross-project SDP, we found that the class-imbalanced source usually leads to misclassification of defective instances. However, only one work has paid attention to this cross-project class-imbalance problem. Objective. We aim to provide effective solutions for both within-project and cross-project class-imbalance problems. Method. Subclass discriminant analysis (SDA), an effective feature learning method, is introduced to solve the problems. It can learn features with more powerful classification ability from original metrics. For within-project prediction, we improve SDA for achieving balanced subclasses and propose the improved SDA (ISDA) approach. For cross-project prediction, we employ the semi-supervised transfer component analysis (SSTCA) method to make the distributions of source and target data consistent, and propose the SSTCA+ISDA prediction approach. Results. Extensive experiments on four widely used datasets indicate that: 1) ISDA-based solution performs better than other state-of-the-art methods for within-project class-imbalance problem; 2) SSTCA+ISDA proposed for cross-project class-imbalance problem significantly outperforms related methods.  Conclusion. Within-project and cross-project class-imbalance problems greatly affect prediction performance, and we provide a unified and effective prediction framework for both problems.",1939-3520,,10.1109/TSE.2016.2597849,"National Natural Science Foundation of China(grant numbers:61272273,61572375,61233011,91418202,61472178); The Chinese 973 Program(grant numbers:2014CB340702); Research Project of NJUPT(grant numbers:XJKY14016); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530877,Software defect prediction (SDP);within-project class-imbalance;cross-project class-imbalance;improved subclass discriminant analysis (ISDA);ISDA based defect prediction framework,Support vector machines;Learning systems;Predictive models;Software;Software engineering;Measurement,,154,,78,IEEE,3 Aug 2016,,,IEEE,IEEE Journals,True
Bellwethers: A Baseline Method for Transfer Learning,R. Krishna; T. Menzies,"Department of Computer Science, North Carolina State University, Raleigh; Department of Computer Science, North Carolina State University, Raleigh",IEEE Transactions on Software Engineering,12 Nov 2019,2019,45,11,1081,1105,"Software analytics builds quality prediction models for software projects. Experience shows that (a) the more projects studied, the more varied are the conclusions; and (b) project managers lose faith in the results of software analytics if those results keep changing. To reduce this conclusion instability, we propose the use of “bellwethers”: given N projects from a community the bellwether is the project whose data yields the best predictions on all others. The bellwethers offer a way to mitigate conclusion instability because conclusions about a community are stable as long as this bellwether continues as the best oracle. Bellwethers are also simple to discover (just wrap a for-loop around standard data miners). When compared to other transfer learning methods (TCA+, transfer Naive Bayes, value cognitive boosting), using just the bellwether data to construct a simple transfer learner yields comparable predictions. Further, bellwethers appear in many SE tasks such as defect prediction, effort estimation, and bad smell detection. We hence recommend using bellwethers as a baseline method for transfer learning against which future work should be compared.",1939-3520,,10.1109/TSE.2018.2821670,"National Science Foundation(grant numbers:#1506586,#1302169); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329264,Transfer learning;defect prediction;bad smells;issue close time;effort estimation;prediction,Estimation;Software;Software engineering;Task analysis;Benchmark testing;Complexity theory;Analytical models,,48,,154,IEEE,2 Apr 2018,,,IEEE,IEEE Journals,True
Effects of Personality Traits on Pull Request Acceptance,R. N. Iyer; S. A. Yun; M. Nagappan; J. Hoey,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2632,2643,"In this paper, we examine the influence of personality traits of developers on the pull request evaluation process in GitHub. We first replicate Tsay et al.’s work that examined the influence of social factors (e.g., ‘social distance’) and technical factors (e.g., test file inclusion) for evaluating contributions, and then extend it with personality based factors. In particular, we extract the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) of developers from their online digital footprints, such as pull request comments. We analyze the personality traits of 16,935 active developers from 1,860 projects and compare their relative importance to other non-personality factors from past research, in the pull request evaluation process. We find that pull requests from authors (requesters) who are more open and conscientious, but less extroverted, have a higher chance of approval. Furthermore, pull requests that are closed by developers (closers) who are more conscientious, extroverted, and neurotic, have a higher likelihood of acceptance. The larger the difference in personality traits between the requester and the closer, the more positive effect it has on pull request acceptance. Finally, although the effect of personality traits is significant and comparable to technical factors, we find that social factors are still more influential on the likelihood of pull request acceptance.",1939-3520,,10.1109/TSE.2019.2960357,Natural Sciences and Engineering Research Council of Canada; Social Sciences and Humanities Research Council of Canada; Trans-Atlantic Platform's Digging; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935389,Pull request;GitHub;online collaborative environments;open source systems;personality;Big Five;five-factor model,Psychology;Social factors;Software engineering;Task analysis;Dictionaries;Robots;Software,,25,,71,IEEE,17 Dec 2019,,,IEEE,IEEE Journals,True
RELAI Testing: A Technique to Assess and Improve Software Reliability,D. Cotroneo; R. Pietrantuono; S. Russo,"Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione (DIETI), Università di Napoli Federico II, Via Claudio 21, Naples, Italy; Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione (DIETI), Università di Napoli Federico II, Via Claudio 21, Naples, Italy; Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione (DIETI), Università di Napoli Federico II, Via Claudio 21, Naples, Italy",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,452,475,"Testing software to assess or improve reliability presents several practical challenges. Conventional operational testing is a fundamental strategy that simulates the real usage of the system in order to expose failures with the highest occurrence probability. However, practitioners find it unsuitable for assessing/achieving very high reliability levels; also, they do not see the adoption of a “real” usage profile estimate as a sensible idea, being it a source of non-quantifiable uncertainty. Oppositely, debug testing aims to expose as many failures as possible, but regardless of their impact on runtime reliability. These strategies are used either to assess or to improve reliability, but cannot improve and assess reliability in the same testing session. This article proposes Reliability Assessment and Improvement (RELAI) testing, a new technique thought to improve the delivered reliability by an adaptive testing scheme, while providing, at the same time, a continuous assessment of reliability attained through testing and fault removal. The technique also quantifies the impact of a partial knowledge of the operational profile. RELAI is positively evaluated on four software applications compared, in separate experiments, with techniques conceived either for reliability improvement or for reliability assessment, demonstrating substantial improvements in both cases.",1939-3520,,10.1109/TSE.2015.2491931,European Commission; FP7 Marie Curie Industry-Academia Partnerships and Pathways (IAPP)(grant numbers:324356); MIUR; SVEVIA(grant numbers:PON02_00485_3487758); COSMIC(grant numbers:PON02_00669); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299696,Software Testing;Reliability;Operational Testing;Random Testing;Sampling;Operational Profile;Software testing;reliability;operational testing;random testing;sampling;operational profile,Testing;Software reliability;Software;Uncertainty;Estimation error,,21,,65,IEEE,16 Oct 2015,,,IEEE,IEEE Journals,True
Predicting Consistency-Maintenance Requirement of Code Clonesat Copy-and-Paste Time,X. Wang; Y. Dang; L. Zhang; D. Zhang; E. Lan; H. Mei,"Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, and with the Department of Computer Science, University of Texas, San Antonio; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Corporation, One Microsoft Way, Redmond, WA; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, and with the Department of Computer Science, University of Texas, San Antonio",IEEE Transactions on Software Engineering,8 Aug 2014,2014,40,8,773,794,"Code clones have always been a double edged sword in software development. On one hand, it is a very convenient way to reuse existing code, and to save coding effort. On the other hand, since developers may need to ensure consistency among cloned code segments, code clones can lead to extra maintenance effort and even bugs. Recently studies on the evolution of code clones show that only some of the code clones experience consistent changes during their evolution history. Therefore, if we can accurately predict whether a code clone will experience consistent changes, we will be able to provide useful recommendations to developers onleveraging the convenience of some code cloning operations, while avoiding other code cloning operations to reduce future consistency maintenance effort. In this paper, we define a code cloning operation as consistency-maintenance-required if its generated code clones experience consistent changes in the software evolution history, and we propose a novel approach that automatically predicts whether a code cloning operation requires consistency maintenance at the time point of performing copy-and-paste operations. Our insight is that whether a code cloning operation requires consistency maintenance may relate to the characteristics of the code to be cloned and the characteristics of its context. Based on a number of attributes extracted from the cloned code and the context of the code cloning operation, we use Bayesian Networks, a machine-learning technique, to predict whether an intended code cloning operation requires consistency maintenance. We evaluated our approach on four subjects—two large-scale Microsoft software projects, and two popular open-source software projects—under two usage scenarios: 1) recommend developers to perform only the cloning operations predicted to be very likely to be consistency-maintenance-free, and 2) recommend developers to perform all cloning operations unless they are predicted very likely to be consistency-maintenance-required. In the first scenario, our approach is able to recommend developers to perform more than 50 percent cloning operations with a precision of at least 94 percent in the four subjects. In the second scenario, our approach is able to avoid 37 to 72 percent consistency-maintenance-required code clones by warning developers on only 13 to 40 percent code clones, in the four subjects.",1939-3520,,10.1109/TSE.2014.2323972,"National 863 Program(grant numbers:2013AA01A605); National 973 Program(grant numbers:2011CB302604); Science Fund for Creative Research Groups(grant numbers:61121063); Natural Science Foundation(grant numbers:91118004,61228203,61225007); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815760,Code cloning;consistency maintenance;programming aid,Cloning;Software;Maintenance engineering;Bayes methods;History;Training;Educational institutions,,22,,46,IEEE,14 May 2014,,,IEEE,IEEE Journals,True
Machine Learning-Based Prototyping of Graphical User Interfaces for Mobile Apps,K. Moran; C. Bernal-Cárdenas; M. Curcio; R. Bonett; D. Poshyvanyk,"Department of Computer Science, College of William & Mary, Williamsburg, USA; Department of Computer Science, College of William & Mary, Williamsburg, USA; Department of Computer Science, College of William & Mary, Williamsburg, USA; Department of Computer Science, College of William & Mary, Williamsburg, USA; Department of Computer Science, College of William & Mary, Williamsburg, USA",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,196,221,"It is common practice for developers of user-facing software to transform a mock-up of a graphical user interface (GUI) into code. This process takes place both at an application's inception and in an evolutionary context as GUI changes keep pace with evolving features. Unfortunately, this practice is challenging and time-consuming. In this paper, we present an approach that automates this process by enabling accurate prototyping of GUIs via three tasks: detection, classification, and assembly. First, logical components of a GUI are detected from a mock-up artifact using either computer vision techniques or mock-up metadata. Then, software repository mining, automated dynamic analysis, and deep convolutional neural networks are utilized to accurately classify GUI-components into domain-specific types (e.g., toggle-button). Finally, a data-driven, K-nearest-neighbors algorithm generates a suitable hierarchical GUI structure from which a prototype application can be automatically assembled. We implemented this approach for Android in a system called ReDraw. Our evaluation illustrates that ReDraw achieves an average GUI-component classification accuracy of 91 percent and assembles prototype applications that closely mirror target mock-ups in terms of visual affinity while exhibiting reasonable code structure. Interviews with industrial practitioners illustrate ReDraw's potential to improve real development workflows.",1939-3520,,10.1109/TSE.2018.2844788,National Science Foundation(grant numbers:CCF-1525902); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374985,GUI;CNN;mobile;prototyping;machine-learning;mining software repositories,Graphical user interfaces;Software;Task analysis;Prototypes;Metadata;Androids;Humanoid robots,,109,,109,IEEE,7 Jun 2018,,,IEEE,IEEE Journals,True
A Deep Learning Model for Estimating Story Points,M. Choetkiertikul; H. K. Dam; T. Tran; T. Pham; A. Ghose; T. Menzies,"Faculty of Information and Communication Technology, Mahidol University, Nakhonpathom, Thailand; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; School of Information Technology, Deakin University, Waurn Ponds, VIC, Australia; School of Information Technology, Deakin University, Waurn Ponds, VIC, Australia; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; North Carolina State University, Raleigh, NC",IEEE Transactions on Software Engineering,16 Jul 2019,2019,45,7,637,656,"Although there has been substantial research in software analytics for effort estimation in traditional software projects, little work has been done for estimation in agile projects, especially estimating the effort required for completing user stories or issues. Story points are the most common unit of measure used for estimating the effort involved in completing a user story or resolving an issue. In this paper, we propose a prediction model for estimating story points based on a novel combination of two powerful deep learning architectures: long short-term memory and recurrent highway network. Our prediction system is end-to-end trainable from raw input data to prediction outcomes without any manual feature engineering. We offer a comprehensive dataset for story points-based estimation that contains 23,313 issues from 16 open source projects. An empirical evaluation demonstrates that our approach consistently outperforms three common baselines (Random Guessing, Mean, and Median methods) and six alternatives (e.g., using Doc2Vec and Random Forests) in Mean Absolute Error, Median Absolute Error, and the Standardized Accuracy.",1939-3520,,10.1109/TSE.2018.2792473,Mahidol University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255666,Software analytics;effort estimation;story point estimation;deep learning,Project management;Software architecture;Learning (artificial intelligence);Deep learning,,107,,111,IEEE,12 Jan 2018,,,IEEE,IEEE Journals,True
Using Natural Language Processing to Automatically Detect Self-Admitted Technical Debt,E. d. S. Maldonado; E. Shihab; N. Tsantalis,"Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1044,1062,"The metaphor of technical debt was introduced to express the trade off between productivity and quality, i.e., when developers take shortcuts or perform quick hacks. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, all approaches thus far heavily depend on the manual classification of source code comments. In this paper, we present an approach to automatically identify design and requirement self-admitted technical debt using Natural Language Processing (NLP). We study 10 open source projects: Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL and find that 1) we are able to accurately identify self-admitted technical debt, significantly outperforming the current state-of-the-art based on fixed keywords and phrases; 2) words related to sloppy code or mediocre source code quality are the best indicators of design debt, whereas words related to the need to complete a partially implemented requirement in the future are the best indicators of requirement debt; and 3) we can achieve 90 percent of the best classification performance, using as little as 23 percent of the comments for both design and requirement self-admitted technical debt, and 80 percent of the best performance, using as little as 9 and 5 percent of the comments for design and requirement self-admitted technical debt, respectively. The last finding shows that the proposed approach can achieve a good accuracy even with a relatively small training dataset.",1939-3520,,10.1109/TSE.2017.2654244,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820211,Technical debt;source code comments;natural language processing;empirical study,Software;Natural language processing;Manuals;Entropy;Unified modeling language;Java;Structured Query Language,,139,,58,IEEE,17 Jan 2017,,,IEEE,IEEE Journals,True
Efficient Parametric Model Checking Using Domain Knowledge,R. Calinescu; C. Paterson; K. Johnson,"Department of Computer Science, University of York, Heslington, York, United Kingdom; Department of Computer Science, University of York, Heslington, York, United Kingdom; School of Engineering, Computer and Mathematical Sciences, Auckland University of Technology, Auckland, New Zealand",IEEE Transactions on Software Engineering,11 Jun 2021,2021,47,6,1114,1133,"We introduce an efficient parametric model checking (ePMC) method for the analysis of reliability, performance and other quality-of-service (QoS) properties of software systems. ePMC speeds up the analysis of parametric Markov chains modelling the behaviour of software by exploiting domain-specific modelling patterns for the software components (e.g., patterns modelling the invocation of functionally-equivalent services used to jointly implement the same operation within service-based systems, or the deployment of the components of multi-tier software systems across multiple servers). To this end, ePMC precomputes closed-form expressions for key QoS properties of such patterns, and uses these expressions in the analysis of whole-system models. To evaluate ePMC, we show that its application to service-based systems and multi-tier software architectures reduces the analysis time by several orders of magnitude compared to current parametric model checking methods.",1939-3520,,10.1109/TSE.2019.2912958,Assuring Autonomy International Programme; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8698796,Parametric model checking;Markov models;model abstraction;probabilistic model checking;quality of service,Markov processes;Quality of service;Analytical models;Unified modeling language;Software;Probabilistic logic;Parametric statistics,,11,,42,IEEE,25 Apr 2019,,,IEEE,IEEE Journals,True
Deep Learning Based Code Smell Detection,H. Liu; J. Jin; Z. Xu; Y. Zou; Y. Bu; L. Zhang,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, China",IEEE Transactions on Software Engineering,16 Sep 2021,2021,47,9,1811,1837,"Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may identify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To this end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such approaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is challenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper we propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and advanced deep learning techniques could automatically select features of source code for code smell detection, and could automatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell detection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the employed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an automatic approach to generating labeled training data for the neural network based classifier, which does not require any human intervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long method, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach significantly improves the state-of-the-art.",1939-3520,,10.1109/TSE.2019.2936376,"National Natural Science Foundation of China(grant numbers:61690205,61772071,61529201); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807230,Software refactoring;code smells;identification;deep learning;quality,Software;Deep learning;Feature extraction;Training data;Neural networks;Measurement,,44,,90,IEEE,20 Aug 2019,,,IEEE,IEEE Journals,True
An Enhanced Bailout Protocol for Mixed Criticality Embedded Software,I. Bate; A. Burns; R. I. Davis,"Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, University of York, York, United Kingdom",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,298,320,"To move mixed criticality research into industrial practice requires models whose run-time behaviour is acceptable to systems engineers. Certain aspects of current models, such as abandoning lower criticality tasks when certain situations arise, do not give the robustness required in application domains such as the automotive and aerospace industries. In this paper a new bailout protocol is developed that still guarantees high criticality software but minimises the negative impact on lower criticality software via a timely return to normal operation. We show how the bailout protocol can be integrated with existing techniques, utilising both offline slack and online gain-time to further improve performance. Static analysis is provided for schedulability guarantees, while scenario-based evaluation via simulation is used to explore the effectiveness of the protocol.",1939-3520,,10.1109/TSE.2016.2592907,ESPRC; MCC(grant numbers:EP/K011626/1); EU FP7 IP PROXIMA(grant numbers:611085); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516652,Real-time systems;mixed criticality;fixed priority scheduling;mode changes,Protocols;Standards;Software;Analytical models;Job shop scheduling;Software engineering;Safety,,20,,44,IEEE,19 Jul 2016,,,IEEE,IEEE Journals,True
Heterogeneous Defect Prediction,J. Nam; W. Fu; S. Kim; T. Menzies; L. Tan,"School of Computer Science and Electrical Engineering, Handong Global University, Pohang, Korea; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,874,896,"Many recent studies have documented the success of cross-project defect prediction (CPDP) to predict defects for new projects lacking in defect data by using prediction models built by other projects. However, most studies share the same limitations: it requires homogeneous data; i.e., different projects must describe themselves using the same metrics. This paper presents methods for heterogeneous defect prediction (HDP) that matches up different metrics in different projects. Metric matching for HDP requires a “large enough” sample of distributions in the source and target projects-which raises the question on how large is “large enough” for effective heterogeneous defect prediction. This paper shows that empirically and theoretically, “large enough” may be very small indeed. For example, using a mathematical model of defect prediction, we identify categories of data sets were as few as 50 instances are enough to build a defect prediction model. Our conclusion for this work is that, even when projects use different metric sets, it is possible to quickly transfer lessons learned about defect prediction.",1939-3520,,10.1109/TSE.2017.2720603,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959597,Defect prediction;quality assurance;heterogeneous metrics;transfer learning,Predictive models;Software metrics;Quality assurance;Training,,190,,103,IEEE,27 Jun 2017,,,IEEE,IEEE Journals,True
The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs,C. Le Goues; N. Holtschulte; E. K. Smith; Y. Brun; P. Devanbu; S. Forrest; W. Weimer,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Department of Computer Science at the University of New Mexico, Albuquerque, NM; College of Information and Computer Science, University of Massachusetts at Amherst, MA; College of Information and Computer Science, University of Massachusetts at Amherst, MA; Department of Computer Science, University of California at Davis, Davis, CA; Department of Computer Science at the University of New Mexico, Albuquerque, NM; Department of Computer Science, University of Virginia, Charlottesville, VA",IEEE Transactions on Software Engineering,8 Dec 2015,2015,41,12,1236,1256,"The field of automated software repair lacks a set of common benchmark problems. Although benchmark sets are used widely throughout computer science, existing benchmarks are not easily adapted to the problem of automatic defect repair, which has several special requirements. Most important of these is the need for benchmark programs with reproducible, important defects and a deterministic method for assessing if those defects have been repaired. This article details the need for a new set of benchmarks, outlines requirements, and then presents two datasets, ManyBugs and IntroClass, consisting between them of 1,183 defects in 15 C programs. Each dataset is designed to support the comparative evaluation of automatic repair algorithms asking a variety of experimental questions. The datasets have empirically defined guarantees of reproducibility and benchmark quality, and each study object is categorized to facilitate qualitative evaluation and comparisons by category of bug or program. The article presents baseline experimental results on both datasets for three existing repair methods, GenProg, AE, and TrpAutoRepair, to reduce the burden on researchers who adopt these datasets for their own comparative evaluations.",1939-3520,,10.1109/TSE.2015.2454513,"AFOSR(grant numbers:FA9550-07-1-0532,FA9550-10-1-0277); US Defense Advanced Research Projects Agency (DARPA)(grant numbers:P-1070-113237); US Department of Energy (DOE)(grant numbers:DE-AC02-05CH11231); US National Science Foundation (NSF)(grant numbers:CCF-0729097,CCF-0905236,CCF-1446683,CNS-0905222)); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153570,Automated program repair;benchmark;subject defect;reproducibility;ManyBugs;IntroClass;Automated program repair;benchmark;subject defect;reproducibility;ManyBugs;IntroClass,Maintenance engineering;Benchmark testing;Computer bugs;Software systems;Electronic mail,,203,,80,IEEE,9 Jul 2015,,,IEEE,IEEE Journals,True
Comparative Analysis of Constraint Handling Techniques for Constrained Combinatorial Testing,H. Wu; C. Nie; J. Petke; Y. Jia; M. Harman,"Department of Computer Science and Technology, State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science and Technology, State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; CREST, Computer Science, University College London, London, U.K; Facebook Inc., London, U.K.; Facebook Inc., London, U.K.",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2549,2562,"Constraints depict the dependency relationships between parameters in a software system under test. Because almost all systems are constrained in some way, techniques that adequately cater for constraints have become a crucial factor for adoption, deployment and exploitation of Combinatorial Testing (CT). Currently, despite a variety of different constraint handling techniques available, the relationship between these techniques and the generation algorithms that use them remains unknown, yielding an important gap and pressing concern in the literature of constrained combination testing. In this article, we present a comparative empirical study to investigate the impact of four common constraint handling techniques on the efficiency of six representative (greedy and search-based) test suite generation algorithms. The results reveal that the Verify technique implemented with the Minimal Forbidden Tuple (MFT) approach is the fastest, while the Replace technique is promising for producing the smallest constrained covering arrays, especially for algorithms that construct test cases one-at-a-time. The results also show that there is an interplay between efficiency of the constraint handler and the test suite generation algorithm into which it is developed.",1939-3520,,10.1109/TSE.2019.2955687,National Key Research and Development Program of China(grant numbers:2018YFB1003800); National Natural Science Foundation of China(grant numbers:61902174); Natural Science Foundation of Jiangsu Province(grant numbers:BK20190291); DAASE EPSRC(grant numbers:EP/J017515/1); EPSRC Fellowship(grant numbers:EP/P023991/1); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913600,combinatorial testing;test suite generation;constraint handling;constrained covering array;empirical comparison,Combinatorial testing;Software systems;Computational efficiency,,13,,53,CCBY,26 Nov 2019,,,IEEE,IEEE Journals,True
An Empirical Study on Heterogeneous Defect Prediction Approaches,H. Chen; X. -Y. Jing; Z. Li; D. Wu; Y. Peng; Z. Huang,"School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Shaanxi Normal University, Xi'an, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China",IEEE Transactions on Software Engineering,10 Dec 2021,2021,47,12,2803,2822,"Software defect prediction has always been a hot research topic in the field of software engineering owing to its capability of allocating limited resources reasonably. Compared with cross-project defect prediction (CPDP), heterogeneous defect prediction (HDP) further relaxes the limitation of defect data used for prediction, permitting different metric sets to be contained in the source and target projects. However, there is still a lack of a holistic understanding of existing HDP studies due to different evaluation strategies and experimental settings. In this paper, we provide an empirical study on HDP approaches. We review the research status systematically and compare the HDP approaches proposed from 2014 to June 2018. Furthermore, we also investigate the feasibility of HDP approaches in CPDP. Through extensive experiments on 30 projects from five datasets, we have the following findings: (1) metric transformation-based HDP approaches usually result in better prediction effects, while metric selection-based approaches have better interpretability. Overall, the HDP approach proposed by Li et al. (CTKCCA) currently has the best performance. (2) Handling class imbalance problems can boost the prediction effects, but the improvements are usually limited. In addition, utilizing mixed project data cannot improve the performance of HDP approaches consistently since the label information in the target project is not used effectively. (3) HDP approaches are feasible for cross-project defect prediction in which the source and target projects have the same metric set.",1939-3520,,10.1109/TSE.2020.2968520,NSFC-Key(grant numbers:61933013); NSFC-Key Project of General Technology Fundamental Research United Fund(grant numbers:U1736211); Natural Science Foundation of Guangdong Province(grant numbers:2019A1515011076); Natural Science Foundation of Hubei Province(grant numbers:2018CFA024); Innovation Group of Guangdong Education Department(grant numbers:2018KCXTD019); National Natural Science Foundation of China(grant numbers:61902228); Fundamental Research Funds for the Central Universities(grant numbers:GK201903086); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964460,Heterogeneous defect prediction;cross-project;empirical study;metric selection;metric transformation,Measurement;NASA;Predictive models;Data models;Software quality,,39,,78,IEEE,22 Jan 2020,,,IEEE,IEEE Journals,True
METRIC$^{+}$+: A Metamorphic Relation Identification Technique Based on Input Plus Output Domains,C. -A. Sun; A. Fu; P. -L. Poon; X. Xie; H. Liu; T. Y. Chen,"Department of Computer Science and Technology, University of Science and Technology Beijing, Beijing, China; Department of Computer Science and Technology, University of Science and Technology Beijing, Beijing, China; School of Engineering and Technology, Central Queensland University, Melbourne, VIC, Australia; School of Computer Science, Wuhan University, Wuhan, China; Department of Computer Science and Software Engineering, Swinburne University of Technology, Melbourne, VIC, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Melbourne, VIC, Australia",IEEE Transactions on Software Engineering,16 Sep 2021,2021,47,9,1764,1785,"Metamorphic testing is well known for its ability to alleviate the oracle problem in software testing. The main idea ofmetamorphic testing is to test a software system by checking whether each identified metamorphic relation (MR) holds among severalexecutions. In this regard, identifying MRs is an essential task in metamorphic testing. In view of the importance of this identificationtask, METRIC (METamorphic Relation Identification based on Category-choice framework) was developed to help software testersidentify MRs from a given set of complete test frames. However, during MR identification, METRIC primarily focuses on the inputdomain without sufficient attention given to the output domain, thereby hindering the effectiveness of METRIC. Inspired by this problem,we have extended METRIC into METRIC+ by incorporating the information derived from the output domain for MR identification. A toolimplementing METRIC+ has also been developed. Two rounds of experiments, involving four real-life specifications, have beenconducted to evaluate the effectiveness and efficiency of METRIC+. The results have confirmed that METRIC+ is highly effective andefficient in MR identification. Additional experiments have been performed to compare the fault detection capability of the MRsgenerated by METRIC+ and those bymMT (another MR identification technique). The comparison results have confirmed that the MRsgenerated by METRIC+ are highly effective in fault detection.",1939-3520,,10.1109/TSE.2019.2934848,National Natural Science Foundation of China(grant numbers:61872039); Natural Science Foundation of Beijing Municipality(grant numbers:4162040); Aeronautical Science Foundation of China(grant numbers:2016ZD74004); Fundamental Research Funds for the Central Universities(grant numbers:FRF-GF-17-B29); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807231,Metamorphic testing;metamorphic relation;category-choice framework;fault detection effectiveness,Measurement;Testing;Software systems;Fault detection;Task analysis;Tools,,20,,59,CCBY,20 Aug 2019,,,IEEE,IEEE Journals,True
A Feature-Based Classification of Model Repair Approaches,N. Macedo; T. Jorge; A. Cunha,"High-Assurance Software Laboratory (HASLab), INESC TEC; European Space Agency (ESA), Paris, France; High-Assurance Software Laboratory (HASLab), INESC TEC",IEEE Transactions on Software Engineering,14 Jul 2017,2017,43,7,615,640,"Consistency management, the ability to detect, diagnose and handle inconsistencies, is crucial during the development process in Model-driven Engineering (MDE). As the popularity and application scenarios of MDE expanded, a variety of different techniques were proposed to address these tasks in specific contexts. Of the various stages of consistency management, this work focuses on inconsistency handling in MDE, particularly in model repair techniques. This paper proposes a feature-based classification system for model repair techniques, based on an systematic literature review of the area. We expect this work to assist developers and researchers from different disciplines in comparing their work under a unifying framework, and aid MDE practitioners in selecting suitable model repair approaches.",1939-3520,,10.1109/TSE.2016.2620145,"North Portugal Regional Operational Programme(grant numbers:NORTE 2020,PORTUGAL 2020); European Regional Development Fund (ERDF)(grant numbers:NORTE-01-0145-FEDER-000016); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7605502,"Model-driven engineering, consistency management, inconsistency handling, model repair",Maintenance engineering;Unified modeling language;Taxonomy;Context;Feature extraction;Software engineering;Systematics,,37,,91,IEEE,21 Oct 2016,,,IEEE,IEEE Journals,True
An Interleaving Approach to Combinatorial Testing and Failure-Inducing Interaction Identification,X. Niu; C. Nie; H. Leung; Y. Lei; X. Wang; J. Xu; Y. Wang,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computing, Hong Kong Polytechnic University, Kowloon, China; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, USA; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, China; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, China",IEEE Transactions on Software Engineering,15 Jun 2020,2020,46,6,584,615,"Combinatorial testing (CT) seeks to detect potential faults caused by various interactions of factors that can influence the software systems. When applying CT, it is a common practice to first generate a set of test cases to cover each possible interaction and then to identify the failure-inducing interaction after a failure is detected. Although this conventional procedure is simple and forthright, we conjecture that it is not the ideal choice in practice. This is because 1) testers desire to identify the root cause of failures before all the needed test cases are generated and executed 2) the early identified failure-inducing interactions can guide the remaining test case generation so that many unnecessary and invalid test cases can be avoided. For these reasons, we propose a novel CT framework that allows both generation and identification process to interact with each other. As a result, both generation and identification stages will be done more effectively and efficiently. We conducted a series of empirical studies on several open-source software, the results of which show that our framework can identify the failure-inducing interactions more quickly than traditional approaches while requiring fewer test cases.",1939-3520,,10.1109/TSE.2018.2865772,National Key Research and Development Plan(grant numbers:2018YFB1003800); National Science Foundation(grant numbers:CNS-1748109); U.S. Department of Homeland Security(grant numbers:DHS-14-ST-062-001); National Institute of Standards and Technologies Award(grant numbers:70NANB15H199); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438906,Software testing;combinatorial testing;covering array;failure-inducing interactions,Testing;Software systems;Computer science;Fault diagnosis;Open source software;Indexes,,18,,73,OAPA,17 Aug 2018,,,IEEE,IEEE Journals,True
Seer: A Lightweight Online Failure Prediction Approach,B. Ozcelik; C. Yilmaz,"freelance software developer; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey",IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,26,46,"Online failure prediction approaches aim to predict the manifestation of failures at runtime before the failures actually occur. Existing approaches generally refrain themselves from collecting internal execution data, which can further improve the prediction quality. One reason behind this general trend is the runtime overhead incurred by the measurement instruments that collect the data. Since these approaches are targeted at deployed software systems, excessive runtime overhead is generally undesirable. In this work we conjecture that large cost reductions in collecting internal execution data for online failure prediction may derive from pushing the substantial parts of the data collection work onto the hardware. To test this hypothesis, we present a lightweight online failure prediction approach, called Seer, in which most of the data collection work is performed by fast hardware performance counters. The hardware-collected data is augmented with further data collected by a minimal amount of software instrumentation that is added to the systems software. In our empirical evaluations conducted on three open source projects, Seer performed significantly better than other related approaches in predicting the manifestation of failures.",1939-3520,,10.1109/TSE.2015.2442577,Marie Curie International Reintegration; European Community Framework Programme(grant numbers:FP7-PEOPLE-IRG-2008); Scientific and Technological Research Council of Turkey(grant numbers:109E182); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120143,Online failure prediction;hardware performance counters;software quality assurance;software reliability;Online failure prediction;hardware performance counters;software quality assurance;software reliability,Radiation detectors;Hardware;Runtime;Predictive models;Instruments;Software;Indexes,,20,,60,IEEE,9 Jun 2015,,,IEEE,IEEE Journals,True
SITAR: GUI Test Script Repair,Z. Gao; Z. Chen; Y. Zou; A. M. Memon,"Department of Computer Science, University of Maryland, College Park, MD, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science, University of Maryland, College Park, MD, USA",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,170,186,"System testing of a GUI-based application requires that test cases, consisting of sequences of user actions/events, be executed and the software's output be verified. To enable automated re-testing, such test cases are increasingly being coded as low-level test scripts, to be replayed automatically using test harnesses. Whenever the GUI changes—widgets get moved around, windows get merged—some scripts become unusable because they no longer encode valid input sequences. Moreover, because the software's output may have changed, their test oracles—assertions and checkpoints—encoded in the scripts may no longer correctly check the intended GUI objects. We present ScrIpT repAireR (SITAR), a technique to automatically repair unusable low-level test scripts. SITAR uses reverse engineering techniques to create an abstract test for each script, maps it to an annotated event-flow graph (EFG), uses repairing transformations and human input to repair the test, and synthesizes a new “repaired” test script. During this process, SITAR also repairs the reference to the GUI objects used in the checkpoints yielding a final test script that can be executed automatically to validate the revised software. SITAR amortizes the cost of human intervention across multiple scripts by accumulating the human knowledge as annotations on the EFG. An experiment using QTP test scripts suggests that SITAR is effective in that 41-89 percent unusable test scripts were repaired. Annotations significantly reduced human cost after 20 percent test scripts had been repaired.",1939-3520,,10.1109/TSE.2015.2454510,"National Key Research and Development Program of China(grant numbers:2014CB340702); NSFC(grant numbers:61170067,61373013); US National Science Foundation(grant numbers:CNS-1205501); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214294,GUI testing;GUI test script;test script repair;human knowledge accumulation;GUI testing;GUI test script;test script repair;human knowledge accumulation,Maintenance engineering;Graphical user interfaces;Software;Testing;Automation;Computational modeling;Electronic mail,,41,,32,IEEE,20 Aug 2015,,,IEEE,IEEE Journals,True
Kernel Spectral Embedding Transfer Ensemble for Heterogeneous Defect Prediction,H. Tong; B. Liu; S. Wang,"Science and Technology on Reliability and Environmental Engineering Laboratory, School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology on Reliability and Environmental Engineering Laboratory, School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology on Reliability and Environmental Engineering Laboratory, School of Reliability and Systems Engineering, Beihang University, Beijing, China",IEEE Transactions on Software Engineering,16 Sep 2021,2021,47,9,1886,1906,"Cross-project defect prediction (CPDP) refers to predicting defects in the target project lacking of defect data by using prediction models trained on the historical defect data of other projects (i.e., source data). However, CPDP requires the source and target projects have common metric set (CPDP-CM). Recently, heterogeneous defect prediction (HDP) has drawn the increasing attention, which predicts defects across projects having heterogeneous metric sets. However, building high-performance HDP methods remains a challenge owing to several serious challenges including class imbalance problem, nonlinear, and the distribution differences between source and target datasets. In this paper, we propose a novel kernel spectral embedding transfer ensemble (KSETE) approach for HDP. KSETE first addresses the class-imbalance problem of the source data and then tries to find the latent common feature space for the source and target datasets by combining kernel spectral embedding, transfer learning, and ensemble learning. Experiments are performed on 22 public projects in both HDP and CPDP-CM scenarios in terms of multiple well-known performance measures such as, AUC, G-Measure, and MCC. The experimental results show that (1) KSETE improves the performance over previous HDP methods by at least 22.7, 138.9, and 494.4 percent in terms of AUC, G-Measure, and MCC, respectively. (2) KSETE improves the performance over previous CPDP-CM methods by at least 4.5, 30.2, and 17.9 percent in AUC, G-Measure, and MCC, respectively. It can be concluded that the proposed KSETE is very effective in both the HDP scenario and the CPDP-CM scenario.",1939-3520,,10.1109/TSE.2019.2939303,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823052,Heterogeneous defect prediction;cross-project defect prediction;class imbalance learning;spectral embedding;transfer learning;ensemble learning;multiple kernel learning,Kernel;Predictive models;Software metrics;Correlation;Buildings;Data models,,20,,103,IEEE,3 Sep 2019,,,IEEE,IEEE Journals,True
Deep Semantic Feature Learning for Software Defect Prediction,S. Wang; T. Liu; J. Nam; L. Tan,"Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computer Science and Electrical Engineering, Handong Global University, Pohang, Korea; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1267,1293,"Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.",1939-3520,,10.1109/TSE.2018.2877612,Natural Sciences and Engineering Research Council of Canada; National Research Foundation of Korea(grant numbers:2018R1C1B6001919); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502853,Defect prediction;quality assurance;deep learning;semantic features,Semantics;Predictive models;Feature extraction;Quality assurance;Computer bugs;Data models;Prediction models,,184,,111,IEEE,23 Oct 2018,,,IEEE,IEEE Journals,True
Automatic Software Repair: A Survey,L. Gazzola; D. Micucci; L. Mariani,"Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy; Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy; Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy",IEEE Transactions on Software Engineering,8 Jan 2019,2019,45,1,34,67,"Despite their growing complexity and increasing size, modern software applications must satisfy strict release requirements that impose short bug fixing and maintenance cycles, putting significant pressure on developers who are responsible for timely producing high-quality software. To reduce developers workload, repairing and healing techniques have been extensively investigated as solutions for efficiently repairing and maintaining software in the last few years. In particular, repairing solutions have been able to automatically produce useful fixes for several classes of bugs that might be present in software programs. A range of algorithms, techniques, and heuristics have been integrated, experimented, and studied, producing a heterogeneous and articulated research framework where automatic repair techniques are proliferating. This paper organizes the knowledge in the area by surveying a body of 108 papers about automatic software repair techniques, illustrating the algorithms and the approaches, comparing them on representative examples, and discussing the open challenges and the empirical evidence reported so far.",1939-3520,,10.1109/TSE.2017.2755013,EU H2020; ERC Consolidator(grant numbers:646867); MIUR(grant numbers:2015KWREMX); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8089448,Automatic program repair;generate and validate;search-based;semantics-driven repair;correct by construction;program synthesis;self-repairing,Software;Maintenance engineering;Debugging;Computer bugs;Software algorithms;Fault diagnosis;Conferences,,220,,176,OAPA,30 Oct 2017,,,IEEE,IEEE Journals,True
Identifying Failure-Causing Schemas in the Presence of Multiple Faults,X. Niu; C. Nie; J. Y. Lei; H. Leung; X. Wang,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, USA; Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Computer Science, University of Texas at San Antonio, San Antonio, USA",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,141,162,"Combinatorial testing (CT) has been proven effective in revealing the failures caused by the interaction of factors that affect the behavior of a system. The theory of Minimal Failure-Causing Schema (MFS) has been proposed to isolate the cause of a failure after CT. Most algorithms that aim to identify MFS focus on handling a single fault in the System Under Test (SUT). However, we argue that multiple faults are more common in practice, under which masking effects may be triggered so that some failures cannot be observed. The traditional MFS theory lacks a mechanism to handle such effects; hence, they may incorrectly isolate the MFS. To address this problem, we propose a new MFS model that takes into account multiple faults. We first formally analyze the impact of the multiple faults on existing MFS identifying algorithms, especially in situations where masking effects are triggered by multiple faults. We then develop an approach that can assist traditional algorithms to better handle multiple faults. Empirical studies were conducted using several kinds of open-source software, which showed that multiple faults with masking effects do negatively affect traditional MFS identifying approaches and that our approach can help to alleviate these effects.",1939-3520,,10.1109/TSE.2018.2844259,National Key Research and Development Plan(grant numbers:2018YFB1003800); National Science Foundation(grant numbers:CNS-1748109); U.S. Department of Homeland Security(grant numbers:DHS-14-ST-062-001); National Institute of Standards and Technology(grant numbers:70NANB15H199); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372636,Software testing;combinatorial testing;failure-causing schemas;masking effects,Testing;Bars;Fault diagnosis;Computer bugs;Software algorithms;Open source software,,12,,51,IEEE,5 Jun 2018,,,IEEE,IEEE Journals,True
Today Was a Good Day: The Daily Life of Software Developers,A. N. Meyer; E. T. Barr; C. Bird; T. Zimmermann,"Department of Informatics, University of Zurich, Zürich, Switzerland; University College London, London, United Kingdom; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,863,880,"What is a good workday for a software developer? What is a typical workday? We seek to answer these two questions to learn how to make good days typical. Concretely, answering these questions will help to optimize development processes and select tools that increase job satisfaction and productivity. Our work adds to a large body of research on how software developers spend their time. We report the results from 5,971 responses of professional developers at Microsoft, who reflected about what made their workdays good and typical, and self-reported about how they spent their time on various activities at work. We developed conceptual frameworks to help define and characterize developer workdays from two new perspectives: good and typical. Our analysis confirms some findings in previous work, including the fact that developers actually spend little time on development and developers’ aversion for meetings and interruptions. It also discovered new findings, such as that only 1.7 percent of survey responses mentioned emails as a reason for a bad workday, and that meetings and interruptions are only unproductive during development phases; during phases of planning, specification and release, they are common and constructive. One key finding is the importance of agency, developers’ control over their workday and whether it goes as planned or is disrupted by external factors. We present actionable recommendations for researchers and managers to prioritize process and tool improvements that make good workdays typical. For instance, in light of our finding on the importance of agency, we recommend that, where possible, managers empower developers to choose their tools and tasks.",1939-3520,,10.1109/TSE.2019.2904957,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666786,Software developer workdays;productivity;job satisfaction;good workdays;typical workdays;quantified workplace,Software;Productivity;Task analysis;Encoding;Tools;Collaboration;Birds,,46,,111,IEEE,13 Mar 2019,,,IEEE,IEEE Journals,True
CACheck: Detecting and Repairing Cell Arrays in Spreadsheets,W. Dou; C. Xu; S. C. Cheung; J. Wei,"State Key Laboratory of Computer Science, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; State Key Laboratory of Computer Science, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,14 Mar 2017,2017,43,3,226,251,"Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column as a cell array. When a spreadsheet evolves, the cells in a cell array can degenerate due to ad hoc modifications. Such degenerated cell arrays no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. We propose CACheck, a novel technique that automatically detects and repairs smelly cell arrays by recovering their intended computational semantics. Our empirical study on the EUSES and Enron corpora finds that such smelly cell arrays are common. Our study also suggests that CACheck is useful for detecting and repairing real spreadsheet problems caused by smelly cell arrays. Compared with our previous work AmCheck, CACheck detects smelly cell arrays with higher precision and recall rate.",1939-3520,,10.1109/TSE.2016.2584059,"Beijing Natural Science Foundation(grant numbers:4164104); National Key Research and Development Plan(grant numbers:2016YFB1000803); Research Grants Council; General Research Fund(grant numbers:611811); National Natural Science Foundation(grant numbers:61472174,91318301,61321491); Collaborative Innovation Center of Novel Software Technology and Industrialization of China; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498607,Spreadsheet;cell array;ambiguous computation smell,Semantics;Maintenance engineering;Software;Computer science;Nonhomogeneous media;Electronic mail;Business,,23,,63,IEEE,23 Jun 2016,,,IEEE,IEEE Journals,True
"Mapping Bug Reports to Relevant Files: A Ranking Model, a Fine-Grained Benchmark, and Feature Evaluation",X. Ye; R. Bunescu; C. Liu,"School of Electrical Engineering and Computer Science, Ohio University, Athens, OH; School of Electrical Engineering and Computer Science, Ohio University, Athens, OH; School of Electrical Engineering and Computer Science, Ohio University, Athens, OH",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,379,402,"When a new bug report is received, developers usually need to reproduce the bug and perform code reviews to find the cause, a process that can be tedious and time consuming. A tool for ranking all the source files with respect to how likely they are to contain the cause of the bug would enable developers to narrow down their search and improve productivity. This paper introduces an adaptive ranking approach that leverages project knowledge through functional decomposition of source code, API descriptions of library components, the bug-fixing history, the code change history, and the file dependency graph. Given a bug report, the ranking score of each source file is computed as a weighted combination of an array of features, where the weights are trained automatically on previously solved bug reports using a learning-to-rank technique. We evaluate the ranking system on six large scale open source Java projects, using the before-fix version of the project for every bug report. The experimental results show that the learning-to-rank approach outperforms three recent state-of-the-art methods. In particular, our method makes correct recommendations within the top 10 ranked source files for over 70 percent of the bug reports in the Eclipse Platform and Tomcat projects.",1939-3520,,10.1109/TSE.2015.2479232,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270328,Bug reports;software maintenance;learning to rank;Bug reports;software maintenance;learning to rank,Software;History;Computational modeling;Computer bugs;Collaboration;Benchmark testing;Standards,,61,1,72,OAPA,16 Sep 2015,,,IEEE,IEEE Journals,True
A Game-Theoretic Foundation for the Maximum Software Resilience against Dense Errors,C. -H. Huang; D. A. Peled; S. Schewe; F. Wang,"Graduate Institute of Electronic Engineering, National Taiwan University, Taiwan, ROC; Department of Computer Science, Bar Ilan University, Ramat Gan, Israel; Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; Graduate Institute of Electronic Engineering, National Taiwan University, Taiwan, ROC",IEEE Transactions on Software Engineering,14 Jul 2016,2016,42,7,605,622,"Safety-critical systems need to maintain their functionality in the presence of multiple errors caused by component failures or disastrous environment events. We propose a game-theoretic foundation for synthesizing control strategies that maximize the resilience of a software system in defense against a realistic error model. The new control objective of such a game is called $k$ -resilience. In order to be $k$ -resilient, a system needs to rapidly recover from infinitely many waves of a small number of up to $k$  close errors provided that the blocks of up to $k$  errors are separated by short time intervals, which can be used by the system to recover. We first argue why we believe this to be the right level of abstraction for safety critical systems when local faults are few and far between. We then show how the analysis of $k$ -resilience problems can be formulated as a model-checking problem of a mild extension to the alternating-time  $\mu$ -calculus (AMC). The witness for $k$  resilience, which can be provided by the model checker, can be used for providing control strategies that are optimal with respect to resilience. We show that the computational complexity of constructing such optimal control strategies is low and demonstrate the feasibility of our approach through an implementation and experimental results.",1939-3520,,10.1109/TSE.2015.2510001,ISF(grant numbers:126/12); Efficient Synthesis Method of Control for Concurrent Systems; Engineering and Physical Science Research Council (EPSRC)(grant numbers:EP/H046623/1); MOST(grant numbers:103-2221-E-002-150-MY3); Research Center for Information Technology Innovation (CITI); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360234,Fault tolerance;resilience;formal verification;model-checking;game;strategy;complexity,Resilience;Games;Software systems;Safety;Game theory;Computer science,,8,,44,IEEE,17 Dec 2015,,,IEEE,IEEE Journals,True
Automatic Detection and Repair Recommendation of Directive Defects in Java API Documentation,Y. Zhou; C. Wang; X. Yan; T. Chen; S. Panichella; H. Gall,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Computer Science and Information Systems, Birkbeck, University of London, Bloomsbury, United Kingdom; Department of Informatics, Zurich University of Applied Science, Winterthur, Switzerland; Department of Informatics, University of Zurich, Zurich, Switzerland",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,1004,1023,"Application Programming Interfaces (APIs) represent key tools for software developers to build complex software systems. However, several studies have revealed that even major API providers tend to have incomplete or inconsistent API documentation. This can severely hamper the API comprehension and, as a consequence, the quality of the software built on them. In this paper, we propose DRONE (Detect and Repair of dOcumentatioN dEfects), a framework to automatically detect and repair defects from API documents by leveraging techniques from program analysis, natural language processing, and constraint solving. Specifically, we target at the directives of API documents, which are related to parameter constraints and exception handling declarations. Furthermore, in presence of defects, we also provide a prototypical repair recommendation system. We evaluate our approach on parts of the well-documented APIs of JDK 1.8 APIs (including javaFX) and Android 7.0 (level 24). Across the two empirical studies, our approach can detect API defects with an average F-measure of 79.9, 71.7, and 81.4 percent, respectively. The API repairing capability has also been evaluated on the generated recommendations in a further experiment. User judgments indicate that the constraint information is addressed correctly and concisely in the rendered directives.",1939-3520,,10.1109/TSE.2018.2872971,"National Key R&D Program of China(grant numbers:2018YFB1003900); Collaborative Innovation Center of Novel Software Technology in China; UK EPSRC(grant numbers:EP/P00430X/1); ARC Discovery Project(grant numbers:DP160101652,DP180100691); National Natural Science Foundation of China(grant numbers:61662035); Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:200021-166275); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478004,API documentation;directive defects;natural language processing;repair recommendation,Documentation;Maintenance engineering;Software;Drones;Androids;Humanoid robots;Facebook,,26,,72,IEEE,30 Sep 2018,,,IEEE,IEEE Journals,True
"Perceptions, Expectations, and Challenges in Defect Prediction",Z. Wan; X. Xia; A. E. Hassan; D. Lo; J. Yin; X. Yang,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China",IEEE Transactions on Software Engineering,11 Nov 2020,2020,46,11,1241,1266,"Defect prediction has been an active research area for over four decades. Despite numerous studies on defect prediction, the potential value of defect prediction in practice remains unclear. To address this issue, we performed a mixed qualitative and quantitative study to investigate what practitioners think, behave and expect in contrast to research findings when it comes to defect prediction. We collected hypotheses from open-ended interviews and a literature review of defect prediction papers that were published at ICSE, ESEC/FSE, ASE, TSE and TOSEM in the last 6 years (2012-2017). We then conducted a validation survey where the hypotheses became statements or options of our survey questions. We received 395 responses from practitioners from over 33 countries across five continents. Some of our key findings include: 1) Over 90 percent of respondents are willing to adopt defect prediction techniques. 2) There exists a disconnect between practitioners' perceptions and well supported research evidence regarding defect density distribution and the relationship between file size and defectiveness. 3) 7.2 percent of the respondents reveal an inconsistency between their behavior and perception regarding defect prediction. 4) Defect prediction at the feature level is the most preferred level of granularity by practitioners. 5) During bug fixing, more than 40 percent of the respondents acknowledged that they would make a “work-around” fix rather than correct the actual error-causing code. Through a qualitative analysis of free-form text responses, we identified reasons why practitioners are reluctant to adopt defect prediction tools. We also noted features that practitioners expect defect prediction tools to deliver. Based on our findings, we highlight future research directions and provide recommendations for practitioners.",1939-3520,,10.1109/TSE.2018.2877678,National Key Research and Development Program of China(grant numbers:2018YFB1003904); NSFC Program(grant numbers:61602403); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502824,Defect prediction;empirical study;practitioner;survey,Interviews;Tools;Software;Bibliographies;Computer bugs;Companies;Continents,,96,,103,IEEE,23 Oct 2018,,,IEEE,IEEE Journals,True
IntRepair: Informed Repairing of Integer Overflows,P. Muntean; M. Monperrus; H. Sun; J. Grossklags; C. Eckert,"Department of Computer Science, Technical University of Munich, München, Germany; Department of Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Computer Science and Technology, State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science, Technical University of Munich, München, Germany; Department of Computer Science, Technical University of Munich, München, Germany",IEEE Transactions on Software Engineering,14 Oct 2021,2021,47,10,2225,2241,"Integer overflows have threatened software applications for decades. Thus, in this paper, we propose a novel technique to provide automatic repairs of integer overflows in C source code. Our technique, based on static symbolic execution, fuses detection, repair generation and validation. This technique is implemented in a prototype named IntRepair. We applied IntRepair to 2,052 C programs (approx. 1 million lines of code) contained in SAMATE's Juliet test suite and 50 synthesized programs that range up to 20 KLOC. Our experimental results show that IntRepair is able to effectively detect integer overflows and successfully repair them, while only increasing the source code (LOC) and binary (Kb) size by around 1 percent, respectively. Further, we present the results of a user study with 30 participants which shows that IntRepair repairs are more than 10x efficient as compared to manually generated code repairs.",1939-3520,,10.1109/TSE.2019.2946148,"Wallenberg Artificial Intelligence, Autonomous Systems, and Software Program; Knut och Alice Wallenbergs Stiftelse; Stiftelsen för Strategisk Forskning; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862860,Program repair;source code refactoring;integer overflow;software fault;symbolic execution;static program analysis,Maintenance engineering;Software;Tools;Fault detection;Runtime;Engines;Fuses,,13,,62,IEEE,8 Oct 2019,,,IEEE,IEEE Journals,True
Effect of Domain Knowledge on Elicitation Effectiveness: An Internally Replicated Controlled Experiment,A. M. Aranda; O. Dieste; N. Juristo,"Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Spain",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,427,451,"Context. Requirements elicitation is a highly communicative activity in which human interactions play a critical role. A number of analyst characteristics or skills may influence elicitation process effectiveness. Aim. Study the influence of analyst problem domain knowledge on elicitation effectiveness.  Method. We executed a controlled experiment with post-graduate students. The experimental task was to elicit requirements using open interview and consolidate the elicited information immediately afterwards. We used four different problem domains about which students had different levels of knowledge. Two tasks were used in the experiment, whereas the other two were used in an internal replication of the experiment; that is, we repeated the experiment with the same subjects but with different domains. Results. Analyst problem domain knowledge has a small but statistically significant effect on the effectiveness of the requirements elicitation activity. The interviewee has a big positive and significant influence, as does general training in requirements activities and interview experience. Conclusion. During early contacts with the customer, a key factor is the interviewee; however, training in tasks related to requirements elicitation and knowledge of the problem domain helps requirements analysts to be more effective.",1939-3520,,10.1109/TSE.2015.2494588,Spanish Ministry of Ministry of Economy and Competitiveness(grant numbers:TIN2011-23216); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307191,Controlled experiment;domain knowledge;requirements elicitation;internal replication;Controlled experiment;domain knowledge;requirements elicitation;internal replication,Interviews;Knowledge engineering;Computer science;Software engineering;Requirements engineering;Training,,20,,56,IEEE,26 Oct 2015,,,IEEE,IEEE Journals,True
Evaluating Model-Driven Development Claims with Respect to Quality: A Family of Experiments,J. I. Panach; Ó. Dieste; B. Marín; S. España; S. Vegas; Ó. Pastor; N. Juristo,"Departament d'Informàtica, Escola Tècnica Superior d'Enginyeria, Universitat de València, Avinguda de la Universitat, València, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain; Escuela de Informática y Telecomunicaciones, Facultad de Ingeniería, Universidad Diego Portales, Santiago, Chile; Utrecht University, Utrecht, The Netherlands; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain; Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València, Valencia, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,130,145,"Context: There is a lack of empirical evidence on the differences between model-driven development (MDD), where code is automatically derived from conceptual models, and traditional software development method, where code is manually written. In our previous work, we compared both methods in a baseline experiment concluding that quality of the software developed following MDD was significantly better only for more complex problems (with more function points). Quality was measured through test cases run on a functional system. Objective: This paper reports six replications of the baseline to study the impact of problem complexity on software quality in the context of MDD. Method: We conducted replications of two types: strict replications and object replications. Strict replications were similar to the baseline, whereas we used more complex experimental objects (problems) in the object replications. Results: MDD yields better quality independently of problem complexity with a moderate effect size. This effect is bigger for problems that are more complex. Conclusions: Thanks to the bigger size of the sample after aggregating replications, we discovered an effect that the baseline had not revealed due to the small sample size. The baseline results hold, which suggests that MDD yields better quality for more complex problems.",1939-3520,,10.1109/TSE.2018.2884706,"Ministerio de Ciencia e Innovación(grant numbers:TIN2016-80811-P,TIN2014-60490-P); European Regional Development Fund; Generalitat Valenciana(grant numbers:PROMETEO/2018/176); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565892,Automatic programming;methodologies;validation,Unified modeling language;Productivity;Complexity theory;Inspection;Model-driven development;Software quality,,11,,50,IEEE,6 Dec 2018,,,IEEE,IEEE Journals,True
Integrative Double Kaizen Loop (IDKL): Towards a Culture of Continuous Learning and Sustainable Improvements for Software Organizations,O. Al-Baik; J. Miller,"Department of Electronics & Computer Engineering, University of Alberta Edmonton, Edmonton, Canada; Department of Electronics & Computer Engineering, University of Alberta Edmonton, Edmonton, Canada",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1189,1210,"In the past decades, software organizations have been relying on implementing process improvement methods to advance quality, productivity, and predictability of their development and maintenance efforts. However, these methods have proven to be challenging to implement in many situations, and when implemented, their benefits are often not sustained. Commonly, the workforce requires guidance during the initial deployment, but what happens after the guidance stops? Why do not traditional improvement methods deliver the desired results? And, how do we maintain the improvements when they are realized? In response to these questions, we have combined social and organizational learning methods with Lean's continuous improvement philosophy, Kaizen, which has resulted in an IDKL model that has successfully promoted continuous learning and improvement. The IDKL has evolved through a real-life project with an industrial partner; the study employed ethnographic action research with 231 participants and had lasted for almost 3 years. The IDKL requires employees to continuously apply small improvements to the daily routines of the work-procedures. The small improvements by themselves are unobtrusive. However, the IDKL has helped the industrial partner to implant continuous improvement as a daily habit. This has led to realizing sustainable and noticeable improvements. The findings show that on average, Lead Time has dropped by 46 percent, Process Cycle Efficiency has increased by 137 percent, First-Pass Process Yield has increased by 27 percent, and Customer Satisfaction has increased by 25 percent.",1939-3520,,10.1109/TSE.2018.2829722,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345680,Kaizen;lean;organization learning;double loop learning;case study;empirical research,Continuous improvement;Research and development;Standards organizations;Learning systems,,6,,66,IEEE,24 Apr 2018,,,IEEE,IEEE Journals,True
A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches,S. Herbold; A. Trautsch; J. Grabowski,"University of Goettingen, University of Goettingen, Göttingen, Germany; University of Goettingen, University of Goettingen, Göttingen, Germany; University of Goettingen, University of Goettingen, Göttingen, Germany",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,811,833,"Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However, within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article, we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark, we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009), Menzies et al. (2011), and Watanabe et al. (2008) are also nearly always among the best results. Moreover, we determined that predictions only seldom achieve a high performance of 0.75 recall, precision, and accuracy. Thus, CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.",1939-3520,,10.1109/TSE.2017.2724538,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7972992,Cross-project defect prediction;benchmark;comparison;replication,Benchmark testing;Prediction methods;Software;Quality assurance;Measurement;Correlation,,159,,90,IEEE,11 Jul 2017,,,IEEE,IEEE Journals,True
Global-Aware Recommendations for Repairing Violations in Exception Handling,E. A. Barbosa; A. Garcia,"Digital Metropolis Institute, Federal University of Rio Grande do Norte, Caicó - RN, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro - RJ, Brazil",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,855,873,"Empirical evidence suggests exception handling is not reliably implemented. Most faults in exception handling are related to global exceptions violating the intended exception handling design. However, repairing these violations is a cumbersome and error-prone task. It requires knowing the intended design and understanding how the source code violates it. It also requires changing the source code to make it compliant with the intended design. But changing the exception handling code is a difficult task, since changes in exception handling requires changing different parts of a program. Currently, there is still no solution to assist the repair of this type of violations. To bridge this gap, we present RAVEN, a heuristic strategy aware of the global context of exceptions that produces recommendations of how violations in exception handling may be repaired. This strategy takes advantage of explicit specifications of the intended design, although their availability is not mandatory. Our results revealed RAVEN provides recommendations able to repair violations in 69 percent of the cases when policy specifications are not available and in 97 percent of the cases when specifications are available. Thus, development teams may benefit from RAVEN, even when exception handling design decisions are not documented in their projects.",1939-3520,,10.1109/TSE.2017.2716925,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953550,Exception handling;recommender heuristic;software repair,Source coding;Robustness;Runtime;Software development management;Software reliability,,14,,51,IEEE,19 Jun 2017,,,IEEE,IEEE Journals,True
Easy-to-Deploy API Extraction by Multi-Level Feature Embedding and Transfer Learning,S. Ma; Z. Xing; C. Chen; C. Chen; L. Qu; G. Li,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; College of Engineering & Computer Science, Australian National University, Canberra, ACT, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; PricewaterhouseCoopers Firm, Shanghai, China; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Software, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Software Engineering,14 Oct 2021,2021,47,10,2296,2311,"Application Programming Interfaces (APIs) have been widely discussed on social-technical platforms (e.g., Stack Overflow). Extracting API mentions from such informal software texts is the prerequisite for API-centric search and summarization of programming knowledge. Machine learning based API extraction has demonstrated superior performance than rule-based methods in informal software texts that lack consistent writing forms and annotations. However, machine learning based methods have a significant overhead in preparing training data and effective features. In this paper, we propose a multi-layer neural network based architecture for API extraction. Our architecture automatically learns character-, word- and sentence-level features from the input texts, thus removing the need for manual feature engineering and the dependence on advanced features (e.g., API gazetteers) beyond the input texts. We also propose to adopt transfer learning to adapt a source-library-trained model to a target-library, thus reducing the overhead of manual training-data labeling when the software text of multiple programming languages and libraries need to be processed. We conduct extensive experiments with six libraries of four programming languages which support diverse functionalities and have different API-naming and API-mention characteristics. Our experiments investigate the performance of our neural architecture for API extraction in informal software texts, the importance of different features, the effectiveness of transfer learning. Our results confirm not only the superior performance of our neural architecture than existing machine learning based methods for API extraction in informal software texts, but also the easy-to-deploy characteristic of our neural architecture.",1939-3520,,10.1109/TSE.2019.2946830,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865646,API extraction;CNN;word embedding;LSTM;transfer learning,Libraries;Feature extraction;Machine learning;Software;Computer architecture;Training data;Manuals,,25,,61,IEEE,14 Oct 2019,,,IEEE,IEEE Journals,True
What Do Programmers Discuss About Blockchain? A Case Study on the Use of Balanced LDA and the Reference Architecture of a Domain to Capture Online Discussions About Blockchain Platforms Across Stack Exchange Communities,Z. Wan; X. Xia; A. E. Hassan,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; Faculty of Information Technology, Monash University, Melbourne, Australia; School of Computing, Queen’s University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,16 Jul 2021,2021,47,7,1331,1349,"Blockchain-related discussions have become increasingly prevalent in programming Q&A websites, such as Stack Overflow and other Stack Exchange communities. Analyzing and understanding those discussions could provide insights about the topics of interest to practitioners, and help the software development and research communities better understand the needs and challenges facing developers as they work in this new domain. Prior studies propose the use of LDA to study the Stack Exchange discussions. However, a simplistic use of LDA would capture the topics in discussions blindly without keeping in mind the variety of the dataset and domain-specific concepts. Specifically, LDA is biased towards larger sized corpora; and LDA-derived topics are not linked to higher level domain-specific concepts. We propose an approach that combines balanced LDA (which ensures that the topics are balanced across a domain) with the reference architecture of a domain to capture and compare the popularity and impact of discussion topics across the Stack Exchange communities. Popularity measures the distribution of interest in discussions, and impact gauges the trend of popularity over time. We made a number of interesting observations, including: (1) Bitcoin, Ethereum, Hyperledger Fabric and Corda are the four most commonly-discussed blockchain platforms on the Stack Exchange communities. (2) A broad range of topics are discussed across the various platforms of distinct layers in our derived reference architecture. (3) The Application layer topics exhibit the highest popularity (33.2 percent) and fastest growth in topic impact since November 2015. (4) The Application, API, Consensus and Network layer topics are discussed across the studied blockchain platforms, but exhibit different distributions in popularity. (5) The impact of architectural layer topics exhibits an upward trend, but is growing at different speeds across the studied blockchain platforms. The breakdown of the topic impact across the architectural layers is relatively stable over time except for the Hyperledger Fabric platform. Based on our findings, we highlighted future directions and provided recommendations for practitioners and researchers.",1939-3520,,10.1109/TSE.2019.2921343,National Key Research and Development Program of China(grant numbers:2018YFB1003904); National Natural Science Foundation of China(grant numbers:61602403); Science and Technology Research and Development Program of China Railway Corporation(grant numbers:P2018X002); Fundamental Research Funds for the Central Universities; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732384,Empirical study;reference architecture;blockchain;stack overflow;stack exchange,Blockchain;Peer-to-peer computing;Computer architecture;Smart contracts;Programming;Bitcoin,,31,,95,IEEE,6 Jun 2019,,,IEEE,IEEE Journals,True
A Layered Reference Architecture for Metamodels to Tailor Quality Modeling and Analysis,R. Heinrich; M. Strittmatter; R. Reussner,"Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,775,800,"Nearly all facets of our everyday life strongly depend on software-intensive systems. Besides correctness, highly relevant quality properties of these systems include performance, as directly perceived by the user, and maintainability, as an important decision factor for evolution. These quality properties strongly depend on architectural design decisions. Hence, to ensure high quality, research and practice is interested in approaches to analyze the system architecture for quality properties. Therefore, models of the system architecture are created and used for analysis. Many different languages (often defined by metamodels) exist to model the systems and reason on their quality. Such languages are mostly specific to quality properties, tools or development paradigms. Unfortunately, the creation of a specific model for any quality property of interest and any different tool used is simply infeasible. Current metamodels for quality modeling and analysis are often not designed to be extensible and reusable. Experience from generalizing and extending metamodels result in hard to evolve and overly complex metamodels. A systematic way of creating, extending and reusing metamodels for quality modeling and analysis, or parts of them, does not exist yet. When comparing metamodels for different quality properties, however, substantial parts show quite similar language features. This leads to our approach to define the first reference architecture for metamodels for quality modeling and analysis. A reference architecture in software engineering provides a general architecture for a given application domain. In this paper, we investigate the applicability of modularization concepts from object-oriented design and the idea of a reference architecture to metamodels for quality modeling and analysis to systematically create, extend and reuse metamodel parts. Thus, the reference architecture allows to tailor metamodels. Requirements on the reference architecture are gathered from a historically grown metamodel. We specify modularization concepts as a foundation of the reference architecture. Detailed application guidelines are described. We argue the reference architecture supports instance compatibility and non-intrusive, independent extension of metamodels. In four case studies, we refactor historically grown metamodels and compare them to the original metamodels. The study results show the reference architecture significantly improves evolvability as well as need-specific use and reuse of metamodels.",1939-3520,,10.1109/TSE.2019.2903797,"Helmholtz Association of German Research Centers and the MWK (Ministry of Science, Research and the Arts Baden-Württemberg) in the funding line Research Seed Capital (RiSC); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662719,Domain-specific modeling language;reference architecture;metamodel;quality analysis,Computer architecture;Object oriented modeling;Analytical models;Biological system modeling;Tools;Software;Systematics,,7,,84,IEEE,7 Mar 2019,,,IEEE,IEEE Journals,True
A Machine Learning Approach to Improve the Detection of CI Skip Commits,R. Abdalkareem; S. Mujahid; E. Shihab,"Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada",IEEE Transactions on Software Engineering,10 Dec 2021,2021,47,12,2740,2754,"Continuous integration (CI) frameworks, such as Travis CI, are growing in popularity, encouraged by market trends towards speeding up the release cycle and building higher-quality software. A key facilitator of CI is to automatically build and run tests whenever a new commit is submitted/pushed. Despite the many advantages of using CI, it is known that the CI process can take a very long time to complete. One of the core causes for such delays is the fact that some commits (e.g., cosmetic changes) unnecessarily kick off the CI process. Therefore, the main goal of this paper is to automate the process of determining which commits can be CI skipped through the use of machine learning techniques. We first extracted 23 features from historical data of ten software repositories. Second, we conduct a study on the detection of CI skip commits using machine learning where we built a decision tree classifier. We then examine the accuracy of using the decision tree in detecting CI skip commits. Our results show that the decision tree can identify CI skip commits with an average AUC equal to 0.89. Furthermore, the top node analysis shows that the number of developers who changed the modified files, the CI-Skip rules, and commit message are the most important features to detect CI skip commits. Finally, we investigate the generalizability of identifying CI skip commits through applying cross-project validation, and our results show that the general classifier achieves an average 0.74 of AUC values.",1939-3520,,10.1109/TSE.2020.2967380,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961089,Continuous integration;travis CI;build status;machine learning,Machine learning;Decision trees;Feature extraction;Message systems;Documentation;Buildings,,31,,69,IEEE,16 Jan 2020,,,IEEE,IEEE Journals,True
Enforcing Exception Handling Policies with a Domain-Specific Language,E. A. Barbosa; A. Garcia; M. P. Robillard; B. Jakobus,"OPUS Research Group, Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rua Marquês de São Vicente, 255-Gávea, Rio de Janeiro, Brazil; OPUS Research Group, Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rua Marquês de São Vicente, 255-Gávea, Rio de Janeiro, Brazil; School of Computer Science, University Street, McConnell Engineering Building, Office 114N, Montreal, Canada; OPUS Research Group, Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rua Marquês de São Vicente, 255-Gávea, Rio de Janeiro, Brazil",IEEE Transactions on Software Engineering,10 Jun 2016,2016,42,6,559,584,"Current software projects deal with exceptions in implementation and maintenance phases without a clear definition of exception handling policies. We call an exception handling policy the set of design decisions that govern the use of exceptions in a software project. Without an explicit exception handling policy, developers can remain unaware of the originally intended use of exceptions. In this paper, we present Exception Handling Policies Language (EPL), a domain-specific language to specify and verify exception handling policies. The evaluation of EPL was based on a user-centric observational study and case studies. The user-centric study was performed to observe how potential users of the language actually use it. With this study, we could better understand the trade-offs related to different language design decisions based on concrete and well-documented observations and experiences reported by participants. We identified some language characteristics that hindered its use and that motivated new language constructs. In addition, we performed case studies with one open-source project and two industry-strength systems to investigate how specifying and verifying exception handling policies may assist in detecting exception handling problems. The results show that violations of exception handling policies help to indicate potential faults in the exception handling code.",1939-3520,,10.1109/TSE.2015.2506164,Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro (FAPERJ)(grant numbers:E-26/100.386/2014); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7348692,Exception handling;Exception handling policy;Policy specification;Domain-specific language;Exception handling;exception handling policy;policy specification;domain-specific language,Java;Software reliability;Robustness;Software systems,,19,,46,IEEE,7 Dec 2015,,,IEEE,IEEE Journals,True
The Risks of Coverage-Directed Test Case Generation,G. Gay; M. Staats; M. Whalen; M. P. E. Heimdahl,"Department of Computer Science & Engineering, University of South Carolina; Google, Inc; Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,803,819,"A number of structural coverage criteria have been proposed to measure the adequacy of testing efforts. In the avionics and other critical systems domains, test suites satisfying structural coverage criteria are mandated by standards. With the advent of powerful automated test generation tools, it is tempting to simply generate test inputs to satisfy these structural coverage criteria. However, while techniques to produce coverage-providing tests are well established, the effectiveness of such approaches in terms of fault detection ability has not been adequately studied. In this work, we evaluate the effectiveness of test suites generated to satisfy four coverage criteria through counterexample-based test generation and a random generation approach-where tests are randomly generated until coverage is achieved-contrasted against purely random test suites of equal size. Our results yield three key conclusions. First, coverage criteria satisfaction alone can be a poor indication of fault finding effectiveness, with inconsistent results between the seven case examples (and random test suites of equal size often providing similar-or even higher-levels of fault finding). Second, the use of structural coverage as a supplement-rather than a target-for test generation can have a positive impact, with random test suites reduced to a coverage-providing subset detecting up to 13.5 percent more faults than test suites generated specifically to achieve coverage. Finally, Observable MC/DC, a criterion designed to account for program structure and the selection of the test oracle, can-in part-address the failings of traditional structural coverage criteria, allowing for the generation of test suites achieving higher levels of fault detection than random test suites of equal size. These observations point to risks inherent in the increase in test automation in critical systems, and the need for more research in how coverage criteria, test generation approaches, the test oracle used, and system structure jointly influence test effectiveness.",1939-3520,,10.1109/TSE.2015.2421011,"NASA(grant numbers:NNA06CB21A); NSF(grant numbers:CCF-0916583,CNS-0931931,CNS-1035715); Fonds National de la Recherche, Luxembourg(grant numbers:FNR/P10/03); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081779,Software Testing;System Testing;Software testing;system testing,Testing;Aerospace electronics;NASA;Standards;Fault detection;Measurement;Software packages,,82,,56,IEEE,8 Apr 2015,,,IEEE,IEEE Journals,True
Model Checking Software with First Order Logic Specifications Using AIG Solvers,M. A. Noureddine; F. A. Zaraket,"Department of Computer Science, University of Illinois at Urbana Champaign, IL; Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon",IEEE Transactions on Software Engineering,11 Aug 2016,2016,42,8,741,763,"Static verification techniques leverage Boolean formula satisfiability solvers such as SAT and SMT solvers that operate on conjunctive normal form and first order logic formulae, respectively, to validate programs. They force bounds on variable ranges and execution time and translate the program and its specifications into a Boolean formula. They are limited to programs of relatively low complexity for the following reasons. (1) A small increase in the bounds can cause a large increase in the size of the translated formula. (2) Boolean satisfiability solvers are restricted to using optimizations that apply at the level of the formula. Finally, (3) the Boolean formulae often need to be regenerated with higher bounds to ensure the correctness of the translation. We present a method that uses And-Inverter-Graph (AIG) sequential circuits, and AIG synthesis and verification frameworks to validate programs. An AIG is a Boolean formula with memory elements, logically complete negated conjunction gates, and a hierarchical structure. Encoding the validation problem of a program as an AIG (1) typically provides a more succinct representation than a Boolean formulae encoding with no memory elements, (2) preserves the high-level structure of the program, and (3) enables the use of a number of powerful automated analysis techniques that have no counterparts for other Boolean formulae such as CNF. Our method takes an imperative program with a first order logic specification consisting of a precondition and a postcondition pair, and a bound on the program variable ranges, and produces an AIG with a designated output that is ${true}$  when the program violates the specification. Our method uses AIG synthesis reduction techniques to reduce the AIG, and then uses AIG verification techniques to check the satisfiability of the designated output. The results show that our method can validate designs that are not possible with other state of the art techniques, and with bounds that are an order of magnitude larger.",1939-3520,,10.1109/TSE.2016.2520468,University Research Board; American University of Beirut; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7389426,Software verification;static analysis;Boolean satisfiability solvers;Hoare triplet,Sequential circuits;Model checking;Software;Encoding;Optimization;Radiation detectors;Interpolation,,4,,57,IEEE,21 Jan 2016,,,IEEE,IEEE Journals,True
Black-Box String Test Case Generation through a Multi-Objective Optimization,A. Shahbazi; J. Miller,"Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,361,378,"String test cases are required by many real-world applications to identify defects and security risks. Random Testing (RT) is a low cost and easy to implement testing approach to generate strings. However, its effectiveness is not satisfactory. In this research, black-box string test case generation methods are investigated. Two objective functions are introduced to produce effective test cases. The diversity of the test cases is the first objective, where it can be measured through string distance functions. The second objective is guiding the string length distribution into a Benford distribution based on the hypothesis that the population of strings is right-skewed within its range. When both objectives are applied via a multi-objective optimization algorithm, superior string test sets are produced. An empirical study is performed with several real-world programs indicating that the generated string test cases outperform test cases generated by other methods.",1939-3520,,10.1109/TSE.2015.2487958,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293669,Adaptive random testing;automated test case generation;black-box testing;mutation;random testing;software testing;string distance;string test cases;Adaptive random testing;automated test case generation;black-box testing;mutation;random testing;software testing;string distance;string test cases,Sociology;Statistics;Biological cells;Subspace constraints;Testing;Power capacitors;Genetic algorithms,,33,1,76,IEEE,7 Oct 2015,,,IEEE,IEEE Journals,True
Are Fix-Inducing Changes a Moving Target? A Longitudinal Case Study of Just-In-Time Defect Prediction,S. McIntosh; Y. Kamei,"Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; Principles of Software Languages Group (POSL), Kyushu University, Fukuoka, Japan",IEEE Transactions on Software Engineering,14 May 2018,2018,44,5,412,428,"Just-In-Time (JIT) models identify fix-inducing code changes. JIT models are trained using techniques that assume that past fix-inducing changes are similar to future ones. However, this assumption may not hold, e.g., as system complexity tends to accrue, expertise may become more important as systems age. In this paper, we study JIT models as systems evolve. Through a longitudinal case study of 37,524 changes from the rapidly evolving Qt and OpenStack systems, we find that fluctuations in the properties of fix-inducing changes can impact the performance and interpretation of JIT models. More specifically: (a) the discriminatory power (AUC) and calibration (Brier) scores of JIT models drop considerably one year after being trained; (b) the role that code change properties (e.g., Size, Experience) play within JIT models fluctuates over time; and (c) those fluctuations yield over- and underestimates of the future impact of code change properties on the likelihood of inducing fixes. To avoid erroneous or misleading predictions, JIT models should be retrained using recently recorded data (within three months). Moreover, quality improvement plans should be informed by JIT models that are trained using six months (or more) of historical data, since they are more resilient to period-specific fluctuations in the importance of code change properties.",1939-3520,,10.1109/TSE.2017.2693980,Natural Sciences and Engineering Research Council of Canada (NSERC); JSPS KAKENHI(grant numbers:15H05306); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898457,Just-In-Time prediction;defect prediction;mining software repositories,Predictive models;Data models;Software;Complexity theory;Market research;Context modeling;Calibration,,148,,48,IEEE,12 Apr 2017,,,IEEE,IEEE Journals,True
The Impact of Class Rebalancing Techniques on the Performance and Interpretation of Defect Prediction Models,C. Tantithamthavorn; A. E. Hassan; K. Matsumoto,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan",IEEE Transactions on Software Engineering,11 Nov 2020,2020,46,11,1200,1219,"Defect models that are trained on class imbalanced datasets (i.e., the proportion of defective and clean modules is not equally represented) are highly susceptible to produce inaccurate prediction models. Prior research compares the impact of class rebalancing techniques on the performance of defect models but arrives at contradictory conclusions due to the use of different choice of datasets, classification techniques, and performance measures. Such contradictory conclusions make it hard to derive practical guidelines for whether class rebalancing techniques should be applied in the context of defect models. In this paper, we investigate the impact of class rebalancing techniques on the performance measures and interpretation of defect models. We also investigate the experimental settings in which class rebalancing techniques are beneficial for defect models. Through a case study of 101 datasets that span across proprietary and open-source systems, we conclude that the impact of class rebalancing techniques on the performance of defect prediction models depends on the used performance measure and the used classification techniques. We observe that the optimized SMOTE technique and the under-sampling technique are beneficial when quality assurance teams wish to increase AUC and Recall, respectively, but they should be avoided when deriving knowledge and understandings from defect models.",1939-3520,,10.1109/TSE.2018.2876537,Grant-in-Aid for JSPS Fellows(grant numbers:16J03360); Natural Sciences and Engineering Research Council of Canada; Australian Research Council(grant numbers:DE200100941); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8494821,Software quality assurance;software defect prediction;class rebalancing techniques;experimental design;empirical investigation,Predictive models;Training;Analytical models;Guidelines;Context modeling;Open source software,,186,,69,IEEE,17 Oct 2018,,,IEEE,IEEE Journals,True
GK-Tail+ An Efficient Approach to Learn Software Models,L. Mariani; M. Pezzè; M. Santoro,"Department of Informatics, University of Milano Bicocca, Milano, Italy; Faculty of Informatics, Universitá della Svizzera Italiana, Lugano, Switzerland; Faculty of Informatics, Universitá della Svizzera Italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,11 Aug 2017,2017,43,8,715,738,"Inferring models of program behavior from execution samples can provide useful information about a system, also in the increasingly common case of systems that evolve and adapt in their lifetime, and without requiring large developers' effort. Techniques for learning models of program behavior from execution traces shall address conflicting challenges of recall, specificity and performance: They shall generate models that comprehensively represent the system behavior (recall) while limiting the amount of illegal behaviors that may be erroneously accepted by the model (specificity), and should infer the models within a reasonable time budget to process industrial scale systems (performance). In our early work, we designed GK-tail, an approach that can infer guarded finite state machines that model the behavior of object-oriented programs in terms of sequences of method calls and constraints on the parameter values. GK-tail addresses well two of the three main challenges, since it infers guarded finite state machines with a high level of recall and specificity, but presents severe limitations in terms of performance that reduce its scalability. In this paper, we present GK-tail+, a new approach to infer guarded finite state machines from execution traces of object-oriented programs. GK-tail+ proposes a new set of inference criteria that represent the core element of the inference process: It largely reduces the inference time of GK-tail while producing guarded finite state machines with a comparable level of recall and specificity. Thus, GK-tail+ advances the preliminary results of GK-tail by addressing all the three main challenges of learning models of program behavior from execution traces.",1939-3520,,10.1109/TSE.2016.2623623,The H2020 Learn project; ERC Consolidator Grant 2014 program; ERC(grant numbers:646867); Swiss National Foundation; SNF(grant numbers:200021_162409); ASysT: Automatic System Testing; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7728088,Dynamic model learning;software models;state based models;guarded finite state machines;specification mining,Object oriented modeling;Merging;Analytical models;Adaptation models;Software systems;Limiting,,24,,55,IEEE,1 Nov 2016,,,IEEE,IEEE Journals,True
A Framework for Temporal Verification Support in Domain-Specific Modelling,B. Meyers; H. Vangheluwe; J. Denil; R. Salay,"Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Computer Science, University of Toronto, Toronto, Canada",IEEE Transactions on Software Engineering,16 Apr 2020,2020,46,4,362,404,"In Domain-Specific Modelling (DSM) the general goal is to provide Domain-Specific Modelling Languages (DSMLs) for domain users to model systems using concepts and notations they are familiar with, in their problem domain. Verifying whether a model satisfies a set of requirements is considered to be an important challenge in DSM, but is nevertheless mostly neglected. We present a solution in the form of ProMoBox, a framework that integrates the definition and verification of temporal properties in discrete-time behavioural DSMLs, whose semantics can be described as a schedule of graph rewrite rules. Thanks to the expressiveness of graph rewriting, this covers a very large class of problems. With ProMoBox, the domain user models not only the system with a DSML, but also its properties, input model, run-time state and output trace. A DSML is thus comprised of five sublanguages, which share domain-specific syntax, and are generated from a single metamodel. Generic transformations to and from a verification backbone ensure that both the language engineer and the domain user are shielded from underlying notations and techniques. We explicitly model the ProMoBox framework's process in the paper. Furthermore, we evaluate ProMoBox to assert that it supports the specification and verification of properties in a highly flexible and automated way.",1939-3520,,10.1109/TSE.2018.2859946,Flanders Make vzw; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419296,Domain-specific modelling;model-driven engineering;language engineering,Syntactics;Semantics;Formal specifications;Formal verification;Model driven engineering;Model checking,,10,,88,IEEE,25 Jul 2018,,,IEEE,IEEE Journals,True
ConPredictor: Concurrency Defect Prediction in Real-World Applications,T. Yu; W. Wen; X. Han; J. H. Hayes,"Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,558,575,"Concurrent programs are difficult to test due to their inherent non-determinism. To address this problem, testing often requires the exploration of thread schedules of a program; this can be time-consuming when applied to real-world programs. Software defect prediction has been used to help developers find faults and prioritize their testing efforts. Prior studies have used machine learning to build such predicting models based on designed features that encode the characteristics of programs. However, research has focused on sequential programs; to date, no work has considered defect prediction for concurrent programs, with program characteristics distinguished from sequential programs. In this paper, we present ConPredictor, an approach to predict defects specific to concurrent programs by combining both static and dynamic program metrics. Specifically, we propose a set of novel static code metrics based on the unique properties of concurrent programs. We also leverage additional guidance from dynamic metrics constructed based on mutation analysis. Our evaluation on four large open source projects shows that ConPredictor improved both within-project defect prediction and cross-project defect prediction compared to traditional features.",1939-3520,,10.1109/TSE.2018.2791521,"National Science Foundation(grant numbers:CCF-1464032,CCF-1652149,CCF-1511117); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252721,Concurrency;defect prediction;software quality;software metrics,Concurrent computing;Predictive models;Software;Programming;Testing;Synchronization,,27,,100,IEEE,9 Jan 2018,,,IEEE,IEEE Journals,True
Where Do Configuration Constraints Stem From? An Extraction Approach and an Empirical Study,S. Nadi; T. Berger; C. Kästner; K. Czarnecki,"Department of Computer Science, Technische Universität Darmstadt, Darmstadt, Hessen, Germany; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,820,841,"Highly configurable systems allow users to tailor software to specific needs. Valid combinations of configuration options are often restricted by intricate constraints. Describing options and constraints in a variability model allows reasoning about the supported configurations. To automate creating and verifying such models, we need to identify the origin of such constraints. We propose a static analysis approach, based on two rules, to extract configuration constraints from code. We apply it on four highly configurable systems to evaluate the accuracy of our approach and to determine which constraints are recoverable from the code. We find that our approach is highly accurate (93% and 77% respectively) and that we can recover 28% of existing constraints. We complement our approach with a qualitative study to identify constraint sources, triangulating results from our automatic extraction, manual inspections, and interviews with 27 developers. We find that, apart from low-level implementation dependencies, configuration constraints enforce correct runtime behavior, improve users’ configuration experience, and prevent corner cases. While the majority of constraints is extractable from code, our results indicate that creating a complete model requires further substantial domain knowledge and testing. Our results aim at supporting researchers and practitioners working on variability model engineering, evolution, and verification techniques.",1939-3520,,10.1109/TSE.2015.2415793,NSERC(grant numbers:CGS-D2-425005); ARTEMIS JU(grant numbers:295397); NSF(grant numbers:CCF-1318808); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065312,Variability models;Reverse-engineering;qualitative studies;Variability models;reverse-engineering;qualitative studies;static analyses;configuration constraints,Feature extraction;Kernel;Accuracy;Linux;Manuals;Interviews,,63,,80,IEEE,23 Mar 2015,,,IEEE,IEEE Journals,True
On Scheduling Constraint Abstraction for Multi-Threaded Program Verification,L. Yin; W. Dong; W. Liu; J. Wang,"Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, China; Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, China; Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, China; Laboratory of Software Engineering for Complex Systems, State Key Laboratory of High Performance Computing, School of Computer, National University of Defense Technology, Changsha, China",IEEE Transactions on Software Engineering,14 May 2020,2020,46,5,549,565,"Bounded model checking is among the most efficient techniques for the automated verification of concurrent programs. However, due to the nondeterministic thread interleavings, a large and complex formula is usually required to give an exact encoding of all possible behaviors, which significantly limits the scalability. Observing that the large formula is usually dominated by the exact encoding of the scheduling constraint, this paper proposes a novel scheduling constraint based abstraction refinement method for multi-threaded C program verification. Our method is both efficient in practice and complete in theory, which is challenging for existing techniques. To achieve this, we first proposed an effective and powerful technique which works well for nearly all benchmarks we evaluated. We have proposed the notion of Event Order Graph (EOG), and have devised two graph-based algorithms over EOG for counterexample validation and refinement generation, which can often obtain a small yet effective refinement constraint. Then, to ensure completeness, our method was enhanced with two constraint-based algorithms for counterexample validation and refinement generation. Experimental results on SV-COMP 2017 benchmarks and two real-world server systems indicate that our method is promising and significantly outperforms the state-of-the-art tools.",1939-3520,,10.1109/TSE.2018.2864122,"National Natural Science Foundation of China(grant numbers:61690203,61532007); National Key R&D program of China(grant numbers:2017YFB1001802); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428438,Multi-threaded program;bounded model checking;scheduling constraint;event order graph,Instruction sets;Electrooculography;Encoding;Concurrent computing;Programming;Model checking;Tools,,22,,45,IEEE,7 Aug 2018,,,IEEE,IEEE Journals,True
Platform-Independent Dynamic Taint Analysis for JavaScript,R. Karim; F. Tip; A. Sochůrková; K. Sen,"Samsung Research America, Mountain View, CA, USA; College of Computer and Information Science, Northeastern University, Boston, MA, USA; Avast, Prague, Czechia; University of California at Berkeley, Berkeley, CA, USA",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1364,1379,"Previous approaches to dynamic taint analysis for JavaScript are implemented directly in a browser or JavaScript engine, limiting their applicability to a single platform and requiring ongoing maintenance as platforms evolve, or they require nontrivial program transformations. We present an approach that relies on instrumentation to encode taint propagation as instructions for an abstract machine. Our approach has two key advantages: it is platform-independent and can be used with any existing JavaScript engine, and it can track taint on primitive values without requiring the introduction of wrapper objects. Furthermore, our technique enables multiple deployment scenarios by varying when and where the generated instructions are executed and it supports indirect taint sources, i.e., situations where taint enters an application via arguments passed to dynamically registered event-listener functions. We implemented the technique for the ECMAScript 5 language in a tool called Ichnaea, and evaluated it on 22 NPM modules containing several types of injection vulnerabilities, including 4 modules containing vulnerabilities that were not previously discovered and reported. On these modules, run-time overheads range from 3.17x to 38.42x, which is significantly better than a previous transformation-based technique. We also report on a case study that shows how Ichnaea can be used to detect privacy leaks in a Tizen web application for the Samsung Gear S2 smart watch.",1939-3520,,10.1109/TSE.2018.2878020,Czech Technical University; European Research Council(grant numbers:695412); National Science Foundation(grant numbers:CCF-1715153); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8511058,Taint analysis;dynamic analysis;JavaScript;platform-independent;instrumentation,Java;Instruments;Browsers;Software engineering;Privacy;Data privacy,,24,,39,IEEE,26 Oct 2018,,,IEEE,IEEE Journals,True
Interlocking Safety Cases for Unmanned Autonomous Systems in Shared Airspaces,M. Vierhauser; S. Bayley; J. Wyngaard; W. Xiong; J. Cheng; J. Huseman; R. Lutz; J. Cleland-Huang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Engineering, Polythechnique Montréal, Montreal, QC, Canada; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,899,918,"The growing adoption of unmanned aerial vehicles (UAVs) for tasks such as eCommerce, aerial surveillance, and environmental monitoring introduces the need for new safety mechanisms in an increasingly cluttered airspace. In our work we thus emphasize safety issues that emerge at the intersection of infrastructures responsible for controlling the airspace, and the diverse UAVs operating in their space. We build on safety assurance cases (SAC) – a state-of-the-art solution for reasoning about safety – and propose a novel approach based on interlocking SACs. The infrastructure safety case (ISAC) specifies assumptions upon UAV behavior, while each UAV demonstrates compliance to the ISAC by presenting its own (pluggable) safety case (pSAC) which connects to the ISAC through a set of interlock points. To collect information on each UAV we enforce a “trust but monitor” policy, supported by runtime monitoring and an underlying reputation model. We evaluate our approach in three ways: first by developing ISACs for two UAV infrastructures, second by running simulations to evaluate end-to-end effectiveness, and finally via an outdoor field-study with physical UAVs. The results show that interlocking SACs can be effective for identifying, specifying, and monitoring safety-related constraints upon UAVs flying in a controlled airspace.",1939-3520,,10.1109/TSE.2019.2907595,"National Science Foundation(grant numbers:CCF-1741781,CCF-1649448,CCF-1513717); Austrian Science Fund(grant numbers:FWF J3998-N31); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674543,UAV;unmanned autonomous systems;safety assurance cases;monitoring,Safety;Unmanned aerial vehicles;Monitoring;Runtime;Software;Atmospheric modeling;NASA,,14,,121,IEEE,26 Mar 2019,,,IEEE,IEEE Journals,True
Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs,J. Xuan; M. Martinez; F. DeMarco; M. Clément; S. L. Marcote; T. Durieux; D. Le Berre; M. Monperrus,"State Key Lab of Software Engineering, School of Computer, Wuhan University, Wuhan, China; Faculty of Informatics, University of Lugano, Lugano, Switzerland; University of Buenos Aires, Buenos Aires, Argentina; Department of Computer Science, University of Lille, Lille, France; University of Buenos Aires, Buenos Aires, Argentina; Department of Computer Science, University of Lille, Lille, France; University of Artois & CNRS, Lens, France; University of Lille & INRIA, Lille, France",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,34,55,"We propose Nopol, an approach to automatic repair of buggy conditional statements (i.e., if-then-else statements). This approach takes a buggy program as well as a test suite as input and generates a patch with a conditional expression as output. The test suite is required to contain passing test cases to model the expected behavior of the program and at least one failing test case that reveals the bug to be repaired. The process of Nopol consists of three major phases. First, Nopol employs angelic fix localization to identify expected values of a condition during the test execution. Second, runtime trace collection is used to collect variables and their actual values, including primitive data types and objected-oriented features (e.g., nullness checks), to serve as building blocks for patch generation. Third, Nopol encodes these collected data into an instance of a Satisfiability Modulo Theory (SMT) problem; then a feasible solution to the SMT instance is translated back into a code patch. We evaluate Nopol on 22 real-world bugs (16 bugs with buggy if conditions and six bugs with missing preconditions) on two large open-source projects, namely Apache Commons Math and Apache Commons Lang. Empirical analysis on these bugs shows that our approach can effectively fix bugs with buggy if conditions and missing preconditions. We illustrate the capabilities and limitations of Nopol using case studies of real bug fixes.",1939-3520,,10.1109/TSE.2016.2560811,INRIA Internship program; INRIA postdoctoral research fellowship; CNRS delegation program; National Natural Science Foundation of China(grant numbers:61502345); Young Talent Development Program of the China Computer Federation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463060,Automatic repair;patch generation;SMT;fault localization,Maintenance engineering;Computer bugs;Runtime;Java;Encoding;Open source software;Indexes,,281,,56,IEEE,29 Apr 2016,,,IEEE,IEEE Journals,True
A Tool-Supported Methodology for Validation and Refinement of Early-Stage Domain Models,M. Autili; A. Bertolino; G. De Angelis; D. D. Ruscio; A. D. Sandro,"Department of Information Engineering Computer Science and Mathematics University of L’Aquila, Italy; CNR-ISTI of Pisa, Italy; CNR-ISTI of Pisa, Italy; Department of Information Engineering Computer Science and Mathematics University of L’Aquila, Italy; Department of Computer Science, University of Toronto, Toronto, ON, Canada",IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,2,25,"Model-driven engineering (MDE) promotes automated model transformations along the entire development process. Guaranteeing the quality of early models is essential for a successful application of MDE techniques and related tool-supported model refinements. Do these models properly reflect the requirements elicited from the owners of the problem domain? Ultimately, this question needs to be asked to the domain experts. The problem is that a gap exists between the respective backgrounds of modeling experts and domain experts. MDE developers cannot show a model to the domain experts and simply ask them whether it is correct with respect to the requirements they had in mind. To facilitate their interaction and make such validation more systematic, we propose a methodology and a tool that derive a set of customizable questionnaires expressed in natural language from each model to be validated. Unexpected answers by domain experts help to identify those portions of the models requiring deeper attention. We illustrate the methodology and the current status of the developed tool MOTHIA, which can handle UML Use Case, Class, and Activity diagrams. We assess MOTHIA effectiveness in reducing the gap between domain and modeling experts, and in detecting modeling faults on the European Project CHOReOS.",1939-3520,,10.1109/TSE.2015.2449319,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132782,Domain Modeling;Early Stage Model;Model Driven Engineering;Model Refinement;Model Validation;Natural Language Questionnaires;Semantic Model Quality;Domain modeling;early stage model;model driven engineering;model refinement;model validation;natural language questionnaires;semantic model quality,Unified modeling language;Semantics;Context modeling;Load modeling;Engines;Biological system modeling;Context,,2,,50,IEEE,24 Jun 2015,,,IEEE,IEEE Journals,True
An Empirical Comparison of Model Validation Techniques for Defect Prediction Models,C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto,"Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan; Department of Electrical and Computer Engineering, Montreal, QC, Canada; School of Computing, Queen’s University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,1,18,"Defect prediction models help software quality assurance teams to allocate their limited resources to the most defect-prone modules. Model validation techniques, such as $k$ -fold cross-validation, use historical data to estimate how well a model will perform in the future. However, little is known about how accurate the estimates of model validation techniques tend to be. In this paper, we investigate the bias and variance of model validation techniques in the domain of defect prediction. Analysis of 101 public defect datasets suggests that 77 percent of them are highly susceptible to producing unstable results– - selecting an appropriate model validation technique is a critical experimental design choice. Based on an analysis of 256 studies in the defect prediction literature, we select the 12 most commonly adopted model validation techniques for evaluation. Through a case study of 18 systems, we find that single-repetition holdout validation tends to produce estimates with 46-229 percent more bias and 53-863 percent more variance than the top-ranked model validation techniques. On the other hand, out-of-sample bootstrap validation yields the best balance between the bias and variance of estimates in the context of our study. Therefore, we recommend that future defect prediction studies avoid single-repetition holdout validation, and instead, use out-of-sample bootstrap validation.",1939-3520,,10.1109/TSE.2016.2584050,JSPS; Advancing Strategic International Networks to Accelerate the Circulation of Talented Researchers; Interdisciplinary Global Networks for Accelerating Theory and Practice in Software Ecosystem; JSPS Fellows(grant numbers:16J03360); Natural Sciences and Engineering Research Council of Canada (NSERC); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497471,Defect prediction models;model validation techniques;bootstrap validation;cross validation;holdout validation,Predictive models;Data models;Analytical models;Context;Context modeling;Software;Logistics,,377,,5,IEEE,22 Jun 2016,,,IEEE,IEEE Journals,True
Explaining Regressions via Alignment Slicing and Mending,H. Wang; Y. Lin; Z. Yang; J. Sun; Y. Liu; J. Dong; Q. Zheng; T. Liu,"Ant Financial Services Group, China; School of Computing, National University of Singapore, Singapore; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; School of Information System, Singapore Management University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; Department of Computer Science, National University of Singapore, Singapore; Department of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Control, System Engineering Institute, Xi'an, Shaanxi, China",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2421,2437,"Regression faults, which make working code stop functioning, are often introduced when developers make changes to the software. Many regression fault localization techniques have been proposed. However, issues like inaccuracy and lack of explanation are still obstacles for their practical application. In this work, we propose a trace-based approach to identifying not only where the root cause of a regression bug lies, but also how the defect is propagated to its manifestation as the explanation. In our approach, we keep the trace of original correct version as reference and infer the faulty steps on the trace of regression version so that we can build a causality graph of how the defect is propagated. To this end, we overcomes two technical challenges. First, we align two traces derived from two program versions by extending state-of-the-art trace alignment technique for regression fault with novel relaxation technique. Second, we construct causality graph (i.e., explanation) by adopting a technique called alignment slicing and mending to isolate the failure-inducing changes and explain the failure. Our comparative experiment with the state-of-the-art techniques including dynamic slicing, delta-debugging, and symbolic execution on 24 real-world regressions shows that (1) our approach is more accurate on isolating the failure-inducing changes, (2) the generated explanation requires acceptable manual effort to inspect, and (3) our approach requires lower runtime overhead. In addition, we also conduct an applicability experiment based on Defects4J bug repository, showing the potential limitations of our trace-based approach and providing guidance for its practical use.",1939-3520,,10.1109/TSE.2019.2949568,"Ant Financial Research Program; National Research Foundation Singapore; Corporate Laboratory@University Scheme; National University of Singapore; National Cybersecurity R&D Program(grant numbers:NRF2014NCR-NCR001-30); Singapore Telecommunications Limited; Singapore Ministry of Education Academic Research Fund; National Cybersecurity R&D Directorate; National Satellite of Excellence in Trustworthy Software Systems; National Research Foundation Singapore; National Cyber-security R&D (NCR) programme; National Key Research and Development Program of China(grant numbers:2016YFB1000903); National Natural Science Foundation of China(grant numbers:61632015,61721002,U1766215,61833015); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883062,Regression bug;trace alignment;alignment slicing and mending;fault localization,Computer bugs;Semantics;Debugging;Java;Software;Runtime;Task analysis,,11,,50,IEEE,25 Oct 2019,,,IEEE,IEEE Journals,True
Improving Multi-Objective Test Case Selection by Injecting Diversity in Genetic Algorithms,A. Panichella; R. Oliveto; M. D. Penta; A. De Lucia,"Department of Mathematics and Computer Science, University of Salerno, Fisciano, Salerno, Italy; Department of Bioscience and Territory, University of Molise, Pesche, Isernia, Italy; Department of Engineering, University of Sannio, Benevento, Italy; Department of Mathematics and Computer Science, University of Salerno, Fisciano, Salerno, Italy",IEEE Transactions on Software Engineering,14 Apr 2015,2015,41,4,358,383,"A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.",1939-3520,,10.1109/TSE.2014.2364175,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936894,Test Case Selection;Regression Testing;Orthogonal Design;Singular Value Decomposition;Genetic Algorithms;Empirical Studies;Test case selection;regression testing;orthogonal design;singular value decomposition;genetic algorithms;empirical studies,Optimization;Greedy algorithms;Testing;Linear programming;Genetic algorithms;Genetics;Sociology,,94,,76,IEEE,27 Oct 2014,,,IEEE,IEEE Journals,True
An Integrated Approach for Effective Injection Vulnerability Analysis of Web Applications Through Security Slicing and Hybrid Constraint Solving,J. Thomé; L. K. Shar; D. Bianculli; L. Briand,"Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,163,195,"Malicious users can attack Web applications by exploiting injection vulnerabilities in the source code. This work addresses the challenge of detecting injection vulnerabilities in the server-side code of Java Web applications in a scalable and effective way. We propose an integrated approach that seamlessly combines security slicing with hybrid constraint solving; the latter orchestrates automata-based solving with meta-heuristic search. We use static analysis to extract minimal program slices relevant to security from Web programs and to generate attack conditions. We then apply hybrid constraint solving to determine the satisfiability of attack conditions and thus detect vulnerabilities. The experimental results, using a benchmark comprising a set of diverse and representative Web applications/services as well as security benchmark applications, show that our approach (implemented in the JOACO tool) is significantly more effective at detecting injection vulnerabilities than state-of-the-art approaches, achieving 98 percent recall, without producing any false alarm. We also compared the constraint solving module of our approach with state-of-the-art constraint solvers, using six different benchmark suites; our approach correctly solved the highest number of constraints (665 out of 672), without producing any incorrect result, and was the one with the least number of time-out/failing cases. In both scenarios, the execution time was practically acceptable, given the offline nature of vulnerability detection.",1939-3520,,10.1109/TSE.2018.2844343,"Qatar National Research Fund(grant numbers:Luxembourg FNR/P10/03,INTER/DFG/14/11092585,FNR9132112); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373739,Vulnerability detection;constraint solving;static analysis;search-based software engineering,Security;Benchmark testing;Tools;Explosions;Java;Static analysis;Reliability,,15,,100,IEEE,6 Jun 2018,,,IEEE,IEEE Journals,True
Automated Selection of Optimal Model Transformation Chains via Shortest-Path Algorithms,F. Basciani; M. D'Emidio; D. D. Ruscio; D. Frigioni; L. Iovino; A. Pierantonio,"Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, Italy; Gran Sasso Science Institute (GSSI), Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, Italy",IEEE Transactions on Software Engineering,13 Mar 2020,2020,46,3,251,279,"Conventional wisdom on model transformations in Model-Driven Engineering (MDE) suggests that they are crucial components in modeling environments to achieve superior automation, whether it be refactoring, simulation, or code generation. While their relevance is well-accepted, model transformations are challenging to design, implement, and verify because of the inherent complexity that they must encode. Thus, defining transformations by chaining existing ones is key to success for enhancing their reusability. This paper proposes an approach, based on well-established algorithms, to support modellers when multiple transformation chains are available to bridge a source metamodel with a target one. The all-important goal of selecting the optimal chain has been based on the quality criteria of coverage and information loss. The feasibility of the approach has been demonstrated by means of experiments operated on chains obtained from transformations borrowed from a publicly available repository.",1939-3520,,10.1109/TSE.2018.2846223,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383962,Model-driven engineering;model transformation composition;graph algorithms;shortest paths,Unified modeling language;Adaptation models;Bridges;Analytical models;Model driven engineering;Ecosystems,,8,,63,IEEE,13 Jun 2018,,,IEEE,IEEE Journals,True
Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning,Y. Yamagata; S. Liu; T. Akazaki; Y. Duan; J. Hao,"National Institute of Advanced Industrial Science and Technology (AIST), Ikeda, Osaka, Japan; College of Intelligence and Computing, Tianjin University, Nankai, Tianjin, China; Fujitsu Laboratories, Kawasaki, Kanagawa, Japan; College of Intelligence and Computing, Tianjin University, Nankai, Tianjin, China; College of Intelligence and Computing, Tianjin University, Nankai, Tianjin, China",IEEE Transactions on Software Engineering,10 Dec 2021,2021,47,12,2823,2840,"A Cyber-Physical System (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to minimize the robustness. In this paper, we explore state-of-the-art Deep Reinforcement Learning (DRL) techniques, i.e., Asynchronous Advantage Actor-Critic (A3C) and Double Deep Q Network (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample.",1939-3520,,10.1109/TSE.2020.2969178,"National Natural Science Foundation of China(grant numbers:U1836214,61802275,61702362); Application Foundation and Advanced Technology(grant numbers:16JCQNJC00100); Artificial Intelligence of Tianjin Municipal Science and Technology Commission(grant numbers:17ZXRGGX00150); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967146,Robustness guided falsification;CPS;reinforcement learning,Robustness;Reinforcement learning;Model checking;Software;Optimization,,26,,56,IEEE,23 Jan 2020,,,IEEE,IEEE Journals,True
SOSRepair: Expressive Semantic Search for Real-World Program Repair,A. Afzal; M. Motwani; K. T. Stolee; Y. Brun; C. Le Goues,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",IEEE Transactions on Software Engineering,14 Oct 2021,2021,47,10,2162,2181,"Automated program repair holds the potential to significantly reduce software maintenance effort and cost. However, recent studies have shown that it often produces low-quality patches that repair some but break other functionality. We hypothesize that producing patches by replacing likely faulty regions of code with semantically-similar code fragments, and doing so at a higher level of granularity than prior approaches can better capture abstraction and the intended specification, and can improve repair quality. We create SOSRepair, an automated program repair technique that uses semantic code search to replace candidate buggy code regions with behaviorally-similar (but not identical) code written by humans. SOSRepair is the first such technique to scale to real-world defects in real-world systems. On a subset of the ManyBugs benchmark of such defects, SOSRepair produces patches for 22 (34%) of the 65 defects, including 3, 5, and 6 defects for which previous state-of-the-art techniques Angelix, Prophet, and GenProg do not, respectively. On these 22 defects, SOSRepair produces more patches (9, 41%) that pass all independent tests than the prior techniques. We demonstrate a relationship between patch granularity and the ability to produce patches that pass all independent tests. We then show that fault localization precision is a key factor in SOSRepair's success. Manually improving fault localization allows SOSRepair to patch 23 (35%) defects, of which 16 (70%) pass all independent tests. We conclude that (1) higher-granularity, semantic-based patches can improve patch quality, (2) semantic search is promising for producing high-quality real-world defect repairs, (3) research in fault localization can significantly improve the quality of program repair techniques, and (4) semi-automated approaches in which developers suggest fix locations may produce high-quality patches.",1939-3520,,10.1109/TSE.2019.2944914,"National Science Foundation(grant numbers:CCF-1453474,CCF-1563797,CCF-1564162,CCF-1645136,CCF-1763423); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854217,Automated program repair;semantic code search;patch quality;program repair quality;SOSRepair,Maintenance engineering;Semantic search;Encoding;Benchmark testing;Computer bugs;Software,,19,,115,IEEE,1 Oct 2019,,,IEEE,IEEE Journals,True
Test Case Generation for Boolean Expressions by Cell Covering,L. Yu; W. -T. Tsai,"School of Software and Microelectronics in Peking University, Beijing, China; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ",IEEE Transactions on Software Engineering,10 Jan 2018,2018,44,1,70,99,"This paper characterizes Boolean expression faults as changes of the topological structures in terms of shrinking and/or expanding regions in K-map. A cell-covering is a set of cells (test cases) in K-map to cover the fault regions such that faults guarantee to be detected. Minimizing cell covering can be formulated as an Integer Linear Programming (ILP) problem. By analyzing the structures of the constraint coefficient matrix, the original problem can be decomposed into sub-programs that can be solved instead of the original problem, and this significantly reduces the time needed for ILP execution. An efficient approximate algorithm with a tight theoretical bound is used to address those complex Boolean expressions by corresponding the cell-covering problem to the set-covering problem. The optimal approach and the approximate approach are combined into a hybrid process to identify test cases based on the fraction analysis on the ILP relaxation. The proposed approach is evaluated by three sets of Boolean expressions and the results are compared with three leading approaches with respect to test sizes, time consumption and fault detection capabilities. For most Boolean expressions encountered, the proposed approach obtains optimal solutions quickly, and produces near-optimal solutions rapidly for those rare and complex expressions.",1939-3520,,10.1109/TSE.2017.2669184,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7855791,Boolean expression testing;fault characterization;cell-covering problem;approximate algorithms,Fault detection;Approximation algorithms;Optimization;Periodic structures;Algorithm design and analysis;Testing;Software,,3,,51,IEEE,14 Feb 2017,,,IEEE,IEEE Journals,True
oo7: Low-Overhead Defense Against Spectre Attacks via Program Analysis,G. Wang; S. Chattopadhyay; I. Gotovchits; T. Mitra; A. Roychoudhury,"National University of Singapore, Singapore; Singapore University of Technology and Design, Singapore; Carnegie Mellon University, Pittsburgh, PA, USA; National University of Singapore, Singapore; National University of Singapore, Singapore",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2504,2519,"The Spectre vulnerability in modern processors has been widely reported. The key insight in this vulnerability is that speculative execution in processors can be misused to access the secrets. Subsequently, even though the speculatively executed instructions are squashed, the secret may linger in micro-architectural states such as cache, and can potentially be accessed by an attacker via side channels. In this paper, we propose oo7, a static analysis approach that can mitigate Spectre attacks by detecting potentially vulnerable code snippets in program binaries and protecting them against the attack by patching them. Our key contribution is to balance the concerns of effectiveness, analysis time and run-time overheads. We employ control flow extraction, taint analysis, and address analysis to detect tainted conditional branches and speculative memory accesses. oo7 can detect all fifteen purpose-built Spectre-vulnerable code patterns [1] , whereas Microsoft compiler with Spectre mitigation option can only detect two of them. We also report the results of a large-scale study on applying oo7 to over 500 program binaries (average binary size 261 KB) from different real-world projects. We protect programs against Spectre attack by selectively inserting fences only at vulnerable conditional branches to prevent speculative execution. Our approach is experimentally observed to incur around 5.9 percent performance overheads on SPECint benchmarks.",1939-3520,,10.1109/TSE.2019.2953709,National Research Foundation Singapore; National Cybersecurity R&D Program(grant numbers:NRF2014NCRNCR001-21); National Cybersecurity R&D Directorate; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902081,Cache side-channel attacks;taint analysis;binary analysis;binary hardening;software security,Program processors;Malware;Arrays;Transient analysis;Benchmark testing;Analytical models;Maintenance engineering,,31,,34,IEEE,15 Nov 2019,,,IEEE,IEEE Journals,True
ARJA: Automated Repair of Java Programs via Multi-Objective Genetic Programming,Y. Yuan; W. Banzhaf,"Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA",IEEE Transactions on Software Engineering,14 Oct 2020,2020,46,10,1040,1067,"Automated program repair is the problem of automatically fixing bugs in programs in order to significantly reduce the debugging costs and improve the software quality. To address this problem, test-suite based repair techniques regard a given test suite as an oracle and modify the input buggy program to make the entire test suite pass. GenProg is well recognized as a prominent repair approach of this kind, which uses genetic programming (GP) to rearrange the statements already extant in the buggy program. However, recent empirical studies show that the performance of GenProg is not fully satisfactory, particularly for Java. In this paper, we propose ARJA, a new GP based repair approach for automated repair of Java programs. To be specific, we present a novel lower-granularity patch representation that properly decouples the search subspaces of likely-buggy locations, operation types and potential fix ingredients, enabling GP to explore the search space more effectively. Based on this new representation, we formulate automated program repair as a multi-objective search problem and use NSGA-II to look for simpler repairs. To reduce the computational effort and search space, we introduce a test filtering procedure that can speed up the fitness evaluation of GP and three types of rules that can be applied to avoid unnecessary manipulations of the code. Moreover, we also propose a type matching strategy that can create new potential fix ingredients by exploiting the syntactic patterns of existing statements. We conduct a large-scale empirical evaluation of ARJA along with its variants on both seeded bugs and real-world bugs in comparison with several state-of-the-art repair approaches. Our results verify the effectiveness and efficiency of the search mechanisms employed in ARJA and also show its superiority over the other approaches. In particular, compared to jGenProg (an implementation of GenProg for Java), an ARJA version fully following the redundancy assumption can generate a test-suite adequate patch for more than twice the number of bugs (from 27 to 59), and a correct patch for nearly four times of the number (from 5 to 18), on 224 real-world bugs considered in Defects4J. Furthermore, ARJA is able to correctly fix several real multi-location bugs that are hard to be repaired by most of the existing repair approaches.",1939-3520,,10.1109/TSE.2018.2874648,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485732,Program repair;patch generation;genetic programming;multi-objective optimization;genetic improvement,Maintenance engineering;Computer bugs;Java;Genetic programming;Search problems;Sociology;Statistics,,114,,87,IEEE,7 Oct 2018,,,IEEE,IEEE Journals,True
Contract-Based Program Repair Without The Contracts: An Extended Study,L. Chen; Y. Pei; C. A. Furia,"Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Software Institute of USI Università della Svizzera italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,10 Dec 2021,2021,47,12,2841,2857,"Most techniques for automated program repair (APR) use tests to drive the repair process; this makes them prone to generating spurious repairs that overfit the available tests unless additional information about expected program behavior is available. Our previous work on Jaid, an APR technique for Java programs, showed that constructing detailed state abstractions—similar to those employed by techniques for programs with contracts—from plain Java code without any special annotations provides valuable additional information, and hence helps mitigate the overfitting problem. This paper extends the work on Jaid with a comprehensive experimental evaluation involving 693 bugs in three different benchmark suites. The evaluation shows, among other things, that: 1) Jaid is effective: it produced correct fixes for over 15 percent of all bugs, with a precision of nearly 60 percent; 2) Jaid is reasonably efficient: on average, it took less than 30 minutes to output a correct fix; 3) Jaid is competitive with the state of the art, as it fixed more bugs than any other technique, and 11 bugs that no other tool can fix; 4) Jaid is robust: its heuristics are complementary and their effectiveness does not depend on the fine-tuning of parameters. The experimental results also indicate the main trade-offs involved in designing an APR technique based on tests, as well as possible directions for further progress in this line of work.",1939-3520,,10.1109/TSE.2020.2970009,"Hong Kong RGC General Research Fund(grant numbers:PolyU 152703/16E,PolyU 152002/18E); Hong Kong Polytechnic University(grant numbers:1-ZVJ1,G-YBXU); Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:Hi-Fi 200021-182060); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972483,,Maintenance engineering;Computer bugs;Tools;Java;Monitoring;Contracts;Programming,,8,,55,IEEE,28 Jan 2020,,,IEEE,IEEE Journals,True
HYDRA: Massively Compositional Model for Cross-Project Defect Prediction,X. Xia; D. Lo; S. J. Pan; N. Nagappan; X. Wang,"College of Computer Science and Technology, Zhejiang University Hangzhou, Zhejiang, China; School of Information Systems, Singapore Management University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; Testing, Verification and Measurement Research, Microsoft Research, Redmond, WA; College of Computer Science and Technology, Zhejiang University Hangzhou, Zhejiang, China",IEEE Transactions on Software Engineering,13 Oct 2016,2016,42,10,977,998,"Most software defect prediction approaches are trained and applied on data from the same project. However, often a new project does not have enough training data. Cross-project defect prediction, which uses data from other projects to predict defects in a particular project, provides a new perspective to defect prediction. In this work, we propose a HYbrid moDel Reconstruction Approach (HYDRA) for cross-project defect prediction, which includes two phases: genetic algorithm (GA) phase and ensemble learning (EL) phase. These two phases create a massive composition of classifiers. To examine the benefits of HYDRA, we perform experiments on 29 datasets from the PROMISE repository which contains a total of 11,196 instances (i.e., Java classes) labeled as defective or clean. We experiment with logistic regression as the underlying classification algorithm of HYDRA. We compare our approach with the most recently proposed cross-project defect prediction approaches: TCA+ by Nam et al., Peters filter by Peters et al., GP by Liu et al., MO by Canfora et al., and CODEP by Panichella et al. Our results show that HYDRA achieves an average F1-score of 0.544. On average, across the 29 datasets, these results correspond to an improvement in the F1-scores of 26.22 , 34.99, 47.43, 28.61, and 30.14 percent over TCA+, Peters filter, GP, MO, and CODEP, respectively. In addition, HYDRA on average can discover 33 percent of all bugs if developers inspect the top 20 percent lines of code, which improves the best baseline approach (TCA+) by 44.41 percent. We also find that HYDRA improves the F1-score of Zero-R which predict all the instances to be defective by 5.42 percent, but improves Zero-R by 58.65 percent when inspecting the top 20 percent lines of code. In practice, Zero-R can be hard to use since it simply predicts all of the instances to be defective, and thus developers have to inspect all of the instances to find the defective ones. Moreover, we notice the improvement of HYDRA over other baseline approaches in terms of F1-score and when inspecting the top 20 percent lines of code are substantial, and in most cases the improvements are significant and have large effect sizes across the 29 datasets.",1939-3520,,10.1109/TSE.2016.2543218,National Basic Research Program of China(grant numbers:2015CB352201); NSFC(grant numbers:61572426); National Key Technology R&D Program; Ministry of Science and Technology of China(grant numbers:2015BAH17F01); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435328,Cross-project defect prediction;transfer learning;genetic algorithm;ensemble learning,Genetic algorithms;Predictive models;Training;Buildings;Architecture;Data models;Measurement,,227,,58,IEEE,17 Mar 2016,,,IEEE,IEEE Journals,True
"Comments on ScottKnottESD in response to ""An empirical comparison of model validation techniques for defect prediction models""",S. Herbold,"Institute of Computer Science, University of Goettingen, Goettingen, Germany",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1091,1094,"In this article, we discuss the ScottKnottESD test, which was proposed in a recent paper “An Empirical Comparison of Model Validation Techniques for Defect Prediction Models” that was published in this journal. We discuss the implications and the empirical impact of the proposed normality correction of ScottKnottESD and come to the conclusion that this correction does not necessarily lead to the fulfillment of the assumptions of the original Scott-Knott test and may cause problems with the statistical analysis.",1939-3520,,10.1109/TSE.2017.2748129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024011,"Scott-knott test, log transformation, statistics",Analysis of variance;Measurement;Distributed databases;Predictive models;Sociology,,28,,23,IEEE,1 Sep 2017,,,IEEE,IEEE Journals,True
Automated Checking of Conformance to Requirements Templates Using Natural Language Processing,C. Arora; M. Sabetzadeh; L. Briand; F. Zimmer,"SnT Centre for Security, University of Luxembourg, Luxembourg; SnT Centre for Security, University of Luxembourg, Luxembourg; SnT Centre for Security, University of Luxembourg, Luxembourg; SES TechCom, Luxembourg",IEEE Transactions on Software Engineering,13 Oct 2015,2015,41,10,944,968,"Templates are effective tools for increasing the precision of natural language requirements and for avoiding ambiguities that may arise from the use of unrestricted natural language. When templates are applied, it is important to verify that the requirements are indeed written according to the templates. If done manually, checking conformance to templates is laborious, presenting a particular challenge when the task has to be repeated multiple times in response to changes in the requirements. In this article, using techniques from natural language processing (NLP), we develop an automated approach for checking conformance to templates. Specifically, we present a generalizable method for casting templates into NLP pattern matchers and reflect on our practical experience implementing automated checkers for two well-known templates in the requirements engineering community. We report on the application of our approach to four case studies. Our results indicate that: (1) our approach provides a robust and accurate basis for checking conformance to templates; and (2) the effectiveness of our approach is not compromised even when the requirements glossary terms are unknown. This makes our work particularly relevant to practice, as many industrial requirements documents have incomplete glossaries.",1939-3520,,10.1109/TSE.2015.2428709,National Research Fund-Luxembourg(grant numbers:FNR/P10/03); Validation Laboratory and AFR(grant numbers:FNR-6911386); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100933,Requirements Templates;Natural Language Processing (NLP);Case Study Research;Requirements templates;natural language processing (NLP);case study research,Terminology;Natural language processing;Ear;Safety;Pipelines;Pattern matching,,121,,71,IEEE,1 May 2015,,,IEEE,IEEE Journals,True
Automated Test Case Generation as a Many-Objective Optimisation Problem with Dynamic Selection of the Targets,A. Panichella; F. M. Kifetew; P. Tonella,"SnT, University of Luxembourg, Luxembourg, Esch-sur-Alzette, Luxembourg; Fondazione Bruno Kessler, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy",IEEE Transactions on Software Engineering,12 Feb 2018,2018,44,2,122,158,"The test case generation is intrinsically a multi-objective problem, since the goal is covering multiple test targets (e.g., branches). Existing search-based approaches either consider one target at a time or aggregate all targets into a single fitness function (whole-suite approach). Multi and many-objective optimisation algorithms (MOAs) have never been applied to this problem, because existing algorithms do not scale to the number of coverage objectives that are typically found in real-world software. In addition, the final goal for MOAs is to find alternative trade-off solutions in the objective space, while in test generation the interesting solutions are only those test cases covering one or more uncovered targets. In this paper, we present Dynamic Many-Objective Sorting Algorithm (DynaMOSA), a novel many-objective solver specifically designed to address the test case generation problem in the context of coverage testing. DynaMOSA extends our previous many-objective technique Many-Objective Sorting Algorithm (MOSA) with dynamic selection of the coverage targets based on the control dependency hierarchy. Such extension makes the approach more effective and efficient in case of limited search budget. We carried out an empirical study on 346 Java classes using three coverage criteria (i.e., statement, branch, and strong mutation coverage) to assess the performance of DynaMOSA with respect to the whole-suite approach (WS), its archive-based variant (WSA) and MOSA. The results show that DynaMOSA outperforms WSA in 28 percent of the classes for branch coverage (+8 percent more coverage on average) and in 27 percent of the classes for mutation coverage (+11 percent more killed mutants on average). It outperforms WS in 51 percent of the classes for statement coverage, leading to +11 percent more coverage on average. Moreover, DynaMOSA outperforms its predecessor MOSA for all the three coverage criteria in 19 percent of the classes with +8 percent more code coverage on average.",1939-3520,,10.1109/TSE.2017.2663435,Fonds National de la Recherche Luxembourg(grant numbers:FNR/P10/03); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840029,Evolutionary testing;many-objective optimisation;automatic test case generation,Heuristic algorithms;Optimization;Testing;Software algorithms;Algorithm design and analysis;Sorting;Genetic algorithms,,230,,59,IEEE,2 Feb 2017,,,IEEE,IEEE Journals,True
Dynamic Testing for Deadlocks via Constraints,Y. Cai; Q. Lu,"State Key Laboratory of Computer Science, Chinese Academy of Sciences, Beijing, China; Technology Center of Software Engineering, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,825,842,"Existing deadlock detectors are either not scalable or may report false positives when suggesting cycles as potential deadlocks. Additionally, they may not effectively trigger deadlocks and handle false positives. We propose a technique called ConLock+, which firstly analyzes each cycle and its corresponding execution to identify a set of scheduling constraints that are necessary conditions to trigger the corresponding deadlock. The ConLock+ technique then performs a second run to enforce the set of constraints, which will trigger a deadlock if the cycle is a real one. Or if not, ConLock+ reports a steering failure for that cycle and also identifies other similar cycles which would also produce steering failures. For each confirmed deadlock, ConLock+ performs a static analysis to identify conflicting memory access that would also contribute to the occurrence of the deadlock. This analysis is helpful to enable developers to understand and fix deadlocks. ConLock+ has been validated on a suite of real-world programs with 16 real deadlocks. The results show that across all 811 cycles, ConLock+ confirmed all of the 16 deadlocks with a probability of ≥80 percent. For the remaining cycles, ConLock+ reported steering failures and also identified that five deadlocks also involved conflicting memory accesses.",1939-3520,,10.1109/TSE.2016.2537335,"National Basic Research (973) Program of China(grant numbers:2014CB340702); National Science Foundation of China (NSFC)(grant numbers:61502465,91418206); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423814,Deadlock triggering;scheduling;should-happen-before relation;constraint;reliability;verification,System recovery;Instruction sets;Schedules;Testing;Synchronization;Detectors;Probabilistic logic,,15,,55,IEEE,2 Mar 2016,,,IEEE,IEEE Journals,True
The Impact of Mislabeled Changes by SZZ on Just-in-Time Defect Prediction,Y. Fan; X. Xia; D. A. da Costa; D. Lo; A. E. Hassan; S. Li,"College of Computer Science and Technology, Ningbo Research Institute, Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Information Science Department, University of Otago, Dunedin, New Zealand; School of Information Systems, Singapore Management University, Singapore, Singapore; School of Computing, Queen's University, Kingston, ON, Canada; College of Computer Science and Technology, Ningbo Research Institute, Zhejiang University, Hangzhou, China",IEEE Transactions on Software Engineering,12 Aug 2021,2021,47,8,1559,1586,"Just-in-Time (JIT) defect prediction-a technique which aims to predict bugs at change level-has been paid more attention. JIT defect prediction leverages the SZZ approach to identify bug-introducing changes. Recently, researchers found that the performance of SZZ (including its variants) is impacted by a large amount of noise. SZZ may considerably mislabel changes that are used to train a JIT defect prediction model, and thus impact the prediction accuracy. In this paper, we investigate the impact of the mislabeled changes by different SZZ variants on the performance and interpretation of JIT defect prediction models. We analyze four SZZ variants (i.e., B-SZZ, AG-SZZ, MA-SZZ, and RA-SZZ) that are proposed by prior studies. We build the prediction models using the labeled data by these four SZZ variants. Among the four SZZ variants, RA-SZZ is least likely to generate mislabeled changes, and we construct the testing set by using RA-SZZ. All of the four prediction models are then evaluated on the same testing set. We choose the prediction model built on the labeled data by RA-SZZ as the baseline model, and we compare the performance and metric importance of the models trained using the labeled data by the other three SZZ variants with the baseline model. Through a large-scale empirical study on a total of 126,526 changes from ten Apache open source projects, we find that in terms of various performance measures (AUC, F1-score, G-mean and Recall@20%), the mislabeled changes by B-SZZ and MA-SZZ are not likely to cause a considerable performance reduction, while the mislabeled changes by AG-SZZ cause a statistically significant performance reduction with an average difference of 1-5 percent. When considering developers' inspection effort (measured by LOC) in practice, the changes mislabeled B-SZZ and AG-SZZ lead to 9-10 and 1-15 percent more wasted inspection effort, respectively. And the mislabeled changes by B-SZZ lead to significantly more wasted effort. The mislabeled changes by MA-SZZ do not cause considerably more wasted effort. We also find that the top-most important metric for identifying bug-introducing changes (i.e., number of files modified in a change) is robust to the mislabeling noise generated by SZZ. But the second- and third-most important metrics are more likely to be impacted by the mislabeling noise, unless random forest is used as the underlying classifier.",1939-3520,,10.1109/TSE.2019.2929761,National Key Research and Development Program of China(grant numbers:2018YFB1003904); NSFC Program(grant numbers:61602403); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765743,Just-in-time defect prediction;SZZ;noisy data;mining software repositories,Predictive models;Data models;Computer bugs;Measurement;Inspection;Analytical models;Testing,,62,,85,IEEE,18 Jul 2019,,,IEEE,IEEE Journals,True
Grammar Based Directed Testing of Machine Learning Systems,S. Udeshi; S. Chattopadhyay,"Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2487,2503,"The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our Ogma approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. Ogma leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our Ogma approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare Ogma with a random test generation approach and observe that Ogma is more effective than such random test generation by up to 489 percent.",1939-3520,,10.1109/TSE.2019.2953066,President's Graduate Fellowship; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907363,Software testing;machine learning;natural language processing,Machine learning;Grammar;Robustness;Systematics;Test pattern generators;Natural language processing,,6,,45,IEEE,20 Nov 2019,,,IEEE,IEEE Journals,True
SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair,Z. Chen; S. Kommrusch; M. Tufano; L. -N. Pouchet; D. Poshyvanyk; M. Monperrus,"KTH Royal Institute of Technology, Stockholm, Sweden; Colorado State University, Fort Collins, CO, USA; The College of William and Mary, Williamsburg, VA, USA; Colorado State University, Fort Collins, CO, USA; The College of William and Mary, Williamsburg, VA, USA; KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Software Engineering,16 Sep 2021,2021,47,9,1943,1959,"This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a technique, called SequenceR, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate SequenceR on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SequenceR is able to perfectly predict the fixed line for 950/4,711 testing samples, and find correct patches for 14 bugs in Defects4J benchmark. SequenceR captures a wide range of repair operators without any domain-specific top-down design.",1939-3520,,10.1109/TSE.2019.2940179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827954,Program repair;machine learning,Maintenance engineering;Computer bugs;Vocabulary;Training;Natural languages;Benchmark testing,,140,,51,IEEE,10 Sep 2019,,,IEEE,IEEE Journals,True
EnergyPatch: Repairing Resource Leaks to Improve Energy-Efficiency of Android Apps,A. Banerjee; L. K. Chong; C. Ballabriga; A. Roychoudhury,"School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore; University of Lille, Villeneuve, France; School of Computing, National University of Singapore, Singapore",IEEE Transactions on Software Engineering,14 May 2018,2018,44,5,470,490,"Increased usage of mobile devices, such as smartphones and tablets, has led to widespread popularity and usage of mobile apps. If not carefully developed, such apps may demonstrate energy-inefficient behaviour, where one or more energy-intensive hardware components (such as Wifi, GPS, etc) are left in a high-power state, even when no apps are using these components. We refer to such kind of energy-inefficiencies as energy bugs. Executing an app with an energy bug causes the mobile device to exhibit poor energy consumption behaviour and a drastically shortened battery life. Since mobiles apps can have huge input domains, therefore exhaustive exploration is often impractical. We believe that there is a need for a framework that can systematically detect and fix energy bugs in mobile apps in a scalable fashion. To address this need, we have developed EnergyPatch, a framework that uses a combination of static and dynamic analysis techniques to detect, validate and repair energy bugs in Android apps. The use of a light-weight, static analysis technique enables EnergyPatch to quickly narrow down to the potential program paths along which energy bugs may occur. Subsequent exploration of these potentially buggy program paths using a dynamic analysis technique helps in validations of the reported bugs and to generate test cases. Finally, EnergyPatch generates repair expressions to fix the validated energy bugs. Evaluation with real-life apps from repositories such as F-droid and Github, shows that EnergyPatch is scalable and can produce results in reasonable amount of time. Additionally, we observed that the repair expressions generated by EnergyPatch could bring down the energy consumption on tested apps up to 60 percent.",1939-3520,,10.1109/TSE.2017.2689012,Singapore MoE Tier 2(grant numbers:MOE2013-T2-1-115); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889026,Mobile apps;energy bugs;non-functional testing;energy-aware test generation,Computer bugs;Androids;Humanoid robots;Maintenance engineering;Mobile handsets;Energy consumption;Batteries,,54,,58,IEEE,29 Mar 2017,,,IEEE,IEEE Journals,True
Tell You a Definite Answer: Whether Your Data is Tainted During Thread Scheduling,X. Zhang; Z. Yang; Q. Zheng; Y. Hao; P. Liu; T. Liu,"Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science, Western Michigan University, Kalamazoo, USA; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, China",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,916,931,"With the advent of multicore processors, there is a great need to write parallel programs to take advantage of parallel computing resources. However, due to the nondeterminism of parallel execution, the malware behaviors sensitive to thread scheduling are extremely difficult to detect. Dynamic taint analysis is widely used in security problems. By serializing a multithreaded execution and then propagating taint tags along the serialized schedule, existing dynamic taint analysis techniques lead to under-tainting with respect to other possible interleavings under the same input. In this paper, we propose an approach called DSTAM that integrates symbolic analysis and guided execution to systematically detect tainted instances on all possible executions under a given input. Symbolic analysis infers alternative interleavings of an executed trace that cover new tainted instances, and computes thread schedules that guide future executions. Guided execution explores new execution traces that drive future symbolic analysis. We have implemented a prototype as part of an educational tool that teaches secure C programming, where accuracy is more critical than efficiency. To the best of our knowledge, DSTAM is the first algorithm that addresses the challenge of taint analysis for multithreaded program under fixed inputs.",1939-3520,,10.1109/TSE.2018.2871666,"National Key R&D Program of China(grant numbers:2016YFB1000903); National Natural Science Foundation of China(grant numbers:61632015,61772408,U1766215,U1736205,61721002,61472318,61532015); Fok Ying Tung Education Foundation(grant numbers:151067); Ministry of Education Innovation Research Team(grant numbers:IRT_17R86); Project of China Knowledge Centre for Engineering Science and Technology; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472790,Taint analysis;multithreaded programs;symbolic analysis;encoding;guided execution,Instruction sets;Security;Tools;Monitoring;Schedules;Prototypes,,2,,62,IEEE,26 Sep 2018,,,IEEE,IEEE Journals,True
A Systematic Literature Review and Meta-Analysis on Cross Project Defect Prediction,S. Hosseini; B. Turhan; D. Gunarathna,"M3S, Faculty of Information Technology and Electrical Engineering, University of Oulu, Oulu, Finland; Department of Computer Science, Brunel University London, London, United Kingdom; Vaimo Finland (Oy), Oulu, Finland",IEEE Transactions on Software Engineering,12 Feb 2019,2019,45,2,111,147,"Background: Cross project defect prediction (CPDP) recently gained considerable attention, yet there are no systematic efforts to analyse existing empirical evidence. Objective: To synthesise literature to understand the state-of-the-art in CPDP with respect to metrics, models, data approaches, datasets and associated performances. Further, we aim to assess the performance of CPDP versus within project DP models. Method: We conducted a systematic literature review. Results from primary studies are synthesised (thematic, meta-analysis) to answer research questions. Results: We identified 30 primary studies passing quality assessment. Performance measures, except precision, vary with the choice of metrics. Recall, precision, f-measure, and AUC are the most common measures. Models based on Nearest-Neighbour and Decision Tree tend to perform well in CPDP, whereas the popular naïve Bayes yields average performance. Performance of ensembles varies greatly across f-measure and AUC. Data approaches address CPDP challenges using row/column processing, which improve CPDP in terms of recall at the cost of precision. This is observed in multiple occasions including the meta-analysis of CPDP versus WPDP. NASA and Jureczko datasets seem to favour CPDP over WPDP more frequently. Conclusion: CPDP is still a challenge and requires more research before trustworthy applications can take place. We provide guidelines for further research.",1939-3520,,10.1109/TSE.2017.2770124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097045,Defect prediction;fault prediction;cross project;systematic literature review;meta-analysis;within project,Object oriented modeling;Systematics;Measurement;Bibliographies;Predictive models;Context modeling;Data models,,203,,150,IEEE,7 Nov 2017,,,IEEE,IEEE Journals,True
Coverage-Based Greybox Fuzzing as Markov Chain,M. Böhme; V. -T. Pham; A. Roychoudhury,"Department of Computer Science, National University of Singpore, Singapore; Department of Computer Science, National University of Singpore, Singapore; Department of Computer Science, National University of Singpore, Singapore",IEEE Transactions on Software Engineering,15 May 2019,2019,45,5,489,506,"Coverage-based Greybox Fuzzing (CGF) is a random testing approach that requires no program analysis. A new test is generated by slightly mutating a seed input. If the test exercises a new and interesting path, it is added to the set of seeds; otherwise, it is discarded. We observe that most tests exercise the same few “high-frequency” paths and develop strategies to explore significantly more paths with the same number of tests by gravitating towards low-frequency paths. We explain the challenges and opportunities of CGF using a Markov chain model which specifies the probability that fuzzing the seed that exercises path i generates an input that exercises path j. Each state (i.e., seed) has an energy that specifies the number of inputs to be generated from that seed. We show that CGF is considerably more efficient if energy is inversely proportional to the density of the stationary distribution and increases monotonically every time that seed is chosen. Energy is controlled with a power schedule. We implemented several schedules by extending AFL. In 24 hours, AFLFast exposes 3 previously unreported CVEs that are not exposed by AFL and exposes 6 previously unreported CVEs 7x faster than AFL. AFLFast produces at least an order of magnitude more unique crashes than AFL. We compared AFLFast to the symbolic executor Klee. In terms of vulnerability detection, AFLFast is significantly more effective than Klee on the same subject programs that were discussed in the original Klee paper. In terms of code coverage, AFLFast only slightly outperforms Klee while a combination of both tools achieves best results by mitigating the individual weaknesses.",1939-3520,,10.1109/TSE.2017.2785841,National Research Foundation(grant numbers:NRF2014NCR-NCR001-21); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233151,Vulnerability detection;fuzzing;path exploration;symbolic execution;automated testing,Schedules;Markov processes;Computer crashes;Search problems;Tools;Systematics,,206,,37,IEEE,21 Dec 2017,,,IEEE,IEEE Journals,True
Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation,G. Grano; C. Laaber; A. Panichella; S. Panichella,"University of Zurich, Zürich, Switzerland; University of Zurich, Zürich, Switzerland; Delft University of Technology, Delft, CD, the Netherlands; Zurich University of Applied Science, Zürich, Switzerland",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2332,2347,"Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects. In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases. This study shows that performance-aware test case generation requires solving two main challenges: providing a good approximation of resource usage with minimal overhead and avoiding detrimental effects on both final coverage and fault detection effectiveness. To tackle these challenges, we conceived a set of performance proxies—inspired by previous work on performance testing— that provide a reasonable estimation of the test execution costs (i.e., runtime and memory usage). Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing. Our empirical study —involving 110 non-trivial Java classes—reveals that our adaptive approach generates test suite with statistically significant improvements in runtime (−25 percent) and heap memory consumption (−15 percent) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness. Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.",1939-3520,,10.1109/TSE.2019.2946773,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:165546); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865437,Evolutionary testing;many-objective optimization;performance,Testing;Runtime;Genetic algorithms;Memory management;Fault detection;Sociology;Statistics,,18,,67,IEEE,14 Oct 2019,,,IEEE,IEEE Journals,True
PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel,T. Hoang; J. Lawall; Y. Tian; R. J. Oentaryo; D. Lo,"Singapore Management University, Singapore; Inria, LIP6, Sorbonne University, Paris, France; Queen's University, Kingston, ON, Canada; McLaren Applied Technologies, Singapore; Singapore Management University, Singapore",IEEE Transactions on Software Engineering,11 Nov 2021,2021,47,11,2471,2486,"Linux kernel stable versions serve the needs of users who value stability of the kernel over new features. The quality of such stable versions depends on the initiative of kernel developers and maintainers to propagate bug fixing patches to the stable versions. Thus, it is desirable to consider to what extent this process can be automated. A previous approach relies on words from commit messages and a small set of manually constructed code features. This approach, however, shows only moderate accuracy. In this paper, we investigate whether deep learning can provide a more accurate solution. We propose PatchNet, a hierarchical deep learning-based approach capable of automatically extracting features from commit messages and commit code and using them to identify stable patches. PatchNet contains a deep hierarchical structure that mirrors the hierarchical and sequential structure of commit code, making it distinctive from the existing deep learning models on source code. Experiments on 82,403 recent Linux patches confirm the superiority of PatchNet against various state-of-the-art baselines, including the one recently-adopted by Linux kernel maintainers.",1939-3520,,10.1109/TSE.2019.2952614,National Research Foundation Singapore(grant numbers:NRF2016-NRF-ANR003); ANR ITrans; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896061,Linux kernel;patch classification;deep learning,Kernel;Linux;Computer bugs;Feature extraction;Deep learning;Indexes;Manuals,,17,,72,IEEE,11 Nov 2019,,,IEEE,IEEE Journals,True
Fine-Grained Dynamic Resource Allocation for Big-Data Applications,L. Baresi; A. Leva; G. Quattrocchi,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, MI, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, MI, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, MI, Italy",IEEE Transactions on Software Engineering,12 Aug 2021,2021,47,8,1668,1682,"Many big-data applications are batch applications that exploit dedicated frameworks to perform massively parallel computations across clusters of machines. The time needed to process the entirety of the inputs represents the application's response time, which can be subject to deadlines. Spark, probably the most famous incarnation of these frameworks today, allocates resources to applications statically at the beginning of the execution and deviations are not managed: to meet the applications' deadlines, resources must be allocated carefully. This paper proposes an extension to Spark, called dynaSpark, that is able to allocate and redistribute resources to applications dynamically to meet deadlines and cope with the execution of unanticipated applications. This work is based on two key enablers: containers, to isolate Spark's parallel executors and allow for the dynamic and fast allocation of resources, and control-theory to govern resource allocation at runtime and obtain required precision and speed. Our evaluation shows that dynaSpark can (i) allocate resources efficiently to execute single applications with respect to set deadlines and (ii) reduce deadline violations (w.r.t. Spark) when executing multiple concurrent applications.",1939-3520,,10.1109/TSE.2019.2931537,Italian Technology Cluster For Smart Communities(grant numbers:CTN01_00034_594053); GAUSS national research project(grant numbers:2015KWREMX); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778680,Distributed architectures;control theory;quality assurance;batch processing systems,Sparks;Resource management;Dynamic scheduling;Containers;Task analysis;Runtime;Control theory,,11,,61,IEEE,29 Jul 2019,,,IEEE,IEEE Journals,True
Automated Refactoring of OCL Constraints with Search,H. Lu; S. Wang; T. Yue; s. Ali; J. F. Nygård,"Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Cancer Registry of Norway, Oslo, Norway",IEEE Transactions on Software Engineering,12 Feb 2019,2019,45,2,148,170,"Object Constraint Language (OCL) constraints are typically used to provide precise semantics to models developed with the Unified Modeling Language (UML). When OCL constraints evolve regularly, it is essential that they are easy to understand and maintain. For instance, in cancer registries, to ensure the quality of cancer data, more than one thousand medical rules are defined and evolve regularly. Such rules can be specified with OCL. It is, therefore, important to ensure the understandability and maintainability of medical rules specified with OCL. To tackle such a challenge, we propose an automated search-based OCL constraint refactoring approach (SBORA) by defining and applying four semantics-preserving refactoring operators (i.e., Context Change, Swap, Split and Merge) and three OCL quality metrics (Complexity, Coupling, and Cohesion) to measure the understandability and maintainability of OCL constraints. We evaluate SBORA along with six commonly used multi-objective search algorithms (e.g., Indicator-Based Evolutionary Algorithm (IBEA)) by employing four case studies from different domains: healthcare (i.e., cancer registry system from Cancer Registry of Norway (CRN)), Oil&Gas (i.e., subsea production systems), warehouse (i.e., handling systems), and an open source case study named SEPA. Results show: 1) IBEA achieves the best performance among all the search algorithms and 2) the refactoring approach along with IBEA can manage to reduce on average 29.25 percent Complexity and 39 percent Coupling and improve 47.75 percent Cohesion, as compared to the original OCL constraint set from CRN. To further test the performance of SBORA, we also applied it to refactor an OCL constraint set specified on the UML 2.3 metamodel and we obtained positive results. Furthermore, we conducted a controlled experiment with 96 subjects and results show that the understandability and maintainability of the original constraint set can be improved significantly from the perspectives of the 96 participants of the controlled experiment.",1939-3520,,10.1109/TSE.2017.2774829,RFF Hovedstaden(grant numbers:239063); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114267,Constraints;metrics/measurement;methodologies;CASE,Cancer;Unified modeling language;Measurement;Couplings;Complexity theory;Semantics;Computational modeling,,6,,59,OAPA,17 Nov 2017,,,IEEE,IEEE Journals,True
Correction of “A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches”,S. Herbold; A. Trautsch; J. Grabowski,"Institute of Computer Science, University of Goettingen, Göttingen, Germany; Institute of Computer Science, University of Goettingen, Göttingen, Germany; Institute of Computer Science, University of Goettingen, Göttingen, Germany",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,632,636,"Unfortunately, the article “A Comparative Study to Benchmark Cross-project Defect Prediction Approaches” has a problem in the statistical analysis which was pointed out almost immediately after the pre-print of the article appeared online. While the problem does not negate the contribution of the the article and all key findings remain the same, it does alter some rankings of approaches used in the study. Within this correction, we will explain the problem, how we resolved it, and present the updated results.",1939-3520,,10.1109/TSE.2018.2790413,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8248781,Cross-project defect prediction;benchmark;comparison;replication;correction,Sociology;Measurement;Benchmark testing;Statistical analysis;Ranking (statistics);Terminology,,10,,13,IEEE,8 Jan 2018,,,IEEE,IEEE Journals,True
A Survey on the Use of Computer Vision to Improve Software Engineering Tasks,M. Bajammal; A. Stocco; D. Mazinanian; A. Mesbah,"University of British Columbia, Vancouver, BC, Canada; Università della Svizzera Italiana, Lugano, Switzerland; University of British Columbia, Vancouver, BC, Canada; University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,16 May 2022,2022,48,5,1722,1742,"Software engineering (SE) research has traditionally revolved around engineering the source code. However, novel approaches that analyze software through computer vision have been increasingly adopted in SE. These approaches allow analyzing the software from a different complementary perspective other than the source code, and they are used to either complement existing source code-based methods, or to overcome their limitations. The goal of this manuscript is to survey the use of computer vision techniques in SE with the aim of assessing their potential in advancing the field of SE research. We examined an extensive body of literature from top-tier SE venues, as well as venues from closely related fields (machine learning, computer vision, and human-computer interaction). Our inclusion criteria targeted papers applying computer vision techniques that address problems related to any area of SE. We collected an initial pool of 2,716 papers, from which we obtained 66 final relevant papers covering a variety of SE areas. We analyzed what computer vision techniques have been adopted or designed, for what reasons, how they are used, what benefits they provide, and how they are evaluated. Our findings highlight that visual approaches have been adopted in a wide variety of SE tasks, predominantly for effectively tackling software analysis and testing challenges in the web and mobile domains. The results also show a rapid growth trend of the use of computer vision techniques in SE research.",1939-3520,,10.1109/TSE.2020.3032986,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237151,Computer vision;software engineering;survey,Testing;Visualization;Software engineering;Computer vision;Software;Task analysis;Graphical user interfaces,,8,,111,IEEE,22 Oct 2020,,,IEEE,IEEE Journals,True
On the Validity of Pre-Trained Transformers for Natural Language Processing in the Software Engineering Domain,J. von der Mosel; A. Trautsch; S. Herbold,"Institute of Computer Science, University of Goettingen, Göttingen, GA, Germany; Institute of Computer Science, University of Goettingen, Göttingen, GA, Germany; Institute of Software and System Engineering, TU Clausthal, Clausthal-Zellerfeld, Germany",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1487,1507,"Transformers are the current state-of-the-art of natural language processing in many domains and are using traction within software engineering research as well. Such models are pre-trained on large amounts of data, usually from the general domain. However, we only have a limited understanding regarding the validity of transformers within the software engineering domain, i.e., how good such models are at understanding words and sentences within a software engineering context and how this improves the state-of-the-art. Within this article, we shed light on this complex, but crucial issue. We compare BERT transformer models trained with software engineering data with transformers based on general domain data in multiple dimensions: their vocabulary, their ability to understand which words are missing, and their performance in classification tasks. Our results show that for tasks that require understanding of the software engineering context, pre-training with software engineering data is valuable, while general domain models are sufficient for general language understanding, also within the software engineering domain.",1939-3520,,10.1109/TSE.2022.3178469,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9785808,Natural language processing;software engineering;transformers,Transformers;Task analysis;Context modeling;Bit error rate;Data models;Software engineering;Adaptation models,,28,,72,IEEE,30 May 2022,,,IEEE,IEEE Journals,True
"On the Variability of Software Engineering Needs for Deep Learning: Stages, Trends, and Application Types",K. Gao; Z. Wang; A. Mockus; M. Zhou,"School of Software & Microelectrics, Peking University, Beijing, China; School of Information Science and Technology, University of Tokyo, Bunkyo City, Tokyo, Japan; Department of Electrical Engineering and Computer Science, University of Tennessee, Knoxville, TN, USA; School of Computer Science, Peking University, Beijing, China",IEEE Transactions on Software Engineering,14 Feb 2023,2023,49,2,760,776,"The wide use of Deep learning (DL) has not been followed by the corresponding advances in software engineering (SE) for DL. Research shows that developers writing DL software have specific development stages (i.e., SE4DL stages) and face new DL-specific problems. Despite substantial research, it is unclear how DL developers’ SE needs for DL vary over stages, application types, or if they change over time. To help focus research and development efforts on DL-development challenges, we analyze 92,830 Stack Overflow (SO) questions and 227,756 READMEs of public repositories related to DL. Latent Dirichlet Allocation (LDA) reveals 27 topics for the SO questions where 19 (70.4%) topics mainly relate to a single SE4DL stage, and eight topics span multiple stages. Most questions concern Data Preparation and Model Setup stages. The relative rates of questions for 11 topics have increased, for eight topics decreased over time. Questions for the former 11 topics had a lower percentage of accepting an answer than the remaining questions. LDA on README files reveals 16 distinct application types for the 227k repositories. We apply the LDA model fitted on READMEs to the 92,830 SO questions and find that 27% of the questions are related to the 16 DL application types. The most asked question topic varies across application types, with half primarily relating to the second and third stages. Specifically, developers ask the most questions about topics primarily relating to Data Preparation (2nd) stage for four mature application types such as ${{\sf Image\ Segmentation}}$ImageSegmentation, and topics primarily relating to Model Setup (3rd) stage for four application types concerning emerging methods such as ${{\sf Transfer\ Learning}}$TransferLearning. Based on our findings, we distill several actionable insights for SE4DL research, practice, and education, such as better support for using trained models, application-type specific tools, and teaching materials.",1939-3520,,10.1109/TSE.2022.3163576,National Key R&D Program of China(grant numbers:2018YFB1004201); National Natural Science Foundation of China(grant numbers:61825201); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745323,Software engineering needs for deep learning;mining software repositories;topic modeling;stack overflow,Data models;Market research;Training;Software;Predictive models;Task analysis;Software engineering,,4,,71,IEEE,30 Mar 2022,,,IEEE,IEEE Journals,True
Gender Differences in Personality Traits of Software Engineers,D. Russo; K. -J. Stol,"Department of Computer Science, Aalborg University, Aalborg, Denmark; Lero-The Irish Software Research Centre & School of Computer Science and Information Technology, University College, Cork, Ireland",IEEE Transactions on Software Engineering,15 Mar 2022,2022,48,3,819,834,"There is a growing body of gender studies in software engineering to understand diversity and inclusion issues, as diversity is recognized to be a key issue to healthy teams and communities. A second factor often linked to team performance is personality, which has received far more attention. Very few studies, however, have focused on the intersection of these two fields. Hence, we set out to study gender differences in personality traits of software engineers. Through a survey study we collected personality data, using the HEXACO model, of 483 software engineers. The data were analyzed using a Bayesian independent sample t-test and network analysis. The results suggest that women score significantly higher in Openness to Experience, Honesty-Humility, and Emotionality than men. Further, men show higher psychopathic traits than women. Based on these findings, we develop a number of propositions that can guide future research.",1939-3520,,10.1109/TSE.2020.3003413,"Science Foundation Ireland(grant numbers:15/SIRG/3293,13/RC/2094); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120355,Personality traits;gender;empirical software engineering;bayesian statistics;network analysis,Software;Software engineering;Instruments;Bayes methods;Sea measurements;Data models;Face,,31,,138,IEEE,18 Jun 2020,,,IEEE,IEEE Journals,True
"Software Testing With Large Language Models: Survey, Landscape, and Vision",J. Wang; Y. Huang; C. Chen; Z. Liu; S. Wang; Q. Wang,"State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Technical University of Munich, Munich, Germany; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; York University, Toronto, ON, Canada; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,17 Apr 2024,2024,50,4,911,936,"Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs. It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in software testing.",1939-3520,,10.1109/TSE.2024.3368208,"National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); Youth Innovation Promotion Association Chinese Academy of Sciences, Basic Research Program of ISCAS(grant numbers:ISCAS-JCZD-202304); Major Program of ISCAS(grant numbers:ISCAS-ZD-202302); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440574,Pre-trained large language model;software testing;LLM;GPT,Software testing;Task analysis;Computational modeling;Codes;Software systems;Natural language processing;Reviews,,19,,166,IEEE,20 Feb 2024,,,IEEE,IEEE Journals,True
An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models,J. Jiarpakdee; C. K. Tantithamthavorn; H. K. Dam; J. Grundy,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia",IEEE Transactions on Software Engineering,11 Jan 2022,2022,48,1,166,185,"Software analytics have empowered software organisations to support a wide range of improved decision-making and policy-making. However, such predictions made by software analytics to date have not been explained and justified. Specifically, current defect prediction models still fail to explain why models make such a prediction and fail to uphold the privacy laws in terms of the requirement to explain any decision made by an algorithm. In this paper, we empirically evaluate three model-agnostic techniques, i.e., two state-of-the-art Local Interpretability Model-agnostic Explanations technique (LIME) and BreakDown techniques, and our improvement of LIME with Hyper Parameter Optimisation (LIME-HPO). Through a case study of 32 highly-curated defect datasets that span across 9 open-source software systems, we conclude that (1) model-agnostic techniques are needed to explain individual predictions of defect models; (2) instance explanations generated by model-agnostic techniques are mostly overlapping (but not exactly the same) with the global explanation of defect models and reliable when they are re-generated; (3) model-agnostic techniques take less than a minute to generate instance explanations; and (4) more than half of the practitioners perceive that the contrastive explanations are necessary and useful to understand the predictions of defect models. Since the implementation of the studied model-agnostic techniques is available in both Python and R, we recommend model-agnostic techniques be used in the future.",1939-3520,,10.1109/TSE.2020.2982385,Australian Research Council(grant numbers:DE200100941); ARC Laureate Fellowship(grant numbers:FL190100035); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044387,Explainable software analytics;software quality assurance;defect prediction models;model-agnostic techniques,Predictive models;Software;Analytical models;Software algorithms;Prediction algorithms;Electric breakdown;Software engineering,,78,,113,IEEE,23 Mar 2020,,,IEEE,IEEE Journals,True
How Much Does Software Complexity Matter for Maintenance Productivity? The Link Between Team Instability and Diversity,M. Benaroch; K. Lyytinen,"Whitman School of Management, Syracuse University, Syracuse, NY, USA; Design and Innovation Department, Case Western Reserve University, Cleveland, OH, USA",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2459,2475,"Software complexity decreases maintenance productivity, as do team attributes of instability and knowledge diversity. We know little about the extent to which the two team attributes interact with software complexity and shape productivity across systems of varying complexity. We address this gap by investigating whether and to what degree software complexity moderates the effects of team instability and knowledge diversity on maintenance productivity over the life of a system. We posit, given the exponential growth of code and task dependencies inherent in complex software systems, that system-level complexity has a significant nonlinear amplifying effect on the adverse effects of the two team attributes. To validate the presence of such an effect, we conduct a robust split-sample econometric analysis using three years of maintenance data from 426 mission-critical systems of a Fortune 100 company. The sampled systems vary in size (50KLOC to 2000KLOC, where 20% exceed 500KLOC), with a considerable portion of the sample manifesting “high” to “very high” software complexity. The analysis corroborates the known adverse effects of team instability, team knowledge diversity, and software complexity on maintenance productivity. More importantly, it shows—as theorized—that the adverse effects of the team attributes on maintenance productivity are significantly amplified only when software complexity grows high. We conclude with practical and research implications about how to manage software teams maintaining complex software over the life of a system.",1939-3520,,10.1109/TSE.2022.3222119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9953033,Interaction effects;high software complexity;productivity;software complexity;software maintenance;team instability;team knowledge diversity,Maintenance engineering;Task analysis;Software;Complexity theory;Productivity;Codes;Software maintenance,,1,,90,IEEE,15 Nov 2022,,,IEEE,IEEE Journals,True
A Procedure to Continuously Evaluate Predictive Performance of Just-In-Time Software Defect Prediction Models During Software Development,L. Song; L. L. Minku,"Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, Guangdong, China; School of Computer Science, University of Birmingham, Birmingham, U.K.",IEEE Transactions on Software Engineering,14 Feb 2023,2023,49,2,646,666,"Just-In-Time Software Defect Prediction (JIT-SDP) uses machine learning to predict whether software changes are defect-inducing or clean. When adopting JIT-SDP, changes in the underlying defect generating process may significantly affect the predictive performance of JIT-SDP models over time. Therefore, being able to continuously track the predictive performance of JIT-SDP models during the software development process is of utmost importance for software companies to decide whether or not to trust the predictions provided by such models over time. However, there has been little discussion on how to continuously evaluate predictive performance in practice, and such evaluation is not straightforward. In particular, labeled software changes that can be used for evaluation arrive over time with a delay, which in part corresponds to the time we have to wait to label software changes as ‘clean’ (waiting time). A clean label assigned based on a given waiting time may not correspond to the true label of the software changes. This can potentially hinder the validity of any continuous predictive performance evaluation procedure for JIT-SDP models. This paper provides the first discussion of how to continuously evaluate predictive performance of JIT-SDP models over time during the software development process, and the first investigation of whether and to what extent waiting time affects the validity of such continuous performance evaluation procedure in JIT-SDP. Based on 13 GitHub projects, we found that waiting time had a significant impact on the validity. Though typically small, the differences in estimated predicted performance were sometimes large, and thus inappropriate choices of waiting time can lead to misleading estimations of predictive performance over time. Such impact did not normally change the ranking between JIT-SDP models, and thus conclusions in terms of which JIT-SDP model performs better are likely reliable independent of the choice of waiting time, especially when considered across projects.",1939-3520,,10.1109/TSE.2022.3158831,National Natural Science Foundation of China(grant numbers:62002148); Engineering and Physical Sciences Research Council(grant numbers:EP/R006660/2); Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); Program for Guangdong Introducing Innovative and Enterpreneurial Teams(grant numbers:2017ZT07X386); Shenzhen Science and Technology Program(grant numbers:KQTD2016112514355531); Research Institute of Trustworthy Autonomous Systems; Southern University of Science and Technology(grant numbers:518055); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9735354,Just-in-time software defect prediction;performance evaluation procedure;concept drift;data stream learning;online learning;verification latency;and label noise,Software;Performance evaluation;Predictive models;Training;Estimation;Software reliability;Delays,,7,,39,IEEE,15 Mar 2022,,,IEEE,IEEE Journals,True
Let's Go to the Whiteboard (Again): Perceptions From Software Architects on Whiteboard Architecture Meetings,E. Santana de Almeida; I. Ahmed; A. van der Hoek,"Institute of Computing (IC-UFBA), Federal University of Bahia, Salvador, Bahia, Brazil; Irvine Donald Bren School of Information and Computer Sciences Department of Informatics, University of California, Irvine (UCI), Irvine, CA, USA; Irvine Donald Bren School of Information and Computer Sciences Department of Informatics, University of California, Irvine (UCI), Irvine, CA, USA",IEEE Transactions on Software Engineering,16 Oct 2023,2023,49,10,4773,4795,"The whiteboard plays a crucial role in the day-to-day lives of software architects, as they frequently will organize meetings at the whiteboard to discuss a new architecture, some proposed changes to an existing architecture, a mismatch between a prescribed architecture and its code, and more. While much has been studied about software architects, the architectures they produce, and how they produce them, a detailed understanding of these whiteboards meetings is still lacking. In this paper, we contribute a mixed-methods study involving semi-structured interviews and a subsequent survey to understand the perceptions of software architects on whiteboard architecture meetings. We focus on four aspects: (1) why do they hold these meetings, (2) what is the impact of the experience levels of the participants in these meetings, (3) how do the architects document the meetings, and (4) what kinds of changes are made in downstream activities to the work produced after the meetings have concluded? In studying these aspects, we identify eleven observations related to both technical aspects and social aspects of the meetings. These insights have implications for further research, offer concrete advice to practitioners, and suggest ways of educating future software architects.",1939-3520,,10.1109/TSE.2023.3314410,"National Science Foundation(grant numbers:CCF-2210812); Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:465614/2014-0); Coordenação de Aperfeiçoamento de Pessoal de Nível Superior(grant numbers:88887.136410/2017-00); Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco(grant numbers:APQ-0399-1.03/17,PRONEX APQ/0388-1.03/14); Fundação de Amparo à Pesquisa do Estado da Bahia(grant numbers:INCITE PIE0002/2022); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286472,Software architecture;software architects;whiteboard meetings;architecture documentation;interviews;survey,Surveys;Leadership;Codes;Software architecture;Computer architecture;Software;Interviews,,,,81,IEEE,16 Oct 2023,,,IEEE,IEEE Journals,True
The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring,M. Aniche; E. Maziero; R. Durelli; V. H. S. Durelli,"Delft University of Technology, Delft, CD, The Netherlands; Federal University of Lavras, Lavras, MG, Brazil; Federal University of Lavras, Lavras, MG, Brazil; Federal University of São João del Rei, São João del Rei, MG, Brazil",IEEE Transactions on Software Engineering,15 Apr 2022,2022,48,4,1432,1450,"Refactoring is the process of changing the internal structure of software to improve its quality without modifying its external behavior. Empirical studies have repeatedly shown that refactoring has a positive impact on the understandability and maintainability of software systems. However, before carrying out refactoring activities, developers need to identify refactoring opportunities. Currently, refactoring opportunity identification heavily relies on developers’ expertise and intuition. In this paper, we investigate the effectiveness of machine learning algorithms in predicting software refactorings. More specifically, we train six different machine learning algorithms (i.e., Logistic Regression, Naive Bayes, Support Vector Machine, Decision Trees, Random Forest, and Neural Network) with a dataset comprising over two million refactorings from 11,149 real-world projects from the Apache, F-Droid, and GitHub ecosystems. The resulting models predict 20 different refactorings at class, method, and variable-levels with an accuracy often higher than 90 percent. Our results show that (i) Random Forests are the best models for predicting software refactoring, (ii) process and ownership metrics seem to play a crucial role in the creation of better models, and (iii) models generalize well in different contexts.",1939-3520,,10.1109/TSE.2020.3021736,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186715,Software engineering;software refactoring;machine learning for software engineering,Biological system modeling;Measurement;Tools;Software;Predictive models;Context modeling;Prediction algorithms,,31,,84,IEEE,4 Sep 2020,,,IEEE,IEEE Journals,True
"Let’s Talk With Developers, Not About Developers: A Review of Automatic Program Repair Research",E. Winter; V. Nowack; D. Bowes; S. Counsell; T. Hall; S. Haraldsson; J. Woodward,"School of Computing and Communications, Lancaster University, Bailrigg, Lancaster, U.K; School of Computing and Communications, Lancaster University, Bailrigg, Lancaster, U.K; School of Computing and Communications, Lancaster University, Bailrigg, Lancaster, U.K; Department of Computer Science, Brunel University of London, London, U.K; School of Computing and Communications, Lancaster University, Bailrigg, Lancaster, U.K; Department of Computing Science and Mathematics, University of Stirling, Stirling, U.K; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K",IEEE Transactions on Software Engineering,6 Jan 2023,2023,49,1,419,436,"Automatic program repair (APR) offers significant potential for automating some coding tasks. Using APR could reduce the high costs historically associated with fixing code faults and deliver significant benefits to software engineering. Adopting APR could also have profound implications for software developers’ daily activities, transforming their work practices. To realise the benefits of APR it is vital that we consider how developers feel about APR and the impact APR may have on developers’ work. Developing APR tools without consideration of the developer is likely to undermine the success of APR deployment. In this paper, we critically review how developers are considered in APR research by analysing how human factors are treated in 260 studies from Monperrus’s Living Review of APR. Over half of the 260 studies in our review were motivated by a problem faced by developers (e.g., the difficulty associated with fixing faults). Despite these human-oriented motivations, fewer than 7% of the 260 studies included a human study. We looked in detail at these human studies and found their quality mixed (for example, one human study was based on input from only one developer). Our results suggest that software developers are often talked about in APR studies, but are rarely talked with. A more comprehensive and reliable understanding of developer human factors in relation to APR is needed. Without this understanding, it will be difficult to develop APR tools and techniques which integrate effectively into developers’ workflows. We recommend a future research agenda to advance the study of human factors in APR.",1939-3520,,10.1109/TSE.2022.3152089,Engineering and Physical Sciences Research Council(grant numbers:EP/S005749/2); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9714799,Human factors;software development;automatic program repair,Human factors;Software;Software engineering;Maintenance engineering;Bibliographies;Systematics;Technological innovation,,6,,74,CCBY,16 Feb 2022,,,IEEE,IEEE Journals,True
A Systematic Literature Review of Model-Driven Engineering Using Machine Learning,A. C. Marcén; A. Iglesias; R. Lapeña; F. Pérez; C. Cetina,"SVIT Research Group, Universidad San Jorge, Zaragoza, Spain; SVIT Research Group, Universidad San Jorge, Zaragoza, Spain; SVIT Research Group, Universidad San Jorge, Zaragoza, Spain; SVIT Research Group, Universidad San Jorge, Zaragoza, Spain; Research Center on Software Production Methods (PROS), Universitat Politècnica de València, Valencia, Spain",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2269,2293,"Model-driven engineering (MDE) is a software engineering paradigm based on the systematic use of models. Over the past few years, engineers have significantly increased the use of MDE, which has been reported as a successful paradigm for developing industrial software. Recently, there have also been remarkable advancements in the Artificial Intelligence (AI) domain, with a significant increase in advanced Machine Learning (ML) techniques. The advances in both fields have led to a surge in works that dwell within the intersection of ML and MDE. This work places the focus on systematically reviewing works that leverage ML to solve MDE problems. We have reviewed a total of 9,194 papers, selecting 98 studies for further analysis. The results of our Systematic Literature Review (SLR) bring light to the current state of the art and trends in the field, discussing the drift in the usage of the different available ML techniques along with the remaining research gaps and open challenges. Our SLR has the potential to produce a positive impact in the research community by steering it towards ML techniques that have been successfully applied to solve MDE challenges.",1939-3520,,10.1109/TSE.2024.3430514,"Ministry of Economy and Competitiveness (MINECO)(grant numbers:PID2021-128695OBI00); Gobierno de Aragón (Spain)(grant numbers:Research Group T61_23R); Spanish Ministry of Science, Innovation and Universities(grant numbers:CNS2023-145422); Excellence Network AI4Software(grant numbers:Red2022-134647-T); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10602548,Model-driven engineering;machine learning;systematic literature review,Unified modeling language;Systematics;Machine learning;Vectors;Bibliographies;Codes;Analytical models,,1,,169,IEEE,18 Jul 2024,,,IEEE,IEEE Journals,True
Do Pretrained Language Models Indeed Understand Software Engineering Tasks?,Y. Li; T. Zhang; X. Luo; H. Cai; S. Fang; D. Yuan,"School of Computer Science and Engineering, Macau University of Science and Technology, Macao, China; School of Computer Science and Engineering, Macau University of Science and Technology, Macao, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong, China; School of Electrical Engineering and Computer Science, Washington State University Pullman, WA, USA; School of Computer Science and Engineering, Macau University of Science and Technology, Macao, China; School of Computer Science and Engineering, Macau University of Science and Technology, Macao, China",IEEE Transactions on Software Engineering,16 Oct 2023,2023,49,10,4639,4655,"Artificial intelligence (AI) for software engineering (SE) tasks has recently achieved promising performance. In this article, we investigate to what extent the pre-trained language model truly understands those SE tasks such as code search, code summarization, etc. We conduct a comprehensive empirical study on a board set of AI for SE (AI4SE) tasks by feeding them with variant inputs: 1) with various masking rates and 2) with sufficient input subset method. Then, the trained models are evaluated on different SE tasks, including code search, code summarization, and duplicate bug report detection. Our experimental results show that pre-trained language models are insensitive to the given input, thus they achieve similar performance in these three SE tasks. We refer to this phenomenon as overinterpretation, where a model confidently makes a decision without salient features, or where a model finds some irrelevant relationships between the final decision and the dataset. Our study investigates two approaches to mitigate the overinterpretation phenomenon: whole word mask strategy and ensembling. To the best of our knowledge, we are the first to reveal this overinterpretation phenomenon to the AI4SE community, which is an important reminder for researchers to design the input for the models and calls for necessary future work in understanding and implementing AI4SE tasks.",1939-3520,,10.1109/TSE.2023.3308952,"Macao Science and Technology Development Fund (FDCT)(grant numbers:0047/2020/A1,0014/2022/A); Hong Kong RGC(grant numbers:PolyU15224121); HKPolyU(grant numbers:ZVG0); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10232920,Overinterpretation;deep learning;pre-trained language model;software engineering,Task analysis;Codes;Computer bugs;Software engineering;Artificial intelligence;Deep learning;Computational modeling,,4,,79,IEEE,28 Aug 2023,,,IEEE,IEEE Journals,True
XPro: A Model to Explain the Limited Adoption and Implementation of Experimentation in Software Startups,J. Melegati; H. Edison; X. Wang,"Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy; J. E. Cairnes School of Business and Economics, NUI Galway, Galway, Ireland; Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy",IEEE Transactions on Software Engineering,14 Jun 2022,2022,48,6,1929,1946,"Software startups develop innovative, software-intensive products or services. Such innovativeness translates into uncertainty regarding a matching need for a product from potential customers, representing a possible determinant reason for startup failure. Research has shown that experimentation, an approach based on the use of experiments to guide several aspects of software development, could improve these companies’ success rate by fostering the evaluation of assumptions about customers’ needs before developing a full-fledged product. Nevertheless, software startups are not using experimentation as expected. In this study, we investigated the reasons behind such a mismatch between theory and practice. To achieve it, we performed a qualitative survey study of 106 failed software startups. We built the eXperimentation Progression model (XPro), demonstrating that the effective adoption and implementation of experimentation is a staged process: first, teams should be aware of experimentation, then they need to develop an intention to experiment, perform the experiments, analyze the results, and finally act based on the obtained learning. Based on the XPro model, we further identified 25 inhibitors that prevent a team from progressing along the stages properly. Our findings inform researchers of how to develop practices and techniques to improve experimentation adoption in software startups. Practitioners could learn various factors that could lead to their startup failure so they could take action to avoid them.",1939-3520,,10.1109/TSE.2020.3042610,European Union's Horizon 2020 research and innovation programme(grant numbers:754489); Science Foundation Ireland(grant numbers:13/RC/2094); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282188,Software startups;experimentation;experiment-driven software development;startups,Software;Business;Technological innovation;Companies;Inhibitors;Uncertainty;Testing,,8,,74,IEEE,4 Dec 2020,,,IEEE,IEEE Journals,True
Learning From Mistakes: Machine Learning Enhanced Human Expert Effort Estimates,F. Sarro; R. Moussa; A. Petrozziello; M. Harman,"Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.",IEEE Transactions on Software Engineering,14 Jun 2022,2022,48,6,1868,1882,"In this paper, we introduce a novel approach to predictive modeling for software engineering, named Learning From Mistakes (LFM). The core idea underlying our proposal is to automatically learn from past estimation errors made by human experts, in order to predict the characteristics of their future misestimates, therefore resulting in improved future estimates. We show the feasibility of LFM by investigating whether it is possible to predict the type, severity and magnitude of errors made by human experts when estimating the development effort of software projects, and whether it is possible to use these predictions to enhance future estimations. To this end we conduct a thorough empirical study investigating 402 maintenance and new development industrial software projects. The results of our study reveal that the type, severity and magnitude of errors are all, indeed, predictable. Moreover, we find that by exploiting these predictions, we can obtain significantly better estimates than those provided by random guessing, human experts and traditional machine learners in 31 out of the 36 cases considered (86 percent), with large and very large effect sizes in the majority of these cases (81 percent). This empirical evidence opens the door to the development of techniques that use the power of machine learning, coupled with the observation that human errors are predictable, to support engineers in estimation tasks rather than replacing them with machine-provided estimates.",1939-3520,,10.1109/TSE.2020.3040793,ERC Advanced fellowship(grant numbers:EPIC (741278)); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272884,Software effort estimation;estimate errors;human expert estimates;human bias;human-competitive results,Software;Predictive models;Companies;Software engineering;Estimation error;Task analysis;Software measurement,,11,,104,IEEE,27 Nov 2020,,,IEEE,IEEE Journals,True
Open Science in Software Engineering: A Study on Deep Learning-Based Vulnerability Detection,Y. Nong; R. Sharma; A. Hamou-Lhadj; X. Luo; H. Cai,"School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA; Department of Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada; Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR, China; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1983,2005,"Open science is a practice that makes scientific research publicly accessible to anyone, hence is highly beneficial. Given the benefits, the software engineering (SE) community has been diligently advocating open science policies during peer reviews and publication processes. However, to this date, there has been few studies that look into the status and issues of open science in SE from a systematic perspective. In this paper, we set out to start filling this gap. Given the great breadth of SE in general, we constrained our scope to a particular topic area in SE as an example case. Recently, an increasing number of deep learning (DL) approaches have been explored in SE, including DL-based software vulnerability detection, a popular, fast-growing topic that addresses an important problem in software security. We exhaustively searched the literature in this area and identified 55 relevant works that propose a DL-based vulnerability detection approach. This was then followed by comprehensively investigating the four integral aspects of open science: availability, executability, reproducibility, and replicability. Among other findings, our study revealed that only a small percentage (25.5%) of the studied approaches provided publicly available tools. Some of these available tools did not provide sufficient documentation and complete implementation, making them not executable or not reproducible. The uses of balanced or artificially generated datasets caused significantly overrated performance of the respective techniques, making most of them not replicable. Based on our empirical results, we made actionable suggestions on improving the state of open science in each of the four aspects. We note that our results and recommendations on most of these aspects (availability, executability, reproducibility) are not tied to the nature of the chosen topic (DL-based vulnerability detection) hence are likely applicable to other SE topic areas. We also believe our results and recommendations on replicability to be applicable to other DL-based topics in SE as they are not tied to (the particular application of DL in) detecting software vulnerabilities.",1939-3520,,10.1109/TSE.2022.3207149,Army Research Office(grant numbers:W911NF-21-1-0027); Office of Naval Research(grant numbers:N000142212111); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9894099,Open science;availability;executability;reproducibility;replicability;case study;vulnerability detection;deep learning,Software;Testing;Replicability;Codes;Training;Security;Deep learning,,8,,110,IEEE,16 Sep 2022,,,IEEE,IEEE Journals,True
What Drives and Sustains Self-Assignment in Agile Teams,Z. Masood; R. Hoda; K. Blincoe,"Department of Electrical, Computer, and Software Engineering, The University of Auckland, Auckland, New Zealand; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Department of Electrical, Computer, and Software Engineering, The University of Auckland, Auckland, New Zealand",IEEE Transactions on Software Engineering,16 Sep 2022,2022,48,9,3626,3639,"Self-assignment, where software developers choose their own tasks, is a common practice in agile teams. However, it is not known why developers select certain tasks. It is important for managers to be aware of these reasons to ensure sustainable self-assignment practices. We investigated developers’ preferences while they are choosing tasks for themselves. We collected data from 42 participants working in 25 different software companies. We applied Grounded Theory procedures to study and analyse factors for self-assigning tasks, which we grouped into three categories: task-based, developer-based, and opinion-based. We found that developers have individual preferences and not all factors are important to every developer. Managers share some common and varying perspectives around the identified factors. Most managers want developers to give higher priority to certain factors. Developers often need to balance between task priority and their own individual preferences, and managers facilitate this through a variety of strategies. More risk-averse managers encourage expertise-based self-assignment to ensure tasks are completed quickly. Managers who are risk-balancing encourage developers to choose tasks that provide learning opportunities only when there is little risk of delays or reduced quality. Finally, growth-seeking managers regularly encourage team members to pick tasks outside their comfort zone to encourage growth opportunities. Our findings will help managers to understand what developers consider when self-assigning tasks and help them empower their teams to practice self-assignment in a sustainable manner.",1939-3520,,10.1109/TSE.2021.3101732,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506834,Self-assignment;agile teams;self-assignment factors;task allocation,Task analysis;Software;Interviews;Lead;Business;Resource management;Companies,,2,,41,IEEE,4 Aug 2021,,,IEEE,IEEE Journals,True
Revisiting the Impact of Dependency Network Metrics on Software Defect Prediction,L. Gong; G. K. Rajbahadur; A. E. Hassan; S. Jiang,"School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, Jiangsu, China; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China",IEEE Transactions on Software Engineering,9 Dec 2022,2022,48,12,5030,5049,"Software dependency network metrics extracted from the dependency graph of the software modules by the application of Social Network Analysis (SNA metrics) have been shown to improve the performance of the Software Defect prediction (SDP) models. However, the relative effectiveness of these SNA metrics over code metrics in improving the performance of the SDP models has been widely debated with no clear consensus. Furthermore, some of the common SDP scenarios like predicting the number of defects in a module (Defect-count) in Cross-version and Cross-project SDP contexts remain unexplored. Such lack of clear directive on the effectiveness of SNA metrics when compared to the widely used code metrics prevents us from potentially building better performing SDP models. Therefore, through a case study of 9 open source software projects across 30 versions, we study the relative effectiveness of SNA metrics when compared to code metrics across 3 commonly used SDP contexts (Within-project, Cross-version and Cross-project) and scenarios (Defect-count, Defect-classification (classifying if a module is defective) and Effort-aware (ranking the defective modules w.r.t to the involved effort)). We find the SNA metrics by themselves or along with code metrics improve the performance of SDP models over just using code metrics on 5 out of the 9 studied SDP scenarios (three SDP scenarios across three SDP contexts). However, we note that in some cases the improvements afforded by considering SNA metrics over or alongside code metrics might only be marginal, whereas in other cases the improvements could be potentially large. Based on these findings we suggest that the future work should: consider SNA metrics alongside code metrics in their SDP models; as well as consider Ego metrics and Global metrics, the two different types of the SNA metrics separately when training SDP models as they behave differently.",1939-3520,,10.1109/TSE.2021.3131950,Fundamental Research Funds for the Central Universities(grant numbers:2019XKQYMS84); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9632376,Dependency network metrics;code metrics;software defect prediction;social network analysis (SNA);within-project;cross-version;cross-project;effort-aware,Measurement;Codes;Software;History;Social networking (online);Predictive models;Context modeling,,10,,104,IEEE,1 Dec 2021,,,IEEE,IEEE Journals,True
Machine/Deep Learning for Software Engineering: A Systematic Literature Review,S. Wang; L. Huang; A. Gao; J. Ge; T. Zhang; H. Feng; I. Satyarth; M. Li; H. Zhang; V. Ng,"Department of Computer Science, Southern Methodist University, Dallas, TX, USA; Department of Computer Science, Southern Methodist University, Dallas, TX, USA; Department of Computer Science, Southern Methodist University, Dallas, TX, USA; Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science, Southern Methodist University, Dallas, TX, USA; Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, TX, USA",IEEE Transactions on Software Engineering,14 Mar 2023,2023,49,3,1188,1231,"Since 2009, the deep learning revolution, which was triggered by the introduction of ImageNet, has stimulated the synergy between Software Engineering (SE) and Machine Learning (ML)/Deep Learning (DL). Meanwhile, critical reviews have emerged that suggest that ML/DL should be used cautiously. To improve the applicability and generalizability of ML/DL-related SE studies, we conducted a 12-year Systematic Literature Review (SLR) on 1,428 ML/DL-related SE papers published between 2009 and 2020. Our trend analysis demonstrated the impacts that ML/DL brought to SE. We examined the complexity of applying ML/DL solutions to SE problems and how such complexity led to issues concerning the reproducibility and replicability of ML/DL studies in SE. Specifically, we investigated how ML and DL differ in data preprocessing, model training, and evaluation when applied to SE tasks, and what details need to be provided to ensure that a study can be reproduced or replicated. By categorizing the rationales behind the selection of ML/DL techniques into five themes, we analyzed how model performance, robustness, interpretability, complexity, and data simplicity affected the choices of ML/DL models.",1939-3520,,10.1109/TSE.2022.3173346,National Science Foundation(grant numbers:2034508); NSF of Jiangsu Province(grant numbers:BK20201250); Nanjing University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772253,Software engineering;machine learning;deep learning,Task analysis;Software;Data models;Complexity theory;Codes;Predictive models;Analytical models,,20,,402,IEEE,10 May 2022,,,IEEE,IEEE Journals,True
A Comprehensive Investigation of the Impact of Class Overlap on Software Defect Prediction,L. Gong; H. Zhang; J. Zhang; M. Wei; Z. Huang,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2440,2458,"Software Defect Prediction (SDP) is one of the most vital and cost-efficient operations to ensure the software quality. However, there exists the phenomenon of class overlap in the SDP datasets (i.e., defective and non-defective modules are similar in terms of values of metrics), which hinders the performance as well as the use of SDP models. Even though efforts have been made to investigate the impact of removing overlapping technique on the performance of SDP, many open issues are still challenging yet unknown. Therefore, we conduct an empirical study to comprehensively investigate the impact of class overlap on SDP. Specifically, we first propose an overlapping instances identification approach by analyzing the class distribution in the local neighborhood of a given instance. We then investigate the impact of class overlap and two common overlapping instance handling techniques on the performance and the interpretation of seven representative SDP models. Through an extensive case study on 230 diversity datasets, we observe that: i) 70.0% of SDP datasets contain overlapping instances; ii) different levels of class overlap have different impacts on the performance of SDP models; iii) class overlap affects the rank of the important feature list of SDP models, particularly the feature lists at the top 2 and top 3 ranks; IV) Class overlap handling techniques could statistically significantly improve the performance of SDP models trained on datasets with over 12.5% overlap ratios. We suggest that future work should apply our KNN method to identify the overlap ratios of datasets before building SDP models.",1939-3520,,10.1109/TSE.2022.3220740,National Natural Science Foundation of China(grant numbers:62202223); Natural Science Foundation of Jiangsu Province(grant numbers:BK20220881); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9944157,Class overlap;data quality;k-nearest neighbourhood;local analysis;software defect prediction;software metrics,Software;Measurement;Predictive models;Classification tree analysis;Stability analysis;NASA;Machine learning algorithms,,14,,84,IEEE,9 Nov 2022,,,IEEE,IEEE Journals,True
Federated Learning for Software Engineering: A Case Study of Code Clone Detection and Defect Prediction,Y. Yang; X. Hu; Z. Gao; J. Chen; C. Ni; X. Xia; D. Lo,"Department of Computer Science and Technology, Zhejiang University, Ningbo, China; School of Software Technology, Zhejiang University, Ningbo, China; Shanghai Institute for Advanced Study, Zhejiang University, Hangzhou, China; School of Computer Science, Wuhan University, Wuhan, China; School of Software Technology, Zhejiang University, Ningbo, China; Software Engineering Application Technology Lab, Huawei, Hangzhou, China; School of Computing and Information Systems, Singapore Management University, Singapore",IEEE Transactions on Software Engineering,13 Feb 2024,2024,50,2,296,321,"In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers’ ability to gain insights into industry developers’ concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",1939-3520,,10.1109/TSE.2023.3347898,National Natural Science Foundation of China(grant numbers:62141222); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10379838,Federated learning;parameter aggregation strategy;skewed data distribution;code clone detection;defect prediction,Data models;Training;Codes;Cloning;Task analysis;Benchmark testing;Industries,,,,85,IEEE,3 Jan 2024,,,IEEE,IEEE Journals,True
Towards Reliable Online Just-in-Time Software Defect Prediction,G. G. Cabral; L. L. Minku,"Department of Computing, Federal Rural University of Pernambuco, Recife, Brazil; School of Computer Science, The University of Birmingham, Birmingham, U.K.",IEEE Transactions on Software Engineering,14 Mar 2023,2023,49,3,1342,1358,"Throughout its development period, a software project experiences different phases, comprises modules with different complexities and is touched by many different developers. Hence, it is natural that problems such as Just-in-Time Software Defect Prediction (JIT-SDP) are affected by changes in the defect generating process (concept drifts), potentially hindering predictive performance. JIT-SDP also suffers from delays in receiving the labels of training examples (verification latency), potentially exacerbating the challenges posed by concept drift and further hindering predictive performance. However, little is known about what types of concept drift affect JIT-SDP and how they affect JIT-SDP classifiers in view of verification latency. This work performs the first detailed analysis of that. Among others, it reveals that different types of concept drift together with verification latency significantly impair the stability of the predictive performance of existing JIT-SDP approaches, drastically affecting their reliability over time. Based on the findings, a new JIT-SDP approach is proposed, aimed at providing higher and more stable predictive performance (i.e., reliable) over time. Experiments based on ten GitHub open source projects show that our approach was capable of produce significantly more stable predictive performances in all investigated datasets while maintaining or improving the predictive performance obtained by state-of-art methods.",1939-3520,,10.1109/TSE.2022.3175789,"Engineering and Physical Sciences Research Council(grant numbers:EP/R006660/2,EP/P005578/1); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9778962,Just-in-time software defect prediction;online learning;concept drift;verification latency;class imbalance learning,Software;Reliability;Training;Codes;Software reliability;Software quality;Indexes,,13,,31,IEEE,19 May 2022,,,IEEE,IEEE Journals,True
Cross-Project Online Just-In-Time Software Defect Prediction,S. Tabassum; L. L. Minku; D. Feng,"School of Computer Science, University of Birminigham, Birmingham, U.K; School of Computer Science, University of Birminigham, Birmingham, U.K; Xiliu Tech, Beijing, China",IEEE Transactions on Software Engineering,6 Jan 2023,2023,49,1,268,287,"Cross-Project (CP) Just-In-Time Software Defect Prediction (JIT-SDP) makes use of CP data to overcome the lack of data necessary to train well performing JIT-SDP classifiers at the beginning of software projects. However, such approaches have never been investigated in realistic online learning scenarios, where Within-Project (WP) software changes naturally arrive over time and can be used to automatically update the classifiers. We provide the first investigation of when and to what extent CP data are useful for JIT-SDP in such realistic scenarios. For that, we propose three different online CP JIT-SDP approaches that can be updated with incoming CP and WP training examples over time. We also collect data on 9 proprietary software projects and use 10 open source software projects to analyse these approaches. We find that training classifiers with incoming CP+WP data can lead to absolute improvements in G-mean of up to 53.89% and up to 35.02% at the initial stage of the projects compared to classifiers using WP-only and CP-only data, respectively. Using CP+WP data was also shown to be beneficial after a large number of WP data were received. Using CP data to supplement WP data helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to absolute G-Mean improvements of up to 37.35% and 48.16% compared to WP-only and CP-only data during such periods, respectively. During periods of stable predictive performance, absolute improvements were of up to 29.03% and up to 41.25% compared to WP-only and CP-only classifiers, respectively. Our results highlight the importance of using both CP and WP data together in realistic online JIT-SDP scenarios.",1939-3520,,10.1109/TSE.2022.3150153,Engineering and Physical Sciences Research Council(grant numbers:EP/R006660/2); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9709674,Software defect prediction;cross-project learning;transfer learning;online learning;verification latency;concept drift,Training;Software;Training data;Predictive models;Codes;Resource management;Open source software,,14,,45,IEEE,10 Feb 2022,,,IEEE,IEEE Journals,True
FairBalance: How to Achieve Equalized Odds With Data Pre-Processing,Z. Yu; J. Chakraborty; T. Menzies,"Department of Software Engineering, Rochester Institute of Technology, Rochester, NY, USA; Amazon, Seattle, WA, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2294,2312,"This research seeks to benefit the software engineering society by providing a simple yet effective pre-processing approach to achieve equalized odds fairness in machine learning software. Fairness issues have attracted increasing attention since machine learning software is increasingly used for high-stakes and high-risk decisions. It is the responsibility of all software developers to make their software accountable by ensuring that the machine learning software do not perform differently on different sensitive demographic groups—satisfying equalized odds. Different from prior works which either optimize for an equalized odds related metric during the learning process like a black-box, or manipulate the training data following some intuition; this work studies the root cause of the violation of equalized odds and how to tackle it. We found that equalizing the class distribution in each demographic group with sample weights is a necessary condition for achieving equalized odds without modifying the normal training process. In addition, an important partial condition for equalized odds (zero average odds difference) can be guaranteed when the class distributions are weighted to be not only equal but also balanced (1:1). Based on these analyses, we proposed FairBalance, a pre-processing algorithm which balances the class distribution in each demographic group by assigning calculated weights to the training data. On eight real-world datasets, our empirical results show that, at low computational overhead, the proposed pre-processing algorithm FairBalance can significantly improve equalized odds without much, if any damage to the utility. FairBalance also outperforms existing state-of-the-art approaches in terms of equalized odds. To facilitate reuse, reproduction, and validation, we made our scripts available at https://github.com/hil-se/FairBalance.",1939-3520,,10.1109/TSE.2024.3431445,NSF(grant numbers:2245796); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10606107,Machine learning fairness;ethics in software engineering,Software;Machine learning;Training data;Measurement;Ethics;Machine learning algorithms;Data models,,1,,73,IEEE,22 Jul 2024,,,IEEE,IEEE Journals,True
Making the Most of Small Software Engineering Datasets With Modern Machine Learning,J. A. Prenner; R. Robbes,"Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy; Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy",IEEE Transactions on Software Engineering,9 Dec 2022,2022,48,12,5050,5067,"This paper provides a starting point for Software Engineering (SE) researchers and practitioners faced with the problem of training machine learning models on small datasets. Due to the high costs associated with labeling data, in Software Engineering, there exist many small (< 5,000 samples) and medium-sized (<100,000 samples) datasets. While deep learning has set the state of the art in many machine learning tasks, it is only recently that it has proven effective on small-sized datasets, primarily thanks to pre-training, a semi-supervised learning technique that leverages abundant unlabelled data alongside scarce labelled data. In this work, we evaluate pre-trained Transformer models on a selection of 13 smaller datasets from the SE literature, covering both, source code and natural language. Our results suggest that pre-trained Transformers are competitive and in some cases superior to previous models, especially for tasks involving natural language; whereas for source code tasks, in particular for very small datasets, traditional machine learning methods often has the edge. In addition, we experiment with several techniques that ought to aid training on small datasets, including active learning, data augmentation, soft labels, self-training and intermediate-task fine-tuning, and issue recommendations on when they are effective. We also release all the data, scripts, and most importantly pre-trained models for the community to reuse on their own datasets.",1939-3520,,10.1109/TSE.2021.3135465,University of Bozen-Bolzano; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9653849,Small datasets;transformer;BERT;RoBERTA;pre-training;fine-tuning;data augmentation;back translation;soft labels;active learning,Codes;Task analysis;Transformers;Training;Software;Machine learning;Support vector machines,,9,,97,IEEE,16 Dec 2021,,,IEEE,IEEE Journals,True
Domain-Driven Design for Microservices: An Evidence-Based Investigation,C. Zhong; S. Li; H. Huang; X. Liu; Z. Chen; Y. Zhang; H. Zhang,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Grid Nanjing Power Supply Company, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; DaoCloud, Shanghai, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1425,1449,"MicroService Architecture (MSA), a predominant architectural style in recent years, still faces the arduous task of identifying the boundaries of microservices. Domain-Driven Design (DDD) is regarded as one of the major design methods for addressing this task in practice, which aims to iteratively build domain models using a series of patterns, principles, and practices. The adoption of DDD for MSA (DDD4M in short) can, however, present considerable challenges in terms of a sufficient understanding of the methodological requirements and the application domains. It is imperative to establish a systematic understanding about the various aspects of employing DDD4M and provide effective guidance. This study reports an empirical inquiry that integrates a systematic literature review and a confirmatory survey. By reviewing 34 scientific studies and consulting 63 practitioners, this study reveals several distinctive findings with regard to the state and challenges of as well as the possible solutions for DDD4M applications, from the 5W1H perspectives: When, Where, Why, Who, What, and How. The analysis and synthesis of evidence show a wide variation in understanding of domain modeling artifacts. The status quo indicates the need for further methodological support in terms of application process, domain model design and implementation, and domain knowledge acquisition and management. To advance the state-of-the-practice, our findings were organized into a preliminary checklist that intends to assist practitioners by illuminating a DDD4M application process and the specific key considerations along the way.",1939-3520,,10.1109/TSE.2024.3385835,"Key Research and Development Program of Jiangsu Province(grant numbers:BE2021002-2); National Natural Science Foundation of China(grant numbers:62302210,62072227,62202219); Innovation Projects and Overseas Open Projects of State Key Laboratory for Novel Software Technology (Nanjing University)(grant numbers:ZZKT2022A25,KFKT2022A09,KFKT2023A09,KFKT2023A10); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10495888,Domain-driven design;microservices architecture;systematic literature review;industrial survey;empirical study,Microservice architectures;Software;Surveys;Systematics;Analytical models;Bibliographies;Reviews,,2,,99,IEEE,10 Apr 2024,,,IEEE,IEEE Journals,True
Building Maintainable Software Using Abstraction Layering,J. Spray; R. Sinha; A. Sen; X. Cheng,"Datamars, Auckland, New Zealand; Department of Computer Science & Software Engineering, Auckland University of Technology, Auckland, New Zealand; Department of Computer Science & Software Engineering, Auckland University of Technology, Auckland, New Zealand; Datamars, Auckland, New Zealand",IEEE Transactions on Software Engineering,11 Nov 2022,2022,48,11,4397,4410,"Increased software maintainability can help improve a company's profitability by directly reducing ongoing software development costs. Abstraction Layered Architecture (ALA) is a reference architecture for building maintainable applications, but its effectiveness in commercial projects has remained unexplored. This research, carried out as a 16-month joint industry-academic project, explores developing commercial code bases using ALA and the extent to which ALA improves maintainability. An existing application from Datamars, New Zealand, was re-developed by using ALA and compared with the original application. In order to carry out these comparisons, we developed suitable measures by adapting maintainability characteristics from the ISO 25010 family of standards. Specifically, we determined metrics to capture the five sub-characteristics of maintainability: modularity, reusability, analysability, modifiability, and testability; and used them to test our hypothesis that the use of ALA improved maintainability of the application. During the evaluation, we found that the modularity, reusability, analysability, and testability of the re-developed ALA application were higher than for the original application. The modifiability of the ALA-based application was lower in the short-term, but shown to trend upwards in the longer term. Our findings led to proposing a generalised ALA-based development method that promises a significant reduction in maintenance costs.",1939-3520,,10.1109/TSE.2021.3119012,Callaghan Innovation(grant numbers:DAMAE1802/PROP-62523-FELLOW-DAMAE); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9566775,Maintainability;ALA;modularity;reusability;analysability;modifiability;testability,Codes;Software;Programming;Couplings;Measurement;Maintenance engineering;ISO Standards,,4,,43,IEEE,11 Oct 2021,,,IEEE,IEEE Journals,True
"Automatic Detection, Validation, and Repair of Race Conditions in Interrupt-Driven Embedded Software",Y. Wang; F. Gao; L. Wang; T. Yu; J. Zhao; X. Li,"State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; University of Kentucky, Lexington, KY, USA; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,10 Jan 2022,2022,48,1,346,363,"Interrupt-driven programs are widely deployed in safety-critical embedded systems to perform hardware and resource dependent data operation tasks. The frequent use of interrupts in these systems can cause race conditions to occur due to interactions between application tasks and interrupt handlers (or two interrupt handlers). Numerous program analysis and testing techniques have been proposed to detect races in multithreaded programs. Little work, however, has addressed race condition problems related to hardware interrupts. In this paper, we present SDRacer, an automated framework that can detect, validate and repair race conditions in interrupt-driven embedded software. It uses a combination of static analysis and symbolic execution to generate input data for exercising the potential races. It then employs virtual platforms to dynamically validate these races by forcing the interrupts to occur at the potential racing points. Finally, it provides repair candidates to eliminate the detected races. We evaluate SDRacer on nine real-world embedded programs written in C language. The results show that SDRacer can precisely detect and successfully fix race conditions.",1939-3520,,10.1109/TSE.2020.2989171,National Key Research and Development Program of China(grant numbers:2017YFA0700604); National Natural Science Foundation of China(grant numbers:61632015); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072666,Embedded software;interrupts;race condition;software testing;repair suggestion,Task analysis;Maintenance engineering;Hardware;Embedded systems;Concurrent computing;Testing;Embedded software,,6,,85,IEEE,20 Apr 2020,,,IEEE,IEEE Journals,True
FairMask: Better Fairness via Model-Based Rebalancing of Protected Attributes,K. Peng; J. Chakraborty; T. Menzies,"Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2426,2439,"Context: Machine learning software can generate models that inappropriately discriminate against specific protected social groups (e.g., groups based on gender, ethnicity, etc.). Motivated by those results, software engineering researchers have proposed many methods for mitigating those discriminatory effects. While those methods are effective in mitigating bias, few of them can provide explanations on what is the root cause of bias. Objective: We aim to better detect and mitigate algorithmic discrimination in machine learning software problems. Method: Here we propose ${{\sf FairMask}}$FairMask, a model-based extrapolation method that is capable of both mitigating bias and explaining the cause. In our ${{\sf FairMask}}$FairMask approach, protected attributes are represented by models learned from the other independent variables (and these models offer extrapolations over the space between existing examples). We then use the extrapolation models to relabel protected attributes later seen in testing data or deployment time. Our approach aims to offset the biased predictions of the classification model by rebalancing the distribution of protected attributes. Results: The experiments of this paper show that, without compromising (original) model performance, ${{\sf FairMask}}$FairMask can achieve significantly better group and individual fairness (as measured in different metrics) than benchmark methods. Moreover, compared to another instance-based rebalancing method, our model-based approach shows faster runtime and thus better scalability. Conclusion: Algorithmic decision bias can be removed via extrapolation that corrects the misleading latent correlation between the protected attributes and other non-protected ones. As evidence for this, our proposed ${{\sf FairMask}}$FairMask is not only performance-wise better (measured by fairness and performance metrics) than two state-of-the-art fairness algorithms. Reproduction Package: In order to better support open science, all scripts and data used in this study are available online at https://github.com/anonymous12138/biasmitigation.",1939-3520,,10.1109/TSE.2022.3220713,Meta Inc; Laboratory for Analytical Sciences; North Carolina State University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9951398,Software fairness;explanation;bias mitigation,Measurement;Software;Data models;Predictive models;Social groups;Extrapolation;Software algorithms,,14,,64,IEEE,15 Nov 2022,,,IEEE,IEEE Journals,True
Mutation Analysis for Cyber-Physical Systems: Scalable Solutions and Results in the Space Domain,O. Cornejo; F. Pastore; L. C. Briand,"SnT Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Software Engineering,18 Oct 2022,2022,48,10,3913,3939,"On-board embedded software developed for spaceflight systems (space software) must adhere to stringent software quality assurance procedures. For example, verification and validation activities are typically performed and assessed by third party organizations. To further minimize the risk of human mistakes, space agencies, such as the European Space Agency (ESA), are looking for automated solutions for the assessment of software testing activities, which play a crucial role in this context. Though space software is our focus here, it should be noted that such software shares the above considerations, to a large extent, with embedded software in many other types of cyber-physical systems. Over the years, mutation analysis has shown to be a promising solution for the automated assessment of test suites; it consists of measuring the quality of a test suite in terms of the percentage of injected faults leading to a test failure. A number of optimization techniques, addressing scalability and accuracy problems, have been proposed to facilitate the industrial adoption of mutation analysis. However, to date, two major problems prevent space agencies from enforcing mutation analysis in space software development. First, there is uncertainty regarding the feasibility of applying mutation analysis optimization techniques in their context. Second, most of the existing techniques either can break the real-time requirements common in embedded software or cannot be applied when the software is tested in Software Validation Facilities, including CPU emulators and sensor simulators. In this paper, we enhance mutation analysis optimization techniques to enable their applicability to embedded software and propose a pipeline that successfully integrates them to address scalability and accuracy issues in this context, as described above. Further, we report on the largest study involving embedded software systems in the mutation analysis literature. Our research is part of a research project funded by ESA ESTEC involving private companies (GomSpace Luxembourg and LuxSpace) in the space sector. These industry partners provided the case studies reported in this paper; they include an on-board software system managing a microsatellite currently on-orbit, a set of libraries used in deployed cubesats, and a mathematical library certified by ESA.",1939-3520,,10.1109/TSE.2021.3107680,European Space Agency(grant numbers:ITT-1-9873/FAQAS); European Research Council; European Union's Horizon 2020 research and innovation programme(grant numbers:694277); Canada Research Chair programs; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524475,Mutation analysis;mutation testing;space software;embedded software;cyber-physical systems,Software;Embedded software;Optimization;Libraries;Scalability;Pipelines;Hardware,,7,,129,IEEE,27 Aug 2021,,,IEEE,IEEE Journals,True
Multi-Objective Software Defect Prediction via Multi-Source Uncertain Information Fusion and Multi-Task Multi-View Learning,M. Yang; S. Yang; W. E. Wong,"School of Reliability and Systems Engineering, Beihang University, Beijing, China; School of Reliability and Systems Engineering, Beihang University, Beijing, China; Department of Computer Science, University of Texas at Dallas, Richardson, TX, USA",IEEE Transactions on Software Engineering,14 Aug 2024,2024,50,8,2054,2076,"Effective software defect prediction (SDP) is important for software quality assurance. Numerous advanced SDP methods have been proposed recently. However, how to consider the task correlations and achieve multi-objective SDP accurately and efficiently still remains to be further explored. In this paper, we propose a novel multi-objective SDP method via multi-source uncertain information fusion and multi-task multi-view learning (MTMV) to accurately and efficiently predict the proneness, location, and type of defects. Firstly, multi-view features are extracted from multi-source static analysis results, reflecting uncertain defect location distribution and semantic information. Then, a novel MTMV model is proposed to fully fuse the uncertain defect information in multi-view features and realize effective multi-objective SDP. Specifically, the convolutional GRU encoders capture the consistency and complementarity of multi-source defect information to automatically filter the noise of false and missed alarms, and reduce location and type uncertainty of static analysis results. A global attention mechanism combined with the hard parameter sharing in MTMV fuse features according to their global importance of all tasks for balanced learning. Then, considering the latent task and feature correlations, multiple task-specific decoders jointly optimize all SDP tasks by sharing the learning experience. Through the extensive experiments on 14 datasets, the proposed method significantly improves the prediction performance over 12 baseline methods for all SDP objectives. The average improvements are 30.7%, 31.2%, and 32.4% for defect proneness, location, and type prediction, respectively. Therefore, the proposed multi-objective SDP method can provide more sufficient and precise insights for developers to significantly improve the efficiency of software analysis and testing.",1939-3520,,10.1109/TSE.2024.3421591,National Natural Science Foundation of China(grant numbers:61672080); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10584421,Software defect prediction;multi-objective prediction;multi-source uncertainty;information fusion;multi-task multi-view learning,Feature extraction;Codes;Task analysis;Static analysis;Multitasking;Correlation;Accuracy,,,,66,IEEE,3 Jul 2024,,,IEEE,IEEE Journals,True
Software Updates Strategies: A Quantitative Evaluation Against Advanced Persistent Threats,G. D. Tizio; M. Armellini; F. Massacci,"University of Trento, Trento, Italy; University of Trento, Trento, Italy; University of Trento, Trento, Italy",IEEE Transactions on Software Engineering,14 Mar 2023,2023,49,3,1359,1373,"Software updates reduce the opportunity for exploitation. However, since updates can also introduce breaking changes, enterprises face the problem of balancing the need to secure software with updates with the need to support operations. We propose a methodology to quantitatively investigate the effectiveness of software updates strategies against attacks of Advanced Persistent Threats (APTs). We consider strategies where the vendor updates are the only limiting factors to cases in which enterprises delay updates from 1 to 7 months based on SANS data. Our manually curated dataset of APT attacks covers 86 APTs and 350 campaigns from 2008 to 2020. It includes information about attack vectors, exploited vulnerabilities (e.g., 0-days versus public vulnerabilities), and affected software and versions. Contrary to common belief, most APT campaigns employed publicly known vulnerabilities. If an enterprise could theoretically update as soon as an update is released, it would face lower odds of being compromised than those waiting one (4.9x) or three (9.1x) months. However, if attacked, it could still be compromised from 14% to 33% of the times. As in practice enterprises must do regression testing before applying an update, our major finding is that one could perform 12% of all possible updates restricting oneself only to versions fixing publicly known vulnerabilities without significant changes to the odds of being compromised compared to a company that updates for all versions.",1939-3520,,10.1109/TSE.2022.3176674,"European Union through the H2020 Programme(grant numbers:830929,952647); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9780011,Advanced persistent threats;software vulnerabilities;software updates,Software;Delays;Companies;Testing;Measurement;Faces;Terminology,,5,,82,IEEE,23 May 2022,,,IEEE,IEEE Journals,True
Better Data Labelling With EMBLEM (and how that Impacts Defect Prediction),H. Tu; Z. Yu; T. Menzies,"Computer Science, North Carolina State University College of Engineering, Raleigh, NC, USA; Computer Science, North Carolina State University College of Engineering, Raleigh, NC, USA; Computer Science, North Carolina State University College of Engineering, Raleigh, NC, USA",IEEE Transactions on Software Engineering,10 Jan 2022,2022,48,1,278,294,"Standard automatic methods for recognizing problematic development commits can be greatly improved via the incremental application of human+artificial expertise. In this approach, called EMBLEM, an AI tool first explore the software development process to label commits that are most problematic. Humans then apply their expertise to check those labels (perhaps resulting in the AI updating the support vectors within their SVM learner). We recommend this human+AI partnership, for several reasons. When a new domain is encountered, EMBLEM can learn better ways to label which comments refer to real problems. Also, in studies with 9 open source software projects, labelling via EMBLEM's incremental application of human+AI is at least an order of magnitude cheaper than existing methods ($\approx$≈ eight times). Further, EMBLEM is very effective. For the data sets explored here, EMBLEM better labelling methods significantly improved $P_{opt}20$Popt20 and G-scores performance in nearly all the projects studied here.",1939-3520,,10.1109/TSE.2020.2986415,"National Science Foundation(grant numbers:#1826574,#1931425); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064604,Human-in-the-loop AI;data labelling;defect prediction;software analytics,Labeling;Computer bugs;Data models;Software;Support vector machines;Standards;Task analysis,,18,,119,IEEE,13 Apr 2020,,,IEEE,IEEE Journals,True
APPT: Boosting Automated Patch Correctness Prediction via Fine-Tuning Pre-Trained Models,Q. Zhang; C. Fang; W. Sun; Y. Liu; T. He; X. Hao; Z. Chen,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,474,494,"Automated program repair (APR) aims to fix software bugs automatically without human debugging efforts and plays a crucial role in software development and maintenance. Despite the recent significant progress in the number of fixed bugs, APR is still challenged by a long-standing overfitting problem (i.e., the generated patch is plausible but overfitting). Various techniques have thus been proposed to address the overfitting problem. Recently, researchers have employed BERT to extract code features, which are then used to train a classifier for patch correctness prediction, indicating the potential of such pre-trained models in reasoning about patch correctness. However, BERT is restricted to feature extraction for classifier training without benefiting from the training process, potentially generating sub-optimal vector representations for patched code snippets. In this paper, we propose APPT, a pre-trained model-based automated patch correctness assessment technique by both pre-training and fine-tuning. APPT adopts a pre-trained model as the encoder stack, followed by an LSTM stack and a deep learning classifier. More importantly, the pre-trained model is fine-tuned in conjunction with other components as a whole pipeline to fully adapt it specifically for reasoning about patch correctness. Although our idea is general and can be built on various existing pre-trained models, we have implemented APPT based on the BERT model. We conduct an extensive experiment on 1,183 Defects4J patches and the experimental results show that APPT achieves prediction accuracy of 79.7% and recall of 83.2%, outperforming the state-of-the-art technique CACHE by 4.3% and 6.7%. Our additional investigation on 49,694 real-world patches shows that APPT achieves the optimum performance (exceeding 99% in five common metrics for assessing patch classification techniques) compared with existing representation learning techniques. We further investigate the impact of each component and find that they all positively contribute to APPT, e.g., the fine-tuning process and the LSTM stack increase F1-score by 10.22% and 4.11%, respectively. We also prove that adopting advanced pre-trained models can further provide substantial advancement (e.g., GraphCodeBERT-based APPT improves BERT-based APPT by 2.8% and 3.3% in precision and AUC, respectively), highlighting the generalizability of APPT. Overall, our study highlights the promising future of fine-tuning pre-trained models to assess patch correctness and reduce the manual inspection effort of debugging experts when deploying APR tools in practice.",1939-3520,,10.1109/TSE.2024.3354969,"National Key Research and Development Program of China(grant numbers:2021YFB1715600); National Natural Science Foundation of China(grant numbers:61932012,62141215,62372228); China Scholarship Council(grant numbers:202306190117); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10402095,Automated program repair;patch correctness;pre-trained model,Codes;Feature extraction;Task analysis;Predictive models;Maintenance engineering;Computer bugs;Adaptation models,,1,,87,IEEE,17 Jan 2024,,,IEEE,IEEE Journals,True
"Machine Learning Testing: Survey, Landscapes and Horizons",J. M. Zhang; M. Harman; L. Ma; Y. Liu,"CREST, University College London, London, U.K; CREST, University College London, London, U. K.; Kyushu University, Fukuoka, Japan; Nanyang Technological University, Singapore",IEEE Transactions on Software Engineering,10 Jan 2022,2022,48,1,1,36,"This paper provides a comprehensive survey of techniques for testing machine learning systems; Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing.",1939-3520,,10.1109/TSE.2019.2962027,"ERC(grant numbers:741278); JSPS KAKENHI(grant numbers:19K24348,19H04086); Qdai-jump Research Program(grant numbers:01277); Nvidia; National Research Foundation Singapore(grant numbers:NRF2018NCR-NCR005-0001); National Satellite of Excellence in Trustworthy Software System(grant numbers:NRF2018NCR-NSOE003-0001); NTU(grant numbers:NGF-2019-06-024); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000651,Machine learning;software testing;deep neural network,Machine learning;Software testing;Software engineering;Training data;Data models;Robustness,,417,,292,IEEE,17 Feb 2020,,,IEEE,IEEE Journals,True
ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation,Y. Tang; Z. Liu; Z. Zhou; X. Luo,"University of Glasgow, Glasgow, U.K.; ShanghaiTech University, Shanghai, China; ShanghaiTech University, Shanghai, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong SAR, China",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1340,1359,"Recent advancements in large language models (LLMs) have demonstrated exceptional success in a wide range of general domain tasks, such as question answering and following instructions. Moreover, LLMs have shown potential in various software engineering applications. In this study, we present a systematic comparison of test suites generated by the ChatGPT LLM and the state-of-the-art SBST tool EvoSuite. Our comparison is based on several critical factors, including correctness, readability, code coverage, and bug detection capability. By highlighting the strengths and weaknesses of LLMs (specifically ChatGPT) in generating unit test cases compared to EvoSuite, this work provides valuable insights into the performance of LLMs in solving software engineering problems. Overall, our findings underscore the potential of LLMs in software engineering and pave the way for further research in this area.",1939-3520,,10.1109/TSE.2024.3382365,Hong Kong RGC Project(grant numbers:PolyU15224121); HKPolyU(grant numbers:ZGGG); National Natural Science Foundation of China(grant numbers:62202306); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10485640,ChatGPT;search-based software testing;large language models,Chatbots;Codes;Task analysis;Software;Question answering (information retrieval);Computer bugs;Benchmark testing,,5,,86,IEEE,29 Mar 2024,,,IEEE,IEEE Journals,True
Detecting the Locations and Predicting the Maintenance Costs of Compound Architectural Debts,L. Xiao; Y. Cai; R. Kazman; R. Mo; Q. Feng,"School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Computer Science, Drexel University, Philadelphia, PA, USA; Department of Information Technology Management, University of Hawaii, Honolulu, HI, USA; Computer Science, Central China Normal University, Wuhan, Hubei, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,16 Sep 2022,2022,48,9,3686,3715,"Architectural Technical Debt (ATD) refers to sub-optimal architectural design in a software system that incurs high maintenance “interest” over time. Previous research revealed that ATD has significant negative impact on daily development. This paper contributes an approach to enable an architect to precisely locate ATDs, as well as capture the trajectory of maintenance cost on each debt, based on which, predict the cost of the debt in a future release. The ATDs are expressed in four typical patterns, which entail the core of each debt. Furthermore, we aggregate compound ATDs to capture the complicated relationship among multiple ATD instances, which should be examined together for effective refactoring solutions. We evaluate our approach on 18 real-world projects. We identified ATDs that persistently incur significant (up to 95 percent of) maintenance costs in most projects. The maintenance costs on the majority of debts fit into a linear regression model—indicating stable “interest” rate. In five projects, 12.1 to 27.6 percent of debts fit into an exponential model, indicating increasing “interest” rate, which deserve higher priority from architects. The regression models can accurately predict the costs of the majority of (82 to 100 percent) debts in the next release of a system. By aggregating related ATDs, architects can focus on a small number of cost-effective compound debts, which contain a relatively small number of source files, but account for a large portion of maintenance costs in their projects. With these capabilities, our approach can help architects make informed decisions regarding whether, where, and how to refactor for eliminating ATDs in their systems.",1939-3520,,10.1109/TSE.2021.3102221,"National Science Foundation(grant numbers:CNS-1823074,CNS-1823177,CNS-1823214,CCF-1817267,CCF-1816594,OAC-1835292); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9508122,Software architecture;technical debt;software maintenance;debt quantification and prioritization,Maintenance engineering;Software;Compounds;Computer architecture;History;Trajectory;Aggregates,,9,,120,IEEE,5 Aug 2021,,,IEEE,IEEE Journals,True
Automatically Tagging the “AAA” Pattern in Unit Test Cases Using Machine Learning Models,C. Wei; L. Xiao; T. Yu; X. Chen; X. Wang; S. Wong; A. Clune,"School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Department of EECS, University of Cincinnati, Cincinnati, OH, USA; HSBC Software Development (Guangdong) Limited, Guangzhou, Guangdong Province, China; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Envestnet, Inc., Berwyn, PA, USA; AGI, Ansys Company, Exton, PA, USA",IEEE Transactions on Software Engineering,15 May 2023,2023,49,5,3305,3324,"The AAA pattern (i.e., Arrange-Act-Assert) is a common and natural layout to create a test case. Following this pattern in test cases may benefit comprehension, debugging, and maintenance. The AAA structure of real-life test cases, however, may not be clear due to their high complexity. Manually labeling AAA statements in test cases is tedious. Thus, we envision that an automated approach for labeling AAA statements in existing test cases could benefit new developers and projects that practice collective code ownership and test-driven development. This paper contributes an automatic approach based on machine learning models. The “secret sauce” of this approach is a set of three learning features that are based on the semantic, syntax, and context information in test cases, derived from the manual tagging process. Thus, our approach mimics how developers may manually tag the AAA pattern of a test case. We assess the precision, recall, and F-1 score of our approach based on 449 test cases, containing about 16,612 statements, across 4 Apache open source projects. To achieve the best performance in our approach, we explore the usage of six machine learning models; the contribution of the SMOTE data balancing technique; the comparison of the three learning features; and the comparison of five different methods for calculating the semantic feature. The results show our approach is able to identify Arrangement, Action, and Assertion statements with a precision upwards of 92%, and recall up to 74%. We also summarize some experience based on our experiments—regarding the choice of machine learning models, data balancing algorithm, and feature engineering methods—which could potentially provide some reference to related future research.",1939-3520,,10.1109/TSE.2023.3252442,"National Science Foundation(grant numbers:CCF-1909085,CCF-1909763); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058578,AAA pattern;feature engineering;machine learning;natural language processing;software testing;unit testing,Codes;Machine learning;Tagging;Debugging;Production;Maintenance engineering;Computer bugs,,1,,81,IEEE,3 Mar 2023,,,IEEE,IEEE Journals,True
Chain-of-Thought in Neural Code Generation: From and for Lightweight Language Models,G. Yang; Y. Zhou; X. Chen; X. Zhang; T. Y. Zhuo; T. Chen,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; School of Information Science and Technology, Nantong University, Nantong, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Monash University, Melbourne, VIC, Australia; School of Computing and Mathematical Sciences, Birkbeck, University of London, London, U.K.",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2437,2457,"Large Language Models (LLMs) have demonstrated remarkable potential in code generation. The integration of Chain of Thought (CoT) reasoning can further boost their performance. However, current CoT methods often require manual writing or LLMs with over 100 billion parameters to generate, impeding their applicability in resource-constrained scenarios. In this study, we investigate lightweight Language Models ($\ell$ℓLMs), which are defined to have fewer than 10 billion parameters. Empirically, we find that most $\ell$ℓLMs cannot generate high-quality CoTs when prompted by the few-shot method, but can take advantage of high-quality CoTs generated elsewhere to improve their performance in code generation. Based on these findings, we design a novel approach COTTON which can leverage $\ell$ℓLMs to automatically generate CoTs for code generation. We synthesize new datasets and conduct extensive experiments on various benchmarks. The results show that the CoTs generated by COTTON outperform the baselines in terms of automated and human evaluation metrics. In particular, the CoTs generated by COTTON boost various $\ell$ℓLMs to achieve higher performance gains than those generated by LLMs such as ChatGLM (130B), and are competitive with those generated by Gemini and gpt-3.5-turbo. The results also reveal that COTTON not only improves the performance of $\ell$ℓLMs, but also enhances the performance of LLMs. Our study showcases the potential of $\ell$ℓLMs in software engineering applications.",1939-3520,,10.1109/TSE.2024.3440503,"National Natural Science Foundation of China(grant numbers:62372232); Fundamental Research Funds for the Central Universities(grant numbers:NG2023005); Collaborative Innovation Center of Novel Software Technology and Industrialization; Postgraduate Research & Practice Innovation Program of Jiangsu Province(grant numbers:KYCX23_0396); Short-term Visiting Program of Nanjing University of Aeronautics and Astronautics for Ph.D. Students Abroad(grant numbers:240501DF16); State Key Laboratory of Novel Software Technology, Nanjing University(grant numbers:KFKT2022A03,KFKT2023A04); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10634302,Code generation;chain-of-thought;large language model;lightweight language model;program language processing,Codes;Cotton;Task analysis;Computational modeling;Benchmark testing;Training;Software engineering,,,,115,IEEE,12 Aug 2024,,,IEEE,IEEE Journals,True
DeepLineDP: Towards a Deep Learning Approach for Line-Level Defect Prediction,C. Pornprasit; C. K. Tantithamthavorn,"Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia",IEEE Transactions on Software Engineering,9 Jan 2023,2023,49,1,84,98,"Defect prediction is proposed to assist practitioners effectively prioritize limited Software Quality Assurance (SQA) resources on the most risky files that are likely to have post-release software defects. However, there exist two main limitations in prior studies: (1) the granularity levels of defect predictions are still coarse-grained and (2) the surrounding tokens and surrounding lines have not yet been fully utilized. In this paper, we perform a survey study to better understand how practitioners perform code inspection in modern code review process, and their perception on a line-level defect prediction. According to the responses from 36 practitioners, we found that 50% of them spent at least 10 minutes to more than one hour to review a single file, while 64% of them still perceived that code inspection activity is challenging to extremely challenging. In addition, 64% of the respondents perceived that a line-level defect prediction tool would potentially be helpful in identifying defective lines. Motivated by the practitioners’ perspective, we present DeepLineDP, a deep learning approach to automatically learn the semantic properties of the surrounding tokens and lines in order to identify defective files and defective lines. Through a case study of 32 releases of 9 software projects, we find that the risk score of code tokens varies greatly depending on their location. Our DeepLineDP is 17%-37% more accurate than other file-level defect prediction approaches; is 47%-250% more cost-effective than other line-level defect prediction approaches; and achieves a reasonable performance when transferred to other software projects. These findings confirm that the surrounding tokens and surrounding lines should be considered to identify the fine-grained locations of defective files (i.e., defective lines).",1939-3520,,10.1109/TSE.2022.3144348,Australian Research Council; Discovery Early Career Researcher Award(grant numbers:DE200100941); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689967,Software quality assurance;line-level defect prediction;deep learning;explainable AI,Codes;Software;Inspection;Social networking (online);Deep learning;Predictive models;Semantics,,45,,80,IEEE,21 Jan 2022,,,IEEE,IEEE Journals,True
MASTER: Multi-Source Transfer Weighted Ensemble Learning for Multiple Sources Cross-Project Defect Prediction,H. Tong; D. Zhang; J. Liu; W. Xing; L. Lu; W. Lu; Y. Wu,"School of Software Engineering, Beijing Jiaotong University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China; School of Software Engineering, Beijing Jiaotong University, Beijing, China; School of Reliability and Systems Engineering, Beihang University, Beijing, China",IEEE Transactions on Software Engineering,15 May 2024,2024,50,5,1281,1305,"Multi-source cross-project defect prediction (MSCPDP) attempts to transfer defect knowledge learned from multiple source projects to the target project. MSCPDP has drawn increasing attention from academic and industry communities owing to its advantages compared with single-source cross-project defect prediction (SSCPDP). However, two main problems, which are how to effectively extract the transferable knowledge from each source dataset and how to measure the amount of knowledge transferred from each source dataset to the target dataset, seriously restrict the performance of existing MSCPDP models. In this paper, we propose a novel multi-source transfer weighted ensemble learning (MASTER) method for MSCPDP. MASTER measures the weight of each source dataset based on feature importance and distribution difference and then extracts the transferable knowledge based on the proposed feature-weighted transfer learning algorithm. Experiments are performed on 30 software projects. We compare MASTER with the latest state-of-the-art MSCPDP methods with statistical test in terms of famous effort-unaware measures (i.e., PD, PF, AUC, and MCC) and two widely used effort-aware measures ($P_{opt}20\%$Popt20% and IFA). The experiment results show that: 1) MASTER can substantially improve the prediction performance compared with the baselines, e.g., an improvement of at least 49.1% in MCC, 48.1% in IFA; 2) MASTER significantly outperforms each baseline on most datasets in terms of AUC, MCC, $P_{opt}20\%$Popt20% and IFA; 3) MSCPDP model significantly performs better than the mean case of SSCPDP model on most datasets and even outperforms the best case of SSCPDP on some datasets. It can be concluded that 1) it is very necessary to conduct MSCPDP, and 2) the proposed MASTER is a more promising alternative for MSCPDP.",1939-3520,,10.1109/TSE.2024.3381235,Fundamental Research Funds for the Central Universities(grant numbers:2023JBMC003); National Key Research and Development Program of China(grant numbers:2021YFB2900704); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10479078,Multiple source datasets;cross-project defect prediction;software defect proneness;feature weighting;transfer learning,Predictive models;Training;Weight measurement;Feature extraction;Software;Genetic algorithms;Ensemble learning,,,,65,IEEE,25 Mar 2024,,,IEEE,IEEE Journals,True
Accelerating Finite State Machine-Based Testing Using Reinforcement Learning,U. C. Türker; R. M. Hierons; K. El-Fakih; M. R. Mousavi; I. Y. Tyukin,"School of Computing and Communications, Lancaster University, Lancaster, U.K.; Department of Computer Science, The University of Sheffield, Sheffield, U.K.; Department of Computer Science and Engineering, American University of Sharjah, University City, UAE; Department of Informatics, King’s College London, London, U.K.; Department of Mathematics, King’s College London, London, U.K.",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,574,597,"Testing is a crucial phase in the development of complex systems, and this has led to interest in automated test generation techniques based on state-based models. Many approaches use models that are types of finite state machine (FSM). Corresponding test generation algorithms typically require that certain test components, such as reset sequences (RSs) and preset distinguishing sequences (PDSs), have been produced for the FSM specification. Unfortunately, the generation of RSs and PDSs is computationally expensive, and this affects the scalability of such FSM-based test generation algorithms. This paper addresses this scalability problem by introducing a reinforcement learning framework: the $\mathcal{Q}$Q-Graph framework for MBT. We show how this framework can be used in the generation of RSs and PDSs and consider both (potentially partial) timed and untimed models. The proposed approach was evaluated using three types of FSMs: randomly generated FSMs, FSMs from a benchmark, and an FSM of an Engine Status Manager for a printer. In experiments, the proposed approach was much faster and used much less memory than the state-of-the-art methods in computing PDSs and RSs.",1939-3520,,10.1109/TSE.2024.3358416,"UKRI Trustworthy Autonomous Systems Node in Verifiability(grant numbers:EP/V026801/2); EPSRC: RoboTest: Systematic Model-Based Testing and Simulation of Mobile Autonomous Robots(grant numbers:EP/R025134/1); Security Lancaster(grant numbers:IRL1032 Poison Attack Mitigation); AUS(grant numbers:FRG23-R-E39); EPSRC project on Verified Simulation for Large Quantum Systems (VSL-Q)(grant numbers:EP/Y005244/1); EPSRC project on Robust and Reliable Quantum Computing (RoaRQ), Investigation 009 Model-based monitoring and calibration of quantum computations (ModeMCQ)(grant numbers:EP/W032635/1); King’s College London(grant numbers:King’s Quantum); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414288,Finite state machines;reset sequences;state identification sequences;reinforcement learning;Q-value function;software engineering/software/program verification;software engineering/test design;software engineering/testing and debugging,Test pattern generators;Scalability;Graphics processing units;Automata;Software systems;Engines;Real-time systems,,,,86,IEEE,25 Jan 2024,,,IEEE,IEEE Journals,True
Understanding Newcomers’ Onboarding Process in Deep Learning Projects,J. Han; J. Zhang; D. Lo; X. Xia; S. Deng; M. Wu,"School of Computer & Computing Science, Hangzhou City University, Hangzhou, China; Alibaba Group, Hangzhou, China; School of Computing and Information Systems, Singapore Management University, Singapore; Software Engineering Application Technology Lab, Huawei, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Computer & Computing Science, Hangzhou City University, Hangzhou, China",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,443,460,"Attracting and retaining newcomers are critical for the sustainable development of Open Source Software (OSS) projects. Considerable efforts have been made to help newcomers identify and overcome barriers in the onboarding process. However, fewer studies focus on newcomers’ activities before their successful onboarding. Given the rising popularity of deep learning (DL) techniques, we wonder what the onboarding process of DL newcomers is, and if there exist commonalities or differences in the onboarding process for DL and non-DL newcomers. Therefore, we reported a study to understand the growth trends of DL and non-DL newcomers, mine DL and non-DL newcomers’ activities before their successful onboarding (i.e., past activities), and explore the relationships between newcomers’ past activities and their first commit patterns and retention rates. By analyzing 20 DL projects with 9,191 contributors and 20 non-DL projects with 9,839 contributors, and conducting email surveys with contributors, we derived the following findings: 1) DL projects have attracted and retained more newcomers than non-DL projects. 2) Compared to non-DL newcomers, DL newcomers encounter more deployment, documentation, and version issues before their successful onboarding. 3) DL newcomers statistically require more time to successfully onboard compared to non-DL newcomers, and DL newcomers with more past activities (e.g., issues, issue comments, and watch) are prone to submit an intensive first commit (i.e., a commit with many source code and documentation files being modified). Based on the findings, we shed light on the onboarding process for DL and non-DL newcomers, highlight future research directions, and provide practical suggestions to newcomers, researchers, and projects.",1939-3520,,10.1109/TSE.2024.3353297,"Zhejiang Provincial Natural Science Foundation of China(grant numbers:LQ24F020019); Scientific Research Project of Zhejiang Provincial Education Department(grant numbers:Y202351453,FX2023067); National Natural Science Foundation of China(grant numbers:U20A20173,62202133); Supercomputing Center of Hangzhou City University; Ministry of Education, Singapore under its Academic Research Fund Tier 3(grant numbers:MOET32020-0004); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398589,Deep learning projects;newcomer onboarding;open source software,Market research;Deep learning;Documentation;Software development management;Libraries;Open source software;Tutorials,,,,77,IEEE,12 Jan 2024,,,IEEE,IEEE Journals,True
On the Value of Oversampling for Deep Learning in Software Defect Prediction,R. Yedida; T. Menzies,"Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",IEEE Transactions on Software Engineering,16 Aug 2022,2022,48,8,3103,3116,"One truism of deep learning is that the automatic feature engineering (seen in the first layers of those networks) excuses data scientists from performing tedious manual feature engineering prior to running DL. For the specific case of deep learning for defect prediction, we show that that truism is false. Specifically, when we pre-process data with a novel oversampling technique called fuzzy sampling, as part of a larger pipeline called GHOST (Goal-oriented Hyper-parameter Optimization for Scalable Training), then we can do significantly better than the prior DL state of the art in 14/20 defect data sets. Our approach yields state-of-the-art results significantly faster deep learners. These results present a cogent case for the use of oversampling prior to applying deep learning on software defect prediction datasets.",1939-3520,,10.1109/TSE.2021.3079841,National Science Foundation(grant numbers:CCF #1703487); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429914,Defect prediction;oversampling;class imbalance;neural networks,Deep learning;Tuning;Predictive models;Standards;Prediction algorithms;Training;Tools,,26,,64,IEEE,12 May 2021,,,IEEE,IEEE Journals,True
"Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression Against Heterogeneous Attacks Toward AI Software Deployment",J. Zhu; L. Wang; X. Han; A. Liu; T. Xie,"Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, Beijing, China; Shanghai University of Finance and Economics, Shanghai, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, Beijing, China",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,376,390,"The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynamic sparse training paradigm. Then, considering two kinds of representative and heterogeneous attack mechanisms, i.e., black-box membership inference attack and white-box membership inference attack, we develop two concrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we implement another instance called MMIA-SafeCompress by extending SafeCompress to defend against the occasion when adversaries conduct black-box and white-box membership inference attacks simultaneously. We conduct extensive experiments on five datasets for both computer vision and natural language processing tasks. The results show the effectiveness and generalizability of our framework. We also discuss how to adapt SafeCompress to other attacks besides membership inference attack, demonstrating the flexibility of SafeCompress.",1939-3520,,10.1109/TSE.2023.3348515,"NSFC(grant numbers:61972008,72031001,72071125,62161146003); Tencent Foundation/XPLORER PRIZE; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10378737,AI software safe compression;test-driven development;heterogeneous membership inference attack,Artificial intelligence;Training;Safety;Computational modeling;Task analysis;Glass box;Artificial neural networks,,1,,76,IEEE,1 Jan 2024,,,IEEE,IEEE Journals,True
Isolating Compiler Bugs by Generating Effective Witness Programs With Large Language Models,H. Tu; Z. Zhou; H. Jiang; I. N. B. Yusuf; Y. Li; L. Jiang,"School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore",IEEE Transactions on Software Engineering,17 Jul 2024,2024,50,7,1768,1788,"Compiler bugs pose a significant threat to safety-critical applications, and promptly as well as effectively isolating these bugs is crucial for assuring the quality of compilers. However, the limited availability of debugging information on reported bugs complicates the compiler bug isolation task. Existing compiler bug isolation approaches convert the problem into a test program mutation problem, but they are still limited by ineffective mutation strategies or high human effort requirements. Drawing inspiration from the recent progress of pre-trained Large Language Models (LLMs), such as ChatGPT, in code generation, we propose a new approach named LLM4CBI to utilize LLMs to generate effective test programs for compiler bug isolation. However, using LLMs directly for test program mutation may not yield the desired results due to the challenges associated with formulating precise prompts and selecting specialized prompts. To overcome the challenges, three new components are designed in LLM4CBI. First, LLM4CBI utilizes a program complexity-guided prompt production component, which leverages data and control flow analysis to identify the most valuable variables and locations in programs for mutation. Second, LLM4CBI employs a memorized prompt selection component, which adopts reinforcement learning to select specialized prompts for mutating test programs continuously. Third, a test program validation component is proposed to select specialized feedback prompts to avoid repeating the same mistakes during the mutation process. Compared with the state-of-the-art approaches (DiWi and RecBi) over 120 real bugs from the two most popular compilers, namely GCC and LLVM, our evaluation demonstrates the advantages of LLM4CBI: It can isolate 69.70%/21.74% and 24.44%/8.92% more bugs than DiWi and RecBi within Top-1/Top-5 ranked results. Additionally, we demonstrate that the LLMs component (i.e., GPT-3.5) used in LLM4CBI can be easily replaced by other LLMs while still achieving reasonable results in comparison to related studies.",1939-3520,,10.1109/TSE.2024.3397822,"National Natural Science Foundation of China(grant numbers:62032004,62302077); China Postdoctoral Science Foundation(grant numbers:2023M730472); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10521881,Software debugging;bug isolation;compilers;GCC;LLVM;reinforcement learning;large language models (LLMs),Computer bugs;Program processors;Task analysis;Codes;Reinforcement learning;Production;Mathematical models,,,,89,IEEE,7 May 2024,,,IEEE,IEEE Journals,True
Mitigating Noise in Quantum Software Testing Using Machine Learning,A. Muqeet; T. Yue; S. Ali; P. Arcaini,"Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; National Institute of Informatics, Tokyo, Japan",IEEE Transactions on Software Engineering,13 Nov 2024,2024,50,11,2947,2961,"Quantum Computing (QC) promises computational speedup over classic computing. However, noise exists in near-term quantum computers. Quantum software testing (for gaining confidence in quantum software's correctness) is inevitably impacted by noise, i.e., it is impossible to know if a test case failed due to noise or real faults. Existing testing techniques test quantum programs without considering noise, i.e., by executing tests on ideal quantum computer simulators. Consequently, they are not directly applicable to test quantum software on real quantum computers or noisy simulators. Thus, we propose a noise-aware approach (named $\mathit{QOIN}$QOIN) to alleviate the noise effect on test results of quantum programs. $\mathit{QOIN}$QOIN employs machine learning techniques (e.g., transfer learning) to learn the noise effect of a quantum computer and filter it from a program's outputs. Such filtered outputs are then used as the input to perform test case assessments (determining the passing or failing of a test case execution against a test oracle). We evaluated $\mathit{QOIN}$QOIN on IBM's 23 noise models, Google's two available noise models, and Rigetti's Quantum Virtual Machine, with six real-world and 800 artificial programs. We also generated faulty versions of these programs to check if a failing test case execution can be determined under noise. Results show that $\mathit{QOIN}$QOIN can reduce the noise effect by more than $80\%$80% on most noise models. We used an existing test oracle to evaluate $\mathit{QOIN}$QOIN's effectiveness in quantum software testing. The results showed that $\mathit{QOIN}$QOIN attained scores of $99\%$99%, $75\%$75%, and $86\%$86% for precision, recall, and F1-score, respectively, for the test oracle across six real-world programs. For artificial programs, $\mathit{QOIN}$QOIN achieved scores of $93\%$93%, $79\%$79%, and $86\%$86% for precision, recall, and F1-score respectively. This highlights $\mathit{QOIN}$QOIN's effectiveness in learning noise patterns for noise-aware quantum software testing.",1939-3520,,10.1109/TSE.2024.3462974,"Research Council of Norway(grant numbers:299827); Oslo Metropolitan University’s Quantum Hub and Simula’s internal strategic project on quantum software engineering; ERATO HASUO Metamathematics for Systems Design Project(grant numbers:JPMJER1603,JST); Engineerable AI Techniques for Practical Applications of High-Quality Machine Learning-based Systems Project(grant numbers:JPMJMI20B8,JST-Mirai); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10682972,Software testing and debugging;computing methodologies;quantum computing;and machine learning,Noise;Quantum computing;Qubit;Computers;Software testing;Logic gates;Computational modeling,,,,64,IEEE,18 Sep 2024,,,IEEE,IEEE Journals,True
"DexBERT: Effective, Task-Agnostic and Fine-Grained Representation Learning of Android Bytecode",T. Sun; K. Allix; K. Kim; X. Zhou; D. Kim; D. Lo; T. F. Bissyandé; J. Klein,"University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; Singapore Management University, Singapore; Singapore Management University, Singapore; Kyungpook National University, Daegu, Republic of Korea; Singapore Management University, Singapore; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg",IEEE Transactions on Software Engineering,18 Oct 2023,2023,49,10,4691,4706,"The automation of an increasingly large number of software engineering tasks is becoming possible thanks to Machine Learning (ML). One foundational building block in the application of ML to software artifacts is the representation of these artifacts (e.g., source code or executable code) into a form that is suitable for learning. Traditionally, researchers and practitioners have relied on manually selected features, based on expert knowledge, for the task at hand. Such knowledge is sometimes imprecise and generally incomplete. To overcome this limitation, many studies have leveraged representation learning, delegating to ML itself the job of automatically devising suitable representations and selections of the most relevant features. Yet, in the context of Android problems, existing models are either limited to coarse-grained whole-app level (e.g., apk2vec) or conducted for one specific downstream task (e.g., smali2vec). Thus, the produced representation may turn out to be unsuitable for fine-grained tasks or cannot generalize beyond the task that they have been trained on. Our work is part of a new line of research that investigates effective, task-agnostic, and fine-grained universal representations of bytecode to mitigate both of these two limitations. Such representations aim to capture information relevant to various low-level downstream tasks (e.g., at the class-level). We are inspired by the field of Natural Language Processing, where the problem of universal representation was addressed by building Universal Language Models, such as BERT, whose goal is to capture abstract semantic information about sentences, in a way that is reusable for a variety of tasks. We propose DexBERT, a BERT-like Language Model dedicated to representing chunks of DEX bytecode, the main binary format used in Android applications. We empirically assess whether DexBERT is able to model the DEX language and evaluate the suitability of our model in three distinct class-level software engineering tasks: Malicious Code Localization, Defect Prediction, and Component Type Classification. We also experiment with strategies to deal with the problem of catering to apps having vastly different sizes, and we demonstrate one example of using our technique to investigate what information is relevant to a given task.",1939-3520,,10.1109/TSE.2023.3310874,"Fonds National de la Recherche (FNR), Luxembourg(grant numbers:REPROCESS C21/IS/16344458); National Research Foundation of Korea (NRF); Korea government (MSIT)(grant numbers:2021R1A5A1021944,2021R1I1A3048013); National Cybersecurity Research and Development Programme(grant numbers:NCRP25-P03-NCR-TAU); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10237047,Representation learning;Android app analysis;code representation;malicious code localization;defect prediction,Task analysis;Malware;Predictive models;Codes;Location awareness;Operating systems;Software engineering,,3,,93,CCBY,1 Sep 2023,,,IEEE,IEEE Journals,True
Astraea: Grammar-Based Fairness Testing,E. Soremekun; S. Udeshi; S. Chattopadhyay,"Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore",IEEE Transactions on Software Engineering,9 Dec 2022,2022,48,12,5188,5211,"Software often produces biased outputs. In particular, machine learning (ML) based software is known to produce erroneous predictions when processing discriminatory inputs. Such unfair program behavior can be caused by societal bias. In the last few years, Amazon, Microsoft and Google have provided software services that produce unfair outputs, mostly due to societal bias (e.g., gender or race). In such events, developers are saddled with the task of conducting fairness testing. Fairness testing is challenging; developers are tasked with generating discriminatory inputs that reveal and explain biases. We propose a grammar-based fairness testing approach (called Astraea) which leverages context-free grammars to generate discriminatory inputs that reveal fairness violations in software systems. Using probabilistic grammars, Astraea also provides fault diagnosis by isolating the cause of observed software bias. Astraea’s diagnoses facilitate the improvement of ML fairness. Astraea was evaluated on 18 software systems that provide three major natural language processing (NLP) services. In our evaluation, Astraea generated fairness violations at a rate of about 18%. Astraea generated over 573K discriminatory test cases and found over 102K fairness violations. Furthermore, Astraea improves software fairness by about 76% via model-retraining, on average.",1939-3520,,10.1109/TSE.2022.3141758,"University of Luxembourg, Ezekiel Soremekun; University of Luxembourg(grant numbers:AUDACITY-2019-Laiwyers); OneConnect Financial(grant numbers:RGOCFT2001); Singapore Ministry of Education; MOE(grant numbers:MOE2018-T2-1-098); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678017,software fairness;machine learning;natural language processing;software testing;program debugging,Testing;Grammar;Task analysis;Sentiment analysis;Test pattern generators;Software testing;Software systems,,8,,88,IEEE,11 Jan 2022,,,IEEE,IEEE Journals,True
How do Developers Really Feel About Bug Fixing? Directions for Automatic Program Repair,E. Winter; D. Bowes; S. Counsell; T. Hall; S. Haraldsson; V. Nowack; J. Woodward,"School of Computing and Communications, Lancaster University, Lancaster, U.K.; School of Computing and Communications, Lancaster University, Lancaster, U.K.; Department of Computer Science, Brunel University of London, Uxbridge, U.K.; School of Computing and Communications, Lancaster University, Lancaster, U.K.; Department of Computing Science and Mathematics, University of Stirling, Stirling, U.K.; School of Computing and Communications, Lancaster University, Lancaster, U.K.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1823,1841,"Automatic program repair (APR) is a rapidly advancing field of software engineering that aims to supplement or replace manual bug fixing with an automated tool. For APR to be successfully adopted in industry, it is vital that APR tools respond to developer needs and preferences. However, very little research has considered developers’ general attitudes to APR or developers’ current bug fixing practices (the activity APR aims to replace). This article responds to this gap by reporting on a survey of 386 software developers about their bug finding and fixing practices and experiences, and their instinctive attitudes towards APR. We find that bug finding and fixing is not necessarily as onerous for developers as has often been suggested, being rated as more satisfying than developers’ general work. The fact that developers derive satisfaction and benefit from bug fixing indicates that APR adoption is not as simple as APR replacing an unwanted activity. When it comes to potential APR approaches, we find a strong preference for developers being kept in the loop (for example, choosing between different fixes or validating fixes) as opposed to a fully automated process. This suggests that advances in APR should be careful to consider the agency of the developer, as well as what information is presented to developers alongside fixes. It also indicates that there are key barriers related to trust that would need to be overcome for full scale APR adoption, supported by the fact that even those developers who stated that they were positive about APR listed several caveats and concerns. We find very few statistically significant relationships between particular demographic variables (for example, developer experience, age, education) and key attitudinal variables, suggesting that developers’ instinctive attitudes towards APR are little influenced by experience level but are held widely across the developer community.",1939-3520,,10.1109/TSE.2022.3194188,Engineering and Physical Sciences Research Council(grant numbers:EP/S005730/1); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842369,,Computer bugs;Software;Debugging;Automation;Maintenance engineering;Task analysis;Manuals,,12,,60,CCBY,27 Jul 2022,,,IEEE,IEEE Journals,True
Pots of Gold at the End of the Rainbow: What is Success for Open Source Contributors?,B. Trinkenreich; M. Guizani; I. Wiese; T. Conte; M. Gerosa; A. Sarma; I. Steinmacher,"Northern Arizona University, Flagstaff, AZ, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; Department of Computer Science, Universidade Tecnológica Federal do Paraná (UTFPR), Apucarana, PR, Brazil; Institute of Computing (IComp), Federal University of Amazonas (UFAM), Manaus, AM, Brazil; Northern Arizona University, Flagstaff, AZ, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; Northern Arizona University, Flagstaff, AZ, USA",IEEE Transactions on Software Engineering,18 Oct 2022,2022,48,10,3940,3953,"Success in Open Source Software (OSS) is often perceived as an exclusively code-centric endeavor. This perception can exclude a variety of individuals with a diverse set of skills and backgrounds, in turn helping exacerbate the current diversity & inclusion imbalance in OSS. Because one's perspective of success can affect one's personal, professional, and life choices, to support a diverse class of individuals we must first understand how OSS contributors understand success. Thus far, research has used a uni-dimensional, code-centric lens to define success. In this paper, we challenge this status quo to reveal OSS contributors’ multifaceted definitions of success. We do so through interviews with 27 OSS contributors whose communities recognize them as successful, and a follow-up open survey with 193 OSS contributors. Our study provides nuanced definitions of success perceptions in OSS, which might help devise strategies to attract and retain a diverse set of contributors, helping them attain their unique “pot of gold at the end of the rainbow”.",1939-3520,,10.1109/TSE.2021.3108032,"National Science Foundation(grant numbers:1815486,1815503,1900903,1901031); Conselho Nacional de Desenvolvimento Científico e Tecnológico(grant numbers:313067/2020-1); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524493,Open source software;success;career;qualitative analysis,Interviews;Engineering profession;Data models;Analytical models;Open source software;Gold;Data analysis,,7,,89,IEEE,27 Aug 2021,,,IEEE,IEEE Journals,True
Prevent: An Unsupervised Approach to Predict Software Failures in Production,G. Denaro; R. Heydarov; A. Mohebbi; M. Pezzè,"Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milano, Italy; Faculty of Informatics, USI Università della Svizzera Italiana (USI), Lugano, Switzerland; Faculty of Informatics, USI Università della Svizzera Italiana (USI), Lugano, Switzerland; Faculty of Informatics, USI Università della Svizzera Italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,12 Dec 2023,2023,49,12,5139,5153,"This paper presents Prevent, a fully unsupervised approach to predict and localize failures in distributed enterprise applications. Software failures in production are unavoidable. Predicting failures and locating failing components online are the first steps to proactively manage faults in production. Many techniques predict failures from anomalous combinations of system metrics with supervised, weakly supervised, and semi-supervised learning models. Supervised approaches require large sets of labelled data not commonly available in large enterprise applications, and address failure types that can be either captured with predefined rules or observed while training supervised models. Prevent integrates the core ingredients of unsupervised approaches into a novel fully unsupervised approach to predict failures and localize failing resources. The results of experimenting with Prevent on a commercially-compliant distributed cloud system indicate that Prevent provides more stable, reliable and timely predictions than supervised learning approaches, without requiring the often impractical training with labeled data.",1939-3520,,10.1109/TSE.2023.3327583,Swiss SNF project ASTERIx: Automatic System TEsting of InteRactive software applications(grant numbers:SNF 200021_178742); Italian PRIN project SISMA(grant numbers:PRIN 201752ENYB); Italian PRIN project BigSistah(grant numbers:PRIN 2022EYX28N); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305549,Failure prediction;distributed applications;machine learning,Training;Production;Predictive models;Monitoring;Key performance indicator;Training data;Time measurement,,2,,67,CCBY,2 Nov 2023,,,IEEE,IEEE Journals,True
Deep Learning Based Program Generation From Requirements Text: Are We There Yet?,H. Liu; M. Shen; J. Zhu; N. Niu; G. Li; L. Zhang,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Department of Electrical Engineering and Computer Science, University of Cincinnati, Cincinnati, OH, USA; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, China",IEEE Transactions on Software Engineering,15 Apr 2022,2022,48,4,1268,1289,"To release developers from time-consuming software development, many approaches have been proposed to generate source code automatically according to software requirements. With significant advances in deep learning and natural language processing, deep learning-based approaches are proposed to generate source code from natural language descriptions. The key insight is that given a large corpus of software requirements and their corresponding implementations, advanced deep learning techniques may learn how to translate software requirements into source code that fulfill such requirements. Although such approaches are reported to be highly accurate, they are evaluated on datasets that are rather small, lack of diversity, and significantly different from real-world software requirements. To this end, we build a large scale dataset that is composed of longer requirements as well as validated implementations. We evaluate the state-of-the-art approaches on this new dataset, and the results suggest that their performance on our dataset is significantly lower than that on existing datasets concerning the common metrics, i.e., BLEU. Evaluation results also suggest that the generated programs often contain syntactic and semantical errors, and none of them can pass even a single predefined test case. Further analysis reveals that the state-of-the-art approaches learn little from software requirements, and most of the successfully generated statements are popular statements in the training programs. Based on this finding, we propose a popularity-based approach that always generates the most popular statements in training programs regardless of the input (software requirements). Evaluation results suggest that none of the state-of-the-art approaches can outperform this simple statistics-based approach. As a conclusion, deep learning-based program generation requires significant improvement in the future, and our dataset may serve as a basis for future research in this direction.",1939-3520,,10.1109/TSE.2020.3018481,"National Key Research and Development Program of China(grant numbers:2017YFB1001803); National Natural Science Foundation of China(grant numbers:61772071,61690205); National Science Foundation(grant numbers:CCF-1350487); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173704,Software requirements;code generation;deep learning;data set,Software;Unified modeling language;Object oriented modeling;Syntactics;Tools;DSL;Deep learning,,19,,75,IEEE,21 Aug 2020,,,IEEE,IEEE Journals,True
Evaluating the Impact of Possible Dependencies on Architecture-Level Maintainability,W. Jin; D. Zhong; Y. Cai; R. Kazman; T. Liu,"School of Software Engineering, Xi’an Jiaotong University, Xi’An, Shaanxi, China; Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi’an Jiaotong University, Xi’An, Shaanxi, China; Department of Computer Science, Drexel University, Philadelphia, PA, USA; Department of Information Technology Management, University of Hawaii, Honolulu, HI, USA; Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi’an Jiaotong University, Xi’An, Shaanxi, China",IEEE Transactions on Software Engineering,14 Mar 2023,2023,49,3,1064,1085,"Dependencies among software entities are the foundation for much of the research on software architecture analysis and architecture analysis tools. Dynamically typed languages, such as Python, JavaScript and Ruby, tolerate the lack of explicit type references, making certain dependencies indiscernible by a purely syntactic analysis of source code. We call these possible dependencies, in contrast with the explicit dependencies that are directly manifested in source code. We find that existing architecture analysis tools have not taken possible dependencies into consideration. An important question therefore is: to what extent will these missing possible dependencies impact architecture analysis?To answer this question, we conducted a study of 499 open-source Python projects, employing type inference techniques and type hint practices to discern possible dependencies. We investigated the consequences of possible dependencies in three software maintenance contexts, including capturing co-change relations recorded in revision history, measuring architectural maintainability, and detecting architecture anti-patterns that violate design principles and impact maintainability. Our study revealed that the impact of possible dependencies on architecture-level maintainability is substantial—higher than that of explicit dependencies. Our findings suggest that architecture analysis and tools should take into account, assess, and highlight the impacts of possible dependencies caused by dynamic typing.",1939-3520,,10.1109/TSE.2022.3171288,"National Key R&D Program of China(grant numbers:2018YFB1004500); National Natural Science Foundation of China(grant numbers:62002280,61721002,61833015,61902306); Fundamental Research Funds for the Central Universities; China Postdoctoral Science Foundation(grant numbers:2020M683507,2019TQ0251,2020M673439); Youth Talent Support Plan of Xi’an Association for Science and Technology(grant numbers:095920201303); National Sciences Foundation(grant numbers:1835292,1823177,1817267,1816594); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9765666,Dynamic typing;possible dependency;software architecture;empirical study,Codes;Python;Computer architecture;Syntactics;Java;Software architecture;Annotations,,7,,100,IEEE,29 Apr 2022,,,IEEE,IEEE Journals,True
Evaluating Diverse Large Language Models for Automatic and General Bug Reproduction,S. Kang; J. Yoon; N. Askarbekkyzy; S. Yoo,"Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",IEEE Transactions on Software Engineering,17 Oct 2024,2024,50,10,2677,2694,"Bug reproduction is a critical developer activity that is also challenging to automate, as bug reports are often in natural language and thus can be difficult to transform to test cases consistently. As a result, existing techniques mostly focused on crash bugs, which are easier to automatically detect and verify. In this work, we overcome this limitation by using large language models (LLMs), which have been demonstrated to be adept at natural language processing and code generation. By prompting LLMs to generate bug-reproducing tests, and via a post-processing pipeline to automatically identify promising generated tests, our proposed technique Libro could successfully reproduce about one-third of all bugs in the widely used Defects4J benchmark. Furthermore, our extensive evaluation on 15 LLMs, including 11 open-source LLMs, suggests that open-source LLMs also demonstrate substantial potential, with the StarCoder LLM achieving 70% of the reproduction performance of the closed-source OpenAI LLM code-davinci-002 on the large Defects4J benchmark, and 90% of performance on a held-out bug dataset likely not part of any LLM's training data. In addition, our experiments on LLMs of different sizes show that bug reproduction using Libro improves as LLM size increases, providing information as to which LLMs can be used with the Libro pipeline.",1939-3520,,10.1109/TSE.2024.3450837,National Research Foundation of Korea (NRF)(grant numbers:RS-2023-00208998); Engineering Research Center Program(grant numbers:2021R1A5A1021944); Institute for Information and Communications Technology Promotion(grant numbers:IITP2022-0-00995); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10664637,Test generation;natural language processing;software engineering,Computer bugs;Codes;Pipelines;Large language models;Debugging;Java;Computational modeling,,1,,58,IEEE,4 Sep 2024,,,IEEE,IEEE Journals,True
T-Evos: A Large-Scale Longitudinal Study on CI Test Execution and Failure,A. R. Chen; T. -H. P. Chen; S. Wang,"Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science, University of Manitoba, Winnipeg, MB, Canada",IEEE Transactions on Software Engineering,19 Apr 2023,2023,49,4,2352,2365,"Continuous integration is widely adopted in software projects to reduce the time it takes to deliver the changes to the market. To ensure software quality, developers also run regression test cases in a continuous fashion. The CI practice generates commit-by-commit software evolution data that provides great opportunities for future testing research. However, such data is often unavailable due to space limitation (e.g., developers only keep the data for a certain period) and the significant effort involved in re-running the test cases on a per-commit basis. In this paper, we present T-Evos, a dataset on test result and coverage evolution, covering 8,093 commits across 12 open-source Java projects. Our dataset includes the evolution of statement-level code coverage for every test case (either passed and failed), test result, all the builds information, code changes, and the corresponding bug reports. We conduct an initial analysis to demonstrate the overall dataset. In addition, we conduct an empirical study using T-Evos to study the characteristics of test failures in CI settings. We find that test failures are frequent, and while most failures are resolved within a day, some failures require several weeks to resolve. We highlight the relationship between code changes and test failure, and provide insights for future automated testing research. Our dataset may be used for future testing research and benchmarking in CI. Our findings provide an important first step in understanding code coverage evolution and test failures in a continuous environment.",1939-3520,,10.1109/TSE.2022.3218264,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9933015,Evolution and maintenance;mining software repositories;software testing,Codes;Computer bugs;Benchmark testing;Java;Manuals;Data collection;Software testing,,1,,39,IEEE,31 Oct 2022,,,IEEE,IEEE Journals,True
Local and Global Explainability for Technical Debt Identification,D. Tsoukalas; N. Mittas; E. -M. Arvanitou; A. Ampatzoglou; A. Chatzigeorgiou; D. Kehagias,"Centre for Research and Technology Hellas, Information Technologies Institute, Thessaloniki, Greece; Hephaestus Laboratory, Department of Chemistry, School of Science, Democritus University of Thrace, Kavala, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Centre for Research and Technology Hellas, Information Technologies Institute, Thessaloniki, Greece",IEEE Transactions on Software Engineering,14 Aug 2024,2024,50,8,2110,2123,"In recent years, we have witnessed an important increase in research focusing on how machine learning (ML) techniques can be used for software quality assessment and improvement. However, the derived methodologies and tools lack transparency, due to the black-box nature of the employed machine learning models, leading to decreased trust in their results. To address this shortcoming, in this paper we extend the state-of-the-art and -practice by building explainable AI models on top of machine learning ones, to interpret the factors (i.e. software metrics) that constitute a module as in risk of having high technical debt (HIGH TD), to obtain thresholds for metric scores that are alerting for poor maintainability, and finally, we dig further to achieve local interpretation that explains the specific problems of each module, pinpointing to specific opportunities for improvement during TD management. To achieve this goal, we have developed project-specific classifiers (characterizing modules as HIGH and NOT-HIGH TD) for 21 open-source projects, and we explain their rationale using the SHapley Additive exPlanation (SHAP) analysis. Based on our analysis, complexity, comments ratio, cohesion, nesting of control flow statements, coupling, refactoring activity, and code churn are the most important reasons for characterizing classes as in HIGH TD risk. The analysis is complemented with global and local means of interpretation, such as metric thresholds and case-by-case reasoning for characterizing a class as in-risk of having HIGH TD. The results of the study are compared against the state-of-the-art and are interpreted from the point of view of both researchers and practitioners.",1939-3520,,10.1109/TSE.2024.3422427,European Union’s Horizon 2023(grant numbers:101132663); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10586898,Technical debt;technical debt identification;software quality;software metrics;explainable AI;SHAP,Codes;Software;Software measurement;Complexity theory;Object oriented modeling;Informatics;Feature extraction,,,,54,IEEE,4 Jul 2024,,,IEEE,IEEE Journals,True
Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics,S. Dalla Palma; D. Di Nucci; F. Palomba; D. A. Tamburri,"Jheronimous Academy of Data Science, Tilburg University, Tilburg, The Netherlands; Jheronimous Academy of Data Science, Tilburg University, Tilburg, The Netherlands; Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy; Jheronimous Academy of Data Science, Eindhoven University of Technology, Eindhoven, The Netherlands",IEEE Transactions on Software Engineering,14 Jun 2022,2022,48,6,2086,2104,"Infrastructure-as-code (IaC) is the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files, hereinafter referred to as IaC scripts. Similarly to other source code artefacts, these files may contain defects that can preclude their correct functioning. In this paper, we aim at assessing the role of product and process metrics when predicting defective IaC scripts. We propose a fully integrated machine-learning framework for IaC Defect Prediction, that allows for repository crawling, metrics collection, model building, and evaluation. To evaluate it, we analyzed 104 projects and employed five machine-learning classifiers to compare their performance in flagging suspicious defective IaC scripts. The key results of the study report Random Forest as the best-performing model, with a median AUC-PR of 0.93 and MCC of 0.80. Furthermore, at least for the collected projects, product metrics identify defective IaC scripts more accurately than process metrics. Our findings put a baseline for investigating IaC Defect Prediction and the relationship between the product and process metrics, and IaC scripts’ quality.",1939-3520,,10.1109/TSE.2021.3051492,"European Commission(grant numbers:825040 (RADON H2020),825480 (SODALITE H2020)); Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:PZ00P2 186090); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321740,Infrastructure-as-code;defect prediction;empirical software engineering,Measurement;Software;Predictive models;Machine learning;Radon;Cloud computing;Task analysis,,33,,52,CCBY,13 Jan 2021,,,IEEE,IEEE Journals,True
X-SBR: On the Use of the History of Refactorings for Explainable Search-Based Refactoring and Intelligent Change Operators,C. Abid; D. E. Rzig; T. d. N. Ferreira; M. Kessentini; T. Sharma,"Department of Computer and Information Science, University of Michigan, Dearborn, MI, USA; Department of Computer and Information Science, University of Michigan, Dearborn, MI, USA; Department of Computer and Information Science, University of Michigan, Dearborn, MI, USA; Department of Computer and Information Science, University of Michigan, Dearborn, MI, USA; Siemens Corporate Technology, Charlotte, NC, USA",IEEE Transactions on Software Engineering,18 Oct 2022,2022,48,10,3753,3770,"Refactoring is widely adopted nowadays in industry to restructure the code and meet high quality while preserving the external behavior. Many of the existing refactoring tools and research are based on search-based techniques to find relevant recommendations by finding trade-offs between different quality attributes. While these techniques show promising results on open-source and industry projects, they lack explanations of the recommended changes which can impact their trustworthiness when adopted in practice by developers. Furthermore, most of the adopted search-based techniques are based on random population generation and random change operators (e.g., crossover and mutation). However, it is critical to understand which good refactoring patterns may exist when applying change operators to either keep them or exchange with other solutions rather than destroying them with random changes. In this paper, we propose knowledge-informed change operators and an improved seeding mechanism that we integrated in a multi-objective genetic algorithm. We also provide explanations for refactoring solutions. First, we generate association rules using the Apriori algorithm to find relationships between applied refactorings in previous commits, their locations, and their rationale (quality improvements). Then, we use these rules to 1) initialize the population, 2) improve the change operators and seeding mechanisms of the multi-objective search in order to preserve and exchange good patterns in the refactoring solutions, and 3) explain how a sequence of refactorings collaborate in order to improve the quality of the system (e.g., fitness functions). The validation on large open-source systems shows that X-SBR provides refactoring solutions of a better quality than those given by the state-of-the-art techniques in terms of reducing the invalid refactorings, improving the quality, and increasing trustworthiness of the developers in the suggested refactorings via the provided explanations.",1939-3520,,10.1109/TSE.2021.3105037,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9514445,Refactoring recommendations;search-based software engineering;QMOOD metrics;multi-objective search,Measurement;Statistics;Sociology;Tools;History;Software systems;Software engineering,,7,,68,IEEE,16 Aug 2021,,,IEEE,IEEE Journals,True
Evaluating Automatic Program Repair Capabilities to Repair API Misuses,M. Kechagia; S. Mechtaev; F. Sarro; M. Harman,"Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.",IEEE Transactions on Software Engineering,15 Jul 2022,2022,48,7,2658,2679,"API misuses are well-known causes of software crashes and security vulnerabilities. However, their detection and repair is challenging given that the correct usages of (third-party) apis might be obscure to the developers of client programs. This paper presents the first empirical study to assess the ability of existing automated bug repair tools to repair api misuses, which is a class of bugs previously unexplored. Our study examines and compares 14 Java test-suite-based repair tools (11 proposed before 2018, and three afterwards) on a manually curated benchmark (APIRepBench) consisting of 101 api misuses. We develop an extensible execution framework (APIARTy) to automatically execute multiple repair tools. Our results show that the repair tools are able to generate patches for 28 percent of the api misuses considered. While the 11 less recent tools are generally fast (the median execution time of the repair attempts is 3.87 minutes and the mean execution time is 30.79 minutes), the three most recent are less efficient (i.e., 98 percent slower) than their predecessors. The tools generate patches for api misuses that mostly belong to the categories of missing null check, missing value, missing exception, and missing call. Most of the patches generated by all tools are plausible (65 percent), but only few of these patches are semantically correct to human patches (25 percent). Our findings suggest that the design of future repair tools should support the localisation of complex bugs, including different categories of api misuses, handling of timeout issues, and ability to configure large software projects. Both APIRepBench and APIARTy have been made publicly available for other researchers to evaluate the capabilities of repair tools on detecting and fixing api misuses.",1939-3520,,10.1109/TSE.2021.3067156,ERC Advanced fellowship(grant numbers:741278); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381596,Automatic program repair;Application Programming Interfaces (APIs);API misuses;bug benchmarks,Tools;Maintenance engineering;Computer bugs;Benchmark testing;Software;Java;Security,,20,,84,IEEE,18 Mar 2021,,,IEEE,IEEE Journals,True
LUNA: A Model-Based Universal Analysis Framework for Large Language Models,D. Song; X. Xie; J. Song; D. Zhu; Y. Huang; F. Juefei-Xu; L. Ma,"Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Computer Science, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; New York University, New York, NY, USA; The University of Tokyo, Tokyo, Japan",IEEE Transactions on Software Engineering,17 Jul 2024,2024,50,7,1921,1948,"Over the past decade, Artificial Intelligence (AI) has had great success recently and is being used in a wide range of academic and industrial fields. More recently, Large Language Models (LLMs) have made rapid advancements that have propelled AI to a new level, enabling and empowering even more diverse applications and industrial domains with intelligence, particularly in areas like software engineering and natural language processing. Nevertheless, a number of emerging trustworthiness concerns and issues exhibited in LLMs, e.g., robustness and hallucination, have already recently received much attention, without properly solving which the widespread adoption of LLMs could be greatly hindered in practice. The distinctive characteristics of LLMs, such as the self-attention mechanism, extremely large neural network scale, and autoregressive generation usage contexts, differ from classic AI software based on Convolutional Neural Networks and Recurrent Neural Networks and present new challenges for quality analysis. Up to the present, it still lacks universal and systematic analysis techniques for LLMs despite the urgent industrial demand across diverse domains. Towards bridging such a gap, in this paper, we initiate an early exploratory study and propose a universal analysis framework for LLMs, named LUNA, which is designed to be general and extensible and enables versatile analysis of LLMs from multiple quality perspectives in a human-interpretable manner. In particular, we first leverage the data from desired trustworthiness perspectives to construct an abstract model as an auxiliary analysis asset and proxy, which is empowered by various abstract model construction methods built-in LUNA. To assess the quality of the abstract model, we collect and define a number of evaluation metrics, aiming at both the abstract model level and the semantics level. Then, the semantics, which is the degree of satisfaction of the LLM w.r.t. the trustworthiness perspective, is bound to and enriches the abstract model with semantics, which enables more detailed analysis applications for diverse purposes, e.g., abnormal behavior detection. To better understand the potential usefulness of our analysis framework LUNA, we conduct a large-scale evaluation, the results of which demonstrate that 1) the abstract model has the potential to distinguish normal and abnormal behavior in LLM, 2) LUNA is effective for the real-world analysis of LLMs in practice, and the hyperparameter settings influence the performance, 3) different evaluation metrics are in different correlations with the analysis performance. In order to encourage further studies in the quality assurance of LLMs, we made all of the code and more detailed experimental results data available on the supplementary website of this paper https://sites.google.com/view/llm-luna.",1939-3520,,10.1109/TSE.2024.3411928,"Canada CIFAR AI Chairs Program; Natural Sciences and Engineering Research Council of Canada; JST-Mirai Program(grant numbers:JPMJMI20B8); JSPS KAKENHI(grant numbers:JP21H04877,JP23H03372,JP24K02920); Autoware Foundation; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10562221,Large language models;deep neural networks;model-based analysis;quality assurance,Hidden Markov models;Analytical models;Measurement;Semantics;Codes;Task analysis;Transformers,,,,255,IEEE,18 Jun 2024,,,IEEE,IEEE Journals,True
A Zone-Based Model for Analysis of Dependent Failures in Requirements Inspection,B. Li; C. Smidts,"Department of Mechanical and Aerospace Engineerings, Ohio State University, Columbus, OH, USA; Department of Mechanical and Aerospace Engineerings, Ohio State University, Columbus, OH, USA",IEEE Transactions on Software Engineering,13 Jun 2023,2023,49,6,3581,3598,"In the software development life cycle, the quality of the requirements specification affects the overall quality of the subsequent phases and hence, the software product. The requirements specification is usually inspected by an inspection team to detect defects. To enhance the quality of the requirements specification, one conventional strategy usually used is adding redundancies to the inspection team. However, this strategy suffers from the problem of dependent failures of the redundant inspectors which was not studied systematically in previous research. To analyze the dependent failures and independent failures in an inspection team, this paper first defines the independent failures and dependent failures in an inspection team from the perspective of human errors. Then a quantification model, i.e., the Zone-based Model, is proposed to analyze the dependent and independent failures. The Zone-based Model considers the following situations: 1) the probability of failures of an inspector may be high; 2) the probability of failures of the inspectors may be different; 3) the failures in an inspection team can be a combination of dependent failures and independent failures. By considering all those situations, the Z model has a meaningful interpretation and a convincing assessment of the failures of an inspection team. To verify the effectiveness of the new model, the Zone-based model is compared to conventional models using simulation data. The results show that the Zone-based model is significantly better than the traditional models in analyzing the independent and dependent failures.",1939-3520,,10.1109/TSE.2023.3266157,"U.S. Department of Energy(grant numbers:DE-NE0008434,DE-NE308896); Department of Mechanical and Aerospace Engineering, West Virginia University; Ohio State University; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10102922,Common cause failures;dependent failures;requirements inspection;zone-based model,Inspection;Analytical models;Data models;Software;Estimation;Power system protection;Power system faults,,,,36,IEEE,17 Apr 2023,,,IEEE,IEEE Journals,True
A Data Transfer and Relevant Metrics Matching Based Approach for Heterogeneous Defect Prediction,P. R. Bal; S. Kumar,"Department of Computer Science and Engineering, Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India; Department of Computer Science and Engineering, Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India",IEEE Transactions on Software Engineering,14 Mar 2023,2023,49,3,1232,1245,"Heterogeneous defect prediction (HDP) is a promising research area in the software defect prediction domain to handle the unavailability of the past homogeneous data. In HDP, the prediction is performed using source dataset in which the independent features (metrics) are entirely different than the independent features of target dataset. One important assumption in machine learning is that independent features of the source and target datasets should be relevant to each other for better prediction accuracy. However, these assumptions do not generally hold in HDP. Further in HDP, the selected source dataset for a given target dataset may be of small size causing insufficient training. To resolve these issues, we have proposed a novel heterogeneous data preprocessing method, namely, Transfer of Data from Target dataset to Source dataset selected using Relevance score (TDTSR), for heterogeneous defect prediction. In the proposed approach, we have used chi-square test to select the relevant metrics between source and target datasets and have performed experiments using proposed approach with various machine learning algorithms. Our proposed method shows an improvement of at least 14% in terms of AUC score in the HDP scenario compared to the existing state of the art models.",1939-3520,,10.1109/TSE.2022.3173678,Ministry of Human Resource Development; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772411,Heterogeneous defect prediction;heterogeneous metrics;chi square test;random forest;relevant metrics,Measurement;Software;Data models;Predictive models;Kernel;Correlation;Transfer learning,,2,,36,IEEE,10 May 2022,,,IEEE,IEEE Journals,True
Predicting the First Response Latency of Maintainers and Contributors in Pull Requests,S. Khatoonabadi; A. Abdellatif; D. E. Costa; E. Shihab,"Department of Computer Science & Software Engineering, Concordia University, Montreal, QC, Canada; Department of Electrical & Software Engineering, University of Calgary, Calgary, AB, Canada; Department of Computer Science & Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science & Software Engineering, Concordia University, Montreal, QC, Canada",IEEE Transactions on Software Engineering,17 Oct 2024,2024,50,10,2529,2543,"The success of a Pull Request (PR) depends on the responsiveness of the maintainers and the contributor during the review process. Being aware of the expected waiting times can lead to better interactions and managed expectations for both the maintainers and the contributor. In this paper, we propose a machine-learning approach to predict the first response latency of the maintainers following the submission of a PR, and the first response latency of the contributor after receiving the first response from the maintainers. We curate a dataset of 20 large and popular open-source projects on GitHub and extract 21 features to characterize projects, contributors, PRs, and review processes. Using these features, we then evaluate seven types of classifiers to identify the best-performing models. We also conduct permutation feature importance and SHAP analyses to understand the importance and the impact of different features on the predicted response latencies. We find that our CatBoost models are the most effective for predicting the first response latencies of both maintainers and contributors. Compared to a dummy classifier that always returns the majority class, these models achieved an average improvement of 29% in AUC-ROC and 51% in AUC-PR for maintainers, as well as 39% in AUC-ROC and 89% in AUC-PR for contributors across the studied projects. The results indicate that our models can aptly predict the first response latencies using the selected features. We also observe that PRs submitted earlier in the week, containing an average number of commits, and with concise descriptions are more likely to receive faster first responses from the maintainers. Similarly, PRs with a lower first response latency from maintainers, that received the first response of maintainers earlier in the week, and containing an average number of commits tend to receive faster first responses from the contributors. Additionally, contributors with a higher acceptance rate and a history of timely responses in the project are likely to both obtain and provide faster first responses. Moreover, we show the effectiveness of our approach in a cross-project setting. Finally, we discuss key guidelines for maintainers, contributors, and researchers to help facilitate the PR review process.",1939-3520,,10.1109/TSE.2024.3443741,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10636098,Pull request abandonment;pull-based development;modern code review;social coding;open source software,Reviews;Predictive models;Feature extraction;Software development management;History;Time measurement;Machine learning,,,,78,IEEE,13 Aug 2024,,,IEEE,IEEE Journals,True
LIVABLE: Exploring Long-Tailed Classification of Software Vulnerability Types,X. -C. Wen; C. Gao; F. Luo; H. Wang; G. Li; Q. Liao,"Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Huazhong University of Science and Technology, Wuhan, China; Peking University, Beijing, China; Harbin Institute of Technology, Shenzhen, China",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1325,1339,"Prior studies generally focus on software vulnerability detection and have demonstrated the effectiveness of Graph Neural Network (GNN)-based approaches for the task. Considering the various types of software vulnerabilities and the associated different degrees of severity, it is also beneficial to determine the type of each vulnerable code for developers. In this paper, we observe that the distribution of vulnerability type is long-tailed in practice, where a small portion of classes have massive samples (i.e., head classes) but the others contain only a few samples (i.e., tail classes). Directly adopting previous vulnerability detection approaches tends to result in poor detection performance, mainly due to two reasons. First, it is difficult to effectively learn the vulnerability representation due to the over-smoothing issue of GNNs. Second, vulnerability types in tails are hard to be predicted due to the extremely few associated samples. To alleviate these issues, we propose a Long-taIled software VulnerABiLity typE classification approach, called LIVABLE. LIVABLE mainly consists of two modules, including (1) vulnerability representation learning module, which improves the propagation steps in GNN to distinguish node representations by a differentiated propagation method. A sequence-to-sequence model is also involved to enhance the vulnerability representations. (2) adaptive re-weighting module, which adjusts the learning weights for different types according to the training epochs and numbers of associated samples by a novel training loss. We verify the effectiveness of LIVABLE in both type classification and vulnerability detection tasks. For vulnerability type classification, the experiments on the Fan et al. dataset show that LIVABLE outperforms the state-of-the-art methods by 24.18% in terms of the accuracy metric, and also improves the performance in predicting tail classes by 7.7%. To evaluate the efficacy of the vulnerability representation learning module in LIVABLE, we further compare it with the recent vulnerability detection approaches on three benchmark datasets, which shows that the proposed representation learning module improves the best baselines by 4.03% on average in terms of accuracy.",1939-3520,,10.1109/TSE.2024.3382361,"National Key R & D Program of China(grant numbers:2022YFB3103900); Natural Science Foundation of Guangdong Province(grant numbers:2023A1515011959); Shenzhen-Hong Kong Jointly Funded Project(grant numbers:SGDX20230116091246007); Shenzhen Basic Research(grant numbers:JCYJ20220531095214031); Shenzhen International Science and Technology Cooperation Project(grant numbers:GJHZ20220913143008015); Major Key Project of PCL(grant numbers:PCL2022A03); National Natural Science Foundation of China(grant numbers:62072007,62192733,61832009,62192731,62192730); Key Program of Hubei(grant numbers:JD2023008); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10497542,Software vulnerability;deep learning;graph neural network,Tail;Codes;Software;Representation learning;Training;Source coding;Graph neural networks,,,,67,IEEE,11 Apr 2024,,,IEEE,IEEE Journals,True
NLP-Based Automated Compliance Checking of Data Processing Agreements Against GDPR,O. A. Cejas; M. I. Azeem; S. Abualhaija; L. C. Briand,"SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Software Engineering,19 Sep 2023,2023,49,9,4282,4303,"When the entity processing personal data (the processor) differs from the one collecting personal data (the controller), processing personal data is regulated in Europe by the General Data Protection Regulation (GDPR) through data processing agreements (DPAs). Checking the compliance of DPAs contributes to the compliance verification of software systems as DPAs are an important source of requirements for software development involving the processing of personal data. However, manually checking whether a given DPA complies with GDPR is challenging as it requires significant time and effort for understanding and identifying DPA-relevant compliance requirements in GDPR and then verifying these requirements in the DPA. Legal texts introduce additional complexity due to convoluted language and inherent ambiguity leading to potential misunderstandings. In this paper, we propose an automated solution to check the compliance of a given DPA against GDPR. In close interaction with legal experts, we first built two artifacts: (i) the “shall” requirements extracted from the GDPR provisions relevant to DPA compliance and (ii) a glossary table defining the legal concepts in the requirements. Then, we developed an automated solution that leverages natural language processing (NLP) technologies to check the compliance of a given DPA against these “shall” requirements. Specifically, our approach automatically generates phrasal-level representations for the textual content of the DPA and compares them against predefined representations of the “shall” requirements. By comparing these two representations, the approach not only assesses whether the DPA is GDPR compliant but it further provides recommendations about missing information in the DPA. Over a dataset of 30 actual DPAs, the approach correctly finds 618 out of 750 genuine violations while raising 76 false violations, and further correctly identifies 524 satisfied requirements. The approach has thus an average precision of 89.1%, a recall of 82.4%, and an accuracy of 84.6%. Compared to a baseline that relies on off-the-shelf NLP tools, our approach provides an average accuracy gain of $\approx$≈20 percentage points. The accuracy of our approach can be improved to $\approx$≈94% with limited manual verification effort.",1939-3520,,10.1109/TSE.2023.3288901,"Linklaters, Luxembourg's National Research Fund(grant numbers:BRIDGES/19/IS/13759068/ARTAGO); NSERC of Canada; Discovery and CRC programs; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10167495,Requirements engineering (RE);the general data protection regulation (GDPR);regulatory compliance;natural language processing (NLP);data processing agreement (DPA);privacy,Process control;General Data Protection Regulation;Companies;Data processing;Data breach;Standards organizations;Software systems,,8,,117,CCBY,27 Jun 2023,,,IEEE,IEEE Journals,True
Robust Test Selection for Deep Neural Networks,W. Sun; M. Yan; Z. Liu; D. Lo,"School of Big Data and Software Engineering, Chongqing University, Chongqing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China; College of Computer Science and Technology and Ningbo Research Institute, Zhejiang University, Hangzhou, Zhejiang, China; School of Information Systems, Singapore Management University, Singapore",IEEE Transactions on Software Engineering,12 Dec 2023,2023,49,12,5250,5278,"Deep Neural Networks (DNNs) have been widely used in various domains, such as computer vision and software engineering. Although many DNNs have been deployed to assist various tasks in the real world, similar to traditional software, they also suffer from defects that may lead to severe outcomes. DNN testing is one of the most widely used methods to ensure the quality of DNNs. Such method needs rich test inputs with oracle information (expected output) to reveal the incorrect behaviors of a DNN model. However, manually labeling all the collected test inputs is a labor-intensive task, which delays the quality assurance process. Test selection tackles this problem by carefully selecting a small, more suspicious set of test inputs to label, enabling the failure detection of a DNN model with reduced effort. Researchers have proposed different test selection methods, including neuron-coverage-based and uncertainty-based methods, where the uncertainty-based method is arguably the most popular technique. Unfortunately, existing uncertainty-based selection methods meet the performance bottleneck due to one or several limitations: 1) they ignore noisy data in real scenarios; 2) they wrongly exclude many failure-revealing test inputs but rather include many successful test inputs (referring to those test inputs that are correctly predicted by the model); 3) they ignore the diversity of the selected test set. In this paper, we propose RTS, a Robust Test Selection method for deep neural networks to overcome the limitations mentioned above. First, RTS divides all unlabeled candidate test inputs into noise set, successful set, and suspicious set and assigns different selection prioritization to divided sets, which effectively alleviates the impact of noise and improves the ability to identify suspect test inputs. Subsequently, RTS leverages a probability-tier-matrix-based test metric for prioritizing the test inputs in each divided set (i.e., suspicious, successful, and noise set). As a result, RTS can select more suspicious test inputs within a limited selection size. We evaluate RTS by comparing it with 14 baseline methods under 5 widely-used DNN models and 6 widely-used datasets. The experimental results demonstrate that RTS can significantly outperform all test selection methods in failure detection capability and the test suites selected by RTS have the best model optimization capability. For example, when selecting 2.5% test input, RTS achieves an improvement of 9.37%-176.75% over baseline methods in terms of failure detection.",1939-3520,,10.1109/TSE.2023.3330982,"National Key Research and Development Project(grant numbers:2021YFB1714200); National Natural Science Foundation of China(grant numbers:62372071); Fundamental Research Funds for the Central Universities(grant numbers:2022CDJDX-005); Chongqing Technology Innovation and Application Development Project(grant numbers:CSTB2022TIADSTX0007,CSTB2022TIAD-KPX0067); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10319282,Deep learning testing;deep neural networks;test selection,Testing;Artificial neural networks;Neurons;Data models;Noise measurement;Labeling;Task analysis,,3,,97,IEEE,15 Nov 2023,,,IEEE,IEEE Journals,True
VulExplainer: A Transformer-Based Hierarchical Distillation for Explaining Vulnerability Types,M. Fu; V. Nguyen; C. K. Tantithamthavorn; T. Le; D. Phung,"Faculty of Information Technology, Monash University, Melbourne, Australia; Faculty of Information Technology, Monash University, Melbourne, Australia; Faculty of Information Technology, Monash University, Melbourne, Australia; Faculty of Information Technology, Monash University, Melbourne, Australia; Faculty of Information Technology, Monash University, Melbourne, Australia",IEEE Transactions on Software Engineering,17 Oct 2023,2023,49,10,4550,4565,"Deep learning-based vulnerability prediction approaches are proposed to help under-resourced security practitioners to detect vulnerable functions. However, security practitioners still do not know what type of vulnerabilities correspond to a given prediction (aka CWE-ID). Thus, a novel approach to explain the type of vulnerabilities for a given prediction is imperative. In this paper, we propose VulExplainer, an approach to explain the type of vulnerabilities. We represent VulExplainer as a vulnerability classification task. However, vulnerabilities have diverse characteristics (i.e., CWE-IDs) and the number of labeled samples in each CWE-ID is highly imbalanced (known as a highly imbalanced multi-class classification problem), which often lead to inaccurate predictions. Thus, we introduce a Transformer-based hierarchical distillation for software vulnerability classification in order to address the highly imbalanced types of software vulnerabilities. Specifically, we split a complex label distribution into sub-distributions based on CWE abstract types (i.e., categorizations that group similar CWE-IDs). Thus, similar CWE-IDs can be grouped and each group will have a more balanced label distribution. We learn TextCNN teachers on each of the simplified distributions respectively, however, they only perform well in their group. Thus, we build a transformer student model to generalize the performance of TextCNN teachers through our hierarchical knowledge distillation framework. Through an extensive evaluation using the real-world 8,636 vulnerabilities, our approach outperforms all of the baselines by 5%–29%. The results also demonstrate that our approach can be applied to Transformer-based architectures such as CodeBERT, GraphCodeBERT, and CodeGPT. Moreover, our method maintains compatibility with any Transformer-based model without requiring any architectural modifications but only adds a special distillation token to the input. These results highlight our significant contributions towards the fundamental and practical problem of explaining software vulnerability.",1939-3520,,10.1109/TSE.2023.3305244,ARC(grant numbers:DE200100941); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10220166,Software vulnerability;software security,Software;Transformers;Security;Static VAr compensators;Data models;Codes;Task analysis,,10,,82,IEEE,16 Aug 2023,,,IEEE,IEEE Journals,True
An Empirical Study on the Usage of Transformer Models for Code Completion,M. Ciniselli; N. Cooper; L. Pascarella; A. Mastropaolo; E. Aghajani; D. Poshyvanyk; M. Di Penta; G. Bavota,"SEART @ Software Institute, Università della Svizzera italiana, Lugano, Switzerland; SEMERU @ William & Mary, Williamsburg, VA, USA; SEART @ Software Institute, Università della Svizzera italiana, Lugano, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Lugano, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Lugano, Switzerland; SEMERU @ William & Mary, Williamsburg, VA, USA; University of Sannio, Benevento, BN, Italy; SEART @ Software Institute, Università della Svizzera italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,9 Dec 2022,2022,48,12,4818,4837,"Code completion aims at speeding up code writing by predicting the next code token(s) the developer is likely to write. Works in this field focused on improving the accuracy of the generated predictions, with substantial leaps forward made possible by deep learning (DL) models. However, code completion techniques are mostly evaluated in the scenario of predicting the next token to type, with few exceptions pushing the boundaries to the prediction of an entire code statement. Thus, little is known about the performance of state-of-the-art code completion approaches in more challenging scenarios in which, for example, an entire code block must be generated. We present a large-scale study exploring the capabilities of state-of-the-art Transformer-based models in supporting code completion at different granularity levels, including single tokens, one or multiple entire statements, up to entire code blocks (e.g., the iterated block of a for loop). We experimented with several variants of two recently proposed Transformer-based models, namely RoBERTa and the Text-To-Text Transfer Transformer (T5), for the task of code completion. The achieved results show that Transformer-based models, and in particular the T5, represent a viable solution for code completion, with perfect predictions ranging from $\sim$∼29%, obtained when asking the model to guess entire blocks, up to $\sim$∼69%, reached in the simpler scenario of few tokens masked from the same code statement.",1939-3520,,10.1109/TSE.2021.3128234,"European Research Council; European Union's Horizon 2020 Research and Innovation Programme(grant numbers:851720); National Science Foundation(grant numbers:CCF-1955853,CCF-2007246); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616462,Code completion;deep learning;empirical software engineering,Codes;Task analysis;Predictive models;Transformers;Data models;Context modeling;Training,,37,,88,IEEE,16 Nov 2021,,,IEEE,IEEE Journals,True
Restore: Retrospective Fault Localization Enhancing Automated Program Repair,T. Xu; L. Chen; Y. Pei; T. Zhang; M. Pan; C. A. Furia,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Software Institute, Nanjing University, Nanjing, Jiangsu, China; Software Institute of USI Università della Svizzera italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,10 Jan 2022,2022,48,1,309,326,"Fault localization is a crucial step of automated program repair, because accurately identifying program locations that are most closely implicated with a fault greatly affects the effectiveness of the patching process. An ideal fault localization technique would provide precise information while requiring moderate computational resources—to best support an efficient search for correct fixes. In contrast, most automated program repair tools use standard fault localization techniques—which are not tightly integrated with the overall program repair process, and hence deliver only subpar efficiency. In this paper, we present retrospective fault localization: a novel fault localization technique geared to the requirements of automated program repair. A key idea of retrospective fault localization is to reuse the outcome of failed patch validation to support mutation-based dynamic analysis—providing accurate fault localization information without incurring onerous computational costs. We implemented retrospective fault localization in a tool called Restore—based on the Jaid Java program repair system. Experiments involving faults from the Defects4J standard benchmark indicate that retrospective fault localization can boost automated program repair: Restore efficiently explores a large fix space, delivering state-of-the-art effectiveness (41 Defects4J bugs correctly fixed, 8 of which no other automated repair tool for Java can fix) while simultaneously boosting performance (speedup over 3 compared to Jaid). Retrospective fault localization is applicable to any automated program repair techniques that rely on fault localization and dynamic validation of patches.",1939-3520,,10.1109/TSE.2020.2987862,"National Natural Science Foundation of China(grant numbers:61690204,61972193); Fundamental Research Funds for the Central Universities(grant numbers:14380020,14380022); Hong Kong RGC General Research Fund(grant numbers:PolyU 152703/16E,PolyU 152002/18E); Hong Kong Polytechnic University(grant numbers:1-ZVJ1,G-YBXU); Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:Hi-Fi 200021-182060); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068412,,Maintenance engineering;Tools;Java;Computer bugs;Software;Standards;Electronic mail,,7,,63,IEEE,15 Apr 2020,,,IEEE,IEEE Journals,True
RLocator: Reinforcement Learning for Bug Localization,P. Chakraborty; M. Alfadel; M. Nagappan,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; Department of Computer Science, University of Calgary, Calgary, AB, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,17 Oct 2024,2024,50,10,2695,2708,"Software developers spend a significant portion of time fixing bugs in their projects. To streamline this process, bug localization approaches have been proposed to identify the source code files that are likely responsible for a particular bug. Prior work proposed several similarity-based machine-learning techniques for bug localization. Despite significant advances in these techniques, they do not directly optimize the evaluation measures. We argue that directly optimizing evaluation measures can positively contribute to the performance of bug localization approaches. Therefore, in this paper, we utilize Reinforcement Learning (RL) techniques to directly optimize the ranking metrics. We propose RLocator, a Reinforcement Learning-based bug localization approach. We formulate RLocator using a Markov Decision Process (MDP) to optimize the evaluation measures directly. We present the technique and experimentally evaluate it based on a benchmark dataset of 8,316 bug reports from six highly popular Apache projects. The results of our evaluation reveal that RLocator achieves a Mean Reciprocal Rank (MRR) of 0.62, a Mean Average Precision (MAP) of 0.59, and a Top 1 score of 0.46. We compare RLocator with three state-of-the-art bug localization tools, FLIM, BugLocator, and BL-GAN. Our evaluation reveals that RLocator outperforms both approaches by a substantial margin, with improvements of 38.3% in MAP, 36.73% in MRR, and 23.68% in the Top K metric. These findings highlight that directly optimizing evaluation measures considerably contributes to performance improvement of the bug localization problem.",1939-3520,,10.1109/TSE.2024.3452595,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10659717,Reinforcement learning;bug localization;deep learning,Computer bugs;Source coding;Location awareness;Measurement;Feature extraction;Reinforcement learning;Software,,1,,87,IEEE,30 Aug 2024,,,IEEE,IEEE Journals,True
Requirements of API Documentation: A Case Study into Computer Vision Services,A. Cummaudo; R. Vasa; J. Grundy; M. Abdelrazek,"Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Information Technology, Deakin University, Geelong, VIC, Australia",IEEE Transactions on Software Engineering,14 Jun 2022,2022,48,6,2010,2027,"Using cloud-based computer vision services is gaining traction, where developers access AI-powered components through familiar RESTful APIs, not needing to orchestrate large training and inference infrastructures or curate/label training datasets. However, while these APIs seem familiar to use, their non-deterministic run-time behaviour and evolution is not adequately communicated to developers. Therefore, improving these services’ API documentation is paramount—more extensive documentation facilitates the development process of intelligent software. In a prior study, we extracted 34 API documentation artefacts from 21 seminal works, devising a taxonomy of five key requirements to produce quality API documentation. We extend this study in two ways. First, by surveying 104 developers of varying experience to understand what API documentation artefacts are of most value to practitioners. Second, identifying which of these highly-valued artefacts are or are not well-documented through a case study in the emerging computer vision service domain. We identify: (i) several gaps in the software engineering literature, where aspects of API documentation understanding is/is not extensively investigated; and (ii) where industry vendors (in contrast) document artefacts to better serve their end-developers. We provide a set of recommendations to enhance intelligent software documentation for both vendors and the wider research community.",1939-3520,,10.1109/TSE.2020.3047088,Australian Government Research Training Program; Laureate Fellowship(grant numbers:FL190100035); ARC Research Hub for Digital Enhanced Living(grant numbers:IH170100013); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307242,Intelligent web services and Semantic Web;code documentation;computer vision,Documentation;Taxonomy;Computer vision;Usability;Guidelines;Measurement;Tools,,3,,59,Crown,24 Dec 2020,,,IEEE,IEEE Journals,True
Making Sense of AI Systems Development,M. Dolata; K. Crowston,"Department of Informatics, University of Zurich, Zurich, Switzerland; School of Information Systems, Syracuse University, Syracuse, NY, USA",IEEE Transactions on Software Engineering,8 Jan 2024,2024,50,1,123,140,"We identify and describe episodes of sensemaking around challenges in modern Artificial-Intelligence (AI)-based systems development that emerged in projects carried out by IBM and client companies. All projects used IBM Watson as the development platform for building tailored AI-based solutions to support workers or customers of the client companies. Yet, many of the projects turned out to be significantly more challenging than IBM and its clients had expected. The analysis reveals that project members struggled to establish reliable meanings about the technology, the project, context, and data to act upon. The project members report multiple aspects of the projects that they were not expecting to need to make sense of yet were problematic. Many issues bear upon the current-generation AI’s inherent characteristics, such as dependency on large data sets and continuous improvement as more data becomes available. Those characteristics increase the complexity of the projects and call for balanced mindfulness to avoid unexpected problems.",1939-3520,,10.1109/TSE.2023.3338857,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; Innosuisse - Schweizerische Agentur für Innovationsförderung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10341212,Artificial intelligence;empirical study;industry;social issues;software engineering;systems development,Artificial intelligence;Software;Probabilistic logic;Companies;Training;Cognition;Task analysis,,2,,88,IEEE,4 Dec 2023,,,IEEE,IEEE Journals,True
Black-Box Testing of Deep Neural Networks through Test Case Diversity,Z. Aghababaeyan; M. Abdellatif; L. Briand; R. S; M. Bagherzadeh,"School of EECS, University of Ottawa, Ottawa, ON, Canada; Software and Information Technology Engineering Department, École de Technologie Supérieure, Montreal, QC, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada; Department of Research and Development, General Motors, Warren, MI, USA; School of EECS, University of Ottawa, Ottawa, ON, Canada",IEEE Transactions on Software Engineering,15 May 2023,2023,49,5,3182,3204,"Deep Neural Networks (DNNs) have been extensively used in many areas including image processing, medical diagnostics and autonomous driving. However, DNNs can exhibit erroneous behaviours that may lead to critical errors, especially when used in safety-critical systems. Inspired by testing techniques for traditional software systems, researchers have proposed neuron coverage criteria, as an analogy to source code coverage, to guide the testing of DNNs. Despite very active research on DNN coverage, several recent studies have questioned the usefulness of such criteria in guiding DNN testing. Further, from a practical standpoint, these criteria are white-box as they require access to the internals or training data of DNNs, which is often not feasible or convenient. Measuring such coverage requires executing DNNs with candidate inputs to guide testing, which is not an option in many practical contexts. In this paper, we investigate diversity metrics as an alternative to white-box coverage criteria. For the previously mentioned reasons, we require such metrics to be black-box and not rely on the execution and outputs of DNNs under test. To this end, we first select and adapt three diversity metrics and study, in a controlled manner, their capacity to measure actual diversity in input sets. We then analyze their statistical association with fault detection using four datasets and five DNNs. We further compare diversity with state-of-the-art white-box coverage criteria. As a mechanism to enable such analysis, we also propose a novel way to estimate fault detection in DNNs. Our experiments show that relying on the diversity of image features embedded in test input sets is a more reliable indicator than coverage criteria to effectively guide DNN testing. Indeed, we found that one of our selected black-box diversity metrics far outperforms existing coverage criteria in terms of fault-revealing capability and computational time. Results also confirm the suspicions that state-of-the-art coverage criteria are not adequate to guide the construction of test input sets to detect as many faults as possible using natural inputs.",1939-3520,,10.1109/TSE.2023.3243522,General Motors and Canada Research Chair; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10041782,Coverage;deep neural network;diversity;faults;test,Measurement;Testing;Feature extraction;Closed box;Fault detection;Neurons;Computational modeling,,27,,93,CCBY,9 Feb 2023,,,IEEE,IEEE Journals,True
DSSDPP: Data Selection and Sampling Based Domain Programming Predictor for Cross-Project Defect Prediction,Z. Li; H. Zhang; X. -Y. Jing; J. Xie; M. Guo; J. Ren,"School of Computer Science, Shaanxi Normal University, Xi'an, China; School of Electrical Engineering and Computing, The University of Newcastle, Callaghan, NSW, Australia; School of Computer Science and Technology, Zhejiang Sci-Tech University, Hangzhou, China; School of Computer Science, Shaanxi Normal University, Xi'an, China; School of Computer Science, Shaanxi Normal University, Xi'an, China; School of Computer Science, Shaanxi Normal University, Xi'an, China",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1941,1963,"Cross-project defect prediction (CPDP) refers to recognizing defective software modules in one project (i.e., target) using historical data collected from other projects (i.e., source), which can help developers find defects and prioritize their testing efforts. Unfortunately, there often exists large distribution difference between the source and target data. Most CPDP methods neglect to select the appropriate source data for a given target at the project level. More importantly, existing CPDP models are parametric methods, which usually require intensive parameter selection and tuning to achieve better prediction performance. This would hinder wide applicability of CPDP in practice. Moreover, most CPDP methods do not address the cross-project class imbalance problem. These limitations lead to suboptimal CPDP results. In this paper, we propose a novel data selection and sampling based domain programming predictor (DSSDPP) for CPDP, which addresses the above limitations. DSSDPP is a non-parametric CPDP method, which can perform knowledge transfer across projects without the need for parameter selection and tuning. By exploiting the structures of source and target data, DSSDPP can learn a discriminative transfer classifier for identifying defects of the target project. Extensive experiments on 22 projects from four datasets indicate that DSSDPP achieves better MCC and AUC results against a range of competing methods both in the single-source and multi-source scenarios. Since DSSDPP is easy, effective, extensible, and efficient, we suggest that future work can use it with the well-chosen source data to conduct CPDP especially for the projects with limited computational budget.",1939-3520,,10.1109/TSE.2022.3204589,"National Natural Science Foundation of China(grant numbers:61902228,62176069); Natural Science Basic Research Program of Shaanxi Province(grant numbers:2020JQ-422); Innovation Group of Guangdong Education Department(grant numbers:2020KCXTD014); Fundamental Research Funds for the Central Universities(grant numbers:GK202103083,GK202105006); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9878214,Cross-project defect prediction;domain programming predictor;data selection;data sampling;transfer learning;software quality assurance,Data models;Prediction algorithms;Measurement;Predictive models;Tuning;Transfer learning;Programming,,7,,88,IEEE,6 Sep 2022,,,IEEE,IEEE Journals,True
GUI-Guided Test Script Repair for Mobile Apps,M. Pan; T. Xu; Y. Pei; Z. Li; T. Zhang; X. Li,"State Key Laboratory for Novel Software Technology, Software Institute of Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computer Science and Technology, State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,15 Mar 2022,2022,48,3,910,929,"Graphical User Interface (GUI) testing is widely used to test mobile apps. As mobile apps are frequently updated and need repeated testing, to reduce the test cost, their test cases are often coded as scripts to enable automated execution using test harnesses/tools. When those mobile apps evolve, many of the test scripts, however, may become broken due to changes made to the app GUIs. While it is desirable that the broken scripts get repaired, doing it manually can be preventively expensive if the number of tests need repairing is large. We propose in this paper a novel approach named Meter to repairing broken GUI test scripts automatically when mobile apps evolve. Meter leverages computer vision techniques to infer GUI changes between two versions of a mobile app and uses the inferred changes to guide the repair of GUI test scripts. Since Meter only relies on screenshots to repair GUI tests, it is applicable to apps targeting open or closed source mobile platforms. In experiments conducted on 22 Android apps and 6 iOS apps, repairs produced by Meter helped preserve 63.7 and 38.8 percent of all the test actions broken by the GUI changes, respectively.",1939-3520,,10.1109/TSE.2020.3007664,"National Natural Science Foundation of China(grant numbers:61690204,61972193,61632015); Fundamental Research Funds for the Central Universities(grant numbers:14380022,14380020); Hong Kong RGC General Research Fund(grant numbers:PolyU 152703/16E,PolyU 152002/18E); Hong Kong Polytechnic University(grant numbers:1-ZVJ1,G-YBXU); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136844,Mobile GUI testing;test script repair;computer vision.,Meters;Graphical user interfaces;Mobile applications;Maintenance engineering;Testing;Tools;Computer vision,,10,,65,IEEE,8 Jul 2020,,,IEEE,IEEE Journals,True
An Empirical Study on Correlations Between Deep Neural Network Fairness and Neuron Coverage Criteria,W. Zheng; L. Lin; X. Wu; X. Chen,"School of Software, Northwestern Polytechnical University, Xi’an, China; School of Software, Northwestern Polytechnical University, Xi’an, China; School of Information Engineering, Yangzhou University, Yangzhou, China; School of Information Science and Technology, Nantong University, Nantong, China",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,391,412,"Recently, with the widespread use of deep neural networks (DNNs) in high-stakes decision-making systems (such as fraud detection and prison sentencing), concerns have arisen about the fairness of DNNs in terms of the potential negative impact they may have on individuals and society. Therefore, fairness testing has become an important research topic in DNN testing. At the same time, the neural network coverage criteria (such as criteria based on neuronal activation) is considered as an adequacy test for DNN white-box testing. It is implicitly assumed that improving the coverage can enhance the quality of test suites. Nevertheless, the correlation between DNN fairness (a test property) and coverage criteria (a test method) has not been adequately explored. To address this issue, we conducted a systematic empirical study on seven coverage criteria, six fairness metrics, three fairness testing techniques, and five bias mitigation methods on five DNN models and nine fairness datasets to assess the correlation between coverage criteria and DNN fairness. Our study achieved the following findings: 1) with the increase in the size of the test suite, some of the coverage and fairness metrics changed significantly, as the size of the test suite increased; 2) the statistical correlation between coverage criteria and DNN fairness is limited; and 3) after bias mitigation for improving the fairness of DNN, the change pattern in coverage criteria is different; 4) Models debiased by different bias mitigation methods have a lower correlation between coverage and fairness compared to the original models. Our findings cast doubt on the validity of coverage criteria concerning DNN fairness (i.e., increasing the coverage may even have a negative impact on the fairness of DNNs). Therefore, we warn DNN testers against blindly pursuing higher coverage of coverage criteria at the cost of test properties of DNNs (such as fairness).",1939-3520,,10.1109/TSE.2023.3349001,"National Natural Science Foundation of China(grant numbers:62141208,62202414); Key R&D Program in Shaanxi Province(grant numbers:2023-YBGY-262); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10384481,Software testing;deep neural networks;deep learning fairness;neuron coverage criteria;bias mitigation,Testing;Neurons;Artificial neural networks;Correlation;Measurement;Software;Deep learning,,7,,79,IEEE,8 Jan 2024,,,IEEE,IEEE Journals,True
AI-Enabled Automation for Completeness Checking of Privacy Policies,O. Amaral; S. Abualhaija; D. Torre; M. Sabetzadeh; L. C. Briand,"SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Software Engineering,11 Nov 2022,2022,48,11,4647,4674,"Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall.",1939-3520,,10.1109/TSE.2021.3124332,"Linklaters, Luxembourg's National Research Fund(grant numbers:BRIDGES/19/IS/13759068/ARTAGO); Natural Sciences and Engineering Research Council of Canada; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599471,Requirements engineering;legal compliance;privacy policies;the general data protection regulation (GDPR);artificial intelligence (AI);conceptual modeling;qualitative research,Privacy;Metadata;Law;General Data Protection Regulation;Software;Organizations;Europe,,20,,75,IEEE,2 Nov 2021,,,IEEE,IEEE Journals,True
An Architectural Technical Debt Index Based on Machine Learning and Architectural Smells,D. Sas; P. Avgeriou,"Bernoulli Institute for Mathematics, Computer Science, and Artificial Intelligence, University of Groningen, Groningen, Netherlands; Bernoulli Institute for Mathematics, Computer Science, and Artificial Intelligence, University of Groningen, Groningen, Netherlands",IEEE Transactions on Software Engineering,14 Aug 2023,2023,49,8,4169,4195,"A key aspect of technical debt (TD) management is the ability to measure the amount of principal accumulated in a system. The current literature contains an array of approaches to estimate TD principal, however, only a few of them focus specifically on architectural TD, but none of them satisfies all three of the following criteria: being fully automated, freely available, and thoroughly validated. Moreover, a recent study has shown that many of the current approaches suffer from certain shortcomings, such as relying on hand-picked thresholds. In this article, we propose a novel approach to estimate architectural technical debt principal based on machine learning and architectural smells to address such shortcomings. Our approach can estimate the amount of technical debt principal generated by a single architectural smell instance. To do so, we adopt novel techniques from Information Retrieval to train a learning-to-rank machine learning model (more specifically, a gradient boosting machine) that estimates the severity of an architectural smell and ensure the transparency of the predictions. Then, for each instance, we statically analyse the source code to calculate the exact number of lines of code creating the smell. Finally, we combine these two values to calculate the technical debt principal. To validate the approach, we conducted a case study and interviewed 16 practitioners, from both open source and industry, and asked them about their opinions on the TD principal estimations for several smells detected in their projects. The results show that for 71% of instances, practitioners agreed that the estimations provided were representative of the effort necessary to refactor the smell.",1939-3520,,10.1109/TSE.2023.3286179,ITEA3 research project(grant numbers:17038 VISDOM); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10152491,Machine learning;technical debt;architectural smells;arcan;learning-to-rank;case study,Codes;Estimation;Indexes;Couplings;Standards;Source coding;Shape,,5,,88,IEEE,14 Jun 2023,,,IEEE,IEEE Journals,True
Quality of Automated Program Repair on Real-World Defects,M. Motwani; M. Soto; Y. Brun; R. Just; C. Le Goues,"Manning College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Manning College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",IEEE Transactions on Software Engineering,14 Feb 2022,2022,48,2,637,661,"Automated program repair is a promising approach to reducing the costs of manual debugging and increasing software quality. However, recent studies have shown that automated program repair techniques can be prone to producing patches of low quality, overfitting to the set of tests provided to the repair technique, and failing to generalize to the intended specification. This paper rigorously explores this phenomenon on real-world Java programs, analyzing the effectiveness of four well-known repair techniques, GenProg, Par, SimFix, and TrpAutoRepair, on defects made by the projects’ developers during their regular development process. We find that: (1) When applied to real-world Java code, automated program repair techniques produce patches for between 10.6 and 19.0 percent of the defects, which is less frequent than when applied to C code. (2) The produced patches often overfit to the provided test suite, with only between 13.8 and 46.1 percent of the patches passing an independent set of tests. (3) Test suite size has an extremely small but significant effect on the quality of the patches, with larger test suites producing higher-quality patches, though, surprisingly, higher-coverage test suites correlate with lower-quality patches. (4) The number of tests that a buggy program fails has a small but statistically significant positive effect on the quality of the produced patches. (5) Test suite provenance, whether the test suite is written by a human or automatically generated, has a significant effect on the quality of the patches, with developer-written tests typically producing higher-quality patches. And (6) the patches exhibit insufficient diversity to improve quality through some method of combining multiple patches. We develop JaRFly, an open-source framework for implementing techniques for automatic search-based improvement of Java programs. Our study uses JaRFly to faithfully reimplement GenProg and TrpAutoRepair to work on Java code, and makes the first public release of an implementation of Par. Unlike prior work, our study carefully controls for confounding factors and produces a methodology, as well as a dataset of automatically-generated test suites, for objectively evaluating the quality of Java repair techniques on real-world defects.",1939-3520,,10.1109/TSE.2020.2998785,"National Science Foundation(grant numbers:CCF-1453474,CCF-1563797,CCF-1564162,CCF-1750116); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9104918,Automated program repair;patch quality;objective quality measure;Java;GenProg;Par;TrpAutoRepair;Defects4J,Maintenance engineering;Java;Contracts;Manuals;Diversity reception;Inspection;Software quality,,25,,142,IEEE,1 Jun 2020,,,IEEE,IEEE Journals,True
Modelling Second-Order Uncertainty in State Machines,N. Walkinshaw; R. M. Hierons,"Department of Computer Science, The University of Sheffield, Sheffield, U.K.; Department of Computer Science, The University of Sheffield, Sheffield, U.K.",IEEE Transactions on Software Engineering,15 May 2023,2023,49,5,3261,3276,"Modelling the behaviour of state-based systems can be challenging, especially when the modeller is not entirely certain about its intended interactions with the user or the environment. Currently, it is possible to associate a stated level of uncertainty with a given event by attaching probabilities to transitions (producing ‘Probabilistic State Machines’). This captures the ‘First-order uncertainty’ - the (un-)certainty that a given event will occur. However, this does not permit the modeller to capture their own uncertainty (or lack thereof) about that stated probability - also known as ‘Second-order uncertainty’. In this article we introduce a generalisation of probabilistic finite state machines that makes it possible to incorporate this important additional dimension of uncertainty. For this we adopt a formalism for reasoning about uncertainty called Subjective Logic. We present an algorithm to create these enhanced state machines automatically from a conventional state machine and a set of observed sequences. We show how this approach can be used for reverse-engineering predictive state machines from traces.",1939-3520,,10.1109/TSE.2023.3250835,EPSRC CITCOM(grant numbers:EP/T030526/1); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10057480,State machine;second order uncertainty;subjective logic;inference;test prioritization,Uncertainty;Probabilistic logic;Testing;Protocols;Predictive models;IEEE 1394 Standard;Finite element analysis,,2,,62,IEEE,2 Mar 2023,,,IEEE,IEEE Journals,True
Pull Request Decisions Explained: An Empirical Overview,X. Zhang; Y. Yu; G. Gousios; A. Rastogi,"National Key Lab of Parallel Distribution, National University of Defense Technology, Changsha, Hunan, China; National Key Lab of Parallel Distribution, National University of Defense Technology, Changsha, Hunan, China; TU Delft, Delft, CD, The Netherlands; Faculty of Science and Engineering, University of Groningen, Groningen, CP, The Netherlands",IEEE Transactions on Software Engineering,14 Feb 2023,2023,49,2,849,871,"Context: The pull-based development model is widely used in open source projects, leading to the emergence of trends in distributed software development. One aspect that has garnered significant attention concerning pull request decisions is the identification of explanatory factors. Objective: This study builds on a decade of research on pull request decisions and provides further insights. We empirically investigate how factors influence pull request decisions and the scenarios that change the influence of such factors. Method: We identify factors influencing pull request decisions on GitHub through a systematic literature review and infer them by mining archival data. We collect a total of 3,347,937 pull requests with 95 features from 11,230 diverse projects on GitHub. Using these data, we explore the relations among the factors and build mixed effects logistic regression models to empirically explain pull request decisions. Results: Our study shows that a small number of factors explain pull request decisions, with that concerning whether the integrator is the same as or different from the submitter being the most important factor. We also note that the influence of factors on pull request decisions change with a change in context; e.g., the area hotness of pull request is important only in the early stage of project development, however it becomes unimportant for pull request decisions as projects become mature.",1939-3520,,10.1109/TSE.2022.3165056,National Key R&D Program of China(grant numbers:2020AAA0103504); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749844,Pull-based development;pull request decision;distributed software development;GitHub,Software development management;Software;Systematics;Bibliographies;Internet;Data models;Data mining,,16,,104,IEEE,5 Apr 2022,,,IEEE,IEEE Journals,True
"A3-CodGen : A Repository-Level Code Generation Framework for Code Reuse with Local-Aware, Global-Aware, and Third-Party-Library-Aware",D. Liao; S. Pan; X. Sun; X. Ren; Q. Huang; Z. Xing; H. Jin; Q. Li,"School of Computing, Australian National University, Australia; CSIRO’s Data61, Australia; School of Computing, Australian National University, Australia; State Key Laboratory of Blockchain and Data Security, Zhejiang University; School of Computer Information Engineering at Jiangxi Normal University, China; CSIRO’s Data61, Australia; Jiangxi University of Technology, China; Jiangxi University of Technology, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,16,"LLM-based code generation tools are essential to help developers in the software development process. Existing tools often disconnect with the working context, i.e., the code repository, causing the generated code to be not similar to human developers. In this paper, we propose a novel code generation framework, dubbed A3-CodGen, to harness information within the code repository to generate code with fewer potential logical errors, code redundancy, and library-induced compatibility issues. We identify three types of representative information for the code repository: local-aware information from the current code file, global-aware information from other code files, and third-party- library information. Results demonstrate that by adopting the A3-CodGen framework, we successfully extract, fuse, and feed code repository information into the LLM, generating more accurate, efficient, and highly reusable code. The effectiveness of our framework is further underscored by generating code with a higher reuse rate, compared to human developers. This research contributes significantly to the field of code generation, providing developers with a more powerful tool to address the evolving demands in software development in practice.",1939-3520,,10.1109/TSE.2024.3486195,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10734067,Code Generation;Repository Knowledge Mining;Code Reuse;Retrieval-Augmented Generation,Codes;Libraries;Software development management;Data mining;Benchmark testing;Transformers;Software engineering;Context modeling;Chatbots;Australia,,1,,,IEEE,24 Oct 2024,,,IEEE,IEEE Early Access Articles,True
Fight Fire with Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?,X. Yu; L. Liu; X. Hu; J. W. Keung; J. Liu; X. Xia,"State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China; Faculty of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China; School of Computer Science, Wuhan University, Wuhan, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,19,"With the increasing utilization of large language models such as ChatGPT during software development, it has become crucial to verify the quality of code content it generates. Recent studies proposed utilizing ChatGPT as both a developer and tester for multi-agent collaborative software development. The multi-agent collaboration empowers ChatGPT to produce test reports for its generated code, enabling it to self-verify the code content and fix bugs based on these reports. However, these studies did not assess the effectiveness of the generated test reports in validating the code. Therefore, we conduct a comprehensive empirical investigation to evaluate ChatGPT’s self-verification capability in code generation, code completion, and program repair. We request ChatGPT to (1) generate correct code and then self-verify its correctness; (2) complete code without vulnerabilities and then self-verify for the presence of vulnerabilities; and (3) repair buggy code and then selfverify whether the bugs are resolved. Our findings on two code generation datasets, one code completion dataset, and two program repair datasets reveal the following observations: (1) ChatGPT often erroneously predicts its generated incorrect code as correct, its vulnerable completed code as non-vulnerable, and its failed program repairs as successful during its self-verification. (2) The self-contradictory hallucinations in ChatGPT’s behavior arise: (a) ChatGPT initially generates code that it believes to be correct but later predicts it to be incorrect; (b) ChatGPT initially generates code completions that it deems secure but later predicts them to be vulnerable; (c) ChatGPT initially outputs code that it considers successfully repaired but later predicts it to be buggy during its self-verification. (3) The self-verification capability of ChatGPT can be enhanced by asking the guiding question, which queries whether ChatGPT agrees with assertions about incorrectly generated or repaired code and vulnerabilities in completed code. (4) Using test reports generated by ChatGPT can identify more vulnerabilities in completed code, but the explanations for incorrectly generated code and failed repairs are mostly inaccurate in the test reports. Based on these findings, we provide implications for further research or development using ChatGPT.",1939-3520,,10.1109/TSE.2024.3492204,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10745266,Empirical study;ChatGPT;self-verification;code generation;code completion;program repair,Codes;Chatbots;Maintenance engineering;Software development management;Software;Computer bugs;Urban areas;Computer science;Accuracy;Source coding,,,,,IEEE,5 Nov 2024,,,IEEE,IEEE Early Access Articles,True
Active Code Learning: Benchmarking Sample-Efficient Training of Code Models,Q. Hu; Y. Guo; X. Xie; M. Cordy; L. Ma; M. Papadakis; Y. L. Traon,"University of Luxembourg, Belval, Luxembourg; Luxembourg Institute of Science and Technology, Belval, Luxembourg; Singapore Management University, Singapore; University of Luxembourg, Belval, Luxembourg; University of Tokyo, Tokyo, Japan; University of Luxembourg, Belval, Luxembourg; University of Luxembourg, Belval, Luxembourg",IEEE Transactions on Software Engineering,15 May 2024,2024,50,5,1080,1095,"The costly human effort required to prepare the training data of machine learning (ML) models hinders their practical development and usage in software engineering (ML4Code), especially for those with limited budgets. Therefore, efficiently training models of code with less human effort has become an emergent problem. Active learning is such a technique to address this issue that allows developers to train a model with reduced data while producing models with desired performance, which has been well studied in computer vision and natural language processing domains. Unfortunately, there is no such work that explores the effectiveness of active learning for code models. In this paper, we bridge this gap by building the first benchmark to study this critical problem - active code learning. Specifically, we collect 11 acquisition functions (which are used for data selection in active learning) from existing works and adapt them for code-related tasks. Then, we conduct an empirical study to check whether these acquisition functions maintain performance for code data. The results demonstrate that feature selection highly affects active learning and using output vectors to select data is the best choice. For the code summarization task, active code learning is ineffective which produces models with over a 29.64% gap compared to the expected performance. Furthermore, we explore future directions of active code learning with an exploratory study. We propose to replace distance calculation methods with evaluation metrics and find a correlation between these evaluation-based distance methods and the performance of code models.",1939-3520,,10.1109/TSE.2024.3376964,European Union’s Horizon Research and Innovation Programme; Project LAZARUS(grant numbers:101070303); Luxembourg National Research Funds (FNR)(grant numbers:C18/IS/12669767/STELLAR/LeTraon); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10471610,Active learning;machine learning for code;benchmark;empirical analysis,Codes;Data models;Task analysis;Training;Feature extraction;Training data;Labeling,,,,61,CCBYNCND,13 Mar 2024,,,IEEE,IEEE Journals,True
Using Transfer Learning for Code-Related Tasks,A. Mastropaolo; N. Cooper; D. N. Palacio; S. Scalabrino; D. Poshyvanyk; R. Oliveto; G. Bavota,"SEART Software Institute, Università della Svizzera italiana, Lugano, Switzerland; SEMERU William & Mary, Williamsburg, VA, USA; SEMERU William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy; SEMERU William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy; SEART Software Institute, Università della Svizzera italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1580,1598,"Deep learning (DL) techniques have been used to support several code-related tasks such as code summarization and bug-fixing. In particular, pre-trained transformer models are on the rise, also thanks to the excellent results they achieved in Natural Language Processing (NLP) tasks. The basic idea behind these models is to first pre-train them on a generic dataset using a self-supervised task (e.g., filling masked words in sentences). Then, these models are fine-tuned to support specific tasks of interest (e.g., language translation). A single model can be fine-tuned to support multiple tasks, possibly exploiting the benefits of transfer learning. This means that knowledge acquired to solve a specific task (e.g., language translation) can be useful to boost performance on another task (e.g., sentiment classification). While the benefits of transfer learning have been widely studied in NLP, limited empirical evidence is available when it comes to code-related tasks. In this paper, we assess the performance of the Text-To-Text Transfer Transformer (T5) model in supporting four different code-related tasks: (i) automatic bug-fixing, (ii) injection of code mutants, (iii) generation of assert statements, and (iv) code summarization. We pay particular attention in studying the role played by pre-training and multi-task fine-tuning on the model's performance. We show that (i) the T5 can achieve better performance as compared to state-of-the-art baselines; and (ii) while pre-training helps the model, not all tasks benefit from a multi-task fine-tuning.",1939-3520,,10.1109/TSE.2022.3183297,"European Research Council(grant numbers:851720); National Science Foundation(grant numbers:CCF-1955853,CCF-1815186,CCF-2007246); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797060,Deep learning;empirical software engineering,Task analysis;Codes;Multitasking;Electronic mail;Computer bugs;Natural language processing;Java,,26,,87,IEEE,15 Jun 2022,,,IEEE,IEEE Journals,True
Uncovering Bugs in Code Coverage Profilers via Control Flow Constraint Solving,Y. Wang; P. Zhang; M. Sun; Z. Lu; Y. Yang; Y. Tang; J. Qian; Z. Li; Y. Zhou,"State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; Huawei Technologies Company Ltd., Hangzhou, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; School of Computer Science and Engineering, University of Glasgow, Scotland, U.K.; Key Laboratory of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, Guilin, China; Key Laboratory of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, Guilin, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,16 Nov 2023,2023,49,11,4964,4987,"Code coverage has been widely used as the basis for various software quality assurance techniques. Therefore, it is of great importance to ensure that coverage profilers provide reliable code coverage. However, it is challenging to validate the correctness of the code coverage generated due to the lack of an effective oracle. In this paper, we propose an effective approach based on control flow constraint solving to test coverage profilers and have implemented a coverage bug hunting tool, DOG (finD cOverage buGs). Our core idea is to leverage inherent control flow features to generate control flow constraints that the resulting coverage statistics should respect. If DOG identifies any unsatisfiable constraints, it signifies the presence of incorrect coverage statistics. In such cases, DOG provides detailed diagnostic information about the suspicious coverage statistics for manual inspection. Compared with the state-of-the-art works, DOG has the following prominent advantages: (1) wide applicability: DOG eliminates the need for multiple coverage profilers (as required by differential testing) and program variants (as needed in metamorphic testing), making it highly versatile; (2) unique testing capability: DOG effectively analyzes and utilizes relationships among available coverage statistics, boosting its testing capabilities; and (3) enhanced interpretability: DOG provides clear control flow explanations for incorrect code coverage, enabling the localization of suspicious coverage areas. During our testing period with DOG, we successfully identified and reported 27 bugs in Gcov and llvm-cov, both widely-used coverage profilers. Of these, 17 bugs have been confirmed (11 have been fixed), 3 were deemed expected behaviors by developers, and 7 remain unresolved. Remarkably, 21 out of 24 unexpected bugs had been latent for over two and a half years, and nearly half of the coverage bugs (10 out of 24) were undetectable by state-of-the-art coverage profiler validators. These results demonstrate the effectiveness and importance of using DOG to improve the reliability of code coverage profilers.",1939-3520,,10.1109/TSE.2023.3321381,"Natural Science Foundation of China(grant numbers:62172205,62072194,62162004,62362006,U21A20474,62202306); Natural Science Foundation of Jiangsu Province(grant numbers:SBK2023022696); NJU-Huawei Software New Technology Joint Laboratory(grant numbers:TC20230202021-2023-08); CCF-Huawei Populus euphratica(grant numbers:CCF-HuaweiSY2022007); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10272026,Coverage bugs;control flow;constraint solving;coverage profilers;testing,Computer bugs;Testing;Codes;Source coding;Inspection,,1,,68,IEEE,4 Oct 2023,,,IEEE,IEEE Journals,True
Revisiting the Performance of Deep Learning-Based Vulnerability Detection on Realistic Datasets,P. Chakraborty; K. K. Arumugam; M. Alfadel; M. Nagappan; S. McIntosh,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,14 Aug 2024,2024,50,8,2163,2177,"The impact of software vulnerabilities on everyday software systems is concerning. Although deep learning-based models have been proposed for vulnerability detection, their reliability remains a significant concern. While prior evaluation of such models reports impressive recall/F1 scores of up to 99%, we find that these models underperform in practical scenarios, particularly when evaluated on the entire codebases rather than only the fixing commit. In this paper, we introduce a comprehensive dataset (Real-Vul) designed to accurately represent real-world scenarios for evaluating vulnerability detection models. We evaluate DeepWukong, LineVul, ReVeal, and IVDetect vulnerability detection approaches and observe a surprisingly significant drop in performance, with precision declining by up to 95 percentage points and F1 scores dropping by up to 91 percentage points. A closer inspection reveals a substantial overlap in the embeddings generated by the models for vulnerable and uncertain samples (non-vulnerable or vulnerability not reported yet), which likely explains why we observe such a large increase in the quantity and rate of false positives. Additionally, we observe fluctuations in model performance based on vulnerability characteristics (e.g., vulnerability types and severity). For example, the studied models achieve 26 percentage points better F1 scores when vulnerabilities are related to information leaks or code injection rather than when vulnerabilities are related to path resolution or predictable return values. Our results highlight the substantial performance gap that still needs to be bridged before deep learning-based vulnerability detection is ready for deployment in practical settings. We dive deeper into why models underperform in realistic settings and our investigation revealed overfitting as a key issue. We address this by introducing an augmentation technique, potentially improving performance by up to 30%. We contribute (a) an approach to creating a dataset that future research can use to improve the practicality of model evaluation; (b) Real-Vul– a comprehensive dataset that adheres to this approach; and (c) empirical evidence that the deep learning-based models struggle to perform in a real-world setting.",1939-3520,,10.1109/TSE.2024.3423712,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10587162,Vulnerability;security;machine learning;deep learning,Codes;Synthetic data;Software systems;Security;Training;Source coding;Software reliability,,,,54,IEEE,5 Jul 2024,,,IEEE,IEEE Journals,True
Program Repair With Repeated Learning,L. Chen; Y. Pei; M. Pan; T. Zhang; Q. Wang; C. A. Furia,"Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; State Key Laboratory for Novel Software Technology, Software Institute of Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Software Institute of USI, Università della Svizzera italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,14 Feb 2023,2023,49,2,831,848,"A key challenge in generate-and-validate automated program repair is directing the search for fixes so that it can efficiently find those that are more likely to be correct. To this end, several techniques use machine learning to capture the features of programmer-written fixes. In existing approaches, fitting the model typically takes place before fix generation and is independent of it: the fix generation process uses the learned model as one of its inputs. However, the intermediate outcomes of an ongoing fix generation process often provide valuable information about which candidate fixes were “better”; this information could profitably be used to retrain the model, so that each new iteration of the fixing process would also learn from the outcome of previous ones. In this paper, we propose the Liana technique for automated program repair, which is based on this idea of repeatedly learning the features of generated fixes. To this end, Liana uses a fine-grained model that combines information about fix characteristics, their relations to the fixing context, and the results of test execution. The model is initially trained offline, and then repeatedly updated online as the fix generation process unravels; at any step, the most up-to-date model is used to guide the search for fixes—prioritizing those that are more likely to include the right ingredients. In an experimental evaluation on 732 real-world Java bugs from 3 popular benchmarks, Liana built correct fixes for 134 faults (83 ranked as first in its output)— improving over several other generate-and-validate program repair tools according to various measures.",1939-3520,,10.1109/TSE.2022.3164662,"Hong Kong Research Grants Council(grant numbers:PolyU 152002/18E); National Natural Science Foundation of China(grant numbers:61972193); Hong Kong RGC Theme-Based Research Scheme(grant numbers:T22-505/19-N (P0031331, RBCR, P0031259, RBCP)); RGC GRF(grant numbers:PolyU 152002/18E (P0005550, Q67V),PolyU 152164/14E (P0004750, Q44B)); RGC Germany/HK(grant numbers:G-PolyU503/16); Hong Kong Polytechnic University Fund(grant numbers:P0033695 (ZVRD),P0013879 (BBWH),P0031950 (ZE1N),P0036469 (CDA8),8B2V); Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:Hi-Fi 200021-182060); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749899,Automated program repair (APR);generate-and-validate APR;learning-to-rank;repeated learning,Java;Fitting;Computer bugs;Machine learning;Maintenance engineering;Benchmark testing;Context modeling,,2,,84,IEEE,5 Apr 2022,,,IEEE,IEEE Journals,True
HSTCG: State-Aware Simulink Model Test Case Generation with Heuristic Strategy,Z. Su; Z. Yu; D. Wang; Y. Yang; R. Wang; W. Chang; A. Cui; Y. Jiang,"KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; Information Technology Center, Renmin University of China, Beijing, China; Information Engineering College, Capital Normal University, Beijing, China; Information Engineering College, Capital Normal University, Beijing, China; Department of Computer Science, University of York, York, United Kingdom; HUAWEI Technologies Co. LTD., Shanghai, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,17,"Simulink has gained widespread recognition as a valuable tool for system design. It supports efficient modeling and synthesis of embedded controllers. Test cases can also be automatically generated to simulate and verify the correctness of the Simulink model. Nevertheless, as systems grow increasingly complex, particularly in terms of their internal states, this complexity poses new challenges for existing model testing methodologies. Traditional techniques such as constraint solving and random search encounter difficulties when attempting to explore the intricate logic embedded within these models. In this paper, we introduce HSTCG, a state-aware test case generation method for Simulink models with heuristic strategy. HSTCG solves only one iteration of the model each time to get the test input that can cover a target branch, then executes the model once to obtain and update the new model state based on the solved input dynamically. Then, it solves the remaining branches based on the new model state iteratively until all the coverage requirements are satisfied. To improve the efficiency of test case generation, we also designed a heuristic strategy containing heuristic branch searching, repeated state filter and unreached branch filter to minimize the times of constraint solving. We implemented HSTCG and evaluated it on several benchmark Simulink models. Compared to the built-in Simulink Design Verifier and state-of-the-art academic work SimCoTest, HSTCG achieves an average improvement of 55% and 103% on Decision Coverage, 53% and 62% on Condition Coverage and 192% and 201% on Modified Condition Decision Coverage, respectively. We also validated the significant improvement of the heuristic strategy, which can improve the efficiency of test case generation by 62.2% on average.",1939-3520,,10.1109/TSE.2024.3428528,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10599334,Test case generation;Simulink;Constraint solving;Heuristic strategy,Task analysis;Software packages;Computational modeling;Data models;Testing;Logic;Codes,,,,,IEEE,15 Jul 2024,,,IEEE,IEEE Early Access Articles,True
On Inter-dataset Code Duplication and Data Leakage in Large Language Models,J. A. Hernández López; B. Chen; M. Saad; T. Sharma; D. Varró,"Linköping University, Sweden; McGill University, Canada; Dalhousie University, Canada; Dalhousie University, Canada; Linköping University, Sweden",IEEE Transactions on Software Engineering,,2024,PP,99,1,14,"Motivation. Large language models (LLMs) have exhibited remarkable proficiency in diverse software engineering (SE) tasks, such as code summarization, code translation, and code search. Handling such tasks typically involves acquiring foundational coding knowledge on large, general-purpose datasets during a pre-training phase, and subsequently refining on smaller, task-specific datasets as part of a fine-tuning phase. Problem statement. Data leakage i.e., using information of the test set to perform the model training, is a well-known issue in training of machine learning models. A manifestation of this issue is the intersection of the training and testing splits. While intra-dataset code duplication examines this intersection within a given dataset and has been addressed in prior research, inter-dataset code duplication, which gauges the overlap between different datasets, remains largely unexplored. If this phenomenon exists, it could compromise the integrity of LLM evaluations because of the inclusion of fine-tuning test samples that were already encountered during pre-training, resulting in inflated performance metrics. Contribution. This paper explores the phenomenon of inter-dataset code duplication and its impact on evaluating LLMs across diverse SE tasks. Study design. We conduct an empirical study using the CodeSearchNet dataset (CSN), a widely adopted pre-training dataset, and five fine-tuning datasets used for various SE tasks. We first identify the intersection between the pre-training and fine-tuning datasets using a deduplication process. Next, we pre-train two versions of LLMs using a subset of CSN: one leaky LLM, which includes the identified intersection in its pre-training set, and one non-leaky LLM that excludes these samples. Finally, we fine-tune both models and compare their performances using fine-tuning test samples that are part of the intersection. Results. Our findings reveal a potential threat to the evaluation of LLMs across multiple SE tasks, stemming from the inter-dataset code duplication phenomenon. We also demonstrate that this threat is accentuated by the chosen fine-tuning technique. Furthermore, we provide evidence that open-source models such as CodeBERT, GraphCodeBERT, and UnixCoder could be affected by inter-dataset duplication. Based on our findings, we delve into prior research that may be susceptible to this threat. Additionally, we offer guidance to SE researchers on strategies to prevent inter-dataset code duplication.",1939-3520,,10.1109/TSE.2024.3504286,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759822,LLM;inter-dataset code duplication;data leakage,Codes;Cloning;Training;Data models;Software development management;Tuning;Source coding;Software engineering;Context modeling;Transformers,,,,,IEEE,21 Nov 2024,,,IEEE,IEEE Early Access Articles,True
AIM: Automated Input Set Minimization for Metamorphic Security Testing,N. Bayati Chaleshtari; Y. Marquer; F. Pastore; L. C. Briand,"School of Electrical and Computer Engineering of University of Ottawa, Canada; Interdisciplinary Centre for Security, Reliability, and Trust (SnT) of the University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT) of the University of Luxembourg, Luxembourg; School of Electrical and Computer Engineering of University of Ottawa, Canada",IEEE Transactions on Software Engineering,,2024,PP,99,1,31,"Although the security testing of Web systems can be automated by generating crafted inputs, solutions to automate the test oracle, i.e., vulnerability detection, remain difficult to apply in practice. Specifically, though previous work has demonstrated the potential of metamorphic testing-security failures can be determined by metamorphic relations that turn valid inputs into malicious inputs-metamorphic relations are typically executed on a large set of inputs, which is time-consuming and thus makes metamorphic testing impractical. We propose AIM, an approach that automatically selects inputs to reduce testing costs while preserving vulnerability detection capabilities. AIM includes a clustering-based black-box approach, to identify similar inputs based on their security properties. It also relies on a novel genetic algorithm to efficiently select diverse inputs while minimizing their total cost. Further, it contains a problem-reduction component to reduce the search space and speed up the minimization process. We evaluated the effectiveness of AIM on two well-known Web systems, Jenkins and Joomla, with documented vulnerabilities. We compared AIM's results with four baselines involving standard search approaches. Overall, AIM reduced metamorphic testing time by 84% for Jenkins and 82% for Joomla, while preserving the same level of vulnerability detection. Furthermore, AIM significantly outperformed all the considered baselines regarding vulnerability coverage.",1939-3520,,10.1109/TSE.2024.3488525,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10738434,System Security Testing;Metamorphic Testing;Test Suite Minimization;Many-Objective Search,Testing;Security;Software;Uniform resource locators;Minimization;Costs;Reactive power;Software reliability;Search problems;Scalability,,,,,IEEE,30 Oct 2024,,,IEEE,IEEE Early Access Articles,True
FlakyFix: Using Large Language Models for Predicting Flaky Test Fix Categories and Test Code Repair,S. Fatima; H. Hemmati; L. Briand,"School of EECS, University of Ottawa, Canada; Electrical Engineering and Computer Science Department, York University, Canada; School of EECS, University of Ottawa, Canada",IEEE Transactions on Software Engineering,,2024,PP,99,1,26,"Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting development effort. While machine learning models have been used to predict flakiness and its root causes, there is much less work on providing support to fix the problem. To address this gap, in this paper, we focus on predicting the type of fix that is required to remove flakiness and then repair the test code on that basis. We do this for a subset of flaky tests where the root cause of flakiness is in the test itself and not in the production code. One key idea is to guide the repair process with additional knowledge about the test’s flakiness in the form of its predicted fix category. Thus, we first propose a framework that automatically generates labeled datasets for 13 fix categories and trains models to predict the fix category of a flaky test by analyzing the test code only. Our experimental results using code models and few-shot learning show that we can correctly predict most of the fix categories. To show the usefulness of such fix category labels for automatically repairing flakiness, we augment the prompts of GPT 3.5 Turbo, a Large Language Model (LLM), with such extra knowledge to request repair suggestions. The results show that our suggested fix category labels, complemented with in-context learning, significantly enhance the capability of GPT 3.5 Turbo in generating fixes for flaky tests. Based on the execution and analysis of a sample of GPT-repaired flaky tests, we estimate that a large percentage of such repairs, (roughly between 51% and 83%) can be expected to pass. For the failing repaired tests, on average, 16% of the test code needs to be further changed for them to pass.",1939-3520,,10.1109/TSE.2024.3472476,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10704582,Flaky Tests;Fix Category;Test Repair;Large Language Models;Code Models;Few Shot Learning;Software Testing,Codes;Predictive models;Maintenance engineering;Analytical models;Production;Large language models;Java;Few shot learning;Python;Manuals,,,,,CCBYNCND,2 Oct 2024,,,IEEE,IEEE Early Access Articles,True
Improving Cross-Language Code Clone Detection via Code Representation Learning and Graph Neural Networks,N. Mehrotra; A. Sharma; A. Jindal; R. Purandare,"Department of Computer Science Engineering, IIIT Delhi, Delhi, India; Department of Computer Science Engineering, IIIT Delhi, Delhi, India; Department of Computer Science Engineering, IIIT Delhi, Delhi, India; University of Nebraska–Lincoln, Lincoln, NE, USA",IEEE Transactions on Software Engineering,16 Nov 2023,2023,49,11,4846,4868,"Code clone detection is an important aspect of software development and maintenance. The extensive research in this domain has helped reduce the complexity and increase the robustness of source code, thereby assisting bug detection tools. However, the majority of the clone detection literature is confined to a single language. With the increasing prevalence of cross-platform applications, functionality replication across multiple languages is common, resulting in code fragments having similar functionality but belonging to different languages. Since such clones are syntactically unrelated, single language clone detection tools are not applicable in their case. In this article, we propose a semi-supervised deep learning-based tool Rubhus, capable of detecting clones across different programming languages. Rubhus uses the control and data flow enriched abstract syntax trees (ASTs) of code fragments to leverage their syntactic and structural information and then applies graph neural networks (GNNs) to extract this information for the task of clone detection. We demonstrate the effectiveness of our proposed system through experiments conducted over datasets consisting of Java, C, and Python programs and evaluate its performance in terms of precision, recall, and F1 score. Our results indicate that Rubhus outperforms the state-of-the-art cross-language clone detection tools.",1939-3520,,10.1109/TSE.2023.3311796,Department of Science and Technology (DST) (India); Science and Engineering Research Board (SERB); Confederation of Indian Industry (CII); Infosys Center for Artificial Intelligence at IIIT-Delhi; Nucleus Software Exports Ltd; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242168,Program representation learning;cross-language code clone detection;graph-based neural networks;abstract syntax trees,Codes;Cloning;Syntactics;Semantics;Java;Task analysis;Source coding,,4,,76,IEEE,6 Sep 2023,,,IEEE,IEEE Journals,True
Transfer Learning Across Variants and Versions: The Case of Linux Kernel Size,H. Martin; M. Acher; J. A. Pereira; L. Lesoil; J. -M. Jézéquel; D. E. Khelladi,"Inria, CNRS, IRISA, University Rennes, Rennes, France; Inria, CNRS, IRISA, University Rennes, Rennes, France; PUC-Rio, Rio de Janeiro, RJ, Brazil; Inria, CNRS, IRISA, University Rennes, Rennes, France; Inria, CNRS, IRISA, University Rennes, Rennes, France; Inria, CNRS, IRISA, University Rennes, Rennes, France",IEEE Transactions on Software Engineering,11 Nov 2022,2022,48,11,4274,4290,"With large scale and complex configurable systems, it is hard for users to choose the right combination of options (i.e., configurations) in order to obtain the wanted trade-off between functionality and performance goals such as speed or size. Machine learning can help in relating these goals to the configurable system options, and thus, predict the effect of options on the outcome, typically after a costly training step. However, many configurable systems evolve at such a rapid pace that it is impractical to retrain a new model from scratch for each new version. In this paper, we propose a new method to enable transfer learning of binary size predictions among versions of the same configurable system. Taking the extreme case of the Linux kernel with its $\approx 14,500$≈14,500 configuration options, we first investigate how binary size predictions of kernel size degrade over successive versions. We show that the direct reuse of an accurate prediction model from 2017 quickly becomes inaccurate when Linux evolves, up to a 32% mean error by August 2020. We thus propose a new approach for transfer evolution-aware model shifting (tEAMS). It leverages the structure of a configurable system to transfer an initial predictive model towards its future versions with a minimal amount of extra processing for each version. We show that tEAMS vastly outperforms state of the art approaches over the 3 years history of Linux kernels, from 4.13 to 5.8.",1939-3520,,10.1109/TSE.2021.3116768,Agence Nationale de la Recherche(grant numbers:ANR-17-CE25-0010); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9555247,Software product line;software evolution;machine learning;transfer learning;performance prediction,Kernel;Linux;Transfer learning;Predictive models;Codes;Training;Software systems,,10,,104,IEEE,30 Sep 2021,,,IEEE,IEEE Journals,True
Neural Transfer Learning for Repairing Security Vulnerabilities in C Code,Z. Chen; S. Kommrusch; M. Monperrus,"KTH Royal Institute of Technology, Stockholm, Sweden; Colorado State University, Fort Collins, CO, USA; KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Software Engineering,6 Jan 2023,2023,49,1,147,165,"In this paper, we address the problem of automatic repair of software vulnerabilities with deep learning. The major problem with data-driven vulnerability repair is that the few existing datasets of known confirmed vulnerabilities consist of only a few thousand examples. However, training a deep learning model often requires hundreds of thousands of examples. In this work, we leverage the intuition that the bug fixing task and the vulnerability fixing task are related and that the knowledge learned from bug fixes can be transferred to fixing vulnerabilities. In the machine learning community, this technique is called transfer learning. In this paper, we propose an approach for repairing security vulnerabilities named VRepair which is based on transfer learning. VRepair is first trained on a large bug fix corpus and is then tuned on a vulnerability fix dataset, which is an order of magnitude smaller. In our experiments, we show that a model trained only on a bug fix corpus can already fix some vulnerabilities. Then, we demonstrate that transfer learning improves the ability to repair vulnerable C functions. We also show that the transfer learning model performs better than a model trained with a denoising task and fine-tuned on the vulnerability fixing task. To sum up, this paper shows that transfer learning works well for repairing security vulnerabilities in C compared to learning on a small dataset.",1939-3520,,10.1109/TSE.2022.3147265,"Wallenberg Artificial Intelligence, Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; Swedish Foundation for Strategic Research; National Science Foundation(grant numbers:CCF-1750399); Vetenskapsrådet(grant numbers:2018-05973); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9699412,Vulnerability fixing;transfer learning;seq2seq learning,Transfer learning;Task analysis;Computer bugs;Transformers;Codes;Training;Software,,39,,81,CCBY,1 Feb 2022,,,IEEE,IEEE Journals,True
Line-Level Defect Prediction by Capturing Code Contexts with Graph Convolutional Networks,S. Yin; S. Guo; H. Li; C. Li; R. Chen; X. Li; H. Jiang,"School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Computer and Artificial Intelligence, Liaoning Normal University, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,20,"Software defect prediction refers to the systematic analysis and review of software using various approaches and tools to identify potential defects or errors. Software defect prediction aids developers in swiftly identifying defects and optimizing development resource allocation, thus enhancing software quality and reliability. Previous defect prediction approaches still face two main limitations: 1) lacking of contextual semantic information and 2) Ignoring the joint reasoning between different granularities of defect predictions. In response to these challenges, we propose LineDef, a line-level defect prediction approach by capturing code contexts with graph convolutional networks. Specifically, LineDef comprises three components: the token embedding component, the graph extraction component, and the multi-granularity defect prediction component. The token embedding component maps each token to a vector to obtain a high-dimensional semantic feature representation of the token. Subsequently, the graph extraction component utilizes a sliding window to extract line-level and token-level graphs, addressing the challenge of capturing contextual semantic relationships in the code. Finally, the multi-granularity defect prediction component leverages graph convolutional layers and attention mechanisms to acquire prediction labels and risk scores, thereby achieving file-level and line-level defect prediction. Experimental studies on 32 datasets across 9 different software projects show that LineDef exhibits significantly enhanced balanced accuracy, ranging from 15.61% to 45.20%, compared to state-of-the-art file-level defect prediction approaches, and a remarkable cost-effectiveness improvement ranging from 15.32% to 278%, compared to state-of-the-art line-level defect prediction approaches. These results demonstrate that LineDef approach can extract more comprehensive information from lines of code for defect prediction.",1939-3520,,10.1109/TSE.2024.3503723,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10759072,Line-level defect prediction;software quality assurance;graph convolutional network,Codes;Semantics;Distance measurement;Costs;Reviews;Predictive models;Indexes;Feature extraction;Convolutional codes;Cognition,,,,,IEEE,20 Nov 2024,,,IEEE,IEEE Early Access Articles,True
BEQAIN: An Effective and Efficient Identifier Normalization Approach With BERT and the Question Answering System,J. Zhang; S. Liu; L. Gong; H. Zhang; Z. Huang; H. Jiang,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Queen's University, Kingston, ON, Canada; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; School of Software, Dalian University of Technology, Dalian, China",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2597,2620,"As one of the most important resources to express the semantics of source code, identifiers are usually composed of several common or domain-specific terms and abbreviations, thus heavily hindering developers from analyzing and comprehending source code. Hence, it is very necessary to normalize identifiers, which aims to align the vocabulary found in identifiers with natural language words found in other software artifacts. Even though researchers have proposed several identifier normalization approaches in the literature, these approaches only rely on the lexical information in identifiers and related source code entities to normalize identifiers, suffering from the lack of deep semantic understanding of identifiers. In this paper, we propose an effective and efficient identifier normalization approach BEQAIN to split identifiers into their composing words and expand the enclosed abbreviations. Specifically, BEQAIN employs a deep learning model, which is mainly composed of a Bidirectional Encoder Representation from Transformers (BERT) layer and a Conditional Random Fields (CRF) layer to embed identifiers into low-level vectors and learn the identifier splitting patterns. The BERT-CRF network is also combined with a pre-processing component and a post-processing component to resolve the problems of over-splitting and under-splitting so as to improve the identifier splitting performance. Furthermore, BEQAIN also employs a Question Answering (Q&A) system to learn the abbreviation expansion mappings and leverages the current programming context to determine the exactly correct expansion when there are multiple expansions for specific abbreviations. After BEQAIN is fully trained, it can be used to normalize identifiers. We conduct extensive experiments to validate the effectiveness and efficiency of BEQAIN over two publicly available datasets with nine projects. Experimental results show that BEQAIN achieves the overall average Accuracy of 80.20% and outperforms the existing state-of-the-art approach by 9.88% in normalizing identifiers. The pre-processing and post-processing components could improve the Accuracy of BEQAIN in identifier splitting by 11.70%. Employing the programming context information could improve the Accuracy of BEQAIN in abbreviation expansion by 11.15% on average. In addition, the average normalization time of BEQAIN is less than one second. Finally, we also discuss some observations for the road ahead for identifier normalization to inspire other researchers.",1939-3520,,10.1109/TSE.2022.3227559,"National Natural Science Foundation of China(grant numbers:61902181,62032004); Nanjing University of Aeronautics and Astronautics; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9976241,Identifier expansion;identifier normalization;identifier splitting;source code comprehension,Source coding;Software;Semantics;Programming;Natural languages;Codes;Task analysis,,3,,57,IEEE,8 Dec 2022,,,IEEE,IEEE Journals,True
An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation,M. Schäfer; S. Nadi; A. Eghbali; F. Tip,"GitHub, Kidlington, U.K.; University of Alberta, Edmonton, Canada; University of Stuttgart, Stuttgart, Baden-Württemberg, Germany; Northeastern University, Boston, MA, USA",IEEE Transactions on Software Engineering,8 Jan 2024,2024,50,1,85,105,"Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. Large Language Models (LLMs) have recently been applied to various aspects of software development, including their suggested use for automated generation of unit tests, but while requiring additional training or few-shot learning on examples of existing tests. This paper presents a large-scale empirical evaluation on the effectiveness of LLMs for automated unit test generation without requiring additional training or manual effort. Concretely, we consider an approach where the LLM is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. Furthermore, if a generated test fails, our approach attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We implement our approach in TestPilot, an adaptive LLM-based test generation tool for JavaScript that automatically generates unit tests for the methods in a given project's API. We evaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a total of 1,684 API functions. The generated tests achieve a median statement coverage of 70.2% and branch coverage of 52.8%. In contrast, the state-of-the feedback-directed JavaScript test generation technique, Nessie, achieves only 51.3% statement coverage and 25.6% branch coverage. Furthermore, experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. We also find that 92.8% of TestPilot's generated tests have $\leq$≤ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies. Finally, we run TestPilot with two additional LLMs, OpenAI's older code-cushman-002 LLM and StarCoder, an LLM for which the training process is publicly documented. Overall, we observed similar results with the former (68.2% median statement coverage), and somewhat worse results with the latter (54.0% median statement coverage), suggesting that the effectiveness of the approach is influenced by the size and training set of the LLM, but does not fundamentally depend on the specific model.",1939-3520,,10.1109/TSE.2023.3334955,"National Science Foundation(grant numbers:CCF-1907727,CCF-2307742); Canada Research Chairs; Natural Sciences and Engineering Research Council of Canada (NSERC)(grant numbers:RGPIN-2017-04289); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329992,Test generation;JavaScript;language models,Training;Test pattern generators;Documentation;Codes;Source coding;Software;Electronic mail,,25,,83,IEEE,28 Nov 2023,,,IEEE,IEEE Journals,True
Diversity-Oriented Testing for Competitive Game Agent via Constraint-Guided Adversarial Agent Training,X. Ma; Y. Wang; J. Wang; X. Xie; B. Wu; Y. Yan; S. Li; F. Xu; Q. Wang,"State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Singapore Management University, Singapore; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,16,"Deep reinforcement learning has achieved remarkable success in competitive games, surpassing human performance in applications ranging from business competitions to video games. In competitive environments, agents face the challenge of adapting to continuously shifting adversary strategies, necessitating the ability to handle diverse scenarios. Existing studies primarily focus on evaluating agent robustness either through perturbing observations, which has practical limitations, or through training adversarial agents to expose weaknesses, which lacks strategy diversity exploration. There are also studies which rely on curiosity-based mechanism to explore the diversity, yet they may lack direct guidance to enhance identified decision-making flaws. In this paper, we propose a novel diversity-oriented testing framework (called AdvTest) to test the competitive game agent via constraint-guided adversarial agent training. Specifically, AdvTest adds constraints as the explicit guidance during adversarial agent training to make it capable of defeating the target agent using diverse strategies. To realize the method, three challenges need to be addressed, i.e., what are the suitable constraints, when to introduce constraints, and which constraint should be added. We experimentally evaluate AdvTest on the commonly-used competitive game environment, StarCraft II. The results on four maps show that AdvTest exposes more diverse failure scenarios compared with the commonly-used and state-of-the-art baselines.",1939-3520,,10.1109/TSE.2024.3491193,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10742957,Adversarial Agent;Constrained Reinforcement Learning;Testing Diversity,Training;Testing;Games;Reinforcement learning;Decision making;Business;Safety;Robustness;Fault diagnosis;Diversity methods,,,,,IEEE,5 Nov 2024,,,IEEE,IEEE Early Access Articles,True
Reinforcement Learning for Test Case Prioritization,M. Bagherzadeh; N. Kahani; L. Briand,"School of EECS, University of Ottawa, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada",IEEE Transactions on Software Engineering,16 Aug 2022,2022,48,8,2836,2856,"Continuous Integration (CI) significantly reduces integration problems, speeds up development time, and shortens release time. However, it also introduces new challenges for quality assurance activities, including regression testing, which is the focus of this work. Though various approaches for test case prioritization have shown to be very promising in the context of regression testing, specific techniques must be designed to deal with the dynamic nature and timing constraints of CI. Recently, Reinforcement Learning (RL) has shown great potential in various challenging scenarios that require continuous adaptation, such as game playing, real-time ads bidding, and recommender systems. Inspired by this line of work and building on initial efforts in supporting test case prioritization with RL techniques, we perform here a comprehensive investigation of RL-based test case prioritization in a CI context. To this end, taking test case prioritization as a ranking problem, we model the sequential interactions between the CI environment and a test case prioritization agent as an RL problem, using three alternative ranking models. We then rely on carefully selected and tailored state-of-the-art RL techniques to automatically and continuously learn a test case prioritization strategy, whose objective is to be as close as possible to the optimal one. Our extensive experimental analysis shows that the best RL solutions provide a significant accuracy improvement over previous RL-based work, with prioritization strategies getting close to being optimal, thus paving the way for using RL to prioritize test cases in a CI context.",1939-3520,,10.1109/TSE.2021.3070549,Huawei Technologies Canada; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394799,Continuous integration;CI;reinforcement learning;test prioritization,Testing;History;Training;Reinforcement learning;Software systems;Adaptation models;Software algorithms,,39,,78,IEEE,2 Apr 2021,,,IEEE,IEEE Journals,True
Mitigating the Uncertainty and Imprecision of Log-Based Code Coverage Without Requiring Additional Logging Statements,X. Xu; F. R. Cogo; S. McIntosh,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada; Huawei Centre for Software Excellence, Kingston, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2350,2362,"Understanding code coverage is an important precursor to software maintenance activities (e.g., better testing). Although modern code coverage tools provide key insights, they typically rely on code instrumentation, resulting in significant performance overhead. An alternative approach to code instrumentation is to process an application's source code and the associated log traces in tandem. This so-called “log-based code coverage” approach does not impose the same performance overhead as code instrumentation. Chen et al. proposed LogCoCo — a tool that implements log-based code coverage for Java. While LogCoCo breaks important new ground, it has fundamental limitations, namely: uncertainty due to the lack of logging statements in conditional branches, and imprecision caused by dependency injection. In this study, we propose Log2Cov, a tool that generates log-based code coverage for programs written in Python and addresses uncertainty and imprecision issues. We evaluate Log2Cov on three large and active open-source systems. More specifically, we compare the performance of Log2Cov to that of Coverage.py, an instrumentation-based coverage tool for Python. Our results indicate that 1) Log2Cov achieves high precision without introducing runtime overhead; and 2) uncertainty and imprecision can be reduced by up to 11% by statically analyzing the program's source code and execution logs, without requiring additional logging instrumentation from developers. While our enhancements make substantial improvements, we find that future work is needed to handle conditional statements and exception handling blocks to achieve parity with instrumentation-based approaches. We conclude the paper by drawing attention to these promising directions for future work.",1939-3520,,10.1109/TSE.2024.3435067,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10613788,Static analysis;code coverage;software logging,Codes;Instruments;Uncertainty;Software;Python;Runtime;Source coding,,,,52,IEEE,29 Jul 2024,,,IEEE,IEEE Journals,True
CirFix: Automated Hardware Repair and its Real-World Applications,P. Santiesteban; Y. Huang; W. Weimer; H. Ahmad,"Computer Science and Engineering, University of Michigan, Ann Arbor, MI, USA; Computer Science, Vanderbilt University, Nashville, TN, USA; Computer Science and Engineering, University of Michigan, Ann Arbor, MI, USA; Computer Science and Engineering, University of Michigan, Ann Arbor, MI, USA",IEEE Transactions on Software Engineering,17 Jul 2023,2023,49,7,3736,3752,"This article presents CirFix, a framework for automatically repairing defects in hardware designs implemented in languages like Verilog. We propose a novel fault localization approach based on assignments to wires and registers, and a fitness function tailored to the hardware domain to bridge the gap between software-level automated program repair and hardware descriptions. We also present a benchmark suite of 32 defect scenarios corresponding to a variety of hardware projects. Overall, CirFix produces plausible repairs for 21/32 and correct repairs for 16/32 of the defect scenarios. Additionally, we evaluate CirFix's fault localization independently through a human study (n = 41), and find that the approach may be a beneficial debugging aid for complex multi-line hardware defects.",1939-3520,,10.1109/TSE.2023.3269899,National Science Foundation(grant numbers:1908633); Air Force Research Laboratory(grant numbers:2211749); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108500,Circuit designs;automated repair;empirical study;user study,Hardware;Maintenance engineering;Circuit faults;Hardware design languages;Location awareness;Wires;Software,,1,,120,IEEE,25 Apr 2023,,,IEEE,IEEE Journals,True
Aroc: An Automatic Repair Framework for On-Chain Smart Contracts,H. Jin; Z. Wang; M. Wen; W. Dai; Y. Zhu; D. Zou,"National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China",IEEE Transactions on Software Engineering,11 Nov 2022,2022,48,11,4611,4629,"Ongoing smart contract attack events have seriously impeded the practical application of blockchain. Although lots of researches have been conducted, they mostly focus on off-chain vulnerability detection. However, smart contracts cannot be modified once they have been deployed on-chain, thus existing techniques cannot protect those deployed contracts from being attacked. To mitigate this problem, we propose a general smart contract repairer named Aroc, which can automatically patch vulnerable deployed contracts without changing the contract codes. The core insight of Aroc is to generate patch contracts to abort malicious transactions in advance. Taking the three most serious bug types (i.e., reentrancy, arithmetic bugs, and unchecked low-level checks) as examples, we present how Aroc automatically repairs them on-chain. We conduct abundant evaluations on four kinds of datasets to evaluate the effectiveness and efficiency of Aroc. In particular, Aroc can repair 95.95% of the vulnerable contracts with an average correctness ratio of 93.32%. Meanwhile, Aroc introduces acceptable additional overheads to smart contract users and blockchain miners. When compared with the state-of-the-art techniques, Aroc introduces either fewer execution overheads or contract codes.",1939-3520,,10.1109/TSE.2021.3123170,"National Key Research and Development Program of China(grant numbers:2020YFB1006000); National Natural Science Foundation of China(grant numbers:62072202,62002125); Science and Technology Program of Guangzhou, China(grant numbers:201902020016); Fundamental Research Funds for the Central Universities(grant numbers:2020JYCXJJ068); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9591399,Smart contract;vulnerability;repair;on-chain protection,Contracts;Smart contracts;Codes;Blockchains;Computer bugs;Maintenance engineering;Task analysis,,14,,40,CCBYNCND,27 Oct 2021,,,IEEE,IEEE Journals,True
Long Live the Image: On Enabling Resilient Production Database Containers for Microservice Applications,Z. Li; N. Saldías-Vallejos; D. Seco; M. A. Rodríguez; R. Ranjan,"School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, U.K.; Department of Computer Science, University of Concepción, Concepción, Chile; Department of Computer Science and Information Technologies, Universidade de A Coruña, A Coruña, Spain; Department of Computer Science, University of Concepción, Concepción, Chile; School of Computing, Newcastle University, Newcastle upon Tyne, U.K.",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2363,2378,"Microservices architecture advocates decentralized data ownership for building software systems. Particularly, in the Database per Service pattern, each microservice is supposed to maintain its own database and to handle the data related to its functionality. When implementing microservices in practice, however, there seems to be a paradox: The de facto technology (i.e., containerization) for microservice implementation is claimed to be unsuitable for the microservice component (i.e., database) in production environments, mainly due to the data persistence issues (e.g., dangling volumes) and security concerns. As a result, the existing discussions generally suggest replacing database containers with cloud database services, while leaving the on-premises microservice implementation out of consideration. After identifying three statelessness-dominant application scenarios, we proposed container-native data persistence as a conditional solution to enable resilient database containers in production. In essence, this data persistence solution distinguishes stateless data access (i.e., reading) from stateful data processing (i.e., creating, updating, and deleting), and thus it aims at the development of stateless microservices for suitable applications. In addition to developing our proposal, this research is particularly focused on its validation, via prototyping the solution and evaluating its performance, and via applying this solution to two real-world microservice applications. From the industrial perspective, the validation results have proved the feasibility, usability, and efficiency of fully containerized microservices for production in applicable situations. From the academic perspective, this research has shed light on the operation-side micro-optimization of individual microservices, which fundamentally expands the scope of “software micro-optimization” and reveals new research opportunities.",1939-3520,,10.1109/TSE.2024.3436623,ANID Millennium Science Initiative Program(grant numbers:Code ICN17_002); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620003,Container;data persistence;read-only database;stateless microservice;microservices architecture,Databases;Containers;Microservice architectures;Production;Usability;Runtime;Prototypes,,,,67,IEEE,1 Aug 2024,,,IEEE,IEEE Journals,True
Test Data Generation for Mutation Testing Based on Markov Chain Usage Model and Estimation of Distribution Algorithm,C. Wei; X. Yao; D. Gong; H. Liu,"School of Mathematics, China University of Mining and Technology, Xuzhou, China; School of Mathematics, China University of Mining and Technology, Xuzhou, China; College of Automation and Electronic Engineering, Qingdao University of Science and Technology, Qingdao, Shandong, China; Department of Computing Technologies, Swinburne University of Technology, Melbourne, VIC, Australia",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,551,573,"Mutation testing, a mainstream fault-based software testing technique, can mimic a wide variety of software faults by seeding them into the target program and resulting in the so-called mutants. Test data generated in mutation testing should be able to kill as many mutants as possible, hence guaranteeing a high fault-detection effectiveness of testing. Nevertheless, the test data generation can be very expensive, because mutation testing normally involves an extremely large number of mutants and some mutants are hard to kill. It is thus a critical yet challenging job to find an efficient way to generate a small set of test data that are able to kill multiple mutants at the same time as well as reveal those hard-to-detect faults. In this paper, we propose a new approach for test data generation in mutation testing, through the novel applications of the Markov chain usage model and the estimation of distribution algorithm. We first utilize the Markov chain usage model to reduce the so-called mutant branches in weak mutation testing and generate a minimal set of extended paths. Then, we regard the problem of generating test data as the problem of covering extended paths and use an estimation of distribution algorithm based on probability model to solve the problem. Finally, we develop a framework, TAMMEA, to implement the new approach of generating test data for mutation testing. The empirical studies based on fifteen object programs show that TAMMEA can kill more mutants using fewer test data compared with baseline techniques. In addition, the computation overhead of TAMMEA is lower than that of the baseline technique based on the traditional genetic algorithm, and comparable to that of the random method. It is clear that the new approach improves both the effectiveness and efficiency of mutation testing, thus promoting its practicability.",1939-3520,,10.1109/TSE.2024.3358297,"National Natural Science Foundation of China(grant numbers:62373357,42230704); Graduate Innovation Program of China University of Mining and Technology(grant numbers:2021WLKXJ074); 2021 Postgraduate Research and Practice Innovation Program of Jiangsu Province(grant numbers:KYCX21_2136); Major Project of Natural Science Research of the Jiangsu Higher Education Institutions of China(grant numbers:21KJA520006); Xuzhou Science and Technology Program(grant numbers:KC21007); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10413895,Mutation testing;weak mutation;test data generation;Markov chain usage model;coverage of extended path;estimation of distribution algorithm,Testing;Markov processes;Estimation;Software algorithms;Genetic algorithms;Data models;Costs,,1,,51,IEEE,24 Jan 2024,,,IEEE,IEEE Journals,True
D3: Differential Testing of Distributed Deep Learning with Model Generation,J. Wang; H. V. Pham; Q. Li; L. Tan; Y. Guo; A. Aziz; E. Meijer,"Computer Science Department, Purdue University, USA; Electrical Engineering and Computer Science Department, York University, Canada; Computer Science Department, Purdue University, USA; Computer Science Department, Purdue University, USA; Meta Inc., Menlo Park, USA; Meta Inc., Menlo Park, USA; Meta Inc., Menlo Park, USA",IEEE Transactions on Software Engineering,,2024,PP,99,1,16,"Deep Learning (DL) techniques have been widely deployed in many application domains. The growth of DL models’ size and complexity demands distributed training of DL models. Since DL training is complex, software implementing distributed DL training is error-prone. Thus, it is crucial to test distributed deep learning software to improve its reliability and quality. To address this issue, we propose a differential testing technique—D3, which leverages a distributed equivalence rule that we create to test distributed deep learning software. The rationale is that the same model trained with the same model input under different distributed settings should produce equivalent prediction output within certain thresholds. The different output indicates potential bugs in the distributed deep learning software. D3 automatically generates a diverse set of distributed settings, DL models, and model input to test distributed deep learning software. Our evaluation on two of the most popular DL libraries, i.e., PyTorch and TensorFlow, shows that D3 detects 21 bugs, including 12 previously unknown bugs.",1939-3520,,10.1109/TSE.2024.3461657,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10680992,software testing;distributed deep learning;differential testing;model generation,Training;Computer bugs;Software;Sharding;Deep learning;Codes;Testing,,,,,IEEE,16 Sep 2024,,,IEEE,IEEE Early Access Articles,True
Revisiting Supervised and Unsupervised Methods for Effort-Aware Cross-Project Defect Prediction,C. Ni; X. Xia; D. Lo; X. Chen; Q. Gu,"School of Software Technology, Zhejiang University, Ningbo, Zhejiang, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; School of Information Systems, Singapore Management University, Singapore; School of Information Science and Technology Science, Nantong University, Nantong, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,15 Mar 2022,2022,48,3,786,802,"Cross-project defect prediction (CPDP), aiming to apply defect prediction models built on source projects to a target project, has been an active research topic. A variety of supervised CPDP methods and some simple unsupervised CPDP methods have been proposed. In a recent study, Zhou et al. found that simple unsupervised CPDP methods (i.e., ManualDown and ManualUp) have a prediction performance comparable or even superior to complex supervised CPDP methods. Therefore, they suggested that the ManualDown should be treated as the baseline when considering non-effort-aware performance measures (NPMs) and the ManualUp should be treated as the baseline when considering effort-aware performance measures (EPMs) in future CPDP studies. However, in that work, these unsupervised methods are only compared with existing supervised CPDP methods using a small subset of NPMs, and the prediction results of baselines are directly collected from the primary literatures. Besides, the comparison has not considered other recently proposed EPMs, which consider context switches and developer fatigue due to initial false alarms. These limitations may not give a holistic comparison between the supervised methods and unsupervised methods. In this paper, we aim to revisit Zhou et al.’s study. To the best of our knowledge, we are the first to make a comparison between the existing supervised CPDP methods and the unsupervised methods proposed by Zhou et al. in the same experimental setting when considering both NPMs and EPMs. We also propose an improved supervised CPDP method EASC and make a further comparison with the unsupervised methods. According to the results on 82 projects in terms of 11 performance measures, we find that when considering NPMs, EASC can achieve prediction performance comparable or even superior to unsupervised method ManualDown in most cases. Besides, when considering EPMs, EASC can statistically significantly outperform the unsupervised method ManualUp with a large improvement in terms of Cliff’s delta in most cases. Therefore, the supervised CPDP methods are more promising than the unsupervised method in practical application scenarios, since the limitation of testing resource and the impact on developers cannot be ignored in these scenarios.",1939-3520,,10.1109/TSE.2020.3001739,"Australian Research Council(grant numbers:DE200100021); National Natural Science Foundation of China(grant numbers:61872057,61972192,61872263,61702041); Nanjing University(grant numbers:KFKT2019B14); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115238,Defect prediction;cross-project;supervised model;unsupervised model,Manuals;Predictive models;Atmospheric measurements;Particle measurements;Data models;Software;Testing,,52,,80,IEEE,11 Jun 2020,,,IEEE,IEEE Journals,True
Accelerating Patch Validation for Program Repair With Interception-Based Execution Scheduling,Y. -A. Xiao; C. Yang; B. Wang; Y. Xiong,"Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, School of Computer Science, Peking University, Beijing, China; Peking University, Beijing, China; School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, School of Computer Science, Peking University, Beijing, China",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,618,635,"Long patch validation time is a limiting factor for automated program repair (APR). Though the duality between patch validation and mutation testing is recognized, so far there exists no study of systematically adapting mutation testing techniques to general-purpose patch validation. To address this gap, we investigate existing mutation testing techniques and identify five classes of acceleration techniques that are suitable for general-purpose patch validation. Among them, mutant schemata and mutant deduplication have not been adapted to general-purpose patch validation due to the arbitrary changes that third-party APR approaches may introduce. This presents two problems for adaption: 1) the difficulty of implementing the static equivalence analysis required by the state-of-the-art mutant deduplication approach; 2) the difficulty of capturing the changes of patches to the system state at runtime. To overcome these problems, we propose two novel approaches: 1) execution scheduling, which detects the equivalence between patches online, avoiding the static equivalence analysis and its imprecision; 2) interception-based instrumentation, which intercepts the changes of patches to the system state, avoiding a full interpreter and its overhead. Based on the contributions above, we implement ExpressAPR, a general-purpose patch validator for Java that integrates all recognized classes of techniques suitable for patch validation. Our large-scale evaluation with four APR approaches shows that ExpressAPR accelerates patch validation by 137.1x over plain validation or 8.8x over the state-of-the-art approach, making patch validation no longer the time bottleneck of APR. Patch validation time for a single bug can be reduced to within a few minutes on mainstream CPUs.",1939-3520,,10.1109/TSE.2024.3359969,"National Key Research and Development Program of China(grant numbers:2022YFB4501902); National Natural Science Foundation of China(grant numbers:62202040,62161146003); ZTE Industry-University-Institute Cooperation Funds(grant numbers:HC-CN-20210319008); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10417068,Automated program repair;patch validation,Testing;Maintenance engineering;Life estimation;Computer bugs;Runtime;Instruments;Codes,,1,,77,IEEE,30 Jan 2024,,,IEEE,IEEE Journals,True
Machine Learning for Technical Debt Identification,D. Tsoukalas; N. Mittas; A. Chatzigeorgiou; D. Kehagias; A. Ampatzoglou; T. Amanatidis; L. Angelis,"Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Chemistry, International Hellenic University, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Centre for Research and Technology Hellas/Information Technologies Institute, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Computer Science Department, Aristotle University of Thessaloniki, Thessaloniki, Greece",IEEE Transactions on Software Engineering,9 Dec 2022,2022,48,12,4892,4906,"Technical Debt (TD) is a successful metaphor in conveying the consequences of software inefficiencies and their elimination to both technical and non-technical stakeholders, primarily due to its monetary nature. The identification and quantification of TD rely heavily on the use of a small handful of sophisticated tools that check for violations of certain predefined rules, usually through static analysis. Different tools result in divergent TD estimates calling into question the reliability of findings derived by a single tool. To alleviate this issue we use 18 metrics pertaining to source code, repository activity, issue tracking, refactorings, duplication and commenting rates of each class as features for statistical and Machine Learning models, so as to classify them as High-TD or not. As a benchmark we exploit 18,857 classes obtained from 25 Java projects, whose high levels of TD has been confirmed by three leading tools. The findings indicate that it is feasible to identify TD issues with sufficient accuracy and reasonable effort: a subset of superior classifiers achieved an F$_2$2-measure score of approximately 0.79 with an associated Module Inspection ratio of approximately 0.10. Based on the results a tool prototype for automatically assessing the TD of Java projects has been implemented.",1939-3520,,10.1109/TSE.2021.3129355,European Union's Horizon 2020 Research and Innovation Programme(grant numbers:801015); SmartCLIDE(grant numbers:871177); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9622154,Machine learning;metrics/measurement;quality analysis and evaluation;software maintenance,Tools;Software;Java;Radio frequency;Codes;Support vector machines;Benchmark testing,,10,,47,IEEE,19 Nov 2021,,,IEEE,IEEE Journals,True
CAGFuzz: Coverage-Guided Adversarial Generative Fuzzing Testing for Image-Based Deep Learning Systems,P. Zhang; B. Ren; H. Dong; Q. Dai,"Key Laboratory of Water Big Data Technology of Ministry of Water Resources & the College of Computer and Information, Hohai University, Nanjing, China; Key Laboratory of Water Big Data Technology of Ministry of Water Resources & the College of Computer and Information, Hohai University, Nanjing, China; School of Computing Technologies, RMIT University, Melbourne, VIC, Australia; Key Laboratory of Water Big Data Technology of Ministry of Water Resources & the College of Computer and Information, Hohai University, Nanjing, China",IEEE Transactions on Software Engineering,11 Nov 2022,2022,48,11,4630,4646,"Deep Neural Network (DNN) driven technologies have been extensively employed in various aspects of our life. Nevertheless, the applied DNN always fails to detect erroneous behaviors, which may lead to serious problems. Several approaches have been proposed to enhance adversarial examples for automatically testing deep learning (DL) systems, such as image-based DL systems. However, the approaches contain the following two limitations. First, existing approaches only take into account small perturbations on adversarial examples, they design and generate adversarial examples for a certain particular DNN model. This might hamper the transferability of the examples for other DNN models. Second, they only use shallow features (e.g., pixel-level features) to judge the differences between the generated adversarial examples and the original examples. The deep features, which contain high-level semantic information, such as image object categories and scene semantics, are completely neglected. To address these two problems, we propose CAGFuzz, a Coverage-guided Adversarial Generative Fuzzing testing approach for image-based DL systems. CAGFuzz is able to generate adversarial examples for mainstream DNN models to discover their potential errors. First, we train an Adversarial Example Generator (AEG) based on general datasets. AEG only considers the data characteristics to alleviate the transferability problem. Second, we extract the deep features of the original and adversarial examples, and constrain the adversarial examples by cosine similarity to ensure that the deep features of the adversarial examples remain unchanged. Finally, we use the adversarial examples to retrain the models. Based on several standard datasets, we design a set of dedicated experiments to evaluate CAGFuzz. The experimental results show that CAGFuzz can detect more hidden errors, enhance the accuracy of the target DNN models, and generate adversarial examples with higher transferability.",1939-3520,,10.1109/TSE.2021.3124006,Natural Science Foundation of Jiangsu Province(grant numbers:BK20191297); Fundamental Research Funds for the Central Universities(grant numbers:B210202075); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599374,Deep neural network;fuzz testing;adversarial example;coverage criteria,Testing;Fuzzing;Generators;Neurons;Feature extraction;Perturbation methods;Semantics,,16,,73,IEEE,2 Nov 2021,,,IEEE,IEEE Journals,True
Leveraging Android Automated Testing to Assist Crowdsourced Testing,X. Ge; S. Yu; C. Fang; Q. Zhu; Z. Zhao,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2318,2336,"Crowdsourced testing is an emerging trend in mobile application testing. The openness of crowdsourced testing provides a promising way to conduct large-scale and user-oriented testing scenarios on various mobile devices, while it also brings a problem, i.e., crowdworkers with different levels of testing experience severely threaten the quality of crowdsourced testing. Currently, many approaches have been proposed and studied to improve crowdsourced testing. However, these approaches do not fundamentally improve the ability of crowdworkers. In essence, the low-quality crowdsourced testing is caused by crowdworkers who are unfamiliar with the App Under Test (AUT) and do not know which part of the AUT should be tested. To address this problem, we propose a testing assistance approach, which leverages Android automated testing (i.e., dynamic and static analysis) to improve crowdsourced testing. Our approach constructs an Annotated Window Transition Graph (AWTG) model for the AUT by merging dynamic and static analysis results. Based on the AWTG model, our approach implements a testing assistance pipeline that provides the test task extraction, test task recommendation, and test task guidance to assist crowdworkers in testing the AUT. We experimentally evaluate our approach on real-world AUTs. The quantitative results demonstrate that our approach can effectively and efficiently assist crowdsourced testing. Besides, the qualitative results from a user study confirm the usefulness of our approach.",1939-3520,,10.1109/TSE.2022.3216879,"National Natural Science Foundation of China(grant numbers:62141215,62272220,61802171); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:CJGJZD20200617103001003); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9928381,Crowdsourced testing;dynamic analysis;static analysis;test recommendation;test assistance,Testing;Task analysis;Static analysis;Computer bugs;Windows;Mobile applications;Analytical models,,3,,76,IEEE,25 Oct 2022,,,IEEE,IEEE Journals,True
Human-in-the-Loop Automatic Program Repair,C. Geethal; M. Böhme; V. -T. Pham,"Monash University, Clayton, VIC, Australia; Monash University, Clayton, VIC, Australia; The University of Melbourne, Carlton, VIC, Australia",IEEE Transactions on Software Engineering,17 Oct 2023,2023,49,10,4526,4549,"learn2fix is a human-in-the-loop interactive program repair technique, which can be applied when no bug oracle—except the user who is reporting the bug—is available. This approach incrementally learns the condition under which the bug is observed by systematic negotiation with the user. In this process, learn2fix generates alternative test inputs and sends some of those to the user for obtaining their labels. A limited query budget is assigned to the user for this task. A query is a Yes/No question: “When executing this alternative test input, the program under test produces the following output; is the bug observed?”. Using the labelled test inputs, learn2fix incrementally learns an automatic bug oracle to predict the user's response. A classification algorithm in machine learning is used for this task. Our key challenge is to maximise the oracle's accuracy in predicting the tests that expose the bug given a practical, small budget of queries. After learning the automatic oracle, an existing program repair tool attempts to repair the bug using the alternative tests that the user has labelled. Our experiments demonstrate that learn2fix trains a sufficiently accurate automatic oracle with a reasonably low labelling effort (lt. 20 queries), and the oracles represented by interpolation-based classifiers produce more accurate predictions than those represented by approximation-based classifiers. Given the user-labelled test inputs, generated using the interpolation-based approach, the GenProg and Angelix automatic program repair tools produce patches that pass a much larger proportion of validation tests than the manually constructed test suites provided by the repair benchmark.",1939-3520,,10.1109/TSE.2023.3305052,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225252,Automated test oracles;semi-automatic program repair;classification algorithms;active machine learning,Maintenance engineering;Computer bugs;Labeling;Classification algorithms;Human in the loop;Fuzzing;Training,,,,70,CCBYNCND,21 Aug 2023,,,IEEE,IEEE Journals,True
Towards Saving Blockchain Fees via Secure and Cost-Effective Batching of Smart-Contract Invocations,Y. Wang; K. Li; Y. Tang; J. Chen; Q. Zhang; X. Luo; T. Chen,"Syracuse University, Syracuse, NY, USA; San Diego State University, San Diego, CA, USA; Syracuse University, Syracuse, NY, USA; Syracuse University, Syracuse, NY, USA; Syracuse University, Syracuse, NY, USA; Hong Kong Polytechnic University, Hung Hom, Hong Kong; University of Electronic Science, Technology of China, Chengdu, Sichuan, China",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2980,2995,"This paper presents iBatch, a middleware system running on top of an operational Ethereum network to enable secure batching of smart-contract invocations against an untrusted relay server off-chain. iBatch does so at a low overhead by validating the server's batched invocations in smart contracts without additional states of user nonces. The iBatch mechanism supports a variety of policies, ranging from conservative to aggressive batching, and can be configured adaptively to the current workloads. iBatch automatically rewrites smart contracts to integrate with legacy applications and support large-scale deployment. We built an evaluation platform for fast and cost-accurate transaction replaying and constructed real transaction benchmarks on popular Ethereum applications. With a functional prototype of iBatch, we conduct extensive cost evaluations, which shows iBatch saves $14.6\%\sim {}59.1\%$14.6%∼59.1% Gas cost per invocation with a moderate 2-minute delay and $19.06\%\sim {}31.52\%$19.06%∼31.52% Ether cost per invocation with a delay of $0.26\sim {}1.66$0.26∼1.66 blocks.",1939-3520,,10.1109/TSE.2023.3237123,"National Science Foundation(grant numbers:CNS1815814,DGE2104532,CNS2139801); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10018598,Blockchains;cost effectiveness;DeFi;replay attacks;smart contracts,Costs;Decentralized applications;Blockchains;Smart contracts;Delays;Middleware;Relays,,6,,62,IEEE,17 Jan 2023,,,IEEE,IEEE Journals,True
A Search-Based Testing Approach for Deep Reinforcement Learning Agents,A. Zolfagharian; M. Abdellatif; L. C. Briand; M. Bagherzadeh; R. S,"School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, ON, Canada; Software and Information Technology Engineering Department, École de Technologie Supérieure, Montreal, QC, Canada; School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, ON, Canada; Cisco, Ottawa, ON, Canada; Department of Research and Development, General Motors, Warren, MI, USA",IEEE Transactions on Software Engineering,17 Jul 2023,2023,49,7,3715,3735,"Deep Reinforcement Learning (DRL) algorithms have been increasingly employed during the last decade to solve various decision-making problems such as autonomous driving, trading decisions, and robotics. However, these algorithms have faced great challenges when deployed in safety-critical environments since they often exhibit erroneous behaviors that can lead to potentially critical errors. One of the ways to assess the safety of DRL agents is to test them to detect possible faults leading to critical failures during their execution. This raises the question of how we can efficiently test DRL policies to ensure their correctness and adherence to safety requirements. Most existing works on testing DRL agents use adversarial attacks that perturb states or actions of the agent. However, such attacks often lead to unrealistic states of the environment. Furthermore, their main goal is to test the robustness of DRL agents rather than testing the compliance of the agents’ policies with respect to requirements. Due to the huge state space of DRL environments, the high cost of test execution, and the black-box nature of DRL algorithms, exhaustive testing of DRL agents is impossible. In this paper, we propose a Search-based Testing Approach of Reinforcement Learning Agents (STARLA) to test the policy of a DRL agent by effectively searching for failing executions of the agent within a limited testing budget. We rely on machine learning models and a dedicated genetic algorithm to narrow the search toward faulty episodes (i.e., sequences of states and actions produced by the DRL agent). We apply STARLA on Deep-Q-Learning agents trained on two different RL problems widely used as benchmarks and show that STARLA significantly outperforms Random Testing by detecting more faults related to the agent's policy. We also investigate how to extract rules that characterize faulty episodes of the DRL agent using our search results. Such rules can be used to understand the conditions under which the agent fails and thus assess the risks of deploying it.",1939-3520,,10.1109/TSE.2023.3269804,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107813,Genetic algorithm;machine learning;reinforcement learning;state abstraction;testing,Testing;Reinforcement learning;Safety;Deep learning;Closed box;Training;Genetic algorithms,,15,,85,CCBY,25 Apr 2023,,,IEEE,IEEE Journals,True
CPVD: Cross Project Vulnerability Detection Based on Graph Attention Network and Domain Adaptation,C. Zhang; B. Liu; Y. Xin; L. Yao,"School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyberspace Security, Beijing University of Posts and Telecommunications, Beijing, China",IEEE Transactions on Software Engineering,14 Aug 2023,2023,49,8,4152,4168,"Code vulnerability detection is critical for software security prevention. Vulnerability annotation in large-scale software code is quite tedious and challenging, which requires domain experts to spend a lot of time annotating. This work offers CPVD, a cross-domain vulnerability detection approach based on the challenge of ”learning to predict the vulnerability labels of another item quickly using one item with rich vulnerability labels.” CPVD uses the code property graph to represent the code and uses the Graph Attention Network and Convolution Pooling Network to extract the graph feature vector. It reduces the distribution between the source domain and target domain data in the Domain Adaptation Representation Learning stage for cross-domain vulnerability detection. In this paper, we test each other on different real-world project codes. Compared with methods without domain adaptation and domain adaptation methods based on natural language processing, CPVD is more general and performs better in cross-domain vulnerability detection tasks. Specifically, for the four datasets of chr_deb, qemu, libav, and sard, they achieved the best results of 70.2%, 81.1%, 59.7%, and 78.1% respectively on the F1-Score, and 88.4%,86.3%, 85.2%, and 88.6% on the AUC.",1939-3520,,10.1109/TSE.2023.3285910,"National Natural Science Foundation of China(grant numbers:62233003,2020YFB1708602,2020YFC0833201); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10149539,Code property graph;cross-domain vulnerability detection;domain adaptation representation learning;graph attention network,Codes;Feature extraction;Task analysis;Software;Neural networks;Graph neural networks;Security,,7,,58,IEEE,13 Jun 2023,,,IEEE,IEEE Journals,True
Self-Supervised Learning to Prove Equivalence Between Straight-Line Programs via Rewrite Rules,S. Kommrusch; M. Monperrus; L. -N. Pouchet,"Colorado State University, Fort Collins, CO, USA; KTH Royal Institute of Technology, Stockholm, Sweden; Colorado State University, Fort Collins, CO, USA",IEEE Transactions on Software Engineering,17 Jul 2023,2023,49,7,3771,3792,"We target the problem of automatically synthesizing proofs of semantic equivalence between two programs made of sequences of statements. We represent programs using abstract syntax trees (AST), where a given set of semantics-preserving rewrite rules can be applied on a specific AST pattern to generate a transformed and semantically equivalent program. In our system, two programs are equivalent if there exists a sequence of application of these rewrite rules that leads to rewriting one program into the other. We propose a neural network architecture based on a transformer model to generate proofs of equivalence between program pairs. The system outputs a sequence of rewrites, and the validity of the sequence is simply checked by verifying it can be applied. If no valid sequence is produced by the neural network, the system reports the programs as non-equivalent, ensuring by design no programs may be incorrectly reported as equivalent. Our system is fully implemented for one single grammar which can represent straight-line programs with function calls and multiple types. To efficiently train the system to generate such sequences, we develop an original incremental training technique, named self-supervised sample selection. We extensively study the effectiveness of this novel training approach on proofs of increasing complexity and length. Our system, $\mathsf {S4Eq}$S4Eq, achieves 97% proof success on a curated dataset of 10,000 pairs of equivalent programs.",1939-3520,,10.1109/TSE.2023.3271065,"National Science Foundation(grant numbers:CCF-1750399); Wallenberg Artificial Intelligence, Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; Swedish Foundation for Strategic Research; Swedish National Infrastructure for Computing; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109816,Machine learning;program equivalence;self-supervised learning;symbolic reasoning,Symbols;Codes;Training;Software development management;Computational modeling;Syntactics;Source coding,,3,,98,IEEE,27 Apr 2023,,,IEEE,IEEE Journals,True
Sketch2Process: End-to-End BPMN Sketch Recognition Based on Neural Networks,B. Schäfer; H. van der Aa; H. Leopold; H. Stuckenschmidt,"Data and Web Science Group, University of Mannheim, Mannheim, Germany; Data and Web Science Group, University of Mannheim, Mannheim, Germany; Kühne Logistics University, Hamburg, Germany; Data and Web Science Group, University of Mannheim, Mannheim, Germany",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2621,2641,"Process models play an important role in various software engineering contexts. Among others, they are used to capture business-related requirements and provide the basis for the development of process-oriented applications in low-code/no-code settings. To support modelers in creating, checking, and maintaining process models, dedicated tools are available. While these tools are generally considered as indispensable to capture process models for their later use, the initial version of a process model is often sketched on a whiteboard or a piece of paper. This has been found to have great advantages, especially with respect to communication and collaboration. It, however, also creates the need to subsequently transform the model sketch into a digital counterpart that can be further processed by modeling and analysis tools. Therefore, to automate this task, various so-called sketch recognition approaches have been defined in the past. Yet, these existing approaches are too limited for use in practice, since they, for instance, require sketches to be created on a digital device or do not address the recognition of edges or textual labels. Against this background, we use this paper to introduce Sketch2Process, the first end-to-end sketch recognition approach for process models captured using BPMN. Sketch2Process uses a neural network-based architecture to recognize the shapes, edges, and textual labels of highly expressive process models, covering 25 types of BPMN elements. To train and evaluate our approach, we created a dataset consisting of 704 hand-drawn and manually annotated BPMN models. Our experiments demonstrate that our approach is highly accurate and consistently outperforms the state of the art.",1939-3520,,10.1109/TSE.2022.3228308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9980425,Requirements engineering;business process modeling;graphics recognition and interpretation,Unified modeling language;Shape;Flowcharts;Target recognition;Image edge detection;Handwriting recognition;Transforms,,2,,61,IEEE,12 Dec 2022,,,IEEE,IEEE Journals,True
No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT,Z. Liu; Y. Tang; X. Luo; Y. Zhou; L. F. Zhang,"ShanghaiTech University, Shanghai, China; University of Glasgow, Glasgow, U.K.; Department of Computing, Hong Kong Polytechnic University, Hong Kong SAR, China; Nanjing University, Nanjing, China; ShanghaiTech University, Shanghai, China",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1548,1584,"Large language models (LLMs) have demonstrated impressive capabilities across various natural language processing (NLP) tasks, such as machine translation, question answering, summarization, and so on. Additionally, LLMs are also highly valuable in supporting software engineering tasks, particularly in the field of code generation. Automatic code generation is a process of automatically generating source code or executable code based on given specifications or requirements, improving developer productivity. In this study, we perform a systematic empirical assessment to the quality of code generation using ChatGPT, a recent state-of-the-art product LLM. We leverage 728 algorithm problems in five languages (i.e., C, C++, Java, Python, and JavaScript) and 18 CWEs with 54 code scenarios for the code generation task. Our evaluation encompasses a comprehensive analysis of code snippets generated by ChatGPT, focusing on three critical aspects: correctness, complexity, and security. We also specifically investigate ChatGPT's ability to engage in multi-round fixing process (i.e., ChatGPT's dialog ability, chatting between users and ChatGPT for fixing generated buggy code) of facilitating code generation. By delving into the generated code and examining the experimental results, this work provides valuable insights into the performance of ChatGPT in tackling code generation tasks over the three critical aspects. The experimental results demonstrate that (1) ChatGPT is better at generating functionally correct code for problems before 2021 in different languages than problems after 2021 with $48.14\%$48.14% advantage in Accepted rate on judgment platform, but ChatGPT's ability to directly fix erroneous code with multi-round fixing process to achieve correct functionality is relatively weak; (2) the distribution of cyclomatic and cognitive complexity levels for code snippets in different languages varies. Furthermore, the multi-round fixing process with ChatGPT  generally preserves or increases the complexity levels of code snippets; (3) in algorithm scenarios with languages of C, C++, and Java, and CWE scenarios with languages of C and Python3, the code generated by ChatGPT  has relevant vulnerabilities. However, the multi-round fixing process for vulnerable code snippets demonstrates promising results, with more than $89\%$89% of vulnerabilities successfully addressed; and (4) code generation may be affected by ChatGPT's non-determinism factor, resulting in variations of code snippets in functional correctness, complexity, and security. Overall, our findings uncover potential issues and limitations that arise in the ChatGPT-based code generation and lay the groundwork for improving AI and LLM-based code generation techniques.",1939-3520,,10.1109/TSE.2024.3392499,"National Natural Science Foundation of China(grant numbers:62172205,62202306); HKPolyU(grant numbers:ZGGG); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10507163,Large language model;ChatGPT;code generation,Codes;Chatbots;Task analysis;Complexity theory;Security;Transformers;Electronic mail,,9,,89,IEEE,23 Apr 2024,,,IEEE,IEEE Journals,True
SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents,A. Zolfagharian; M. Abdellatif; L. C. Briand; R. S,"School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, Canada; Software and Information Technology Engineering Department, École de Technologie Supérieure, Montreal, Canada; School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, Canada; Department of Research and Development, General Motors, Warren, MI, USA",IEEE Transactions on Software Engineering,,2024,PP,99,1,25,"Deep Reinforcement Learning (DRL) has made significant advancements in various fields, such as autonomous driving, healthcare, and robotics, by enabling agents to learn optimal policies through interactions with their environments. However, the application of DRL in safety-critical domains presents challenges, particularly concerning the safety of the learned policies. DRL agents, which are focused on maximizing rewards, may select unsafe actions, leading to safety violations. Runtime safety monitoring is thus essential to ensure the safe operation of these agents, especially in unpredictable and dynamic environments. This paper introduces SMARLA, a black-box safety monitoring approach specifically designed for DRL agents. SMARLA utilizes machine learning to predict safety violations by observing the agent’s behavior during execution. The approach is based on Q-values, which reflect the expected reward for taking actions in specific states. SMARLA employs state abstraction to reduce the complexity of the state space, enhancing the predictive capabilities of the monitoring model. Such abstraction enables the early detection of unsafe states, allowing for the implementation of corrective and preventive measures before incidents occur. We quantitatively and qualitatively validated SMARLA on three well-known case studies widely used in DRL research. Empirical results reveal that SMARLA is accurate at predicting safety violations, with a low false positive rate, and can predict violations at an early stage, approximately halfway through the execution of the agent, before violations occur. We also discuss different decision criteria, based on confidence intervals of the predicted violation probabilities, to trigger safety mechanisms aiming at a trade-off between early detection and low false positive rates.",1939-3520,,10.1109/TSE.2024.3491496,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10745554,Reinforcement Learning;Safety Monitoring;Machine Learning;State Abstraction,Safety;Monitoring;Runtime;Closed box;Training;Standards;Accuracy;Vehicle dynamics;Predictive models;Decision making,,,,,IEEE,6 Nov 2024,,,IEEE,IEEE Early Access Articles,True
Trident: Controlling Side Effects in Automated Program Repair,N. Parasaram; E. T. Barr; S. Mechtaev,"University College London, London, U.K.; University College London, London, U.K.; University College London, London, U.K.",IEEE Transactions on Software Engineering,9 Dec 2022,2022,48,12,4717,4732,"The goal of program repair is to eliminate a bug in a given program by automatically modifying its source code. The majority of real-world software is written in imperative programming languages. Each function or expression in imperative code may have side effects, observable effects beyond returning a value. Existing program repair approaches have a limited ability to handle side effects. Previous test-driven semantic repair approaches only synthesise patches without side effects. Heuristic repair approaches generate patches with side effects only if suitable code fragments exist in the program or a database of repair patterns, or can be derived from training data. This work introduces Trident, the first test-driven program repair approach that synthesizes patches with side effects without relying on the plastic surgery hypothesis, a database of patterns, or training data. Trident relies on an interplay of several parts. First, it infers a specification for synthesising side-effected patches using symbolic execution with a custom state merging strategy that alleviates path explosion due to side effects. Second, it uses a novel component-based patch synthesis approach that supports lvalues, values that appear on the left-hand sides of assignments. In an evaluation on open-source projects, Trident successfully repaired 6 out of 10 real bugs that require insertion of new code with side effects, which previous techniques do not therefore repair. Evaluated on the ManyBugs benchmark, Trident successfully repaired two new bugs that previous approaches could not. Adding patches with side effects to the search space can exacerbate test-overfitting. We experimentally demonstrate that the simple heuristic of preferring patches with the fewest side effects alleviates the problem. An evaluation on a large number of smaller programs shows that this strategy reduces test-overfitting caused by side-effects, increasing the rate of correct patches from 33.3% to 58.3%.",1939-3520,,10.1109/TSE.2021.3124323,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9611365,program repair;program synthesis;symbolic execution;side effects,Maintenance engineering;Computer bugs;Codes;Databases;Training data;Switches;Semantics,,2,,55,IEEE,11 Nov 2021,,,IEEE,IEEE Journals,True
ExplanaSC: A Framework for Determining Information Requirements for Explainable Blockchain Smart Contracts,H. Al Ghanmi; R. Bahsoon,"School of Computer Science, University of Birmingham, Edgbaston, Birmingham, U.K.; School of Computer Science, University of Birmingham, Edgbaston, Birmingham, U.K.",IEEE Transactions on Software Engineering,14 Aug 2024,2024,50,8,1984,2004,"Blockchain smart contracts (SCs) have emerged as a transformative technology, enabling the automation and execution of contractual agreements without the need for intermediaries. However, as SCs evolve to become more complex in their decentralised decision-making abilities, there are notable difficulties in comprehending the underlying reasoning process and ensuring users’ understanding. The existing literature primarily focuses on the technical aspects of SC, overlooking the exploration of the decision-making process within these systems and the involvement of humans. In this paper, we propose a framework that integrates human-centered design principles by applying Situation Awareness (SA) and goal directed task analysis (GDTA) concepts to determine information requirements necessary to design eXplainable smart contracts (XSC). The framework provides a structured approach for requirements engineers to identify information that can keep users well-informed throughout the decision-making process. The framework considers factors such as the business logic model, data model, and roles and responsibilities model to define specific information requirements that shape SC behaviour and necessitate explanations. To guide the determination of information requirements, the framework categorises SC decision mechanisms into autonomy, governance, processing, and behaviour. The ExplanaSC framework promotes the generation of XSC explanations through three levels aligned with SA: XSC explanation for perception, XSC explanation for comprehension, and XSC explanation for projection. Overall, this framework contributes to the development of XSC systems and lays the foundation for more transparent, and trustworthy decentralised applications. The XSC explanations aims to facilitate user awareness of complex decision-making processes. The evaluation of the framework uses a case to exemplify the working of our framework, its added value and limitations, and consults experts in the field for feedback and refinements.",1939-3520,,10.1109/TSE.2024.3408632,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10546473,Smart contracts;decision-making process;human-centered design;requirements;blockchain,Decision making;Blockchains;Artificial intelligence;Smart contracts;Data models;Automation;Task analysis,,,,91,IEEE,3 Jun 2024,,,IEEE,IEEE Journals,True
Containerization for High Performance Computing Systems: Survey and Prospects,N. Zhou; H. Zhou; D. Hoppe,"High Performance Computing Center Stuttgart (HLRS), University of Stuttgart, Stuttgart, Germany; High Performance Computing Center Stuttgart (HLRS), University of Stuttgart, Stuttgart, Germany; High Performance Computing Center Stuttgart (HLRS), University of Stuttgart, Stuttgart, Germany",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,2722,2740,"Containers improve the efficiency in application deployment and thus have been widely utilised on Cloud and lately in High Performance Computing (HPC) environments. Containers encapsulate complex programs with their dependencies in isolated environments making applications more compatible and portable. Often HPC systems have higher security levels compared to Cloud systems, which restrict users’ ability to customise environments. Therefore, containers on HPC need to include a heavy package of libraries making their size relatively large. These libraries usually are specifically optimised for the hardware, which compromises portability of containers. Per contra, a Cloud container has smaller volume and is more portable. Furthermore, containers would benefit from orchestrators that facilitate deployment and management of containers at a large scale. Cloud systems in practice usually incorporate sophisticated container orchestration mechanisms as opposed to HPC systems. Nevertheless, some solutions to enable container orchestration on HPC systems have been proposed in state of the art. This paper gives a survey and taxonomy of efforts in both containerisation and its orchestration strategies on HPC systems. It highlights differences thereof between Cloud and HPC. Lastly, challenges are discussed and the potentials for research and engineering are envisioned.",1939-3520,,10.1109/TSE.2022.3229221,"European Union's Horizon 2020 Research and Innovation Programme(grant numbers:825355); Ministry of Science, Research and the Arts of the State of Baden-Württemberg; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9985426,AI;cloud computing;container;HPC;job scheduling;orchestration;resource management,Containers;Cloud computing;Engines;Security;Kernel;Hardware;Virtual machine monitors,,14,,125,IEEE,14 Dec 2022,,,IEEE,IEEE Journals,True
Cross-Language Taint Analysis: Generating Caller-Sensitive Native Code Specification for Java,S. Kan; Y. Gao; Z. Zhong; Y. Sui,"University of New South Wales, Sydney, Australia; University of Technology Sydney, Sydney, Australia; University of Technology Sydney, Sydney, Australia; University of New South Wales, Sydney, Australia",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1518,1533,"Cross-language programming is a common practice within the software development industry, offering developers a multitude of advantages such as expressiveness, interoperability, and cross-platform compatibility, for developing large-scale applications. As an important example, JNI (Java Native Interface) programming is widely used in diverse scenarios where Java interacts with code written in other programming languages, such as C or C++. Conventional static analysis based on a single programming language faces challenges when it comes to tracing the flow of values across multiple modules that are coded in different programming languages. In this paper, we introduce CSS, a new Caller-Sensitive Specification approach designed to enhance the static taint analysis of Java programs employing JNI to interface with C/C++ code. In contrast to conservative specifications, this approach takes into consideration the calling context of the invoked C/C++ functions (or cross-language context), resulting in more precise and concise specifications for the side effects of native code. Furthermore, CSS specifically enhances the capabilities of Java analyzers, enabling them to perform precise static taint analysis across language boundaries into native code. The experimental results show that CSS can accurately summarize value-flow information and enhance the ability of Java monolingual static analyzers for cross-language taint flow tracking.",1939-3520,,10.1109/TSE.2024.3392254,"Australian Research(grant numbers:DP210101348,FT220100391); generous Aspire Gift(grant numbers:Google); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10539620,Static analysis;taint analysis;cross-language program;caller-sensitive specification,Java;Codes;C++ languages;Libraries;Static analysis;Source coding;Security,,,,45,IEEE,27 May 2024,,,IEEE,IEEE Journals,True
Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond,P. Xue; L. Wu; Z. Yu; Z. Jin; Z. Yang; X. Li; Z. Yang; Y. Tan,"School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, and the School of Computer Science, Peking University, Beijing, China; School of Computer Science and Technology, Shandong University, Qingdao, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Computer Science and Technology, Shandong University, Qingdao, China; School of Computer Science and Technology, Shandong University, Qingdao, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,16,"Commit Message Generation (CMG) approaches aim to automatically generate commit messages based on given code diff s, which facilitate collaboration among developers and play a critical role in Open-Source Software (OSS). Very recently, Large Language Models (LLMs) have been applied in diverse code-related tasks owing to their powerful generality. Yet, in the CMG field, few studies systematically explored their effectiveness. This paper conducts the first comprehensive experiment to investigate how far we have been in applying LLM to generate high-quality commit messages and how to go further beyond in this field. Motivated by a pilot analysis, we first construct a multi-lingual high-quality CMG test set following practitioners’ criteria. Afterward, we re-evaluate diverse CMG approaches and make comparisons with recent LLMs. To delve deeper into LLMs’ ability, we further propose four manual metrics following the practice of OSS, including Accuracy, Integrity, Readability, and Applicability for assessment. Results reveal that LLMs have outperformed existing CMG approaches overall, and different LLMs carry different advantages, where GPT-3.5 performs best. To further boost LLMs’ performance in the CMG task, we propose an Efficient Retrieval-based In-Context Learning (ICL) framework, namely ERICommiter, which leverages a two-step filtering to accelerate the retrieval efficiency and introduces semantic/lexical-based retrieval algorithm to construct the ICL examples, thereby guiding the generation of high-quality commit messages with LLMs. Extensive experiments demonstrate the substantial performance improvement of ERICommiter on various LLMs across different programming languages. Meanwhile, ERICommiter also significantly reduces the retrieval time while keeping almost the same performance. Our research contributes to the understanding of LLMs’ capabilities in the CMG field and provides valuable insights for practitioners seeking to leverage these tools in their workflows.",1939-3520,,10.1109/TSE.2024.3478317,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10713474,Commit Message Generation;Large Language Model;Empirical Study;In-Context Learning,Codes;Measurement;Manuals;Collaboration;Systematics;Solid modeling;Data models;Python;Large language models;Java,,1,,,IEEE,10 Oct 2024,,,IEEE,IEEE Early Access Articles,True
Towards Security Threats of Deep Learning Systems: A Survey,Y. He; G. Meng; K. Chen; X. Hu; J. He,"Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China; Chinese Academy of Sciences, Institute of Information Engineering, Beijing, China",IEEE Transactions on Software Engineering,16 May 2022,2022,48,5,1743,1770,"Deep learning has gained tremendous success and great popularity in the past few years. However, deep learning systems are suffering several inherent weaknesses, which can threaten the security of learning models. Deep learning’s wide use further magnifies the impact and consequences. To this end, lots of research has been conducted with the purpose of exhaustively identifying intrinsic weaknesses and subsequently proposing feasible mitigation. Yet few are clear about how these weaknesses are incurred and how effective these attack approaches are in assaulting deep learning. In order to unveil the security weaknesses and aid in the development of a robust deep learning system, we undertake an investigation on attacks towards deep learning, and analyze these attacks to conclude some findings in multiple views. In particular, we focus on four types of attacks associated with security threats of deep learning: model extraction attack, model inversion attack, poisoning attack and adversarial attack. For each type of attack, we construct its essential workflow as well as adversary capabilities and attack goals. Pivot metrics are devised for comparing the attack approaches, by which we perform quantitative and qualitative analyses. From the analysis, we have identified significant and indispensable factors in an attack vector, e.g., how to reduce queries to target models, what distance should be used for measuring perturbation. We shed light on 18 findings covering these approaches’ merits and demerits, success probability, deployment complexity and prospects. Moreover, we discuss other potential security weaknesses and possible mitigation which can inspire relevant research in this area.",1939-3520,,10.1109/TSE.2020.3034721,"National Key Research and Development Program of China(grant numbers:2020AAA0140001); Beijing Natural Science Foundation(grant numbers:JQ18011); National Natural Science Foundation of China(grant numbers:U1836211,61902395); National Top-notch Youth Talents Program of China; Youth Innovation Promotion Association of the Chinese Academy of Sciences; Beijing Nova Program; National Frontier Science and Technology Innovation(grant numbers:YJKYYQ20170070); Beijing Academy of Artificial Intelligence; CCF-Tencent Open Fund; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252914,Deep learning;poisoning attack;adversarial attack;model extraction attack;model inversion attack,Deep learning;Security;Data models;Privacy;Predictive models;Training data,,40,,277,IEEE,9 Nov 2020,,,IEEE,IEEE Journals,True
CloudRaid: Detecting Distributed Concurrency Bugs via Log Mining and Enhancement,J. Lu; F. Li; C. Liu; L. Li; X. Feng; J. Xue,"State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences China, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Assessment Technology, Beijing Key Laboratory of Network Security and Protection Technology, Institute of Information Engineering, Chinese Academy of Sciences China, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences China, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences China, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences China, University of Chinese Academy of Sciences, Beijing, China; University of New South Wales, Sydney, NSW, Australia",IEEE Transactions on Software Engineering,14 Feb 2022,2022,48,2,662,677,"Cloud systems suffer from distributed concurrency bugs, which often lead to data loss and service outage. This paper presents CloudRaid, a new automatical tool for finding distributed concurrency bugs efficiently and effectively. Distributed concurrency bugs are notoriously difficult to find as they are triggered by untimely interaction among nodes, i.e., unexpected message orderings. To detect concurrency bugs in cloud systems efficiently and effectively, CloudRaid analyzes and tests automatically only the message orderings that are likely to expose errors. Specifically, CloudRaid mines the logs from previous executions to uncover the message orderings that are feasible but inadequately tested. In addition, we also propose a log enhancing technique to introduce new logs automatically in the system being tested. These extra logs added improve further the effectiveness of CloudRaid without introducing any noticeable performance overhead. Our log-based approach makes it well-suited for live systems. We have applied CloudRaid to analyze six representative distributed systems: Hadoop2/Yarn, HBase, HDFS, Cassandra, Zookeeper, and Flink. CloudRaid has succeeded in testing 60 different versions of these six systems (10 versions per system) in 35 hours, uncovering 31 concurrency bugs, including nine new bugs that have never been reported before. For these nine new bugs detected, which have all been confirmed by their original developers, three are critical and have already been fixed.",1939-3520,,10.1109/TSE.2020.2999364,"National Key Research and Development Program of China(grant numbers:2016YFB1000201); National Natural Science Foundation of China(grant numbers:61802368,61521092,61432016,61432018,61332009,61702485,61872043); CCF-Tencent Open Research Fund; Australian Research Council(grant numbers:DP170103956,DP180104069); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106854,Distributed systems;concurrency bugs;bug detection;cloud computing,Computer bugs;Concurrent computing;Cloud computing;Task analysis;Runtime;Message systems;Tools,,6,,63,IEEE,2 Jun 2020,,,IEEE,IEEE Journals,True
"Analyzing Android Taint Analysis Tools: FlowDroid, Amandroid, and DroidSafe",J. Zhang; Y. Wang; L. Qiu; J. Rubin,"Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,18 Oct 2022,2022,48,10,4014,4040,"Numerous static taint analysis techniques have recently been proposed for identifying information flows in mobile applications. These techniques are often optimized and evaluated on a set of synthetic benchmarks, which makes the comparison results difficult to generalize. Moreover, the techniques are commonly compared under different configuration setups, rendering the comparisons inaccurate. In this paper, we provide a large, controlled, and independent comparison of the three most prominent static taint analysis tools: FlowDroid, Amandroid, and DroidSafe. We align the configuration setup for the tools and evaluate them on both a set of common benchmarks and on real applications from the Google Play app store. We further evaluate the effectiveness of additional reflection handling mechanism implemented by DroidRA, applying it to each of the evaluated tools. We compare the results of our analysis to the results reported in previous studies, identify main reasons for inaccuracy in existing tools, and provide suggestions for future research.",1939-3520,,10.1109/TSE.2021.3109563,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529015,Static analysis;taint analysis;mobile applications;empirical studies;reproducibility studies,Tools;Benchmark testing;Internet;Smart phones;Sensitivity;Mobile applications;Codes,,4,,85,IEEE,3 Sep 2021,,,IEEE,IEEE Journals,True
Beyond Literal Meaning: Uncover and Explain Implicit Knowledge in Code Through Wikipedia-Based Concept Linking,C. Wang; X. Peng; Z. Xing; X. Meng,"School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China; Australian National University, Canberra, ACT, Australia; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China",IEEE Transactions on Software Engineering,15 May 2023,2023,49,5,3226,3240,"When reusing or modifying code, developers need to understand the implicit knowledge behind a piece of code in addition to the literal meaning of code. Such implicit knowledge involves related concepts and their explanations. Uncovering and understanding the implicit knowledge in code are challenging due to the extensive use of abbreviations, scattered expressions of concepts, and ambiguity of concept mentions. In this paper, we propose an automatic approach (called CoLiCo) that can uncover implicit concepts in code and link the uncovered concepts to Wikipedia. Based on a trained identifier embedding model, CoLiCo identifies Wikipedia concepts mentioned in a given code snippet and excerpts a paragraph-level explanation from Wikipedia for each concept. During the process, CoLiCo resolves identifier abbreviation (i.e., concepts mentioned in the form of abbreviations) and identifier aggregation (i.e., concepts mentioned by an aggregation of multiple identifiers) based on identifier embedding and mining of identifier abbreviation/aggregation relations. Experimental study shows that CoLiCo outperforms a general entity linking approach by 38.7% in the correctness of concept linking and identifies 96.7% more correct concept linkings on a dataset with 629 code snippets. The concept linking is significant for program understanding in 54% code snippets. Our user study shows that CoLiCo can significantly shorten the time and improve the correctness in code comprehension tasks that intensively involve implicit knowledge.",1939-3520,,10.1109/TSE.2023.3250029,National Natural Science Foundation of China(grant numbers:61972098); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10054429,Concept;code semantics;knowledge;program comprehension,Codes;Internet;Encyclopedias;Online services;Color;Software development management;Training,,2,,53,IEEE,27 Feb 2023,,,IEEE,IEEE Journals,True
Enhancing Bug-Inducing Commit Identification: A Fine-Grained Semantic Analysis Approach,L. Tang; C. Ni; Q. Huang; L. Bao,"State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; School of Computer Science and Technology, Zhejiang Gongshang University, Hangzhou, China; State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",IEEE Transactions on Software Engineering,13 Nov 2024,2024,50,11,3037,3052,"The SZZ algorithm and its variants have been extensively utilized for identifying bug-inducing commits based on bug-fixing commits. However, these algorithms face challenges when there are no deletion lines in the bug-fixing commit. Previous studies have attempted to address this issue by tracing back all lines in the block that encapsulates the added lines. However, this method is too coarse-grained and suffers from low precision. To address this issue, we propose a novel method in this paper called Sem-SZZ, which is based on fine-grained semantic analysis. Initially, we observe that a significant number of bug-inducing commits can be identified by tracing back the unmodified lines near added lines, resulting in improved precision and F1-score. Building on this observation, we conduct a more fine-grained semantic analysis. We begin by performing program slicing to extract the program part near the added lines. Subsequently, we compare the program's states between the previous version and the current version, focusing on data flow and control flow differences based on the extracted program part. Finally, we extract statements contributing to the bug based on these differences and utilize them to locate bug-inducing commits. We also extend our approach to fit the scenario where the bug-fixing commits contain deleted lines. Experimental results demonstrate that Sem-SZZ outperforms the state-of-the-art methods in identifying bug-inducing commits, regardless of whether the bug-fixing commit contains deleted lines.",1939-3520,,10.1109/TSE.2024.3468296,"National Key Research and Development Program of China(grant numbers:2021YFB2701102); National Natural Science Foundation of China(grant numbers:62372398,62302447,62202419,72342025,U20A20173); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LY24F020008); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10711218,SZZ algorithm;data flow analysis;control flow analysis,Computer bugs;Noise;Software algorithms;Semantics;Reliability;Buildings;Process control;Nickel;Linux;Chaos,,,,56,IEEE,9 Oct 2024,,,IEEE,IEEE Journals,True
BinDiffNN: Learning Distributed Representation of Assembly for Robust Binary Diffing Against Semantic Differences,S. Ullah; H. Oh,"Department of Computer Science and Engineering, Hanyang University, Ansan, South Korea; Department of Computer Science and Engineering, Hanyang University, Ansan, South Korea",IEEE Transactions on Software Engineering,16 Sep 2022,2022,48,9,3442,3466,"Binary diffing is a process to discover the differences and similarities in functionality between two binary programs. Previous research on binary diffing approaches it as a function matching problem to formulate an initial 1:1 mapping between functions, and later a sequence matching ratio is computed to classify two functions being an exact match, a partial match or no-match. The accuracy of existing techniques is best only when detecting exact matches and they are not efficient in detecting partially changed functions; especially those with minor patches. These drawbacks are due to two major challenges (i) In the 1:1 mapping phase, using a strict policy to match function features (ii) In the classification phase, considering an assembly snippet as a normal text, and using sequence matching for similarity comparison. Instruction has a unique structure i.e. mnemonics and registers have a specific position in instruction and also have a semantic relationship, which makes assembly code different from general text. Sequence matching performs best for general text but it fails to detect structural and semantic changes at an instruction level thus, its use for classification produces many false results. In this research, we have addressed the aforementioned underlying challenges by proposing a two-fold solution. For the 1:1 mapping phase, we have proposed computationally inexpensive features, which are compared with distance-based selection criteria to map similar functions and filter unmatched functions. For the classification phase, we have proposed a Siamese binary-classification neural network where each branch is an attention-based distributed learning embedding neural network — that learn the semantic similarity among assembly instructions, learn to highlight the changes at an instruction level and a final stage fully connected layer learn to accurately classify two 1:1 mapped function either an exact or a partial match. We have used x86 kernel binaries for training and achieved $\sim 99\%$∼99% classification accuracy; which is higher than existing binary diffing techniques and tools.",1939-3520,,10.1109/TSE.2021.3093926,National Research Foundation of Korea; Ministry of Science and ICT(grant numbers:NRF-2019R1A2C2003045); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9470904,Asm2Vec;attention network;binary diffing;exact match;Inst2vec;partial match;siamese neural network,Semantics;Heuristic algorithms;Classification algorithms;Syntactics;Registers;Tools;Task analysis,,12,,45,IEEE,1 Jul 2021,,,IEEE,IEEE Journals,True
The Best Laid Plans or Lack Thereof: Security Decision-Making of Different Stakeholder Groups,B. Shreeve; J. Hallett; M. Edwards; K. M. Ramokapane; R. Atkins; A. Rashid,"Bristol Cyber Security Group, University of Bristol, Bristol, U.K.; Bristol Cyber Security Group, University of Bristol, Bristol, U.K.; Bristol Cyber Security Group, University of Bristol, Bristol, U.K.; Bristol Cyber Security Group, University of Bristol, Bristol, U.K.; City of London Police, London, U.K.; Bristol Cyber Security Group, University of Bristol, Bristol, U.K.",IEEE Transactions on Software Engineering,16 May 2022,2022,48,5,1515,1528,"Cyber security requirements are influenced by the priorities and decisions of a range of stakeholders. Board members and Chief Information Security Officers (CISOs) determine strategic priorities. Managers have responsibility for resource allocation and project management. Legal professionals concern themselves with regulatory compliance. Little is understood about how the security decision-making approaches of these different stakeholders contrast, and if particular groups of stakeholders have a better appreciation of security requirements during decision-making. Are risk analysts better decision makers than CISOs? Do security experts exhibit more effective strategies than board members? This paper explores the effect that different experience and diversity of expertise has on the quality of a team's cyber security decision-making and whether teams with members from more varied backgrounds perform better than those with more focused, homogeneous skill sets. Using data from 208 sessions and 948 players of a tabletop game run in the wild by a major national organization over 16 months, we explore how choices are affected by player background (e.g., cyber security experts versus risk analysts, board-level decision makers versus technical experts) and different team make-ups (homogeneous teams of security experts versus various mixes). We find that no group of experts makes significantly better game decisions than anyone else, and that their biases lead them to not fully comprehend what they are defending or how the defenses work.",1939-3520,,10.1109/TSE.2020.3023735,Engineering and Physical Sciences Research Council(grant numbers:EP/M002780/1); DYPOSIT(grant numbers:EP/N021657/2); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195777,Social and professional topics~computational thinking;applied computing~enterprise computing infrastructures,Games;Stakeholders;Computer security;Decision making;Organizations;Investment,,8,,48,IEEE,14 Sep 2020,,,IEEE,IEEE Journals,True
"Answering Uncertain, Under-Specified API Queries Assisted by Knowledge-Aware Human-AI Dialogue",Q. Huang; Z. Li; Z. Xing; Z. Zuo; X. Peng; X. Xu; Q. Lu,"School of Computer Information Engineering, Jiangxi Normal University, Nanchang, China; School of Computer Information Engineering, Jiangxi Normal University, Nanchang, China; CSIRO’s Data61, Canberra, Australia; School of Computer Information Engineering, Jiangxi Normal University, Nanchang, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China; CSIRO’s Data61, Canberra, Australia; CSIRO’s Data61, Canberra, Australia",IEEE Transactions on Software Engineering,12 Feb 2024,2024,50,2,280,295,"Developers’ API needs should be more pragmatic, such as seeking suggestive, explainable, and extensible APIs rather than the so-called best result. Existing API search research cannot meet these pragmatic needs because they are solely concerned with query-API relevance. This necessitates a focus on enhancing the entire query process, from query definition to query refinement through intent clarification to query results promoting divergent thinking about results. This paper designs a novel Knowledge-Aware Human-AI Dialog agent (KAHAID) which guides the developer to clarify the uncertain, under-specified query through multi-round question answering and recommends APIs for the clarified query with relevance explanation and extended suggestions (e.g., alternative, collaborating or opposite-function APIs). We systematically evaluate KAHAID. In terms of human-AI dialogue process, it achieves a high diversity of question options (the average diversity between any two options is 74.9%) and the ability to guide developers to find APIs using fewer dialogue rounds (no more than 3 rounds on average). For API recommendation, KAHAID achieves an MRR and MAP of 0.769 and 0.794, outperforming state-of-the-art API search approaches BIKER and CLEAR by at least 47% in MRR and 226.7% in MAP. For knowledge extension, KAHAID obtains an MRR and MAP of 0.815 and 0.864, surpassing state-of-the-art query clarification approaches by at least 42% in MRR and 45.2% in MAP. As the first of its kind, KAHAID opens the door to integrating the immediate response capability of API research and the interaction, clarification, explanation, and extensibility capability of social-technical information seeking.",1939-3520,,10.1109/TSE.2023.3346954,"National Natural Science Foundation of China(grant numbers:62262031,62367003); Natural Science Foundation of Jiangxi Province(grant numbers:20232BAB202010); Graduate Innovative Special Fund Projects of Jiangxi Province(grant numbers:YJS2023032,YC2022-s258); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10374028,Developers’ API need;knowledge graph;human-AI dialogue;API recommendation;multi-round question answering,Pragmatics;Behavioral sciences;Semantics;Decision trees;Knowledge graphs;Java;Extensibility,,2,,44,IEEE,25 Dec 2023,,,IEEE,IEEE Journals,True
ContractCheck: Checking Ethereum Smart Contracts in Fine-Grained Level,X. Wang; S. Tian; W. Cui,"School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China",IEEE Transactions on Software Engineering,17 Jul 2024,2024,50,7,1789,1806,"The blockchain has been the main computing scenario for smart contracts, and the decentralized infrastructure of the blockchain is effectively implemented in a de-trusted and executable environment. However, vulnerabilities in smart contracts are particularly vulnerable to exploitation by malicious attackers and have always been a key issue in blockchain security. Existing traditional tools are inefficient in detecting vulnerabilities and have a high rate of false positives when detecting contracts. Some neural network methods have improved the detection efficiency, but they are not competent for fine-grained (code line level) vulnerability detection. We propose the ContractCheck model for detecting contract vulnerabilities based on neural network methods. ContractCheck extracts fine-grained segments from the abstract syntax tree (AST) and function call graph of smart contract source code. Furthermore, the segments are parsed into token flow retaining semantic information as uint, which are used to generate numerical vector sequences that can be trained using neural network methods. We conduct multiple rounds of experiments using a dataset constructed from 36,885 smart contracts and identified the optimal ContractCheck model structure by employing the Fasttext embedding vector algorithm and constructing a composite model using CNN and BiGRU for training the network. Evaluation on other datasets demonstrates that ContractCheck exhibits significant improvement in contract-level detection performance compared to other methods, with an increase of 23.60% in F1 score over the best existing method. Particularly, it achieves fine-grained detection based on neural network methods. The cases provide indicate that ContractCheck can effectively assist developers in accurately locating the presence of vulnerabilities, thereby enhancing the security of Ethereum smart contracts.",1939-3520,,10.1109/TSE.2024.3400294,"National Key Research and Development Program of China(grant numbers:2022YFB3103100); National Natural Science Foundation of China(grant numbers:62173151,62273154); Foundation of Key Laboratory of Autonomous Systems and Networked Control, Ministry of Education, China; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10531111,Smart contract;blockchain security;vulnerability detection;neural network,Smart contracts;Codes;Blockchains;Neural networks;Semantics;Security;Vectors,,,,62,IEEE,15 May 2024,,,IEEE,IEEE Journals,True
Deep Learning Based Vulnerability Detection: Are We There Yet?,S. Chakraborty; R. Krishna; Y. Ding; B. Ray,"Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA",IEEE Transactions on Software Engineering,16 Sep 2022,2022,48,9,3280,3296,"Automated detection of software vulnerabilities is a fundamental problem in software security. Existing program analysis techniques either suffer from high false positives or false negatives. Recent progress in Deep Learning (DL) has resulted in a surge of interest in applying DL for automated vulnerability detection. Several recent studies have demonstrated promising results achieving an accuracy of up to 95 percent at detecting vulnerabilities. In this paper, we ask, “how well do the state-of-the-art DL-based techniques perform in a real-world vulnerability prediction scenario?” To our surprise, we find that their performance drops by more than 50 percent. A systematic investigation of what causes such precipitous performance drop reveals that existing DL-based vulnerability prediction approaches suffer from challenges with the training data (e.g., data duplication, unrealistic distribution of vulnerable classes, etc.) and with the model choices (e.g., simple token-based models). As a result, these approaches often do not learn features related to the actual cause of the vulnerabilities. Instead, they learn unrelated artifacts from the dataset (e.g., specific variable/function names, etc.). Leveraging these empirical findings, we demonstrate how a more principled approach to data collection and model design, based on realistic settings of vulnerability prediction, can lead to better solutions. The resulting tools perform significantly better than the studied baseline—up to 33.57 percent boost in precision and 128.38 percent boost in recall compared to the best performing model in the literature. Overall, this paper elucidates existing DL-based vulnerability prediction systems’ potential issues and draws a roadmap for future DL-based vulnerability prediction research.",1939-3520,,10.1109/TSE.2021.3087402,"National Science Foundation(grant numbers:CCF 1845893,CCF 1822965,CNS 1842456); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9448435,Vulnerability;deep learning based vulnerability detection;real world vulnerabilities;graph neural network based vulnerability detection,Predictive models;Neural networks;Testing;Data models;Security;Training;Training data,,210,,76,IEEE,8 Jun 2021,,,IEEE,IEEE Journals,True
Don’t Confuse! Redrawing GUI Navigation Flow in Mobile Apps for Visually Impaired Users,m. Zhang; h. liu; Y. Zhou; C. Chen; P. Huang; J. Zhao,"College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; College of Computer Science and Technology, Jilin University, Changchun, China; Department of Computer Science, Technical University of Munich, Heilbronn, Germany; Department of Computer Science, Stanford University, California, U.S.A.; Department of Computer Science, Changchun University, Changchun, China",IEEE Transactions on Software Engineering,,2024,PP,99,1,18,"Mobile applications (apps) are integral to our daily lives, offering diverse services and functionalities. They enable sighted users to access information coherently in an extremely convenient manner. However, it remains unclear if visually impaired users, who rely solely on the screen readers (e.g., Talkback) to navigate and access app information, can do so in the correct and reasonable order. This may result in significant information bias and operational errors. Furthermore, in our preliminary exploration, we explained and clarified that the navigation sequence-related issues encountered by visually impaired users could be categorized into two types: unintuitive navigation sequence and unapparent focus switching. Considering these issues, in this work, we proposed a method named RGNF (Re-draw GUI Navigation Flow). It aimed to enhance the understandability and coherence of accessing the content of each component within the Graphical User Interface (GUI), together with assisting developers in creating well-designed GUI navigation flow (GNF). This method was inspired by the characteristics identified in our preliminary study, where visually impaired users expected navigation to be associated with close position and similar shape of GUI components that were read consecutively. Thus, our method relied on the principles derived from the Gestalt psychological model, aiming to group GUI components into different regions according to the laws of proximity and similarity, thereby redrawing the GNFs. To evaluate the effectiveness of our method, we calculated sequence similarity values before and after redrawing the GNF, and further employed the tools proposed by Alotaibi et al. to measure the reachability of GUI components. Our results demonstrated a substantial improvement in similarity (0.921) compared to the baseline (0.624), together with the reachability (90.31%) compared to the baseline GNF (74.35%). Furthermore, a qualitative user study revealed that our method had a positive effect on providing visually impaired users with an improved user experience.",1939-3520,,10.1109/TSE.2024.3485225,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10732009,GUI;accessibility;Gestalt psychological model;navigation,Navigation;Graphical user interfaces;Recruitment;Psychology;Guidelines;Computer science;Visualization;Shape;Mobile applications;Filtering,,,,,IEEE,23 Oct 2024,,,IEEE,IEEE Early Access Articles,True
FalsifAI: Falsification of AI-Enabled Hybrid Control Systems Guided by Time-Aware Coverage Criteria,Z. Zhang; D. Lyu; P. Arcaini; L. Ma; I. Hasuo; J. Zhao,"Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; National Institute of Informatics, Tokyo, Japan; University of Alberta, Edmonton, AB, Canada; National Institute of Informatics, Tokyo, Japan; Kyushu University, Fukuoka, Japan",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1842,1859,"Modern Cyber-Physical Systems (CPSs) that need to perform complex control tasks (e.g., autonomous driving) are increasingly using AI-enabled controllers, mainly based on deep neural networks (DNNs). The quality assurance of such types of systems is of vital importance. However, their verification can be extremely challenging, due to their complexity and uninterpretable decision logic. Falsification is an established approach for CPS quality assurance, which, instead of attempting to prove the system correctness, aims at finding a time-variant input signal violating a formal specification describing the desired behavior; it often employs a search-based testing approach that tries to minimize the robustness of the specification, given by its quantitative semantics. However, guidance provided by robustness is mostly black-box and only related to the system output, but does not allow to understand whether the temporal internal behavior determined by multiple consecutive executions of the neural network controller has been explored sufficiently. To bridge this gap, in this paper, we make an early attempt at exploring the temporal behavior determined by the repeated executions of the neural network controllers in hybrid control systems and first propose eight time-aware coverage criteria specifically designed for neural network controllers in the context of CPS, which consider different features by design: the simple temporal activation of a neuron, the continuous activation of a neuron for a given duration, and the differential neuron activation behavior over time. Second, we introduce a falsification framework, named $\mathtt {FalsifAI}$FalsifAI, that exploits the coverage information for better falsification guidance. Namely, inputs of the controller that increase the coverage (so improving the exploration of the DNN behaviors), are prioritized in the exploitation phase of robustness minimization. Our large-scale evaluation over a total of 3 typical CPS tasks, 6 system specifications, 18 DNN models and more than 12,000 experiment runs, demonstrates 1) the advantage of our proposed technique in outperforming two state-of-the-art falsification approaches, and 2) the usefulness of our proposed time-aware coverage criteria for effective falsification guidance.",1939-3520,,10.1109/TSE.2022.3194640,"JST SPRING(grant numbers:JPMJSP2136); ERATO HASUO Metamathematics for Systems Design(grant numbers:JPMJER1603); JST(grant numbers:10.13039/501100009024 ERATO); Engineerable AI Techniques for Practical Applications of High-Quality Machine Learningbased Systems; JST-Mirai Program(grant numbers:JPMJMI20B8); Canada First Research Excellence Fund; CIFAR AI Chairs Program; Amii RAP Program; Natural Sciences and Engineering Research Council of Canada; NSERC RGPIN-2021-02549(grant numbers:NSERC RGPIN-2021-02549,RGPAS-2021-00034,DGECR-2021-00019); JSPS KAKENHI(grant numbers:JP19H04086,JP20H04168,JP21H04877); JST-Mirai Program(grant numbers:JPMJMI20B8); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9844247,Search-based testing;falsification;neural network controllers;coverage criteria;cyber-physical systems,Behavioral sciences;Neurons;Biological neural networks;Robustness;Automobiles;Task analysis;Deep learning,,5,,60,IEEE,28 Jul 2022,,,IEEE,IEEE Journals,True
$\mathtt {SIEGE}$SIEGE: A Semantics-Guided Safety Enhancement Framework for AI-Enabled Cyber-Physical Systems,J. Song; X. Xie; L. Ma,"University of Alberta, Edmonton, AB, Canada; University of Alberta, Edmonton, AB, Canada; University of Alberta, Edmonton, AB, Canada",IEEE Transactions on Software Engineering,14 Aug 2023,2023,49,8,4058,4080,"Cyber-Physical Systems (CPSs) have been widely adopted in various industry domains to support many important tasks that impact our daily lives, such as automotive vehicles, robotics manufacturing, and energy systems. As Artificial Intelligence (AI) has demonstrated its promising abilities in diverse tasks like decision-making, prediction, and optimization, a growing number of CPSs adopt AI components in the loop to further extend their efficiency and performance. However, these modern AI-enabled CPSs have to tackle pivotal problems that the AI-enabled control systems might need to compensate the balance across multiple operation requirements and avoid possible defections in advance to safeguard human lives and properties. Modular redundancy and ensemble method are two widely adopted solutions in the traditional CPSs and AI communities to enhance the functionality and flexibility of a system. Nevertheless, there is a lack of deep understanding of the effectiveness of such ensemble design on AI-CPSs across diverse industrial applications. Considering the complexity of AI-CPSs, existing ensemble methods fall short of handling such huge state space and sophisticated system dynamics. Furthermore, an ideal control solution should consider the multiple system specifications in real-time and avoid erroneous behaviors beforehand. Such that, a new specification-oriented ensemble control system is of urgent need for AI-CPSs. In this paper, we propose $\mathtt {SIEGE}$SIEGE, a semantics-guided ensemble control framework to initiate an early exploratory study of ensemble methods on AI-CPSs and aim to construct an efficient, robust, and reliable control solution for multi-tasks AI-CPSs. We first utilize a semantic-based abstraction to decompose the large state space, capture the ongoing system status and predict future conditions in terms of the satisfaction of specifications. We propose a series of new semantics-aware ensemble strategies and an end-to-end Deep Reinforcement Learning (DRL) hierarchical ensemble method to improve the flexibility and reliability of the control systems. Our large-scale, comprehensive evaluations over five subject CPSs show that 1) the semantics abstraction can efficiently narrow the large state space and predict the semantics of incoming states, 2) our semantics-guided methods outperform state-of-the-art individual controllers and traditional ensemble methods, and 3) the DRL hierarchical ensemble approach shows promising capabilities to deliver a more robust, efficient, and safety-assured control system. To enable further research along this direction to build better AI-enabled CPS, we made all of the code and experimental results data publicly. (https://sites.google.com/view/ai-cps-siege/home).",1939-3520,,10.1109/TSE.2023.3282981,"Canada First Research Excellence Fund; University of Alberta's Future Energy Systems research initiative; Canada CIFAR AI Chairs Program; Amii RAP program; Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2021-02549,RGPAS-2021-00034,DGECR-2021-00019); JSPS KAKENHI(grant numbers:JP20H04168,JP21H04877); JST-Mirai Program(grant numbers:JPMJMI20B8); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10144351,Cyber-physical systems;reinforcement learning;state abstraction;AI controllers;ensemble methods,Ensemble learning;Artificial intelligence;Semantics;Control systems;Reliability;Task analysis;Safety,,2,,101,IEEE,5 Jun 2023,,,IEEE,IEEE Journals,True
Parameterized Verification of Leader/Follower Systems via Arithmetic Constraints,G. Kourtis; C. Dixon; M. Fisher,"Department of Computer Science, The University of Manchester, Manchester, U.K.; Department of Computer Science, The University of Manchester, Manchester, U.K.; Department of Computer Science, The University of Manchester, Manchester, U.K.",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2458,2471,"We introduce a variant of a formalism appearing in recent work geared towards modelling systems in which a distinguished entity (leader) orchestrates the operation of an arbitrary number of identical entities (followers). Our variant is better suited for the verification of system properties involving complex arithmetic conditions. Whereas the original formalism is translated into a tractable fragment of first-order temporal logic, aiming to utilize automated (first-order temporal logic) theorem provers for verification, our variant is translated into linear integer arithmetic, aiming to utilize satisfiability modulo theories (SMT) solvers for verification. In particular, for any given system specified in our formalism, we prove, for any natural number n, the existence of a linear integer arithmetic formula whose models are in one-to-one correspondence with certain counting abstractions (profiles) of executions of the system for n time steps. Thus, one is able to verify, for any natural number n, that all executions for n time steps of any such system have a given property by establishing that said formula logically entails the property. To highlight the practical utility of our approach, we specify and verify three consensus protocols, actively used in distributed database systems and low-power wireless networks.",1939-3520,,10.1109/TSE.2024.3440587,"UKRI(grant numbers:EP/N007565,EP/V026801); Royal Academy of Engineering(grant numbers:Chair in Emerging Technologies); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10632563,Formal methods;parameterized verification;distributed systems;arithmetic constraints,Arithmetic;Automata;Logic;Control systems;Polynomials;Formal verification;Europe,,,,40,CCBY,9 Aug 2024,,,IEEE,IEEE Journals,True
INSPECT: Intrinsic and Systematic Probing Evaluation for Code Transformers,A. Karmakar; R. Robbes,"Free University of Bozen-Bolzano, Bozen-Bolzano, Italy; CNRS, University of Bordeaux, Bordeaux INP, LaBRI, Talence, France",IEEE Transactions on Software Engineering,12 Feb 2024,2024,50,2,220,238,"Pre-trained models of source code have recently been successfully applied to a wide variety of Software Engineering tasks; they have also seen some practical adoption in practice, e.g. for code completion. Yet, we still know very little about what these pre-trained models learn about source code. In this article, we use probing—simple diagnostic tasks that do not further train the models—to discover to what extent pre-trained models learn about specific aspects of source code. We use an extensible framework to define 15 probing tasks that exercise surface, syntactic, structural and semantic characteristics of source code. We probe 8 pre-trained source code models, as well as a natural language model (BERT) as our baseline. We find that models that incorporate some structural information (such as GraphCodeBERT) have a better representation of source code characteristics. Surprisingly, we find that for some probing tasks, BERT is competitive with the source code models, indicating that there are ample opportunities to improve source-code specific pre-training on the respective code characteristics. We encourage other researchers to evaluate their models with our probing task suite, so that they may peer into the hidden layers of the models and identify what intrinsic code characteristics are encoded.",1939-3520,,10.1109/TSE.2023.3341624,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10354028,Machine learning for source code;probing;benchmarking;transformers;pre-trained models,Task analysis;Source coding;Probes;Codes;Training;Natural languages;Data models,,2,,73,IEEE,12 Dec 2023,,,IEEE,IEEE Journals,True
TEASMA: A Practical Methodology for Test Adequacy Assessment of Deep Neural Networks,A. Abbasishahkoo; M. Dadkhah; L. Briand; D. Lin,"School of EECS, University of Ottawa, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada; Huawei Canada, Kingston, ON, Canada",IEEE Transactions on Software Engineering,,2024,PP,99,1,23,"Successful deployment of Deep Neural Networks (DNNs), particularly in safety-critical systems, requires their validation with an adequate test set to ensure a sufficient degree of confidence in test outcomes. Although well-established test adequacy assessment techniques from traditional software, such as mutation analysis and coverage criteria, have been adapted to DNNs in recent years, we still need to investigate their application within a comprehensive methodology for accurately predicting the fault detection ability of test sets and thus assessing their adequacy. In this paper, we propose and evaluate TEASMA, a comprehensive and practical methodology designed to accurately assess the adequacy of test sets for DNNs. In practice, TEASMA allows engineers to decide whether they can trust high-accuracy test results and thus validate the DNN before its deployment. Based on a DNN model’s training set, TEASMA provides a procedure to build accurate DNN-specific prediction models of the Fault Detection Rate (FDR) of a test set using an existing adequacy metric, thus enabling its assessment. We evaluated TEASMA with four state-of-the-art test adequacy metrics: Distance-based Surprise Coverage (DSC), Likelihood-based Surprise Coverage (LSC), Input Distribution Coverage (IDC), and Mutation Score (MS). We calculated MS based on mutation operators that directly modify the trained DNN model (i.e., post-training operators) due to their significant computational advantage compared to the operators that modify the DNN's training set or program (i.e., pre-training operators). Our extensive empirical evaluation, conducted across multiple DNN models and input sets, including large input sets such as ImageNet, reveals a strong linear correlation between the predicted and actual FDR values derived from MS, DSC, and IDC, with minimum R2 values of 0.94 for MS and 0.90 for DSC and IDC. Furthermore, a low average Root Mean Square Error (RMSE) of 9% between actual and predicted FDR values across all subjects, when relying on regression analysis and MS, demonstrates the latter's superior accuracy when compared to DSC and IDC, with RMSE values of 0.17 and 0.18, respectively. Overall, these results suggest that TEASMA provides a reliable basis for confidently deciding whether to trust test results for DNN models.",1939-3520,,10.1109/TSE.2024.3482984,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10720834,Deep Neural Network;Test Assessment;Test Adequacy Metrics,Measurement;Training;Artificial neural networks;Predictive models;Accuracy;Testing;Analytical models;Fault detection;Correlation;Computational modeling,,,,,IEEE,17 Oct 2024,,,IEEE,IEEE Early Access Articles,True
Systematic Evaluation and Usability Analysis of Formal Methods Tools for Railway Signaling System Design,A. Ferrari; F. Mazzanti; D. Basile; M. H. ter Beek,"Institute of Information Science and Technologies (ISTI), Italian National Research Council (CNR), Pisa, Italy; Institute of Information Science and Technologies (ISTI), Italian National Research Council (CNR), Pisa, Italy; Institute of Information Science and Technologies (ISTI), Italian National Research Council (CNR), Pisa, Italy; Institute of Information Science and Technologies (ISTI), Italian National Research Council (CNR), Pisa, Italy",IEEE Transactions on Software Engineering,11 Nov 2022,2022,48,11,4675,4691,"Formal methods and supporting tools have a long record of success in the development of safety-critical systems. However, no single tool has emerged as the dominant solution for system design. Each tool differs from the others in terms of the modeling language used, its verification capabilities and other complementary features, and each development context has peculiar needs that require different tools. This is particularly problematic for the railway industry, in which formal methods are highly recommended by the norms, but no actual guidance is provided for the selection of tools. To guide companies in the selection of the most appropriate formal methods tools to adopt in their contexts, a clear assessment of the features of the currently available tools is required. To address this goal, this paper considers a set of 13 formal methods tools that have been used for the early design of railway systems, and it presents a systematic evaluation of such tools and a preliminary usability analysis of a subset of 7 tools, involving railway practitioners. The results are discussed considering the most desired aspects by industry and earlier related studies. While the focus is on the railway signaling domain, the overall methodology can be applied to similar contexts. Our study thus contributes with a systematic evaluation of formal methods tools and it shows that despite the poor graphical interfaces, usability and maturity of the tools are not major problems, as claimed by contributions from the literature. Instead, support for process integration is the most relevant obstacle for the adoption of most of the tools. Our contribution can be useful to R&D engineers from railway signaling companies and infrastructure managers, but also to tool developers and academic researchers alike.",1939-3520,,10.1109/TSE.2021.3124677,"ASTRail; 4SECURail; Shift2Rail Joint Undertaking; the European Union's Horizon 2020 Research and Innovation Programme(grant numbers:777561 (ASTRail),881775 (4SECURail)); Annual Work Plan and Budget(grant numbers:H2020-S2RJU-2019); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9599463,,Tools;Rail transportation;Systematics;Usability;Europe;Companies;Industries,,23,,128,IEEE,2 Nov 2021,,,IEEE,IEEE Journals,True
GPT2SP: A Transformer-Based Agile Story Point Estimation Approach,M. Fu; C. Tantithamthavorn,"Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia",IEEE Transactions on Software Engineering,14 Feb 2023,2023,49,2,611,625,"Story point estimation is a task to estimate the overall effort required to fully implement a product backlog item. Various estimation approaches (e.g., Planning Poker, Analogy, and expert judgment) are widely-used, yet they are still inaccurate and may be subjective, leading to ineffective sprint planning. Recent work proposed Deep-SE, a deep learning-based Agile story point estimation approach, yet it is still inaccurate, not transferable to other projects, and not interpretable. In this paper, we propose GPT2SP, a Transformer-based Agile Story Point Estimation approach. Our GPT2SP employs a GPT-2 pre-trained language model with a GPT-2 Transformer-based architecture, allowing our GPT2SP models to better capture the relationship among words while considering the context surrounding a given word and its position in the sequence and be transferable to other projects, while being interpretable. Through an extensive evaluation on 23,313 issues that span across 16 open-source software projects with 10 existing baseline approaches for within- and cross-project scenarios, our results show that our GPT2SP approach achieves a median MAE of 1.16, which is (1) 34%-57% more accurate than existing baseline approaches for within-project estimations; (2) 39%-49% more accurate than existing baseline approaches for cross-project estimations. The ablation study also shows that the GPT-2 architecture used in our approach substantially improves Deep-SE by 6%-47%, highlighting the significant advancement of the AI for Agile story point estimation. Finally, we develop a proof-of-concept tool to help practitioners better understand the most important words that contributed to the story point estimation of the given issue with the best supporting examples from past estimates. Our survey study with 16 Agile practitioners shows that the story point estimation task is perceived as an extremely challenging task. In addition, our AI-based story point estimation with explanations is perceived as more useful and trustworthy than without explanations, highlighting the practical need of our Explainable AI-based story point estimation approach.",1939-3520,,10.1109/TSE.2022.3158252,Australian Research Council(grant numbers:DE200100941); Monash University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9732669,Agile story point estimation;AI for SE;explainable AI,Estimation;Transformers;Computer architecture;Planning;Task analysis;Training;Artificial intelligence,,21,,56,IEEE,10 Mar 2022,,,IEEE,IEEE Journals,True
Test Input Prioritization for Machine Learning Classifiers,X. Dang; Y. Li; M. Papadakis; J. Klein; T. F. Bissyandé; Y. L. Traon,"University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg",IEEE Transactions on Software Engineering,18 Mar 2024,2024,50,3,413,442,"Machine learning has achieved remarkable success across diverse domains. Nevertheless, concerns about interpretability in black-box models, especially within Deep Neural Networks (DNNs), have become pronounced in safety-critical fields like healthcare and finance. Classical machine learning (ML) classifiers, known for their higher interpretability, are preferred in these domains. Similar to DNNs, classical ML classifiers can exhibit bugs that could lead to severe consequences in practice. Test input prioritization has emerged as a promising approach to ensure the quality of an ML system, which prioritizes potentially misclassified tests so that such tests can be identified earlier with limited manual labeling costs. However, when applying to classical ML classifiers, existing DNN test prioritization methods are constrained from three perspectives: 1) Coverage-based methods are inefficient and time-consuming; 2) Mutation-based methods cannot be adapted to classical ML models due to mismatched model mutation rules; 3) Confidence-based methods are restricted to a single dimension when applying to binary ML classifiers, solely depending on the model's prediction probability for one class. To overcome the challenges, we propose MLPrior, a test prioritization approach specifically tailored for classical ML models. MLPrior leverages the characteristics of classical ML classifiers (i.e., interpretable models and carefully engineered attribute features) to prioritize test inputs. The foundational principles are: 1) tests more sensitive to mutations are more likely to be misclassified, and 2) tests closer to the model's decision boundary are more likely to be misclassified. Building on the first concept, we design mutation rules to generate two types of mutation features (i.e., model mutation features and input mutation features) for each test. Drawing from the second notion, MLPrior generates attribute features of each test based on its attribute values, which can indirectly reveal the proximity between the test and the decision boundary. For each test, MLPrior combines all three types of features of it into a final vector. Subsequently, MLPrior employs a pre-trained ranking model to predict the misclassification probability of each test based on its final vector and ranks tests accordingly. We conducted an extensive study to evaluate MLPrior based on 185 subjects, encompassing natural datasets, mixed noisy datasets, and fairness datasets. The results demonstrate that MLPrior outperforms all the compared test prioritization approaches, with an average improvement of 14.74%$\sim$∼66.93% on natural datasets, 18.55%$\sim$∼67.73% on mixed noisy datasets, and 15.34%$\sim$∼62.72% on fairness datasets.",1939-3520,,10.1109/TSE.2024.3350019,Luxembourg National Research Fund AFR PhD(grant numbers:17036341); European Research Council (ERC)(grant numbers:949014); Luxembourg National Research Funds (FNR)(grant numbers:C20/IS/14761415/TestFlakes); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10382258,Test input prioritization;machine learning;mutation analysis;learning to rank;labelling,Predictive models;Adaptation models;Labeling;Machine learning;Testing;Noise measurement;Manuals,,5,,120,CCBY,5 Jan 2024,,,IEEE,IEEE Journals,True
Challenging Machine Learning-Based Clone Detectors via Semantic-Preserving Code Transformations,W. Zhang; S. Guo; H. Zhang; Y. Sui; Y. Xue; Y. Xu,"University of Science and Technology of China, Hefei, Anhui, China; Baidu Security, Beijing, China; University of Newcastle, Callaghan, NSW, Australia; University of New South Wales, Sydney, NSW, Australia; University of Science and Technology of China, Hefei, Anhui, China; University of Science and Technology of China, Hefei, Anhui, China",IEEE Transactions on Software Engineering,15 May 2023,2023,49,5,3052,3070,"Software clone detection identifies similar or identical code snippets. It has been an active research topic that attracts extensive attention over the last two decades. In recent years, machine learning (ML) based detectors, especially deep learning-based ones, have demonstrated impressive capability on clone detection. It seems that this longstanding problem has already been tamed owing to the advances in ML techniques. In this work, we would like to challenge the robustness of the recent ML-based clone detectors through code semantic-preserving transformations. We first utilize fifteen simple code transformation operators combined with commonly-used heuristics (i.e., Random Search, Genetic Algorithm, and Markov Chain Monte Carlo) to perform equivalent program transformation. Furthermore, we propose a deep reinforcement learning-based sequence generation (DRLSG) strategy to effectively guide the search process of generating clones that could escape from the detection. We then evaluate the ML-based detectors with the pairs of original and generated clones. We realize our method in a framework named CloneGen (stands for Clone Generator). CloneGen In evaluation, we challenge the three state-of-the-art ML-based detectors and four traditional detectors with the code clones after semantic-preserving transformations via the aid of CloneGen. Surprisingly, our experiments show that, despite the notable successes achieved by existing clone detectors, the ML models inside these detectors still cannot distinguish numerous clones produced by the code transformations in CloneGen. In addition, adversarial training of ML-based clone detectors using clones generated by CloneGen can improve their robustness and accuracy. Meanwhile, compared with the commonly-used heuristics, the DRLSG strategy has shown the best effectiveness in generating code clones to decrease the detection accuracy of the ML-based detectors. Our investigation reveals an explicable but always ignored robustness issue of the latest ML-based detectors. Therefore, we call for more attention to the robustness of these new ML-based detectors.",1939-3520,,10.1109/TSE.2023.3240118,National Natural Science Foundation of China(grant numbers:61972373); Basic Research Program of Jiangsu Province(grant numbers:BK20201192); CAS Pioneer Hundred Talents Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10028657,Clone detection;code transformaiton;semantic clone;machinae learning,Cloning;Codes;Detectors;Semantics;Source coding;Robustness;Training,,8,,88,IEEE,27 Jan 2023,,,IEEE,IEEE Journals,True
Specializing Neural Networks for Cryptographic Code Completion Applications,Y. Xiao; W. Song; J. Qi; B. Viswanath; P. McDaniel; D. Yao,"Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; School of Computer, Data and Information Sciences, University of Wisconsin-Madison, Madison, WI, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA",IEEE Transactions on Software Engineering,13 Jun 2023,2023,49,6,3524,3535,"Similarities between natural languages and programming languages have prompted researchers to apply neural network models to software problems, such as code generation and repair. However, program-specific characteristics pose unique prediction challenges that require the design of new and specialized neural network solutions. In this work, we identify new prediction challenges in application programming interface (API) completion tasks and find that existing solutions are unable to capture complex program dependencies in program semantics and structures. We design a new neural network model Multi-HyLSTM to overcome the newly identified challenges and comprehend complex dependencies between API calls. Our neural network is empowered with a specialized dataflow analysis to extract multiple global API dependence paths for neural network predictions. We evaluate Multi-HyLSTM on 64,478 Android Apps and predict 774,460 Java cryptographic API calls that are usually challenging for developers to use correctly. Our Multi-HyLSTM achieves an excellent top-1 API completion accuracy at 98.99%. Moreover, we show the effectiveness of our design choices through an ablation study and have released our dataset.",1939-3520,,10.1109/TSE.2023.3265362,National Science Foundation(grant numbers:CNS-1929701); Virginia Commonwealth Cyber Initiative; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10097631,API completion;neural networks;program dependencies,Codes;Neural networks;Cryptography;Task analysis;Operating systems;Context modeling;Mathematical models,,1,,57,CCBYNCND,7 Apr 2023,,,IEEE,IEEE Journals,True
Automatic Fairness Testing of Neural Classifiers Through Adversarial Sampling,P. Zhang; J. Wang; J. Sun; X. Wang; G. Dong; X. Wang; T. Dai; J. S. Dong,"Zhejiang University, Hangzhou, Zhejiang, China; Zhejiang University, Hangzhou, Zhejiang, China; Singapore Management University, Singapore, Singapore; Zhejiang University, Hangzhou, Zhejiang, China; Zhejiang University, Hangzhou, Zhejiang, China; Zhejiang University, Hangzhou, Zhejiang, China; Huawei International Pte. Ltd., Shenzhen, China; National University of Singapore, Singapore, Singapore",IEEE Transactions on Software Engineering,16 Sep 2022,2022,48,9,3593,3612,"Although deep learning has demonstrated astonishing performance in many applications, there are still concerns about its dependability. One desirable property of deep learning applications with societal impact is fairness (i.e., non-discrimination). Unfortunately, discrimination might be intrinsically embedded into the models due to the discrimination in the training data. As a countermeasure, fairness testing systemically identifies discriminatory samples, which can be used to retrain the model and improve the model’s fairness. Existing fairness testing approaches however have two major limitations. First, they only work well on traditional machine learning models and have poor performance (e.g., effectiveness and efficiency) on deep learning models. Second, they only work on simple structured (e.g., tabular) data and are not applicable for domains such as text. In this work, we bridge the gap by proposing a scalable and effective approach for systematically searching for discriminatory samples while extending existing fairness testing approaches to address a more challenging domain, i.e., text classification. Compared with state-of-the-art methods, our approach only employs lightweight procedures like gradient computation and clustering, which is significantly more scalable and effective. Experimental results show that on average, our approach explores the search space much more effectively (9.62 and 2.38 times more than the state-of-the-art methods respectively on tabular and text datasets) and generates much more discriminatory samples (24.95 and 2.68 times) within a same reasonable time. Moreover, the retrained models reduce discrimination by 57.2 and 60.2 percent respectively on average.",1939-3520,,10.1109/TSE.2021.3101478,"Key-Area Research and Development Program of Guangdong Province(grant numbers:2020B0101100005); Key Research and Development Program of Zhejiang Province(grant numbers:2021C01014); Zhejiang University; Guangdong Science and Technology Department(grant numbers:2018B010107004); Ministry of Education - Singapore(grant numbers:MOET32020-0004,T2EP20120-0019,T1-251RES1901); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506918,Deep learning;fairness testing;individual discrimination;gradient,Data models;Deep learning;Systematics;Recurrent neural networks;Neurons;Training data;Task analysis,,8,,60,IEEE,4 Aug 2021,,,IEEE,IEEE Journals,True
Explaining Static Analysis With Rule Graphs,L. N. Q. Do; E. Bodden,"Paderborn University, Paderborn, Germany; Paderborn University and Fraunhofer IEM, Paderborn, Germany",IEEE Transactions on Software Engineering,14 Feb 2022,2022,48,2,678,690,"As static data-flow analysis becomes able to report increasingly complex bugs, using an evergrowing set of complex internal rules encoded into flow functions, the analysis tools themselves grow more and more complex. In result, for users to be able to effectively use those tools on specific codebases, they require special configurations—a task which in industry is typically performed by individual developers or dedicated teams. To efficiently use and configure static analysis tools, developers need to build a certain understanding of the analysis’ rules, i.e., how the underlying analyses interpret the analyzed code and their reasoning for reporting certain warnings. In this article, we explore how to assist developers in understanding the analysis’ warnings, and finding weaknesses in the analysis’ rules. To this end, we introduce the concept of rule graphs that expose to the developer selected information about the internal rules of data-flow analyses. We have implemented rule graphs on top of a taint analysis, and show how the graphs can support the abovementioned tasks. Our user study and empirical evaluation show that using rule graphs helps developers understand analysis warnings more accurately than using simple warning traces, and that rule graphs can help developers identify causes for false positives in analysis rules.",1939-3520,,10.1109/TSE.2020.2999534,Heinz Nixdorf Stiftung; BMBF; DFG project RUNSECURE; NRW Research Training Group; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106860,Program analysis;data-flow analysis;rule graphs;analysis configuration;explainability;usability,Static analysis;Tools;SQL injection;Task analysis;Computer bugs;Cognition;Usability,,6,,44,IEEE,2 Jun 2020,,,IEEE,IEEE Journals,True
Any-Horizon Uniform Random Sampling and Enumeration of Constrained Scenarios for Simulation-Based Formal Verification,T. Mancini; I. Melatti; E. Tronci,"Computer Science Department, Sapienza University of Rome, Roma, Italy; Computer Science Department, Sapienza University of Rome, Roma, Italy; Computer Science Department, Sapienza University of Rome, Roma, Italy",IEEE Transactions on Software Engineering,18 Oct 2022,2022,48,10,4002,4013,"Model-based approaches to the verification of non-terminating Cyber-Physical Systems (CPSs) usually rely on numerical simulation of the System Under Verification (SUV) model under input scenarios of possibly varying duration, chosen among those satisfying given constraints. Such constraints typically stem from requirements (or assumptions) on the SUV inputs and its operational environment as well as from the enforcement of additional conditions aiming at, e.g., prioritising the (often extremely long) verification activity, by, e.g., focusing on scenarios explicitly exercising selected requirements, or avoiding vacuity in their satisfaction. In this setting, the possibility to efficiently sample at random (with a known distribution, e.g., uniformly) within, or to efficiently enumerate (possibly in a uniformly random order) scenarios among those satisfying all the given constraints is a key enabler for the practical viability of the verification process, e.g., via simulation-based statistical model checking. Unfortunately, in case of non-trivial combinations of constraints, iterative approaches like Markovian random walks in the space of sequences of inputs in general fail in extracting scenarios according to a given distribution (e.g., uniformly), and can be very inefficient to produce at all scenarios that are both legal (with respect to SUV assumptions) and of interest (with respect to the additional constraints). For example, in our case studies, up to 91% of the scenarios generated using such iterative approaches would need to be neglected. In this article, we show how, given a set of constraints on the input scenarios succinctly defined by multiple finite memory monitors, a data structure (scenario generator) can be synthesised, from which any-horizon scenarios satisfying the input constraints can be efficiently extracted by (possibly uniform) random sampling or (randomised) enumeration. Our approach enables seamless support to virtually all simulation-based approaches to CPS verification, ranging from simple random testing to statistical model checking and formal (i.e., exhaustive) verification, when a suitable bound on the horizon or an iterative horizon enlargement strategy is defined, as in the spirit of bounded model checking.",1939-3520,,10.1109/TSE.2021.3109842,"Italian Ministry of University & Research; Sapienza Università di Roma; INdAM GNCS; Sapienza U. Projects(grant numbers:RG11816436BD4F21,RG11916B892E54DB,RP11916B8665242F); Lazio POR FESR(grant numbers:E84G20000150006,F83G17000830007); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9527998,Simulation-based verification;cyber-physical systems;scenario generation,Monitoring;Integrated circuit modeling;Contracts;Numerical models;Law;Mathematical model;Iterative methods,,6,,74,IEEE,2 Sep 2021,,,IEEE,IEEE Journals,True
Increasing the Confidence of Deep Neural Networks by Coverage Analysis,G. Rossolini; A. Biondi; G. Buttazzo,"Department of Excellence in Robotics & AI, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Excellence in Robotics & AI, Scuola Superiore Sant'Anna, Pisa, Italy; Department of Excellence in Robotics & AI, Scuola Superiore Sant'Anna, Pisa, Italy",IEEE Transactions on Software Engineering,14 Feb 2023,2023,49,2,802,815,"The great performance of machine learning algorithms and deep neural networks in several perception and control tasks is pushing the industry to adopt such technologies in safety-critical applications, as autonomous robots and self-driving vehicles. At present, however, several issues need to be solved to make deep learning methods more trustworthy, predictable, safe, and secure against adversarial attacks. Although several methods have been proposed to improve the trustworthiness of deep neural networks, most of them are tailored for specific classes of adversarial examples, hence failing to detect other corner cases or unsafe inputs that heavily deviate from the training samples. This paper presents a lightweight monitoring architecture based on coverage paradigms to enhance the model robustness against different unsafe inputs. In particular, four coverage analysis methods are proposed and tested in the architecture for evaluating multiple detection logic. Experimental results show that the proposed approach is effective in detecting both powerful adversarial examples and out-of-distribution inputs, introducing limited extra-execution time and memory requirements.",1939-3520,,10.1109/TSE.2022.3163682,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9745342,Neural networks coverage;DNNs robustness;adversarial examples detection,Robustness;Testing;Predictive models;Computer architecture;Monitoring;Deep learning;Task analysis,,3,,55,IEEE,30 Mar 2022,,,IEEE,IEEE Journals,True
Achieving High MAP-Coverage Through Pattern Constraint Reduction,Y. Zhao; Z. Wang; S. Liu; J. Sun; J. Chen; X. Chen,"College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; School of Information Systems, Singapore Management University, Singapore; College of Intelligence and Computing, Tianjin University, Tianjin, China; School of Information Science and Technology, Nantong University, Nantong, China",IEEE Transactions on Software Engineering,6 Jan 2023,2023,49,1,99,112,"Testing multi-threaded programs is challenging due to the enormous space of thread interleavings. Recently, a code coverage criterion for multi-threaded programs called MAP-coverage has been proposed and shown to be effective for testing concurrent programs. Existing approaches for achieving high MAP-coverage are based on random testing with simple heuristics, which is ineffective in systematically triggering rare thread interleavings. In this study, we propose a novel approach called pattern constraint reduction (PCR), which employs optimized constraint solving to generate thread interleavings for high MAP-coverage. The idea is to iteratively encode and solve path conditions to generate thread interleavings which are guaranteed to improve MAP-coverage. Furthermore, we effectively apply interpolation techniques to reduce the efforts of constraint solving by avoiding solving infeasible constraints. The experiment results on 20 benchmark programs show that our approach complements existing random testing based approaches when there are rare failure-inducing interleaving in the whole search space. Specifically, PCR finds concurrency bugs faster in 18 out of 20 programs, with an average speedup of 4.2x and a maximum speedup of 11.4x.",1939-3520,,10.1109/TSE.2022.3144480,"National Natural Science Foundation of China(grant numbers:61872263,U1836214,61802275,62002256); Singapore Ministry of Education Research Found(grant numbers:MOE2016-T2-2-123); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9689981,Concurrency bug detection;constraint solving;coverage criteria;thread-safe class,Computer bugs;Concurrent computing;Instruction sets;Programming;Message systems;Systematics;Sun,,1,,66,IEEE,21 Jan 2022,,,IEEE,IEEE Journals,True
On the Effectiveness of Transfer Learning for Code Search,P. Salza; C. Schwizer; J. Gu; H. C. Gall,"University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1804,1822,"The Transformer architecture and transfer learning have marked a quantum leap in natural language processing, improving the state of the art across a range of text-based tasks. This paper examines how these advancements can be applied to and improve code search. To this end, we pre-train a BERT-based model on combinations of natural language and source code data and fine-tune it on pairs of StackOverflow question titles and code answers. Our results show that the pre-trained models consistently outperform the models that were not pre-trained. In cases where the model was pre-trained on natural language “and” source code data, it also outperforms an information retrieval baseline based on Lucene. Also, we demonstrated that the combined use of an information retrieval-based approach followed by a Transformer leads to the best results overall, especially when searching into a large search pool. Transfer learning is particularly effective when much pre-training data is available and fine-tuning data is limited. We demonstrate that natural language processing models based on the Transformer architecture can be directly applied to source code analysis tasks, such as code search. With the development of Transformer models designed more specifically for dealing with source code data, we believe the results of source code analysis tasks can be further improved.",1939-3520,,10.1109/TSE.2022.3192755,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung(grant numbers:SNSF204632); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9835142,Code search;transfer learning;source code modeling;multimodal embeddings;stackoverflow;deep learning,Codes;Bit error rate;Task analysis;Transformers;Micromechanical devices;Transfer learning;Data models,,11,,84,IEEE,21 Jul 2022,,,IEEE,IEEE Journals,True
MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation,F. Cassano; J. Gouwar; D. Nguyen; S. Nguyen; L. Phipps-Costin; D. Pinckney; M. -H. Yee; Y. Zi; C. J. Anderson; M. Q. Feldman; A. Guha; M. Greenberg; A. Jangda,"Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Hanover High School, Hanover, NH, USA; Computer Science, Wellesley College, Wellesley, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Wellesley College, Wellesley, MA, USA; Computer Science, Oberlin College, Oberlin, OH, USA; Computer Science, Northeastern University, Boston, MA, USA; Computer Science, Stevens Institute of Technology, Hoboken, NJ, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,17 Jul 2023,2023,49,7,3675,3691,"Large language models have demonstrated the ability to generate both natural language and programming language text. Although contemporary code generation models are trained on corpora with several programming languages, they are tested using benchmarks that are typically monolingual. The most widely used code generation benchmarks only target Python, so there is little quantitative evidence of how code generation models perform on other programming languages. We propose MultiPL-E, a system for translating unit test-driven code generation benchmarks to new languages. We create the first massively multilingual code generation benchmark by using MultiPL-E to translate two popular Python code generation benchmarks to 18 additional programming languages. We use MultiPL-E to extend the HumanEval benchmark (Chen et al., 2021) and MBPP benchmark (Austin et al., 2021) to 18 languages that encompass a range of programming paradigms and popularity. Using these new parallel benchmarks, we evaluate the multi-language performance of three state-of-the-art code generation models: Codex (Chen et al., 2021), CodeGen (Nijkamp et al., 2022) and InCoder (Fried et al., 2022). We find that Codex matches or even exceeds its performance on Python for several other languages. The range of programming languages represented in MultiPL-E allow us to explore the impact of language frequency and language features on model performance. Finally, the MultiPL-E approach of compiling code generation benchmarks to new programming languages is both scalable and extensible, making it straightforward to evaluate new models, benchmarks, and languages.",1939-3520,,10.1109/TSE.2023.3267446,National Science Foundation(grant numbers:CCF-2052696); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10103177,"B.2.3 reliability, testing, and fault-tolerance;I.5.1.D neural nets",Codes;Benchmark testing;Python;Programming;Natural languages;Task analysis;Syntactics,,11,,42,CCBY,17 Apr 2023,,,IEEE,IEEE Journals,True
"Pretrain, Prompt, and Transfer: Evolving Digital Twins for Time-to-Event Analysis in Cyber-Physical Systems",Q. Xu; T. Yue; S. Ali; M. Arratibel,"Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Orona Group, Hernani, Basque Country, Spain",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1464,1477,"Cyber-physicalnd systems (CPSs), e.g., elevators and autonomous driving systems, are progressively permeating our everyday lives. To ensure their safety, various analyses need to be conducted, such as anomaly detection and time-to-event analysis (the focus of this paper). Recently, it has been widely accepted that digital Twins (DTs) can be an efficient method to aid in developing, maintaining, and safe and secure operation of CPSs. However, CPSs frequently evolve, e.g., with new or updated functionalities, which demand their corresponding DTs be co-evolved, i.e., in synchronization with the CPSs. To that end, we propose a novel method, named PPT, utilizing an uncertainty-aware transfer learning for DT evolution. Specifically, we first pretrain PPT with a pretraining dataset to acquire generic knowledge about the CPSs, followed by adapting it to a specific CPS with the help of prompt tuning. Results highlight that PPT is effective in time-to-event analysis in both elevator and autonomous driving case studies, on average, outperforming a baseline method by 7.31 and 12.58 in terms of Huber loss, respectively. The experiment results also affirm the effectiveness of transfer learning, prompt tuning, and uncertainty quantification in terms of reducing Huber loss by at least 21.32, 3.14, and 4.08, respectively, in both case studies.",1939-3520,,10.1109/TSE.2024.3388572,Utdannings- og forskningsdepartementet; Horizon 2020 project ADEPTNESS(grant numbers:871319); European Commission and the Co-tester project(grant numbers:314544); Norges Forskningsråd(grant numbers:270053); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10500740,Digital twin;transfer learning;prompt tuning;cyber-physical systems,Elevators;Uncertainty;Mathematical models;Digital twins;Tuning;Transfer learning;Training,,1,,51,IEEE,15 Apr 2024,,,IEEE,IEEE Journals,True
CombTransformers: Statement-Wise Transformers for Statement-Wise Representations,F. Bertolotti; W. Cazzola,"Department of Computer Science, Università degli Studi di Milano, Milan, Italy; Department of Computer Science, Università degli Studi di Milano, Milan, Italy",IEEE Transactions on Software Engineering,17 Oct 2023,2023,49,10,4677,4690,"This study presents a novel category of Transformer architectures known as comb transformers, which effectively reduce the space complexity of the self-attention layer from a quadratic to a subquadratic level. This is achieved by processing sequence segments independently and incorporating $\mathcal{X}$X-word embeddings to merge cross-segment information. The reduction in attention memory requirements enables the deployment of deeper architectures, potentially leading to more competitive outcomes. Furthermore, we design an abstract syntax tree (AST)-based code representation to effectively exploit comb transformer properties. To explore the potential of our approach, we develop nine specific instances based on three popular architectural concepts: funnel, hourglass, and encoder-decoder. These architectures are subsequently trained on three code-related tasks: method name generation, code search, and code summarization. These tasks encompass a range of capabilities: short/long sequence generation and classification. In addition to the proposed comb transformers, we also evaluate several baseline architectures for comparative analysis. Our findings demonstrate that the comb transformers match the performance of the baselines and frequently perform better.",1939-3520,,10.1109/TSE.2023.3310793,MUR project “T-LADIES”(grant numbers:PRIN 2020TL3X8X); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242162,Programming languages;machine learning;learning representations;code search and summarization;method name Gen,Codes;Transformers;Task analysis;Computer architecture;Artificial neural networks;Documentation;Training,,1,,71,CCBYNCND,6 Sep 2023,,,IEEE,IEEE Journals,True
Bootstrapping Automated Testing for RESTful Web Services,Z. Lei; Y. Chen; Y. Yang; M. Xia; Z. Qi,"Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; AppetizerIO, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Software Engineering,18 Apr 2023,2023,49,4,1561,1579,"Modern RESTful services expose RESTful APIs to integrate with diversified applications. Most RESTful API parameters are weakly typed, which greatly increases the possible input value space. Weakly-typed parameters pose difficulties for automated testing tools to generate effective test cases to reveal web service defects related to parameter validation. We call this phenomenon the type collapse problem. To remedy this problem, we introduce FET (Format-encoded Type) techniques, including the FET, the FET lattice, and the FET inference to model fine-grained information for API parameters. Inferred FET can enhance parameter validation, such as generating a parameter validator for a certain RESTful server. Enhanced by FET techniques, automated testing tools can generate targeted test cases. We demonstrate Leif, a trace-driven fuzzing tool, as a proof-of-concept implementation of FET techniques. Experiment results on 27 commercial services show that FET inference precisely captures documented parameter definitions, which helps Leif discover 11 new bugs and reduce $72\% - 86\%$72%-86% fuzzing time compared to state-of-the-art fuzzers. Leveraged by the inter-parameter dependency inference, Leif saves $15\%$15% fuzzing time.",1939-3520,,10.1109/TSE.2022.3182663,"National Key Research Development Program of China(grant numbers:2016YFB1000502); National NSF of China(grant numbers:61672344,61525204,61732010); Shanghai Pujiang Program(grant numbers:19PJ1430900); Shanghai Key Laboratory of Scalable Computing and Systems; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796038,Fuzz testing;RESTful web service;type inference,Field effect transistors;Lattices;Testing;Fuzzing;Codes;Web services;Restful API,,1,,69,IEEE,14 Jun 2022,,,IEEE,IEEE Journals,True
Test Input Prioritization for Graph Neural Networks,Y. Li; X. Dang; W. Pian; A. Habib; J. Klein; T. F. Bissyandé,"University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg",IEEE Transactions on Software Engineering,14 Jun 2024,2024,50,6,1396,1424,"GNNs have shown remarkable performance in a variety of classification tasks. The reliability of GNN models needs to be thoroughly validated before their deployment to ensure their accurate functioning. Therefore, effective testing is essential for identifying vulnerabilities in GNN models. However, given the complexity and size of graph-structured data, the cost of manual labelling of GNN test inputs can be prohibitively high for real-world use cases. Although several approaches have been proposed in the general domain of Deep Neural Network (DNN) testing to alleviate this labelling cost issue, these approaches are not suitable for GNNs because they do not account for the interdependence between GNN test inputs, which is crucial for GNN inference. In this paper, we propose NodeRank, a novel test prioritization approach specifically for GNNs, guided by ensemble learning-based mutation analysis. Inspired by traditional mutation testing, where specific operators are applied to mutate code statements to identify whether provided test cases reveal faults, NodeRank operates on a crucial premise: If a test input (node) can kill many mutated models and produce different prediction results with many mutated inputs, this input is considered more likely to be misclassified by the GNN model and should be prioritized higher. Through prioritization, these potentially misclassified inputs can be identified earlier with limited manual labeling cost. NodeRank introduces mutation operators suitable for GNNs, focusing on three key aspects: the graph structure, the features of the graph nodes, and the GNN model itself. NodeRank generates mutants and compares their predictions against that of the initial test inputs. Based on the comparison results, a mutation feature vector is generated for each test input and used as the input to ranking models for test prioritization. Leveraging ensemble learning techniques, NodeRank combines the prediction results of the base ranking models and produces a misclassification score for each test input, which can indicate the likelihood of this input being misclassified. NodeRank sorts all the test inputs based on their scores in descending order. To evaluate NodeRank, we build 124 GNN subjects (i.e., a pair of dataset and GNN model), incorporating both natural and adversarial contexts. Our results demonstrate that NodeRank outperforms all the compared test prioritization approaches in terms of both APFD and PFD, which are widely-adopted metrics in this field. Specifically, NodeRank achieves an average improvement of between 4.41% and 58.11% on original datasets and between 4.96% and 62.15% on adversarial datasets.",1939-3520,,10.1109/TSE.2024.3385538,European Research Council (ERC) through the European Union’s Horizon 2020(grant numbers:949014); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494069,Test input prioritization;graph neural networks;mutation analysis;learning to rank;labelling,Predictive models;Graph neural networks;Testing;Labeling;Ensemble learning;Artificial neural networks;Context modeling,,,,96,CCBY,5 Apr 2024,,,IEEE,IEEE Journals,True
StagedVulBERT: Multi-Granular Vulnerability Detection with a Novel Pre-trained Code Model,Y. Jiang; Y. Zhang; X. Su; C. Treude; T. Wang,"School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 15001; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 15001; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 15001; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 15001",IEEE Transactions on Software Engineering,,2024,PP,99,1,18,"The emergence of pre-trained model-based vulnerability detection methods has significantly advanced the field of automated vulnerability detection. However, these methods still face several challenges, such as difficulty in learning effective feature representations of statements for fine-grained predictions and struggling to process overly long code sequences. To address these issues, this study introduces StagedVulBERT, a novel vulnerability detection framework that leverages a pre-trained code language model and employs a coarse-to-fine strategy. The key innovation and contribution of our research lies in the development of the CodeBERT-HLS component within our framework, specialized in hierarchical, layered, and semantic encoding. This component is designed to capture semantics at both the token and statement levels simultaneously, which is crucial for achieving more accurate multi-granular vulnerability detection. Additionally, CodeBERT-HLS efficiently processes longer code token sequences, making it more suited to real-world vulnerability detection. Comprehensive experiments demonstrate that our method enhances the performance of vulnerability detection at both coarse- and fine-grained levels. Specifically, in coarse-grained vulnerability detection, StagedVulBERT achieves an F1 score of 92.26%, marking a 6.58% improvement over the best-performing methods. At the fine-grained level, our method achieves a Top-5% accuracy of 65.69%, which outperforms the state-of-the-art methods by up to 75.17%.",1939-3520,,10.1109/TSE.2024.3493245,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10746847,Vulnerability detection;Code language model;Pre-training task;Program representation,Codes;Transformers;Feature extraction;Semantics;Training;Accuracy;Technological innovation;Predictive models;Heating systems;Computer architecture,,,,,IEEE,7 Nov 2024,,,IEEE,IEEE Early Access Articles,True
LLM-Based Test-Driven Interactive Code Generation: User Study and Empirical Evaluation,S. Fakhoury; A. Naik; G. Sakkas; S. Chakraborty; S. K. Lahiri,"Microsoft Research, Redmond, WA, USA; University of Pennsylvania, Philadelphia, PA, USA; University of California, San Diego, CA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,18 Sep 2024,2024,50,9,2254,2268,"Large language models (LLMs) have shown great potential in automating significant aspects of coding by producing natural code from informal natural language (NL) intent. However, given NL is informal, it does not lend easily to checking that the generated code correctly satisfies the user intent. In this paper, we propose a novel interactive workflow TiCoder for guided intent clarification (i.e., partial formalization) through tests to support the generation of more accurate code suggestions. Through a mixed methods user study with 15 programmers, we present an empirical evaluation of the effectiveness of the workflow to improve code generation accuracy. We find that participants using the proposed workflow are significantly more likely to correctly evaluate AI generated code, and report significantly less task-induced cognitive load. Furthermore, we test the potential of the workflow at scale with four different state-of-the-art LLMs on two python datasets, using an idealized proxy for a user feedback. We observe an average absolute improvement of 45.97% in the pass@1 code generation accuracy for both datasets and across all LLMs within 5 user interactions, in addition to the automatic generation of accompanying unit tests.",1939-3520,,10.1109/TSE.2024.3428972,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10606356,Intent disambiguation;code generation;LLMs;human factors;cognitive load;test generation,Codes;Accuracy;Natural languages;Artificial intelligence;Python;Task analysis;Benchmark testing,,,,48,IEEE,22 Jul 2024,,,IEEE,IEEE Journals,True
Unearthing Gas-Wasting Code Smells in Smart Contracts with Large Language Models,J. Jiang; Z. Li; H. Qin; M. Jiang; X. Luo; X. Wu; H. Wang; Y. Tang; C. Qian; T. Chen,NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,IEEE Transactions on Software Engineering,,2024,PP,99,1,26,"Smart contracts are automated programs stored on a blockchain, featuring unique attributes such as permissionlessness, trustlessness, immutability, and transparency. These properties underpin an array of unprecedented decentralized services. Compiled into bytecodes, Ethereum smart contracts are executed within the Ethereum Virtual Machine (EVM). Ethereum’s distinct gas mechanism assigns a price to each bytecode execution, incentivizing resource-efficient computing. However, a disconnect exists between conventional coding practices and the less intuitive gas consumption computation mechanism, resulting in inadvertent gas wastage. Gas-wasting code smells at the source code level have been studied in various related works; however, the task of manually identifying such code smells by reading through codes and reasoning about them is both time-consuming and economically inefficient. In this work, we propose to leverage Large Language Models (LLMs), which have seen a surge in popularity recently, to facilitate undertaking the labor-intensive part of the code-smell-finding pipeline. In particular, we focus on Solidity, the predominant programming language for Ethereum smart contracts. Overall, we identified 26 gas-wasting code smells, out of which 13 were not presented in previous papers. On average, applying these code smells led to a reduction of approximately 10.534% in deployment costs and 21.528% in message call costs across our test codes. We further make a report on each of the identified code smells with associated example contracts sourced from either previous literature or recently deployed contracts.",1939-3520,,10.1109/TSE.2024.3491578,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10757316,Artificial Intelligence;Patterns;Program Analysis;Smart Contracts;Language Models,Codes;Pipelines;Smart contracts;Costs;Cognition;Reliability;Schedules;Computer languages;Trustless services;Source coding,,,,,IEEE,19 Nov 2024,,,IEEE,IEEE Early Access Articles,True
Corrections to “Uncovering Bugs in Code Coverage Profilers via Control Flow Constraint Solving”,Y. Wang; P. Zhang; M. Sun; Z. Lu; Y. Yang; Y. Tang; J. Qian; Z. Li; Y. Zhou,"State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,10 Jan 2024,2024,50,1,158,158,"In [1, p. 4967], a figure citation is incorrect and “Fig. 3(c)” should be “Fig. 1(c)” in the left column, the fourth line from the bottom. It is corrected below.",1939-3520,,10.1109/TSE.2023.3339345,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387509,,Computer bugs;Codes;Testing;Constraint handling,,,,1,IEEE,10 Jan 2024,,,IEEE,IEEE Journals,True
The co-evolution of socio-technical structures in sustainable software development: Lessons from the open source software communities,M. S. Zanetti,"ETH Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1587,1590,"Software development depends on many factors, including technical, human and social aspects. Due to the complexity of this dependence, a unifying framework must be defined and for this purpose we adopt the complex networks methodology. We use a data-driven approach based on a large collection of open source software projects extracted from online project development platforms. The preliminary results presented in this article reveal that the network perspective yields key insights into the sustainability of software development.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227030,complex networks;statistical physics;social networks;software dependency graphs;open source software;free software;quantitative analysis;mining software repositories,Software;Programming;Complex networks;Measurement;Software engineering;Communities;Collaboration,,10,,15,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Software Engineering Research in a World with Generative Artificial Intelligence,M. Rinard,"Department of Electrical Engineering and Computer Science, Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, Massachusetts, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,3,7,Generative artificial intelligence systems such as large language models (LLMs) exhibit powerful capabilities that many see as the kind of flexible and adaptive intelligence that previously only humans could exhibit. I address directions and implications of LLMs for software engineering research.,1558-1225,979-8-4007-0217-4,10.1145/3597503.3649399,DARPA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548653,Software Engineering;Generative Artificial Intelligence;Large Language Models,Adaptation models;Adaptive systems;Generative AI;Software;Software engineering,,,,24,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering,S. McGuire; E. Schultz; B. Ayoola; P. Ralph,"Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1996,2008,"Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or “pillars”-environmental, social, economic, technical and in-dividual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00169,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172842,Sustainable development;software engineering;sustainable software engineering;scoping review;meta-synthesis,Economics;Sociotechnical systems;Systematics;Databases;Biological system modeling;Instruments;Software,,7,,74,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Software Engineering as the Linchpin of Responsible AI,L. Zhu,"CSIRO's Data61, Sydney, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,3,4,"From humanity's existential risks to safety risks in critical systems to ethical risks, responsible AI, as the saviour, has become a major research challenge with significant real-world consequences. However, achieving responsible AI remains elusive despite the plethora of high-level ethical principles, risk frameworks and progress in algorithmic assurance. In the meantime, software engineering (SE) is being upended by AI, grappling with building system-level quality and alignment from inscrutable machine learning models and code generated from natural language prompts. The upending poses new challenges and opportunities for engineering AI systems responsibly. This talk will share our experiences in helping the industry achieve responsible AI systems by inventing new SE approaches. It will dive into industry challenges (such as risk silos and principle-algorithm gaps) and research challenges (such as lack of requirements, emerging properties and inscrutable systems) and make the point that SE is the linchpin of responsible AI. But SE also requires some fundamental rethinking - shifting from building functions into AI systems to discovering and managing emerging functions from AI systems. Only by doing so can SE take on critical new roles, from understanding human intelligence to building a thriving human-AI symbiosis.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00012,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172687,Responsible AI;Ethical AI;Trustworthy AI;AI Engineering;SE4AI,Industries;Symbiosis;Ethics;Machine learning algorithms;Buildings;Software algorithms;Natural languages,,,,6,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
When open source turns cold on innovation — The challenges of navigating licensing complexities in new research domains,C. Forbes; I. Keivanloo; J. Rilling,"Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1447,1448,"In this poster, we review the limitations open source licences introduce to the application of Linked Data in Software Engineering. We investigate whether open source licences support special requirements to publish source code as Linked Data on the Internet.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227071,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227071,source code;license;Linked Data;open source,Licenses;Law;Software engineering;Databases;Software;Complexity theory,,,,10,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
FastFix: Monitoring control for remote software maintenance,D. Pagano; M. A. Juan; A. Bagnato; T. Roehm; B. Bruegge; W. Maalej,"Technical University of München, Munich, Germany; S2 Grupo, Valencia, Spain; TXT e-solutions, Milano, Italy; Technical University of München, Munich, Germany; Technical University of München, Munich, Germany; Technical University of München, Munich, Germany",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1437,1438,"Software maintenance and support services are key factors to the customer perception of software product quality. The overall goal of FastFix is to provide developers with a real-time maintenance environment that increases efficiency and reduces costs, improving accuracy in identification of failure causes and facilitating their resolution. To achieve this goal, FastFix observes application execution and user interaction at runtime. We give an overview of the functionality of FastFix and present one of its main application scenarios.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227076,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227076,software maintenance;context-aware software engineering;event correlation;fault replication;self-healing,Maintenance engineering;Context;Correlation;Monitoring;Sensors;Software maintenance,,3,,7,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Augmented intelligence — The new AI — Unleashing human capabilities in knowledge work,J. M. Corrigan,"Department of Philosophy, Stony Brook University, Stony Brook, NY, USA",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1285,1288,"In this paper I describe a novel application of contemplative techniques to software engineering with the goal of augmenting the intellectual capabilities of knowledge workers within the field in four areas: flexibility, attention, creativity, and trust. The augmentation of software engineers' intellectual capabilities is proposed as a third complement to the traditional focus of methodologies on the process and environmental factors of the software development endeavor. I argue that these capabilities have been shown to be open to improvement through the practices traditionally used in spiritual traditions, but now used increasingly in other fields of knowledge work, such as in the medical profession and the education field. Historically, the intellectual capabilities of software engineers have been treated as a given within any particular software development effort. This is argued to be an aspect ripe for inclusion within software development methodologies.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227098,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227098,Development Methodologies;Knowledge Workers;Contemplative Practices;Contemplative Techniques;Flexibility;Attention;Creativity;Trust;Awareness;Augmented Intelligence,Humans;Software engineering;Software;Stress;Problem-solving;Productivity;Knowledge engineering,,2,,11,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering,R. Choudhuri; D. Liu; I. Steinmacher; M. Gerosa; A. Sarma,"Oregon State University, Corvallis, OR, USA; Oregon State University, Corvallis, OR, USA; Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA; Oregon State University, Corvallis, OR, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2270,2282,"Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639201,"National Science Foundation(grant numbers:2235601,2236198,2247929,2303042,2303043); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549015,Empirical Study;Software Engineering;Generative AI;ChatGPT,Productivity;Uncertainty;Generative AI;Navigation;Chatbots;Task analysis;Standards,,1,,98,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Demystifying and Detecting Misuses of Deep Learning APIs,M. Wei; N. S. Harzevili; Y. Huang; J. Yang; J. Wang; S. Wang,"York University, Toronto, Canada; York University, Toronto, Canada; Chinese Academy of Sciences, Beijing, China; Concordia University, Montreal, Canada; Chinese Academy of Sciences, Beijing, China; York University, Toronto, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2482,2493,"Deep Learning (DL) libraries have significantly impacted various domains in computer science over the last decade. However, developers often face challenges when using the DL APIs, as the development paradigm of DL applications differs greatly from traditional software development. Existing studies on API misuse mainly focus on traditional software, leaving a gap in understanding API misuse within DL APIs. To address this gap, we present the first comprehensive study of DL API misuse in TensorFlow and PyTorch. Specifically, we first collected a dataset of 4,224 commits from the top 200 most-starred projects using these two libraries and manually identified 891 API misuses. We then investigated the characteristics of these misuses from three perspectives, i.e., types, root causes, and symptoms. We have also conducted an evaluation to assess the effectiveness of the current state-of-the-art API misuse detector on our 891 confirmed API misuses. Our results confirmed that the state-of-the-art API misuse detector is ineffective in detecting DL API misuses. To address the limitations of existing API misuse detection for DL APIs, we propose LLMAPIDet, which leverages Large Language Models (LLMs) for DL API misuse detection and repair. We build LLMAPIDet by prompt-tuning a chain of ChatGPT prompts on 600 out of 891 confirmed API misuses and reserve the rest 291 API misuses as the testing dataset. Our evaluation shows that LLMAPIDet can detect 48 out of the 291 DL API misuses while none of them can be detected by the existing API misuse detector. We further evaluate LLMAPIDet on the latest versions of 10 GitHub projects. The evaluation shows that LLMAPIDet can identify 119 previously unknown API misuses and successfully fix 46 of them.",1558-1225,979-8-4007-0217-4,,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549604,Software and its engineering → Software evolution;Software libraries and repositories;Computing methodologies → Machine learning;API misuse;deep learning APIs;empirical study;detection,Deep learning;Computer science;Source coding;Detectors;Maintenance engineering;Libraries;Software,,1,,57,,14 Jun 2024,,,IEEE,IEEE Conferences,True
ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering,C. Ferrara; F. Casillo; C. Gravino; A. De Lucia; F. Palomba,"University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2631,2642,"Machine learning (ML) is increasingly being used as a key component of most software systems, yet serious concerns have been raised about the fairness of ML predictions. Researchers have been proposing novel methods to support the development of fair machine learning solutions. Nonetheless, most of them can only be used in late development stages, e.g., during model training, while there is a lack of methods that may provide practitioners with early fairness analytics enabling the treatment of fairness throughout the development lifecycle. This paper proposes RefAir, a novel context-aware requirements engineering framework that allows to classify sensitive features from User Stories. By exploiting natural language processing and word embedding techniques, our framework first identifies both the use case domain and the machine learning task to be performed in the system being developed; afterward, it recommends which are the context-specific sensitive features to be considered during the implementation. We assess the capabilities of RefAir by experimenting it against a synthetic dataset-which we built as part of our research-composed of 12,401 User Stories related to 34 application domains. Our findings showcase the high accuracy of RefAir, other than highlighting its current limitations.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639185,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548414,Software Fairness;Machine Learning;Requirements Engineering,Training;Analytical models;Machine learning;Software systems;Natural language processing;Requirements engineering;Task analysis,,,,66,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation,P. Mahbub; O. Shuvo; M. M. Rahman,"Department of Computer Science, Dalhousie University, Nova Scotia, Canada; Department of Computer Science, Dalhousie University, Nova Scotia, Canada; Department of Computer Science, Dalhousie University, Nova Scotia, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,640,652,"Software bugs claim ≈ 50 % of development time and cost the global economy billions of dollars. Once a bug is reported, the assigned developer attempts to identify and understand the source code responsible for the bug and then corrects the code. Over the last five decades, there has been significant research on automatically finding or correcting software bugs. However, there has been little research on automatically explaining the bugs to the developers, which is essential but a highly challenging task. In this paper, we propose Bugsplainer, a transformer-based generative model, that generates natural language explanations for software bugs by learning from a large corpus of bug-fix commits. Bugsplainer can leverage structural information and buggy patterns from the source code to generate an explanation for a bug. Our evaluation using three performance metrics shows that Bugsplainer can generate understandable and good explanations according to Google's standard, and can outperform multiple baselines from the literature. We also conduct a developer study involving 20 participants where the explanations from Bugsplainer were found to be more accurate, more precise, more concise and more useful than the baselines.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00063,Dalhousie University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172643,software bug;bug explanation;software engineering;software maintenance;natural language processing;deep learning;transformers,Measurement;Codes;Source coding;Computer bugs;Natural languages;Transformers;Software,,9,,63,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry,W. Jiang; N. Synovic; M. Hyatt; T. R. Schorlemmer; R. Sethi; Y. -H. Lu; G. K. Thiruvathukal; J. C. Davis,Purdue University; Loyola University Chicago; Loyola University Chicago; Purdue University; Loyola University Chicago; Purdue University; Loyola University Chicago; Purdue University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2463,2475,"Deep Neural Networks (DNNs) are being adopted as components in software systems. Creating and specializing DNNs from scratch has grown increasingly difficult as state-of-the-art architectures grow more complex. Following the path of traditional software engineering, machine learning engineers have begun to reuse large-scale pre-trained models (PTMs) and fine-tune these models for downstream tasks. Prior works have studied reuse practices for traditional software packages to guide software engineers towards better package maintenance and dependency management. We lack a similar foundation of knowledge to guide behaviors in pre-trained model ecosystems. In this work, we present the first empirical investigation of PTM reuse. We interviewed 12 practitioners from the most popular PTM ecosystem, Hugging Face, to learn the practices and challenges of PTM reuse. From this data, we model the decision-making process for PTM reuse. Based on the identified practices, we describe useful attributes for model reuse, including provenance, reproducibility, and portability. Three challenges for PTM reuse are missing attributes, discrepancies between claimed and actual performance, and model risks. We substantiate these identified challenges with systematic measurements in the Hugging Face ecosystem. Our work informs future directions on optimizing deep learning ecosystems by automated measuring useful attributes and potential attacks, and envision future research on infrastructure and standardization for model registries.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00206,"Google; Cisco; NSF(grant numbers:2107230,2229703,2107020,2104319); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172757,Software reuse;Empirical software engineering;Machine learning;Deep learning;Software supply chain;Engineering decision making;Cybersecurity;Trust,Deep learning;Systematics;Biological system modeling;Ecosystems;Decision making;Supply chains;Standardization,,19,,96,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
"Characterizing Software Maintenance Meetings: Information Shared, Discussion Outcomes, and Information Captured",A. M. Soria; T. Lopez; N. Mashhadi; A. Van der Hoek; E. Seero; E. Evans; J. Burge,"Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Mathematics and Computer Science Colorado College, Colorado, CO, U.S.A.; Department of Mathematics and Computer Science Colorado College, Colorado, CO, U.S.A.; Department of Mathematics and Computer Science Colorado College, Colorado, CO, U.S.A.",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,665,677,"A type of meeting that has been understudied in the software engineering literature to date is what we term the software maintenance meeting: a regularly scheduled team meeting in which emergent issues are addressed that are usually out of scope of the daily stand-up but not necessarily challenging enough to warrant an entirely separate meeting. These meetings tend to discuss a wide variety of topics and are crucial in keeping software development projects going, but little is known about these meetings and how they proceed. In this paper, we report on a single exploratory case study in which we analyzed ten consecutive maintenance meetings from a major healthcare software provider. We analyzed what kind of information is brought into the discussions held in these meetings and how, what outcomes arose from the discussions, and what information was captured for downstream use. Our findings are varied, giving rise to both practical considerations for those conducting these kinds of meetings and new research directions toward further understanding and supporting them.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623330,"National Science Foundation(grant numbers:CCF-2210812,CCF-2210813); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548798,Meetings;software maintenance;information;resolution,Software maintenance;Heart beat;Conferences;Medical services;Maintenance;Software engineering;Software development management,,,,91,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Exploring Experiences with Automated Program Repair in Practice,F. N. Meem; J. Smith; B. Johnson,"George Mason University, Virginia, USA; Lafayette College, Pennsylvania, USA; George Mason University, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1047,1057,"Automated program repair, also known as APR, is an approach for automatically repairing software faults. There is a large amount of research on automated program repair, but very little offers in-depth insights into how practitioners think about and employ APR in practice. To learn more about practitioners' perspectives and experiences with current APR tools and techniques, we administered a survey, which received valid responses from 331 software practitioners. We analyzed survey responses to gain insights regarding factors that correlate with APR awareness, experience, and use. We established a strong correlation between APR awareness and tool use and attributes including job position, company size, total coding experience, and preferred language of software practitioners. We also found that practitioners are using other forms of support, such as co-workers and ChatGPT, more frequently than APR tools when fixing software defects. We learned about the drawbacks that practitioners encounter while utilizing existing APR tools and the impact that each drawback has on their practice. Our findings provide implications for research and practice centered on development, adoption, and use of APR.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639182,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548569,automated program repair;software bugs;software tools,Surveys;Correlation;Companies;Maintenance engineering;Chatbots;Software;Encoding,,2,,46,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Training Data Debugging for the Fairness of Machine Learning Software,Y. Li; L. Meng; L. Chen; L. Yu; D. Wu; Y. Zhou; B. Xu,"State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; Momenta, Suzhou, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2215,2227,"With the widespread application of machine learning (ML) software, especially in high-risk tasks, the concern about their unfairness has been raised towards both developers and users of ML software. The unfairness of ML software indicates the software behavior affected by the sensitive features (e.g., sex), which leads to biased and illegal decisions and has become a worthy problem for the whole software engineering community. According to the “data-driven” programming paradigm of ML software, we consider the root cause of the unfairness as biased features in training data. Inspired by software debugging, we propose a novel method, Linear-regression based Training Data Debugging (LTDD), to debug feature values in training data, i.e., (a) identify which features and which parts of them are biased, and (b) exclude the biased parts of such features to recover as much valuable and unbiased information as possible to build fair ML software. We conduct an extensive study on nine data sets and three classifiers to evaluate the effect of our method LTDD compared with four baseline methods. Experimental results show that (a) LTDD can better improve the fairness of ML software with less or comparable damage to the performance, and (b) LTDD is more actionable for fairness improvement in realistic scenarios.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510091,"National Natural Science Foundation of China(grant numbers:62172202,61872177,61772259,62172205,61832009,61772263); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794106,Debugging;Fairness;ML Software;Training Data,Training;Linear regression;Training data;Machine learning;Debugging;Programming;Software,,7,,50,,20 Jun 2022,,,IEEE,IEEE Conferences,True
DLInfer: Deep Learning with Static Slicing for Python Type Inference,Y. Yan; Y. Feng; H. Fan; B. Xu,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2009,2021,"Python programming language has gained enor-mous popularity in the past decades. While its flexibility signifi-cantly improves software development productivity, the dynamic typing feature challenges software maintenance and quality assurance. To facilitate programming and type error checking, the Python programming language has provided a type hint mechanism enabling developers to annotate type information for variables. However, this manual annotation process often requires plenty of resources and may introduce errors. In this paper, we propose a deep learning type inference technique, namely DLInfer, to automatically infer the type infor-mation for Python programs. DLInfer collects slice statements for variables through static analysis and then vectorizes them with the Unigram Language Model algorithm. Based on the vectorized slicing features, we designed a bi-directional gated recurrent unit model to learn the type propagation information for inference. To validate the effectiveness of DLInfer, we conduct an extensive empirical study on 700 open-source projects. We evaluate its accuracy in inferring three kinds of fundamental types, including built-in, library, and user-defined types. By training with a large-scale dataset, DLInfer achieves an average of 98.79% Top-1 accuracy for the variables that can get type information through static analysis and manual annotation. Further, DLInfer achieves 83.03% type inference accuracy on average for the variables that can only obtain the type information through dynamic analysis. The results indicate DLInfer is highly effective in inferring types. It is promising to apply it to assist in various software engineering tasks for Python programs.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00170,National Natural Science Foundation of China(grant numbers:62172209); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172544,type inference;Python;static slicing,Deep learning;Training;Software maintenance;Quality assurance;Annotations;Static analysis;Manuals,,3,,76,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Development in Times of Hype: How Freelancers Explore Generative AI?,M. Dolata; N. Lange; G. Schwabe,"Department of Informatics, University of Zurich, Zurich, Switzerland; Entschleunigung Norbert Lange, Kassel, Germany; Department of Informatics, University of Zurich, Zurich, Switzerland",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2257,2269,"The rise of generative AI has led many companies to hire freelanc-ers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with as-pects they perceive as unique to generative AI such as unpredict-ability of its output, the occurrence of hallucinations, and the in-consistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token lim-its and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548766,Generative AI;AI-based Systems;Challenges;Freelancers;Hype;SE for Generative AI;SE4GenAI;Hype-Induced SE;Hype-SE;Fashion;Product;Paradigm;Novelty;Qualitative Research,Generative AI;Ecosystems;Companies;Complexity theory;Time factors;Software engineering,,,,64,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Lightweight Approaches to DNN Regression Error Reduction: An Uncertainty Alignment Perspective,Z. Li; M. Zhang; J. Xu; Y. Yao; C. Cao; T. Chen; X. Ma; J. Lü,"Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science, Birkbeck, University of London, UK; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1187,1199,"Regression errors of Deep Neural Network (DNN) models refer to the case that predictions were correct by the old-version model but wrong by the new-version model. They frequently occur when upgrading DNN models in production systems, causing disproportionate user experience degradation. In this paper, we propose a lightweight regression error reduction approach with two goals: 1) requiring no model retraining and even data, and 2) not sacrificing the accuracy. The proposed approach is built upon the key insight rooted in the unmanaged model uncertainty, which is intrinsic to DNN models, but has not been thoroughly explored especially in the context of quality assurance of DNN models. Specifically, we propose a simple yet effective ensemble strategy that estimates and aligns the two models' uncertainty. We show that a Pareto improvement that reduces the regression errors without compromising the overall accuracy can be guaranteed in theory and largely achieved in practice. Comprehensive experiments with various representative models and datasets confirm that our approaches significantly outperform the state-of-the-art alternatives.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00106,"National Natural Science Foundation of China(grant numbers:62025202,62172199); State Key Laboratory of Novel Software Technology(grant numbers:KFKT2022A03); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172764,Software regression;deep neural networks;uncertainty alignment;model ensemble,Degradation;Production systems;Uncertainty;Quality assurance;Artificial neural networks;Predictive models;Software,,,,77,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support,M. Velez; P. Jamshidi; N. Siegmund; S. Apel; C. Kästner,Carnegie Mellon University; University of South Carolina; Leipzig University; Saarland Informatics Campus - Saarland University; Carnegie Mellon University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1571,1583,"Determining whether a configurable software system has a performance bug or it was misconfigured is often challenging. While there are numerous debugging techniques that can support developers in this task, there is limited empirical evidence of how useful the techniques are to address the actual needs that developers have when debugging the performance of configurable software systems; most techniques are often evaluated in terms of technical accuracy instead of their usability. In this paper, we take a human-centered approach to identify, design, implement, and evaluate a solution to support developers in the process of debugging the performance of configurable software systems. We first conduct an exploratory study with 19 developers to identify the information needs that developers have during this process. Subsequently, we design and implement a tailored tool, adapting techniques from prior work, to support those needs. Two user studies, with a total of 20 developers, validate and confirm that the information that we provide helps developers debug the performance of configurable software systems.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794001,,Adaptation models;Computer bugs;Debugging;Software systems;Usability;Task analysis;Software engineering,,6,,90,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
ChatGPT Incorrectness Detection in Software Reviews,M. H. Tanzil; J. Y. Khan; G. Uddin,"University of Calgary, Calgary, Alberta, Canada; University of Calgary, Calgary, Alberta, Canada; York University, Toronto, Ontario, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2219,2230,"We conducted a survey of 135 software engineering (SE) practitioners to understand how they use Generative Al-based chatbots like ChatGPT for SE tasks. We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses. We developed a suite of techniques and a tool called CID (ChatGPT Incorrectness Detector) to automatically test and detect the incorrectness in ChatGPT re-sponses. CID is based on the iterative prompting to ChatGPT by asking it contextually similar but textually divergent questions (using an approach that utilizes metamorphic relationships in texts). The underlying principle in CID is that for a given question, a response that is different from other responses (across multiple incarnations of the question) is likely an incorrect response. In a benchmark study of library selection, we show that CID can detect incorrect responses from ChatGPT with an Fl-score of 0.74 - 0.75.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639194,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549751,Large language model;ChatGPT;Hallucination;Testing,Surveys;Software reviews;Software libraries;Detectors;Benchmark testing;Chatbots;Iterative methods,,,,78,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Improving failure-inducing changes identification using coverage analysis,K. Yu,"State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1604,1606,"Delta debugging has been proposed for failure-inducing changes identification. Despite promising results, there are two practical factors that thwart the application of delta debugging: large number of tests and misleading false positives. To address the issues, we present a combination of coverage analysis and delta debugging that automatically isolates failure-inducing changes. Evaluations on twelve real regressions in GNU software demonstrate both the speed gain and effectiveness improvements.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227229,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227229,regression faults;delta debugging;coverage analysis;software evolution;automated debugging,Debugging;Software;Software engineering;Computer bugs;Programming;Educational institutions;Fault diagnosis,,,,16,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Conflict-aware Inference of Python Compatible Runtime Environments with Domain Knowledge Graph,W. Cheng; X. Zhu; W. Hu,"State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,451,461,"Code sharing and reuse is a widespread use practice in software engineering. Although a vast amount of open-source Python code is accessible on many online platforms, programmers often find it difficult to restore a successful runtime environment. Previous studies validated automatic inference of Python dependencies using pre-built knowledge bases. However, these studies do not cover sufficient knowledge to accurately match the Python code and also ignore the potential conflicts between their inferred dependencies, thus resulting in a low success rate of inference. In this paper, we propose PyCRE, a new approach to automatically inferring Python compatible runtime environments with domain knowledge graph (KG). Specifically, we design a domain-specific ontology for Python third-party packages and construct KGs for over 10,000 popular packages in Python 2 and Python 3. PyCRE discovers candidate libraries by measuring the matching degree between the known libraries and the third-party resources used in target code. For the NP-complete problem of dependency solving, we propose a heuristic graph traversal algorithm to efficiently guarantee the compatibility between packages. PyCRE achieves superior performance on a real-world dataset and efficiently resolves nearly half more import errors than previous methods.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510078,National Natural Science Foundation of China(grant numbers:61872172); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794028,Python;Runtime environment inference;Knowledge graph;Conflict resolution;Dependency solving;Configuration management,Knowledge engineering;Runtime environment;Codes;Software algorithms;Ontologies;Libraries;NP-complete problem,,7,,25,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Automated Testing of Software that Uses Machine Learning APIs,C. Wan; S. Liu; S. Xie; Y. Liu; H. Hoffmann; M. Maire; S. Lu,University of Chicago; University of Chicago; Whitney Young High School; University of Chicago; University of Chicago; University of Chicago; University of Chicago,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,212,224,"An increasing number of software applications incorporate machine learning (ML) solutions for cognitive tasks that statistically mimic human behaviors. To test such software, tremendous human effort is needed to design image/text/audio inputs that are relevant to the software, and to judge whether the software is processing these inputs as most human beings do. Even when misbehavior is exposed, it is often unclear whether the culprit is inside the cognitive ML API or the code using the API. This paper presents Keeper, a new testing tool for software that uses cognitive ML APIs. Keeper designs a pseudo-inverse function for each ML API that reverses the corresponding cognitive task in an empirical way (e.g., an image search engine pseudo-reverses the image-classification API), and incorporates these pseudo-inverse functions into a symbolic execution engine to automatically gener-ate relevant image/text/audio inputs and judge output correctness. Once misbehavior is exposed, Keeper attempts to change how ML APIs are used in software to alleviate the misbehavior. Our evalu-ation on a variety of open-source applications shows that Keeper greatly improves the branch coverage, while identifying many pre-viously unknown bugs.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510068,"NSF(grant numbers:CNSI764039,CNS1956180,CCF1837120,CCF2119184,CNS1952050,CCFI823032); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793999,software testing;machine learning;machine learning API,Codes;Computer bugs;Web pages;Machine learning;Search engines;Software;Test pattern generators,,6,,108,,20 Jun 2022,,,IEEE,IEEE Conferences,True
An Exploratory Study of Deep learning Supply Chain,X. Tan; K. Gao; M. Zhou; L. Zhang,"State Key Laboratory of Software Development Environment, School of Computer Science and Engineering Beihang University, Beijing, China; School of Software & Microelectronics, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering Beihang University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,86,98,"Deep learning becomes the driving force behind many contemporary technologies and has been successfully applied in many fields. Through software dependencies, a multi-layer supply chain (SC) with a deep learning framework as the core and substantial down-stream projects as the periphery has gradually formed and is constantly developing. However, basic knowledge about the structure and characteristics of the SC is lacking, which hinders effective support for its sustainable development. Previous studies on software SC usually focus on the packages in different registries without paying attention to the SCs derived from a single project. We present an empirical study on two deep learning SCs: TensorFlow and PyTorch SCs. By constructing and analyzing their SCs, we aim to understand their structure, application domains, and evolutionary factors. We find that both SCs exhibit a short and sparse hierarchy structure. Overall, the relative growth of new projects increases month by month. Projects have a tendency to attract downstream projects shortly after the release of their packages, later the growth becomes faster and tends to stabilize. We propose three criteria to identify vulnerabilities and identify 51 types of packages and 26 types of projects involved in the two SCs. A comparison reveals their similarities and differences, e.g., TensorFlow SC provides a wealth of packages in experiment result analysis, while PyTorch SC contains more specific framework packages. By fitting the GAM model, we find that the number of dependent packages is significantly negatively associated with the number of downstream projects, but the relationship with the number of authors is nonlinear. Our findings can help further open the “black box” of deep learning SCs and provide insights for their healthy and sustainable development.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510199,"National Natural Science Foundation of China(grant numbers:62141209,61825201); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793893,software supply chain;deep learning;open source;software structure;software evolution,Deep learning;Industries;Supply chains;Force;Fitting;Ecosystems;Software,,10,,46,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Improving PSP education by pairing: An empirical study,G. Rong; H. Zhang; M. Xie; D. Shao,"State Key Laboratory for Novel, Software Technology, Software Institute, Nanjing University, Nanjing, China; National ICT Australia, University of New South Wales, NSW, Australia; Software Institute, Nanjing University, Nanjing, China; Software Institute, Nanjing University, Nanjing, China",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1245,1254,"Handling large-sized classes and maintaining students' involvement are two of the major challenges in Personal Software Process (PSP) education in universities. In order to tackle these two challenges, we adapted and incorporated some typical practices of Pair Programming (PP) into the PSP class at summer school in Software Institute of Nanjing University in 2010, and received positive results, such as higher students' involvement and conformity of process discipline, as well as (half) workload reduction in evaluating assignments. However, the experiment did not confirm the improved performance of the paired students as expected. Based on the experience and feedbacks, we improved this approach in our PSP course in 2011. Accordingly, by analyzing the previous experiment results, we redesigned the experiment with a number of improvements, such as lab environment, evaluation methods and student selection, to further investigate the effects of this approach in PSP education, in particular students' performance. We also introduced several new metrics to enable the comparison analysis of the data collected from both paired students and solo students. The new experiment confirms the value of pairing practices in PSP education. The results show that in PSP class, compared to solo students, paired students can achieve better performance in terms of program quality and exam scores.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227018,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227018,personal software process;collaborative learning,Educational institutions;Software;Estimation;Training;Programming profession,,7,,25,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges,J. T. Liang; C. Yang; B. A. Myers,"Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,616,628,"The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot. However, in practice, developers do not accept AI programming assistants' initial suggestions at a high frequency. This leaves a number of open questions related to the usability of these tools. To understand developers' practices while using these tools and the important usability challenges they face, we administered a survey to a large population of developers and received responses from a diverse set of 410 developers. Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. We also found the most important reasons why developers do not use these tools are because these tools do not output code that addresses certain functional or non-functional requirements and because developers have trouble controlling the tool to generate the desired output. Our findings have implications for both creators and users of AI programming assistants, such as designing minimal cognitive effort interactions with these tools to reduce distractions for users while they are programming.",1558-1225,979-8-4007-0217-4,,"National Science Foundation(grant numbers:DGE1745016,DGE2140739,IIS-1856641); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548213,Software and its engineering → Software notations and tools;• Human-centered computing → Empirical studies in HCI;• Computing methodologies → Natural language processing;AI programming assistants;usability study,Surveys;Programming;Syntactics;Software;Artificial intelligence;Usability;Task analysis,,4,,62,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Are Prompt Engineering and TODO Comments Friends or Foes? An Evaluation on GitHub Copilot,D. OBrien; S. Biswas; S. M. Imtiaz; R. Abdalkareem; E. Shihab; H. Rajan,"Dept. of Computer Science, Iowa State University, Ames, IA, USA; School of Computer Science Carnegie Mellon University, Pittsburgh, PA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Omar Al-Mukhtar University, Elbyda, JK, Libya; Concordia University, Montreal, QC, Canada; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2707,2719,"Code intelligence tools such as GitHub Copilot have begun to bridge the gap between natural language and programming language. A frequent software development task is the management of technical debts, which are suboptimal solutions or unaddressed issues which hinder future software development. Developers have been found to “self-admit” technical debts (SATD) in software artifacts such as source code comments. Thus, is it possible that the information present in these comments can enhance code generative prompts to repay the described SATD? Or, does the inclusion of such comments instead cause code generative tools to reproduce the harmful symptoms of described technical debt? Does the modification of SATD impact this reaction? Despite the heavy maintenance costs caused by technical debt and the recent improvements of code intelligence tools, no prior works have sought to incorporate SATD towards prompt engineering. Inspired by this, this paper contributes and analyzes a dataset consisting of 36,381 TODO comments in the latest available revisions of their respective 102,424 repositories, from which we sample and manually generate 1,140 code bodies using GitHub Copilot. Our experiments show that GitHub Copilot can generate code with the symptoms of SATD, both prompted and unprompted. Moreover, we demonstrate the tool's ability to automatically repay SATD under different circumstances and qualitatively investigate the characteristics of successful and unsuccessful comments. Finally, we discuss gaps in which GitHub Copilot's successors and future researchers can improve upon code intelligence tasks to facilitate AI-assisted software maintenance.",1558-1225,979-8-4007-0217-4,,"National Science Foundation(grant numbers:CCF-15-18897,CNS-15-13263,CNS-21-20448,CCF-19-34884,CCF-22-23812); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549612,technical debt;GitHub Copilot;LLM;code generation,Software maintenance;Computer languages;Codes;Costs;Source coding;Natural languages;Maintenance,,,,57,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Development of auxiliary functions: Should you be agile? An empirical assessment of pair programming and test-first programming,O. A. L. Lemos; F. C. Ferrari; F. F. Silveira; A. Garcia,"Science and Technology Department, Federal University of Sao Paulo, Sao Jose dos Campos, Brazil; Computing Department, Federal University of Sāo Carlos UFSCar, Brazil; Science and Technology Department, Federal University of Sao Paulo, Sao Jose dos Campos, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro, Brazil",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,529,539,"A considerable part of software systems is comprised of functions that support the main modules, such as array or string manipulation and basic math computation. These auxiliary functions are usually considered less complex, and thus tend to receive less attention from developers. However, failures in these functions might propagate to more critical modules, thereby affecting the system's overall reliability. Given the complementary role of auxiliary functions, a question that arises is whether agile practices, such as pair programming and test-first programming, can improve their correctness without affecting time-to-market. This paper presents an empirical assessment comparing the application of these agile practices with more traditional approaches. Our study comprises independent experiments of pair versus solo programming, and test-first versus test-last programming. The first study involved 85 novice programmers who applied both traditional and agile approaches in the development of six auxiliary functions within three different domains. Our results suggest that the agile practices might bring benefits in this context. In particular, pair programmers delivered correct implementations much more often, and test-first programming encouraged the production of larger and higher coverage test sets. On the downside, the main experiment showed that both practices significantly increase total development time. A replication of the test-first experiment with professional developers shows similar results.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227163,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227163,pair programming;test-first programming;TDD;experimental software engineering;agile methods,Programming profession;Arrays;Reliability;Software testing;Measurement,,11,,48,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Automated Assertion Generation via Information Retrieval and Its Integration with Deep learning,H. Yu; Y. Lou; K. Sun; D. Ran; T. Xie; D. Hao; Y. Li; G. Li; Q. Wang,"School of Software and Microelectronics, Peking University, China; Department of Computer Science, Purdue University, USA; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; National Research Center of Software Engineering, Peking University, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Huawei Technologies CO., LTD., China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,163,174,"Unit testing could be used to validate the correctness of basic units of the software system under test. To reduce manual efforts in conducting unit testing, the research community has contributed with tools that automatically generate unit test cases, including test inputs and test oracles (e.g., assertions). Recently, ATLAS, a deep learning (DL) based approach, was proposed to generate assertions for a unit test based on other already written unit tests. Despite promising, the effectiveness of ATLAS is still limited. To improve the effectiveness, in this work, we make the first attempt to leverage Information Retrieval (IR) in assertion generation and propose an IR-based approach, including the technique of IR-based assertion retrieval and the technique of retrieved-assertion adaptation. In addition, we propose an integration approach to combine our IR-based approach with a DL-based approach (e.g., ATLAS) to further improve the effectiveness. Our experimental results show that our IR-based approach outperforms the state-of-the-art DL-based ap-proach, and integrating our IR-based approach with the DL-based approach can further achieve higher accuracy. Our results convey an important message that information retrieval could be competitive and worthwhile to pursue for software engineering tasks such as assertion generation, and should be seriously considered by the research community given that in recent years deep learning solutions have been over-popularly adopted by the research community for software engineering tasks.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510149,"National Natural Science Foundation of China(grant numbers:62161146003,62072007,62192733); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793891,Unit Testing;Information Retrieval;Test Assertion;Deep Learning,Deep learning;Manuals;Information retrieval;Software systems;Task analysis;Software engineering;Testing,,11,,58,,20 Jun 2022,,,IEEE,IEEE Conferences,True
The Road Toward Dependable AI Based Systems,P. Tonella,"Software Institute, Università della Svizzera italiana (USI), Lugano, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2,2,"With the advent of deep learning, AI components have achieved unprecedented performance on complex, human competitive tasks, such as image, video, text and audio processing. Hence, they are increasingly integrated into sophisticated software systems, some of which (e.g., autonomous vehicles) are required to deliver certified dependability warranties. In this talk, I will consider the unique features of AI based systems and of the faults possibly affecting them, in order to revise the testing fundamentals and redefine the overall goal of testing, taking a statistical view on the dependability warranties that can be actually delivered. Then, I will consider the key elements of a revised testing process for AI based systems, including the test oracle and the test input generation problems. I will also introduce the notion of runtime supervision, to deal with unexpected error conditions that may occur in the field. Finally, I will identify the future steps that are essential to close the loop from testing to operation, proposing an empirical framework that reconnects the output of testing to its original goals.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00011,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172847,Software Testing;Deep Learning;Reliability and Dependability,Testing;Warranties;Indexes;Deep learning;Task analysis;Software testing;Software systems,,1,,,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Fairness Improvement with Multiple Protected Attributes: How Far Are We?,Z. Chen; J. M. Zhang; F. Sarro; M. Harman,"University College London, London, United Kingdom; King's College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1971,1983,"Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on F1-score when handling two protected attributes is about twice that of a single attribute. This has important implications for future fairness research: reporting only accuracy as the ML performance metric, which is currently common in the literature, is inadequate.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639083,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548849,Fairness improvement;machine learning;protected attributes;intersectional fairness,Measurement;Analytical models;Correlation;Machine learning;Benchmark testing;Software;Software engineering,,,,67,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
How Are Paid and Volunteer Open Source Developers Different? A Study of the Rust Project,Y. Zhang; M. Qin; K. -J. Stol; M. Zhou; H. Liu,"Beijing Institute of Technology School of Computer Science & Technology, Beijing, China; Beijing Institute of Technology School of Computer Science & Technology, Beijing, China; University College Cork and Lero School of Computer Science and IT, Cork, Ireland; Peking University School of Computer Science, Beijing, China; Beijing Institute of Technology School of Computer Science & Technology, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2406,2418,"It is now commonplace for organizations to pay developers to work on specific open source software (OSS) projects to pursue their business goals. Such paid developers work alongside voluntary contributors, but given the different motivations of these two groups of developers, conflict may arise, which may pose a threat to a project's sustainability. This paper presents an empirical study of paid developers and volunteers in Rust, a popular open source programming language project. Rust is a particularly interesting case given considerable concerns about corporate participation. We compare volunteers and paid developers through contribution characteristics and long-term participation, and solicit volunteers' perceptions on paid developers. We find that core paid developers tend to contribute more frequently; commits contributed by onetime paid developers have bigger sizes; peripheral paid developers implement more features; and being paid plays a positive role in becoming a long-term contributor. We also find that volunteers do have some prejudices against paid developers. This study suggests that the dichotomous view of paid vs. volunteer developers is too simplistic and that further subgroups can be identified. Companies should become more sensitive to how they engage with OSS communities, in certain ways as suggested by this study.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639197,"National Natural Science Foundation of China(grant numbers:62141209,62202048,61825201,62232003); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549186,Open source software;paid developers;volunteers;sustainability,Computer languages;Companies;Sustainable development;Open source software;Software engineering,,,,95,,14 Jun 2024,,,IEEE,IEEE Conferences,True
DeepStability: A Study of Unstable Numerical Methods and Their Solutions in Deep Learning,E. Kloberdanz; K. G. Kloberdanz; W. Le,"Department of Computer Science, Iowa State University; Cape Privacy; Department of Computer Science, Iowa State University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,586,597,"Deep learning (DL) has become an integral part of solutions to various important problems, which is why ensuring the quality of DL systems is essential. One of the challenges of achieving reliability and robustness of DL software is to ensure that algorithm implementations are numerically stable. DL algorithms require a large amount and a wide variety of numerical computations. A naive implementation of numerical computation can lead to errors that may result in incorrect or inaccurate learning and results. A numerical algorithm or a mathematical formula can have several implementations that are mathematically equivalent, but have different numerical stability properties. Designing numerically stable algorithm implementations is challenging, because it requires an interdisciplinary knowledge of software engineering, DL, and numerical analysis. In this paper, we study two mature DL libraries PyTorch and Tensorflow with the goal of identifying unstable numerical methods and their solutions. Specifically, we investigate which DL algorithms are numerically unstable and conduct an in-depth analysis of the root cause, manifestation, and patches to numerical instabilities. Based on these findings, we launch DeepStability, the first database of numerical stability issues and solutions in DL. Our findings and DeepStability provide future references to developers and tool builders to prevent, detect, localize and fix numerically unstable algorithm implementations. To demonstrate that, using DeepStability we have located numerical stability issues in Tensorflow, and submitted a fix which has been accepted and merged in.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510095,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794088,numerical stability;deep learning;numerical algorithms,Deep learning;Knowledge engineering;Databases;Software algorithms;Software;Robustness;Libraries,,3,,28,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
Understanding the impact of Pair Programming on developers attention: A case study on a large industrial experimentation,A. Sillitti; G. Succi; J. Vlasenko,"Center for Applied Software Engineering, Free University of Bolzano-Bozen, Bozen/Bolzano, Italy; Center for Applied Software Engineering, Free University of Bolzano-Bozen, Bozen/Bolzano, Italy; Center for Applied Software Engineering, Free University of Bolzano-Bozen, Bozen/Bolzano, Italy",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1094,1101,"Pair Programming is one of the most studied and debated development techniques. However, at present, we do not have a clear, objective, and quantitative understanding of the claimed benefits of such development approach. All the available studies focus on the analysis of the effects of Pair Programming (e.g., code quality, development speed, etc.) with different findings and limited replicability of the experiments. This paper adopts a different approach that could be replicated in an easier way: it investigates how Pair Programming affects the way developers write code and interact with their development machine. In particular, the paper focuses on the effects that Pair Programming has on developers' attention and productivity. The study was performed on a professional development team observed for ten months and it finds out that Pair Programming helps developers to eliminate distracting activities and to focus on productive activities.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227110,Software development process;productivity;pair programming,Switches;Visualization;Browsers;Programming profession;PROM;Productivity,,37,,34,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
MalwareTotal: Multi-Faceted and Sequence-Aware Bypass Tactics Against Static Malware Detection,S. He; C. Fu; H. Hu; J. Chen; J. Lv; S. Jiang,"School of Cyber Science and Engineering, Huazhong Science and technology University, China; School of Cyber Science and Engineering, Huazhong Science and technology University, China; Pennsylvania State University, United States; School of Cyber Science and Engineering, Huazhong Science and technology University, China; School of Cyber Science and Engineering, Huazhong Science and technology University, China; School of Cyber Science and Engineering, Huazhong Science and technology University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2123,2134,"Recent methods have demonstrated that machine learning (ML) based static malware detection models are vulnerable to adversarial attacks. However, the generated malware often fails to generalize to production-level anti-malware software (AMS), as they usually involve multiple detection methods. This calls for universal solutions to the problem of malware variants generation. In this work, we demonstrate how the proposed method, MalwareTotal, has allowed malware variants to continue to abound in ML-based, signature-based, and hybrid anti-malware software. Given a malicious binary, we develop sequential bypass tactics that enable malicious behavior to be concealed within multi-faceted manipulations. Through 12 experiments on real-world malware, we demonstrate that an attacker can consistently bypass detection (98.67%, and 100% attack success rate against ML-based methods EMBER and MalConv, respectively; 95.33%, 92.63%, and 98.52% attack success rate against production-level anti-malware software ClamAV, AMS A, and AMS B, respectively) without modifying the malware functionality. We further demonstrate that our approach outperforms state-of-the-art adversarial malware generation techniques both in attack success rate and query consumption (the number of queries to the target model). Moreover, the samples generated by our method have demonstrated transferability in the real-world integrated malware detector, VirusTotal. In addition, we show that common mitigation such as adversarial training on known attacks cannot effectively defend against the proposed attack. Finally, we investigate the value of the generated adversarial examples as a means of hardening victim models through an adversarial training procedure, and demonstrate that the accuracy of the retrained model against generated adversarial examples increases by 88.51 percentage points.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639141,National Natural Science Foundation of China(grant numbers:62072200); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548910,Anti-malware software robustness;black-box attacks;binary manipulation,Training;Pipelines;Detectors;Pressing;Software systems;Malware;Space exploration,,,,73,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Prompting Is All You Need: Automated Android Bug Replay with Large Language Models,S. Feng; C. Chen,"Monash University, Melbourne, Australia; Monash University, Melbourne, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,803,815,"Bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while using the software. As such, researchers have committed considerable resources toward automating bug replay to expedite the process of software maintenance. Nonetheless, the success of current au-tomated approaches is largely dictated by the characteristics and quality of bug reports, as they are constrained by the limitations of manually-crafted patterns and predefined vocabulary lists. In-spired by the success of Large Language Models (LLMs) in natural language understanding, we propose AdbGPT, a new lightweight approach to automatically reproduce the bugs from bug reports through prompt engineering, without any training and hard-coding effort. AdbGPT leverages few-shot learning and chain-of-thought reasoning to elicit human knowledge and logical reasoning from LLMs to accomplish the bug replay in a manner similar to a devel-oper. Our evaluations demonstrate the effectiveness and efficiency of our AdbGPT to reproduce 81.3% of bug reports in 253.6 seconds, outperforming the state-of-the-art baselines and ablation studies. We also conduct a small-scale user study to confirm the usefulness of AdbGPT in enhancing developers' bug replay capabilities.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608137,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548487,automated bug replay;large language model;prompt engineering,Training;Software maintenance;Vocabulary;Computer bugs;Manuals;Cognition;Natural language processing,,8,,86,,14 Jun 2024,,,IEEE,IEEE Conferences,True
How Do We Read Formal Claims? Eye-Tracking and the Cognition of Proofs about Algorithms,H. Ahmad; Z. Karas; K. Diaz; A. Kamil; J. -B. Jeannin; W. Weimer,"University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,208,220,"Formal methods are used successfully in high-assurance software, but they require rigorous mathematical and logical training that practitioners often lack. As such, integrating formal methods into software has been associated with numerous challenges. While educators have placed emphasis on formalisms in undergraduate theory courses, such courses often struggle with poor student outcomes and satisfaction. In this paper, we present a controlled eye-tracking human study (n = 34) investigating the problem-solving strategies employed by students with different levels of incoming preparation (as assessed by theory coursework taken and pre-screening performance on a proof comprehension task), and how educators can better prepare low-outcome students for the rigorous logical reasoning that is a core part of formal methods in software engineering. Surprisingly, we find that incoming preparation is not a good predictor of student outcomes for formalism comprehension tasks, and that student self-reports are not accurate at identifying factors associated with high outcomes for such tasks. Instead, and importantly, we find that differences in outcomes can be attributed to performance for proofs by induction and recursive algorithms, and that better-performing students exhibit significantly more attention switching behaviors, a result that has several implications for pedagogy in terms of the design of teaching materials. Our results suggest the need for a substantial pedagogical intervention in core theory courses to better align student outcomes with the objectives of mastery and retaining the material, and thus bettering preparing students for high-assurance software engineering.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00029,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172680,formalism comprehension;student cognition;eye-tracking;facial behavior analysis;human study,Training;Software algorithms;Gaze tracking;Switches;Prediction algorithms;Software;Cognition,,1,,76,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Manas: Mining Software Repositories to Assist AutoML,G. Nguyen; M. J. Islam; R. Pan; H. Rajan,"Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1368,1380,"Today deep learning is widely used for building software. A software engineering problem with deep learning is that finding an appropriate convolutional neural network (CNN) model for the task can be a challenge for developers. Recent work on AutoML, more precisely neural architecture search (NAS), embodied by tools like Auto-Keras aims to solve this problem by essentially viewing it as a search problem where the starting point is a default CNN model, and mutation of this CNN model allows exploration of the space of CNN models to find a CNN model that will work best for the problem. These works have had significant success in producing high-accuracy CNN models. There are two problems, however. First, NAS can be very costly, often taking several hours to complete. Second, CNN models produced by NAS can be very complex that makes it harder to understand them and costlier to train them. We propose a novel approach for NAS, where instead of starting from a default CNN model, the initial model is selected from a repository of models extracted from GitHub. The intuition being that developers solving a similar problem may have developed a better starting point compared to the default model. We also analyze common layer patterns of CNN models in the wild to understand changes that the developers make to improve their models. Our approach uses commonly occurring changes as mutation operators in NAS. We have extended Auto-Keras to implement our approach. Our evaluation using 8 top voted problems from Kaggle for tasks including image classification and image regression shows that given the same search time, without loss of accuracy, Manas produces models with 42.9% to 99.6% fewer number of parameters than Auto-Keras' models. Benchmarked on GPU, Manas' models train 30.3% to 641.6% faster than Auto-Keras' models.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510052,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794122,Deep Learning;AutoML;Mining Software Repositories;MSR,Deep learning;Training;Analytical models;Search problems;Software;Space exploration;Convolutional neural networks,,7,,62,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
ReMoS: Reducing Defect Inheritance in Transfer Learning via Relevant Model Slicing,Z. Zhang; Y. Li; J. Wang; B. Liu; D. Li; Y. Guo; X. Chen; Y. Liu,"Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Microsoft Research, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1856,1868,"Transfer learning is a popular software reuse technique in the deep learning community that enables developers to build custom mod-els (students) based on sophisticated pretrained models (teachers). However, like vulnerability inheritance in traditional software reuse, some defects in the teacher model may also be inherited by students, such as well-known adversarial vulnerabilities and backdoors. Re-ducing such defects is challenging since the student is unaware of how the teacher is trained and/or attacked. In this paper, we propose ReMoS, a relevant model slicing technique to reduce defect inheri-tance during transfer learning while retaining useful knowledge from the teacher model. Specifically, ReMoS computes a model slice (a subset of model weights) that is relevant to the student task based on the neuron coverage information obtained by profiling the teacher model on the student task. Only the relevant slice is used to fine-tune the student model, while the irrelevant weights are retrained from scratch to minimize the risk of inheriting defects. Our experi-ments on seven DNN defects, four DNN models, and eight datasets demonstrate that ReMoS can reduce inherited defects effectively (by 63% to 86% for CV tasks and by 40% to 61 % for NLP tasks) and efficiently with minimal sacrifice of accuracy (3% on average).",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510191,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793881,Program slicing;deep neural networks;relevant slicing,Deep learning;Computational modeling;Transfer learning;Neurons;Task analysis;Software reusability;Biological neural networks,,9,,73,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Information-Theoretic Testing and Debugging of Fairness Defects in Deep Neural Networks,V. Monjezi; A. Trivedi; G. Tan; S. Tizpaz-Niari,University of Texas at El Paso; University of Colorado Boulder; Pennsylvania State University; University of Texas at El Paso,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1571,1582,"The deep feedforward neural networks (DNNs) are increasingly deployed in socioeconomic critical decision support software systems. DNNs are exceptionally good at finding min-imal, sufficient statistical patterns within their training data. Consequently, DNNs may learn to encode decisions-amplifying existing biases or introducing new ones-that may disadvantage protected individuals/groups and may stand to violate legal protections. While the existing search based software testing approaches have been effective in discovering fairness defects, they do not supplement these defects with debugging aids-such as severity and causal explanations-crucial to help developers triage and decide on the next course of action. Can we measure the severity of fairness defects in DNNs? Are these defects symptomatic of improper training or they merely reflect biases present in the training data? To answer such questions, we present Dice: an information-theoretic testing and debugging framework to discover and localize fairness defects in DNNs. The key goal of Dice is to assist software developers in triaging fairness defects by ordering them by their severity. Towards this goal, we quantify fairness in terms of protected information (in bits) used in decision making. A quantitative view of fairness defects not only helps in ordering these defects, our empirical evaluation shows that it improves the search efficiency due to resulting smoothness of the search space. Guided by the quan-titative fairness, we present a causal debugging framework to localize inadequately trained layers and neurons responsible for fairness defects. Our experiments over ten DNNs, developed for socially critical tasks, show that Dice efficiently characterizes the amounts of discrimination, effectively generates discriminatory instances (vis-a-vis the state-of-the-art techniques), and localizes layers/neurons with significant biases.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00136,NSF(grant numbers:DGE-2043250); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172902,Algorithmic Fairness;Information Theory;Software Testing;Fairness Defect Localization;Bias Mitigation,Training;Software testing;Software algorithms;Decision making;Training data;Debugging;Software systems,,11,,56,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Cross-Domain Requirements Linking via Adversarial-based Domain Adaptation,Z. Chang; M. Li; Q. Wang; S. Li; J. Wang,"Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1596,1608,"Requirements linking is the core of software system maintenance and evolution, and it is critical to assuring software quality. In practice, however, the requirements links are frequently absent or incorrectly labeled, and reconstructing such ties is time-consuming and error-prone. Numerous learning-based approaches have been put forth to address the problem. However, these approaches will lose effectiveness for the Cold-Start projects with few labeled samples. To this end, we propose RADIATION, an adversarial-based domain adaptation approach for cross-domain requirements linking. Generally, RADIATION firstly adopts an IDF-based Masking strategy to filter the domain-specific features. Then it pre-trains a linking model in the source domain with sufficient labeled samples and adapts the model to target domains using a distance-enhanced adversarial technique without using any labeled target samples. Evaluation on five public datasets shows that RADIATION could achieve 66.4% precision, 89.2% recall, and significantly outperform state-of-the-art baselines by 13.4% -42.9% F1. In addition, the designed components, i.e., IDF-based Masking and Distance-enhanced Loss, could significantly improve performance.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00138,"National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172688,Cross-Domain Requirements Linking;Domain Adaptation;Adversarial Learning,Adaptation models;Source coding;Unified modeling language;Software quality;Maintenance engineering;Software systems;Usability,,,,61,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
A generic methodology to derive domain-specific performance feedback for developers,D. Westermann,"SAP Research, Karlsruhe, Germany",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1527,1530,"The performance of a system directly influences business critical metrics like total cost of ownership (TCO) and user satisfaction. However, building responsive, resource efficient and scalable applications is a challenging task. Thus, software engineering approaches are required to support software architects and developers in meeting these challenges. In this PhD research abstract, we propose a novel performance evaluation process applied during the software development phase. The goal is to increase the performance awareness of developers by providing feedback with respect to performance properties that is integrated in the every day development process. The feedback is based on domain-specific prediction functions derived by a generic methodology that executes a series of systematic measurements. We apply and validate the approach in different development scenarios at SAP.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227045,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227045,,Performance evaluation;Software performance;Predictive models;Systematics;Time measurement,,2,,19,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Regression Fuzzing for Deep Learning Systems,H. You; Z. Wang; J. Chen; S. Liu; S. Li,"College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,82,94,"Deep learning (DL) Systems have been widely used in various domains. Similar to traditional software, DL system evolution may also incur regression faults. To find the regression faults between versions of a DL system, we propose a novel regression fuzzing technique called DRFuzz, which facilitates generating inputs that trigger diverse regression faults and have high fidelity. To enhance the diversity of the found regression faults, DRFuzz proposes a diversity-oriented test criterion to explore as many faulty behaviors as possible. Then, DRFuzz incorporates the GAN model to guarantee the fidelity of generated test inputs. We conduct an extensive study on four subjects in four regression scenarios of DL systems. The experimental results demonstrate the superiority of DRFuzz over the two compared state-of-the-art approaches, with an average improvement of 1,177% and 539% in terms of the number of detected regression faults.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00019,"National Natural Science Foundation of China(grant numbers:61872263,62232001,62002256); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172506,Regression;Fuzzing;Deep Learning,Deep learning;Fuzzing;Software;Behavioral sciences;Regression tree analysis;Software engineering,,10,,89,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Efficient reuse of domain-specific test knowledge: An industrial case in the smart card domain,N. Devos; C. Ponsard; J. -C. Deprez; R. Bauvin; B. Moriau; G. Anckaerts,"Software and System Engineering, CETIC research center, Charleroi, Belgium; Software and System Engineering, CETIC research center, Charleroi, Belgium; Software and System Engineering, CETIC research center, Charleroi, Belgium; Quality, Security and Control, STMicroelectronics Belgium, Zaventem, Belgium; Quality, Security and Control, STMicroelectronics Belgium, Zaventem, Belgium; Quality, Security and Control, STMicroelectronics Belgium, Zaventem, Belgium",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1123,1132,"While testing is heavily used and largely automated in software development projects, the reuse of test practices across similar projects in a given domain is seldom systematized and supported by adequate methods and tools. This paper presents a practical approach that emerged from a concrete industrial case in the smart card domain at STMicroelectronics Belgium in order to better address this kind of challenge. The central concept is a test knowledge repository organized as a collection of specific patterns named QPatterns. A systematic process was followed, first to gather, structure and abstract the test practices, then to produce and validate an initial repository, and finally to make it evolve later on Testers can then rely on this repository to produce high quality test plans identifying all the functional and nonfunctional aspects that have to be addressed, as well as the concrete tests that have to be developed within the context of a new project. A tool support was also developed and integrated in a traceable way into the existing industrial test environment. The approach was validated and is currently under deployment at STMicroelectronics Belgium.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227107,patterns;test;generation;smartcard,Smart cards;Testing;Libraries;Software;Security;Concrete,,2,,16,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Using Deep Learning to Generate Complete Log Statements,A. Mastropaolo; L. Pascarella; G. Bavota,"SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2279,2290,"Logging is a practice widely adopted in several phases of the software lifecycle. For example, during software development log statements allow engineers to verify and debug the system by exposing fine-grained information of the running software. While the benefits of logging are undisputed, taking proper decisions about where to inject log statements, what information to log, and at which log level (e.g., error, warning) is crucial for the logging effectiveness. In this paper, we present LANCE (Log stAtemeNt reCommEnder), the first approach supporting developers in all these decisions. LANCE features a Text-To-Text-Transfer-Transformer (T5) model that has been trained on 6,894,456 Java methods. LANCE takes as input a Java method and injects in it a full log statement, including a human-comprehensible logging message and properly choosing the needed log level and the statement location. Our results show that LANCE is able to (i) properly identify the location in the code where to inject the statement in 65.9% of Java methods requiring it; (ii) selecting the proper log level in 66.2% of cases; and (iii) generate a completely correct log statement including a meaningful logging message in 15.2% of cases.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3511561,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794055,Logging;Empirical Study;Machine Learning on Code,Deep learning;Java;Codes;Software;Software engineering,,15,,53,,20 Jun 2022,,,IEEE,IEEE Conferences,True
How much does unused code matter for maintenance?,S. Eder; M. Junker; E. Jürgens; B. Hauptmann; R. Vaas; K. -H. Prommer,"Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Munich Re, Munchen, Germany; Munich Re, Munchen, Germany",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1102,1111,"Software systems contain unnecessary code. Its maintenance causes unnecessary costs. We present tool-support that employs dynamic analysis of deployed software to detect unused code as an approximation of unnecessary code, and static analysis to reveal its changes during maintenance. We present a case study on maintenance of unused code in an industrial software system over the course of two years. It quantifies the amount of code that is unused, the amount of maintenance activity that went into it and makes the potential benefit of tool support explicit, which informs maintainers that are about to modify unused code.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227109,Software maintenance;dynamic analysis;unnecessary code;unused code,Maintenance engineering;Assembly;Software systems;Business;Information systems;Production,,22,1,25,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching,L. Jiang; J. An; H. Huang; Q. Tang; S. Nie; S. Wu; Y. Zhang,"Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Tencent Security Keen Lab, Shanghai, China; Tencent Security Keen Lab, Shanghai, China; Tencent Security Keen Lab, Shanghai, China; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2771,2783,"While third-party libraries (TPLs) are extensively reused to enhance productivity during software development, they can also introduce potential security risks such as vulnerability propagation. Software composition analysis (SCA), proposed to identify reused TPLs for reducing such risks, has become an essential procedure within modern DevSecOps. As one of the mainstream SCA techniques, binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching, which is a major challenge in reverse engineering since binary and source code exhibit substantial disparities after compilation. The existing binary-to-source SCA techniques leverage basic syntactic features that suffer from redundancy and lack robustness in the large-scale TPL dataset, leading to inevitable false positives and compromised recall. To mitigate these limitations, we introduce BinaryAI, a novel binary-to-source SCA technique with two-phase binary source code matching to capture both syntactic and semantic code features. First, BinaryAI trains a transformer-based model to produce function-level embeddings and obtain similar source functions for each binary function accordingly. Then by applying the link-time locality to facilitate function matching, BinaryAI detects the reused TPLs based on the ratio of matched source functions. Our experimental results demonstrate the superior performance of BinaryAI in terms of binary source code matching and the downstream SCA task. Specifically, our embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving 22.54% recall@l and 0.34 MRR compared with 10.75% and 0.17 respectively. Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in TPL detection, increasing the precision from 73.36% to 85.84% and recall from 59.81% to 64.98% compared with the well-recognized commercial SCA product Black Duck. E-https://www.binaryai.net",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548390,Software Composition Analysis;Static Binary Analysis,Codes;Source coding;Semantics;Redundancy;Syntactics;Transformers;Software,,,,77,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Towards Training Reproducible Deep Learning Models,B. Chen; M. Wen; Y. Shi; D. Lin; G. K. Rajbahadur; Z. M. Jiang,"Centre for Software Excellence, Huawei Canada, Kingston, Canada; Huawei Technologies, Shenzhen, China; Huawei Technologies, Shenzhen, China; Centre for Software Excellence, Huawei Canada, Kingston, Canada; Centre for Software Excellence, Huawei Canada, Kingston, Canada; York University, Toronto, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2202,2214,"Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510163,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794033,Artificial Intelligence;Deep Learning;Software Engineering;Reproducibility,Training;Deep learning;Systematics;Reproducibility of results;Software;Hardware;Artificial intelligence,,4,,69,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Automated Program Repair in the Era of Large Pre-trained Language Models,C. S. Xia; Y. Wei; L. Zhang,"University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1482,1494,"Automated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates (traditional) or directly predict potential patches (learning-based). Large Pre-Trained Language Models (LLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged LLMs for APR without relying on any bug-fixing datasets. Meanwhile, such existing work either failed to include state-of-the-art LLMs or was not evaluated on realistic datasets. Thus, the true power of modern LLMs on the important APR problem is yet to be revealed. In this work, we perform the first extensive study on directly applying LLMs for APR. We select 9 recent state-of-the-art LLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use LLMs to generate patches: 1) generate the entire patch function, 2) fill in a chunk of code given the prefix and suffix 3) output a single line fix. We apply the LLMs under these repair settings on 5 datasets across 3 different languages and compare different LLMs in the number of bugs fixed, generation speed and compilation rate. We also compare the LLMs against recent state-of-the-art APR tools. Our study demonstrates that directly applying state-of-the-art LLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied LLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the LLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking. Lastly, we show that LLM-based APR can be further substantially boosted via: 1) increasing the sample size, and 2) incorporating fix template information.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00129,"NSF(grant numbers:CCF-2131943,CCF-2141474); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172803,Automated Program Repair;Machine Learning,Codes;Computer bugs;Maintenance engineering;Software;Distance measurement;Task analysis;Faces,,63,,89,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
SkCoder: A Sketch-based Approach for Automatic Code Generation,J. Li; Y. Li; G. Li; Z. Jin; Y. Hao; X. Hu,"Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; aiXcoder, Beijing, China; Zhejiang University, Ningbo, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2124,2135,"Recently, deep learning techniques have shown great success in automatic code generation. Inspired by the code reuse, some researchers propose copy-based approaches that can copy the content from similar code snippets to obtain better performance. Practically, human developers recognize the content in the similar code that is relevant to their needs, which can be viewed as a code sketch. The sketch is further edited to the desired code. However, existing copy-based approaches ignore the code sketches and tend to repeat the similar code without necessary modifications, which leads to generating wrong results. In this paper, we propose a sketch-based code generation approach named Skcoderto mimic developers' code reuse behavior. Given a natural language requirement, Skcoderretrieves a similar code snippet, extracts relevant parts as a code sketch, and edits the sketch into the desired code. Our motivations are that the extracted sketch provides a well-formed pattern for telling models “how to write”. The post-editing further adds requirement-specific details into the sketch and outputs the complete code. We conduct experiments on two public datasets and a new dataset collected by this work. We compare our approach to 20 baselines using 5 widely used metrics. Experimental results show that (1) Skcodercan generate more correct programs, and outperforms the state-of-the-art -CodeT5-base by 30.30%, 35.39%, and 29.62% on three datasets. (2) Our approach is effective to multiple code generation models and improves them by up to 120.1% in Pass@l. (3) We investigate three plausible code sketches and discuss the importance of sketches. (4) We manually evaluate the generated code and prove the superiority of our Skcoderin three aspects.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172719,Code Generation;Deep Learning,Measurement;Deep learning;Codes;Natural languages;Behavioral sciences;Software engineering,,15,,45,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
"Fine-Grained, Accurate, and Scalable Source Code Differencing",J. -R. Falleri; M. Martinez,"Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, Talence, France; Universitat Politècnica de Catalunya, Barcelona, Spain",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2856,2867,"Understanding code changes is of crucial importance in a wide range of software evolution activities. The traditional approach is to use textual differencing, as done with success since the 1970s with the ubiquitous diff tool. However, textual differencing has the important limitation of not aligning the changes to the syntax of the source code. To overcome these issues, structural (i.e. syntactic) differencing has been proposed in the literature, notably GumTree which was one of the pioneering approaches. The main drawback of GumTree's algorithm is the use of an optimal, but expensive tree-edit distance algorithm that makes it difficult to diff large ASTs. In this article, we describe a less expensive heuristic that enables GumTree to scale to large ASTs while yielding results of better quality than the original GumTree. We validate this new heuristic against 4 datasets of changes in two different languages, where we generate edit-scripts with a median size 50% smaller and a total speedup of the matching time between 50x and 281x.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639148,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548607,Software evolution;Code differencing,Codes;Accuracy;Source coding;Syntactics;Software;Distance measurement;Software engineering,,,,42,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Trust Enhancement Issues in Program Repair,Y. Noller; R. Shariffdeen; X. Gao; A. Roychoudhury,"National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2228,2240,"Automated program repair is an emerging technology that seeks to automatically rectify bugs and vulnerabilities using learning, search, and semantic analysis. Trust in automatically generated patches is necessary for achieving greater adoption of program repair. Towards this goal, we survey more than 100 software practitioners to understand the artifacts and setups needed to enhance trust in automatically generated patches. Based on the feedback from the survey on developer preferences, we quantitatively evaluate existing test-suite based program repair tools. We find that they cannot produce high-quality patches within a top-10 ranking and an acceptable time period of 1 hour. The developer feedback from our qualitative study and the observations from our quantitative examination of existing repair tools point to actionable insights to drive program repair research. Specifically, we note that producing repairs within an acceptable time-bound is very much dependent on leveraging an abstract search space representation of a rich enough search space. Moreover, while additional developer inputs are valuable for generating or ranking patches, developers do not seem to be interested in a significant human-in-the-loop interaction.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510040,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794080,program repair,Semantics;Computer bugs;Maintenance engineering;Software;Human in the loop;Software engineering,,15,,52,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Practical Program Repair via Preference-based Ensemble Strategy,W. Zhong; C. Li; K. Liu; T. Xu; J. Ge; T. F. Bissyandé; B. Luo; V. Ng,"National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; Huawei Software Engineering Application Technology Lab, Hangzhou, China; Huawei Software Engineering Application Technology Lab, Hangzhou, China; National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; University of Luxembourg, Luxembourg; National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,25,37,"To date, over 40 Automated Program Repair (APR) tools have been designed with varying bug-fixing strategies, which have been demonstrated to have complementary performance in terms of being effective for different bug classes. Intuitively, it should be feasible to improve the overall bug-fixing performance of APR via assembling existing tools. Unfortunately, simply invoking all available APR tools for a given bug can result in unacceptable costs on APR execution as well as on patch validation (via expensive testing). Therefore, while assembling existing tools is appealing, it requires an efficient strategy to reconcile the need to fix more bugs and the requirements for practicality. In light of this problem, we propose a Preference-based Ensemble Program Repair framework (P-EPR), which seeks to effectively rank APR tools for repairing different bugs. P-EPR is the first non-learning-based APR ensemble method that is novel in its exploitation of repair patterns as a major source of knowledge for ranking APR tools and its reliance on a dynamic update strategy that enables it to immediately exploit and benefit from newly derived repair results. Experimental results show that P-EPR outperforms existing strategies significantly both in flexibility and effectiveness.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623310,National Key Research and Development Program of China(grant numbers:2022YFF0711404); National Natural Science Foundation of China(grant numbers:62172214); NSF(grant numbers:2034508); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549166,program repair;ensemble strategy,Measurement;Costs;Computer bugs;Maintenance engineering;Software;Ensemble learning;Testing,,,,54,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Learning and Repair of Deep Reinforcement Learning Policies from Fuzz-Testing Data,M. Tappler; A. Pferscher; B. K. Aichernig; B. Könighofer,"Graz University of Technology, Institute of Software Technology, Graz, Austria; Graz University of Technology, Institute of Software Technology, Graz, Austria; Graz University of Technology, Institute of Software Technology, Graz, Austria; Graz University of Technology, Institute of Applied Information Processing and Communications, Graz, Austria",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,38,50,"Reinforcement learning from demonstrations (RLfD) is a promising approach to improve the exploration efficiency of reinforcement learning (RL) by learning from expert demonstrations in addition to interactions with the environment. In this paper, we propose a framework that combines techniques from search-based testing with RLfD with the goal to raise the level of dependability of RL policies and to reduce human engineering effort. Within our framework, we provide methods for efficiently training, evaluating, and repairing RL policies. Instead of relying on the costly collection of demonstrations from (human) experts, we automatically compute a diverse set of demonstrations via search-based fuzzing methods and use the fuzz demonstrations for RLfD. To evaluate the safety and robustness of the trained RL agent, we search for safety-critical scenarios in the black-box environment. Finally, when unsafe behavior is detected, we compute demonstrations through fuzz testing that represent safe behavior and use them to repair the policy. Our experiments show that our framework is able to efficiently learn high-performing and safe policies without requiring any expert knowledge.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623311,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548388,Deep reinforcement learning;Reinforcement learning from demonstrations;Search-based software testing;Policy repair,Training;Video games;Maintenance engineering;Fuzzing;Robustness;Safety;Software reliability,,2,,49,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
An automated approach to generating efficient constraint solvers,D. Balasubramaniam; C. Jefferson; L. Kotthoff; I. Miguel; P. Nightingale,"School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,661,671,"Combinatorial problems appear in numerous settings, from timetabling to industrial design. Constraint solving aims to find solutions to such problems efficiently and automatically. Current constraint solvers are monolithic in design, accepting a broad range of problems. The cost of this convenience is a complex architecture, inhibiting efficiency, extensibility and scalability. Solver components are also tightly coupled with complex restrictions on their configuration, making automated generation of solvers difficult. We describe a novel, automated, model-driven approach to generating efficient solvers tailored to individual problems and present some results from applying the approach. The main contribution of this work is a solver generation framework called Dominion, which analyses a problem and, based on its characteristics, generates a solver using components chosen from a library. The key benefit of this approach is the ability to solve larger and more difficult problems as a result of applying finer-grained optimisations and using specialised techniques as required.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227151,Generative programming;constraint solvers;software architecture;model-driven development,Computer architecture;Software architecture;Libraries;Electronics packaging;Generators;Maintenance engineering;Complexity theory,,6,,39,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Fairness-aware Configuration of Machine Learning Libraries,S. Tizpaz-Niari; A. Kumar; G. Tan; A. Trivedi,University of Texas at El Paso; Pennsylvania State University; Pennsylvania State University; University of Colorado Boulder,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,909,920,"This paper investigates the parameter space of machine learning (ML) algorithms in aggravating or mitigating fairness bugs. Data-driven software is increasingly applied in social-critical applications where ensuring fairness is of paramount importance. The existing approaches focus on addressing fairness bugs by either modifying the input dataset or modifying the learning algorithms. On the other hand, the selection of hyperparameters, which provide finer controls of ML algorithms, may enable a less intrusive approach to influence the fairness. Can hyperparameters amplify or suppress discrimination present in the input dataset? How can we help programmers in detecting, understanding, and exploiting the role of hyperparameters to improve the fairness? We design three search-based software testing algorithms to un-cover the precision-fairness frontier of the hyperparameter space. We complement these algorithms with statistical debugging to explain the role of these parameters in improving fairness. We implement the proposed approaches in the tool Parfait-ML (PARameter FAIrness Testing for ML Libraries) and show its effectiveness and utility over five mature ML algorithms as used in six social-critical applications. In these applications, our approach successfully iden-tified hyperparameters that significantly improve (vis-a-vis the state-of-the-art techniques) the fairness without sacrificing precision. Surprisingly, for some algorithms (e.g., random forest), our approach showed that certain configuration of hyperparameters (e.g., restricting the search space of attributes) can amplify biases across applications. Upon further investigation, we found intuitive explanations of these phenomena, and the results corroborate simi-lar observations from the literature.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510202,NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794108,,Software testing;Machine learning algorithms;Software algorithms;Computer bugs;Libraries;Software;Space exploration,,6,,41,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Evaluating Large Language Models in Class-Level Code Generation,X. Du; M. Liu; K. Wang; H. Wang; J. Liu; Y. Chen; J. Feng; C. Sha; X. Peng; Y. Lou,"School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,982,994,"Recently, many large language models (LLMs) have been proposed, showing advanced proficiency in code generation. Meanwhile, many efforts have been dedicated to evaluating LLMs on code generation benchmarks such as HumanEval. Although being very helpful for comparing different LLMs, existing evaluation focuses on a sim-ple code generation scenario (i.e., function-level or statement-level code generation), which mainly asks LLMs to generate one single code unit (e.g., a function or a statement) for the given natural language description. Such evaluation focuses on generating independent and often small-scale code units, thus leaving it unclear how LLMs perform in real-world software development scenarios. To fill this knowledge gap, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e., class-level code generation. Compared with existing code generation benchmarks, it better reflects real-world software development scenarios due to it comprising broader contextual dependencies and multiple, interdependent units of code. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on the new benchmark ClassEval, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we find that all LLMs perform much worse on class-level code generation compared to the method-level. While GPT models still dominate other LLMs on class-level code generation, the performance rankings of other models on method-level code generation no longer holds for class-level code generation. Besides, most models (except GPT models) perform better when generating the class method by method; and they have the limited ability of generating dependent code. Based on our findings, we call for software engineering (SE) researchers' expertise to build more LLM benchmarks based on practical and complicated software development scenarios.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639219,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549472,Class-level Code Generation;Large Language Model;Benchmark,Codes;Natural languages;Benchmark testing;Task analysis;Software development management;Software engineering;Python,,,,76,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Symbiotic general-purpose and domain-specific languages,C. Atkinson; R. Gerbig; B. Kennel,"Software Engineering Group, University of Mannheim, Mannheim, Germany; Software Engineering Group, University of Mannheim, Mannheim, Germany; Software Engineering Group, University of Mannheim, Mannheim, Germany",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1269,1272,"Domain-Specific Modeling Languages (DSMLs) have received great attention in recent years and are expected to play a big role in the future of software engineering as processes become more view-centric. However, they are a “two-edged sword”. While they provide strong support for communication within communities, allowing experts to express themselves using concepts tailored to their exact needs, they are a poor vehicle for communication across communities because of their lack of common, transcending concepts. In contrast, General-Purpose Modeling Languages (GPMLs) have the opposite problem - they are poor at the former but good at the latter. The value of models in software engineering would therefore be significantly boosted if the advantages of DSMLs and GPMLs could be combined and models could be viewed in a domain-specific or general-purpose way depending on the needs of the user. In this paper we present an approach for achieving such a synergy based on the orthogonal classification architecture. In this architecture model elements have two classifiers: a linguistic one representing their “general-purpose” and an ontological one representing their “domain-specific” type. By associating visualization symbols with both classifiers it is possible to support two concrete syntaxes at the same time and allow the domain-specific and general-purpose notation to support each other - that is, to form a symbiotic relationship.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227102,symbiotic domain-specific languages;orthogonal classification architecture;ontological classification;linguistic classification,Unified modeling language;Visualization;Syntactics;Concrete;Biological system modeling;Object oriented modeling;Pragmatics,,9,,9,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Strengthening Supply Chain Security with Fine-Grained Safe Patch Identification,C. Luo; W. Meng; S. Wang,"The Chinese University of Hong Kong, Hong Kong SAR, China; The Chinese University of Hong Kong, Hong Kong SAR, China; HKUST, Hong Kong SAR, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1084,1095,"Enhancing supply chain security is crucial, often involving the detection of patches in upstream software. However, current security patch analysis works yield relatively low recall rates (i.e., many security patches are missed). In this work, we offer a new solution to detect safe patches and assist downstream developers in patch propagation. Specifically, we develop SPATCH to detect fine-grained safe patches. SPATCH leverages fine-grained patch analysis and a new differential symbolic execution technique to analyze the functional impacts of code changes. We evaluated SPATCH on various software, including the Linux kernel and OpenSSL, and demonstrated that it outperformed existing methods in detecting safe patches, resulting in observable security benefits. In our case studies, we updated hundreds of functions in modern software using safe patches detected by SPATCH without causing any regression issues. Our detected safe security patches have been merged into the latest version of downstream software like ProtonVpn.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548965,Supply Chain Security;Fine-grained Patch Analysis;Differential Symbolic Execution,Codes;Linux;Supply chains;Focusing;Software;Security;Kernel,,,,42,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning,M. Geng; S. Wang; D. Dong; H. Wang; G. Li; Z. Jin; X. Mao; X. Liao,"College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; Key Lab of High Confidence Software Technology, Peking University, Beijing, China; Key Lab of High Confidence Software Technology, Peking University, Beijing, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,453,465,"Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548839,Code Summarization;Large Language Model;In-Context Learning,Computer languages;Codes;Supervised learning;Natural languages;Semantics;Task analysis;Software engineering,,7,,78,,14 Jun 2024,,,IEEE,IEEE Conferences,True
CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models,C. Lemieux; J. P. Inala; S. K. Lahiri; S. Sen,"University of British Columbia, Canada; Microsoft Research, USA; Microsoft Research, USA; Microsoft Research, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,919,931,"Search-based software testing (SBST) generates high-coverage test cases for programs under test with a combination of test case generation and mutation. SBST's performance relies on there being a reasonable probability of generating test cases that exercise the core logic of the program under test. Given such test cases, SBST can then explore the space around them to exercise various parts of the program. This paper explores whether Large Language Models (LLMs) of code, such as OpenAI's Codex, can be used to help SBST's exploration. Our proposed algorithm, CodaMosa, conducts SBST until its coverage improvements stall, then asks Codex to provide example test cases for under-covered functions. These examples help SBST redirect its search to more useful areas of the search space. On an evaluation over 486 benchmarks, CodaMosa achieves statistically significantly higher coverage on many more benchmarks (173 and 279) than it reduces coverage on (10 and 4), compared to SBST and LLM-only baselines.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00085,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172800,search based software testing;codex;test suite generation;python;large language model;automated testing,Software testing;Codes;Benchmark testing;Software;Space exploration;Test pattern generators;Software engineering,,46,,62,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
An Empirical Comparison of Pre-Trained Models of Source Code,C. Niu; C. Li; V. Ng; D. Chen; J. Ge; B. Luo,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2136,2148,"While a large number of pre-trained models of source code have been successfully developed and applied to a variety of software engineering (SE) tasks in recent years, our understanding of these pre-trained models is arguably fairly limited. With the goal of advancing our understanding of these models, we perform the first systematic empirical comparison of 19 recently-developed pre-trained models of source code on 13 SE tasks. To gain additional insights into these models, we adopt a recently -developed 4-dimensional categorization of pre-trained models, and subsequently investigate whether there are correlations between different categories of pre-trained models and their performances on different SE tasks.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00180,National Natural Science Foundation of China(grant numbers:61802167); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201250); NSF(grant numbers:2034508); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172787,Pre-training of Source Code;AI for SE,Systematics;Codes;Correlation;Source coding;Task analysis;Software engineering,,23,,72,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Capturing and exploiting fine-grained IDE interactions,Z. Gu,"Department of Computer Science, University of California,슠Davis, USA",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1630,1631,"Developers interact with IDEs intensively to maximize productivity. A developer's interactions with an IDE reflect his thought process and work habits. In this paper, we propose a general framework to capture and exploit all types of IDE interactions. We have two explicit goals for the framework: its systematic interception of comprehensive user interactions, and the ease of use in writing customized applications. To this end, we developed IDE++ on top of Eclipse IDE. For evaluation, we built applications upon the framework to illustrate 1) the need for capturing comprehensive, finegrained IDE interactions, and 2) IDE++'s ease of use. We believe that IDE++ is a step toward building next generation, customizable and intelligent IDEs.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227220,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227220,IDE++;fine-grained interactions,Monitoring;Productivity;Software;Context;Testing;History;Systematics,,3,,1,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Tare: Type-Aware Neural Program Repair,Q. Zhu; Z. Sun; W. Zhang; Y. Xiong; L. Zhang,"Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China; Zhongguancun Laboratory, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1443,1455,"Automated program repair (APR) aims to reduce the effort of software development. With the development of deep learning, lots of DL-based APR approaches have been proposed using an encoder-decoder architecture. Despite the promising performance, these models share the same limitation: generating lots of untypable patches. The main reason for this phenomenon is that the existing models do not consider the constraints of code captured by a set of typing rules. In this paper, we propose, Tare, a type-aware model for neural program repair to learn the typing rules. To encode an individual typing rule, we introduce three novel components: (1) a novel type of grammars, T-Grammar, that integrates the type information into a standard grammar, (2) a novel representation of code, T-Graph, that integrates the key information needed for type checking an AST, and (3) a novel type-aware neural program repair approach, Tare, that encodes the T-Graph and generates the patches guided by T-Grammar. The experiment was conducted on three benchmarks, 393 bugs from Defects4J v1.2, 444 additional bugs from Defects4J v2.0, and 40 bugs from QuixBugs. Our results show that Tare repairs 62, 32, and 27 bugs on these benchmarks respectively, and outperforms the existing APR approaches on all benchmarks. Further analysis also shows that Tare tends to generate more compilable patches than the existing DL-based APR approaches with the typing rule information.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00126,National Natural Science Foundation of China(grant numbers:62161146003); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172781,program repair;neural networks,Deep learning;Codes;Computer bugs;Maintenance engineering;Benchmark testing;Software;Generators,,9,,60,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
PExReport: Automatic Creation of Pruned Executable Cross-Project Failure Reports,S. Huang; X. Wang,"Department of Computer Science, University of Texas at San Antonio, San Antonio, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,184,195,"Modern software development extensively depends on existing libraries written by other developer teams from the same or a different organization. When a developer executes the software, the execution trace may go across the boundaries of multiple software products and create cross-project failures (CPFs). Existing studies show that a stand-alone executable failure report may enable the most effective communication, but creating such a report is often challenging due to the complicated files and dependencies interactions in the software ecosystems. In this paper, to solve the CPF report trilemma, we developed PExReport, which automatically creates stand-alone executable CPF reports. PExReport leverages build tools to prune source code and dependencies, and further analyzes the build process to create a pruned build environment for reproducing the CPF. We performed an evaluation on 74 software project issues with 198 CPFs, and the evaluation results show that PExReport can create executable CPF reports for 184 out of 198 test failures in our dataset, with an average reduction of 72.97% on source classes and the classes in internal JARs.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00027,"NSF(grant numbers:CCF-1846467,CCF-2007718,CSPECC-1736209); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172556,cross-project failure;executable failure report;failure reproduction;build tool;build environment;debloating,Codes;Source coding;Ecosystems;Organizations;Software;Libraries;Hybrid power systems,,,,44,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Locating Framework-specific Crashing Faults with Compact and Explainable Candidate Set,J. Yan; M. Wang; Y. Liu; J. Yan; L. Zhang,"Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China; Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,172,183,"Nowadays, many applications do not exist independently but rely on various frameworks or libraries. The frequent evolution and the complex implementation of framework APIs induce lots of unexpected post-release crashes. Starting from the crash stack traces, existing approaches either perform application-level call graph (CG) tracing or construct datasets with similar crash-fixing records to locate buggy methods. However, these approaches are limited by the completeness of CG or dependent on historical fixing records, and some of them only focus on specific manually modeled exception types. To achieve effective debugging on complex framework-specific crashes, we propose a code-separation-based locating approach that weakly relies on CG tracing and does not require any prior knowledge. Our key insight is that one crash trace with the description message can be mapped to a definite exception-thrown point in the framework, the semantics analysis of which can help to figure out the root causes of the crash-triggering procedure. Thus, we can pre-construct reusable summaries for all the framework-specific exceptions to support fault localization in application code. Based on that idea, we design the exception-thrown summary (ETS) that describes both the key variables and key APIs related to the exception triggering. Then, we perform static analysis to automatically compute such summaries and make a data-tracking of key variables and APIs in the application code to get the ranked buggy candidates. In the scenario of locating Android framework-specific crashing faults, our tool CrashTracker exhibited an overall MRR value of 0.91 and outperforms the state-of-the-art tool Anchor with higher precision. It only provides a compact candidate set and gives user-friendly reports with explainable reasons for each candidate.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00026,"National Natural Science Foundation of China(grant numbers:62102405,62132020); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172816,Fault Localization;Framework-specific Exception;Crash Stack Trace;Android Application,Location awareness;Codes;Semantics;Debugging;Static analysis;Computer crashes;Libraries,,,,43,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
CoLeFunDa: Explainable Silent Vulnerability Fix Identification,J. Zhou; M. Pacheco; J. Chen; X. Hu; X. Xia; D. Lo; A. E. Hassan,"Centre for Software Excellence, Huawei, Toronto, Canada; Centre for Software Excellence, Huawei, Toronto, Canada; Centre for Software Excellence, Huawei, Toronto, Canada; School of Software Technology, Zhejiang University, Ningbo, China; Huawei, China; School of Information Systems, Singapore Management University, Singapore; Software Analysis and Intelligence Lab (SAIL), Queen's University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2565,2577,"It is common practice for OSS users to leverage and monitor security advisories to discover newly disclosed OSS vulnerabilities and their corresponding patches for vulnerability remediation. It is common for vulnerability fixes to be publicly available one week earlier than their disclosure. This gap in time provides an opportunity for attackers to exploit the vulnerability. Hence, OSS users need to sense the fix as early as possible so that the vulnerability can be remediated before it is exploited. However, it is common for OSS to adopt a vulnerability disclosure policy which causes the majority of vulnerabilities to be fixed silently, meaning the commit with the fix does not indicate any vulnerability information. In this case even if a fix is identified, it is hard for OSS users to understand the vulnerability and evaluate its potential impact. To improve early sensing of vulnerabilities, the identification of silent fixes and their corresponding explanations (e.g., the corresponding common weakness enumeration (CWE) and exploitability rating) are equally important. However, it is challenging to identify silent fixes and provide explanations due to the limited and diverse data. To tackle this challenge, we propose CoLeFunDa: a framework consisting of a Contrastive Learner and FunDa, which is a novel approach for Function change Data augmentation. FunDa first increases the fix data (i.e., code changes) at the function level with unsupervised and supervised strategies. Then the contrastive learner leverages contrastive learning to effectively train a function change encoder, FCBERT, from diverse fix data. Finally, we leverage FCBERT to further fine-tune three downstream tasks, i.e., silent fix identification, CWE category classification, and exploitability rating classification, respectively. Our result shows that CoLeFunDa outperforms all the state-of-art baselines in all downstream tasks. We also conduct a survey to verify the effectiveness of CoLeFunDa in practical usage. The result shows that CoLeFunDa can categorize 62.5% (25 out of 40) CVEs with correct CWE categories within the top 2 recommendations.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00214,National Key Research and Development Program of China(grant numbers:2021 YFB2701102); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172826,OSS Vulnerabilities;Contrastive Learning,Surveys;Codes;Data augmentation;Sensors;Security;Task analysis;Monitoring,,4,,72,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
"Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by Broadening Input Ranges and Sources",X. Zhou; K. Kim; B. Xu; D. Han; D. Lo,"Singapore Management University, Singapore; Singapore Management University, Singapore; North Carolina State University, USA; Royal Holloway University of London, United Kingdom; Singapore Management University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1071,1083,"The advances of deep learning (DL) have paved the way for auto-matic software vulnerability repair approaches, which effectively learn the mapping from the vulnerable code to the fixed code. Never-theless, existing DL-based vulnerability repair methods face notable limitations: 1) they struggle to handle lengthy vulnerable code, 2) they treat code as natural language texts, neglecting its inherent structure, and 3) they do not tap into the valuable expert knowledge present in the expert system. To address this, we propose VulMaster, a Transformer-based neural network model that excels at generating vulnerability repairs by comprehensively understanding the entire vulnerable code, irrespective of its length. This model also integrates diverse information, encompassing vulnerable code structures and expert knowledge from the CWE system. We evaluated VulMaster on a real-world C/C++ vulnerability repair dataset comprising 1,754 projects with 5,800 vulnerable functions. The experimental results demonstrated that VulMaster exhibits substan-tial improvements compared to the learning-based state-of-the-art vulnerability repair approach. Specifically, VulMaster improves the EM, BLEU, and CodeBLEU scores from 10.2% to 20.0%, 21.3% to 29.3%, and 32.5% to 40.9%, respectively.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639222,National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548521,,Deep learning;Codes;Neural networks;Natural languages;Maintenance engineering;Transformers;Software,,1,,88,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Content classification of development emails,A. Bacchelli; T. Dal Sasso; M. D'Ambros; M. Lanza,"REVEAL @ Faculty of Informatics — University of Lugano, Switzerland; REVEAL @ Faculty of Informatics — University of Lugano, Switzerland; REVEAL @ Faculty of Informatics — University of Lugano, Switzerland; REVEAL @ Faculty of Informatics — University of Lugano, Switzerland",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,375,385,"Emails related to the development of a software system contain information about design choices and issues encountered during the development process. Exploiting the knowledge embedded in emails with automatic tools is challenging, due to the unstructured, noisy, and mixed language nature of this communication medium. Natural language text is often not well-formed and is interleaved with languages with other syntaxes, such as code or stack traces. We present an approach to classify email content at line level. Our technique classifies email lines in five categories (i.e., text, junk, code, patch, and stack trace) to allow one to subsequently apply ad hoc analysis techniques for each category. We evaluated our approach on a statistically significant set of emails gathered from mailing lists of four unrelated open source systems.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227177,Empirical software engineering;Unstructured Data Mining;Emails,Electronic mail;Data mining;Software;Context;Noise;Java;Text recognition,,63,1,37,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction,S. Kang; J. Yoon; S. Yoo,"School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2312,2323,"Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose Libro, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of Libro shows that, on the widely studied Defects4J benchmark, Libro can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate Libro against 31 bug reports submitted after the collection of the LLM training data terminated: Libro produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show Libro has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00194,"National Research Foundation of Korea (NRF)(grant numbers:NRF-2020R1A2C1013629,NRF-2018R1A5A1059921); Institute for Information & Communications Technology Promotion; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172763,test generation;natural language processing;software engineering,Codes;Computer bugs;Semantics;Training data;Benchmark testing;Writing;Test pattern generators,,40,,42,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Automated Repair of Programs from Large Language Models,Z. Fan; X. Gao; M. Mirchev; A. Roychoudhury; S. H. Tan,"National University of Singapore, Singapore; Beihang University, Beijing, China; National University of Singapore, Singapore; National University of Singapore, Singapore; Southern University of Science and Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1469,1481,"Large language models such as Codex, have shown the capability to produce code for many programming tasks. However, the success rate of existing models is low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics, resulting in incorrect programs, or even programs which do not compile. In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance reliability in the code produced by large language models. Our study revealed that: (1) automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to fix auto-generated code; (2) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports editing code, is similar to or better than existing Java repair tools TBar and Recoder in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions: (1) enhancing APR tools to surpass limitations in patch space (e.g., introducing more flexible fault localization) is desirable; (2) as large language models can derive more fix patterns by training on more data, future APR tools could shift focus from adding more fix patterns to synthesis/semantics based approaches, (3) combination of language models with APR to curate patch ingredients, is worth studying.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172854,Large Language Model;Program Repair,Location awareness;Training;Analytical models;Codes;Semantics;Maintenance engineering;Programming,,46,,53,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Large Language Models for Test-Free Fault Localization,A. Z. H. Yang; C. L. Goues; R. Martins; V. J. Hellendoorn,"Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,165,176,"Fault Localization (FL) aims to automatically localize buggy lines of code, a key first step in many manual and automatic debugging tasks. Previous FL techniques assume the provision of input tests, and often require extensive program analysis, program instrumentation, or data preprocessing. Prior work on deep learning for APR struggles to learn from small datasets and produces limited results on real-world programs. Inspired by the ability of large language models (LLMs) of code to adapt to new tasks based on very few examples, we investigate the applicability of LLMs to line level fault localization. Specifically, we propose to overcome the left-to-right nature of LLMs by fine-tuning a small set of bidirectional adapter layers on top of the representations learned by LLMs to produce LLMAO, the first language model based fault localization approach that locates buggy lines of code without any test coverage information. We fine-tune LLMs with 350 million, 6 billion, and 16 billion parameters on small, manually curated corpora of buggy programs such as the $Defects4\mathcal{J}$ corpus. We observe that our technique achieves substantially more confidence in fault localization when built on the larger models, with bug localization performance scaling consistently with the LLM size. Our empirical evaluation shows that LLMAO improves the Top-1 results over the state-of-the-art machine learning fault localization (MLFL) baselines by 2.3%-54.4%, and Top-5 results by 14.4%-35.6%. LLMAO is also the first FL technique trained using a language model architecture that can detect security vulnerabilities down to the code line level.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623342,ANI(grant numbers:045917); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548193,Software and its engineering → Software functional properties;Computing methodologies → Neural networks,Location awareness;Deep learning;Training;Adaptation models;Codes;Computer bugs;Manuals,,7,,50,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
PROPR: Property-Based Automatic Program Repair,M. P. Gissurarson; L. Applis; A. Panichella; A. van Deursen; D. Sands,"Chalmers University of Technology, Gothenburg, Sweden; TU Delft, Delft, Netherlands; TU Delft, Delft, Netherlands; TU Delft, Delft, Netherlands; Chalmers University of Technology, Gothenburg, Sweden",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1768,1780,"Automatic program repair (APR) regularly faces the challenge of overfitting patches - patches that pass the test suite, but do not actually address the problems when evaluated manually. Currently, overfit detection requires manual inspection or an oracle making quality control of APR an expensive task. With this work, we want to introduce properties in addition to unit tests for APR to address the problem of overfitting. To that end, we design and implement PROPR, a program repair tool for Haskell that leverages both property-based testing (via QuickCheck) and the rich type sys-tem and synthesis offered by the Haskell compiler. We compare the repair-ratio, time-to-first-patch and overfitting-ratio when using unit tests, property-based tests, and their combination. Our results show that properties lead to quicker results and have a lower overfit ratio than unit tests. The created overfit patches provide valuable insight into the underlying problems of the program to repair (e.g., in terms of fault localization or test quality). We consider this step towards fitter, or at least insightful, patches a critical contribution to bring APR into developer workflows.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510620,Knuth and Alice Wallenberg Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794120,automatic program repair;search based software engineering;synthesis;property-based testing;typed holes,Location awareness;Program processors;Redundancy;Manuals;Maintenance engineering;Inspection;Software,,3,,73,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
BinAug: Enhancing Binary Similarity Analysis with Low-Cost Input Repairing,W. K. Wong; H. Wang; Z. Li; S. Wang,"The Hong Kong University of Science and Technology, Hong Kong, SAR; The Hong Kong University of Science and Technology, Hong Kong, SAR; The Hong Kong University of Science and Technology, Hong Kong, SAR; The Hong Kong University of Science and Technology, Hong Kong, SAR",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,51,63,"Binary code similarity analysis (BCSA) is a fundamental building block for various software security, reverse engineering, and re-engineering applications. Existing research has applied deep neural networks (DNNs) to measure the similarity between binary code, following the major breakthrough of DNNs in processing media data like images. Despite the encouraging results of DNN-based BCSA, it is however not widely deployed in the industry due to the instability and the black-box nature of DNNs. In this work, we first launch an extensive study over the state-of-the-art (SoTA) BCSA tools, and investigate their erroneous predictions from both quantitative and qualitative perspectives. Then, we accordingly design a low-cost and generic framework, namely Binaug, to improve the accuracy of BCSA tools by repairing their input binary codes. Aligned with the typical workflow of DNN-based BCSA, Binaug obtains the sorted top-K results of code similarity, and then re-ranks the results using a set of carefully-designed transformations. Binaug supports both black- and white-box settings, depending on the accessibility of the DNN model internals. Our experimental results show that Binaug can constantly improve performance of the SoTA BCSA tools by an average of 2.38pt and 6.46pt in the black- and the white-box settings. Moreover, with Binaug, we enhance the F1 score of binary software component analysis, an important downstream application of BCSA, by an average of 5.43pt and 7.45pt in the black- and the white-box settings.",1558-1225,979-8-4007-0217-4,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548594,Binary analysis;DNNs;Input repairing,Industries;Reverse engineering;Closed box;Binary codes;Artificial neural networks;Media;Security,,,,110,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Syntax and Domain Aware Model for Unsupervised Program Translation,F. Liu; J. Li; L. Zhang,"State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; Key Lab of High Confidence Software Technology, MoE, Peking University, Beijing, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,755,767,"There is growing interest in software migration as the development of software and society. Manually migrating projects between languages is error-prone and expensive. In recent years, researchers have begun to explore automatic program translation using supervised deep learning techniques by learning from large-scale parallel code corpus. However, parallel resources are scarce in the programming language domain, and it is costly to collect bilingual data manually. To address this issue, several unsupervised programming translation systems are proposed. However, these systems still rely on huge monolingual source code to train, which is very expensive. Besides, these models cannot perform well for translating the languages that are not seen during the pre-training procedure. In this paper, we propose SDA-Trans, a syntax and domain-aware model for program translation, which leverages the syntax structure and domain knowledge to enhance the cross-lingual transfer ability. SDA-Trans adopts unsupervised training on a smaller-scale corpus, including Python and Java monolingual programs. The experimental results on function translation tasks between Python, Java, and C++ show that SDA-Trans outperforms many large-scale pre-trained models, especially for unseen language translation.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00072,National Science Foundation of China(grant numbers:62177003); State Key Laboratory of Software Development Environment(grant numbers:SKLSDE-2022ZX-13); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172589,program translation;neural networks;syntax structure;unsupervised learning,Training;Deep learning;Java;Source coding;Syntactics;Programming;Software,,6,,44,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
NeuronFair: Interpretable White-Box Fairness Testing through Biased Neuron Identification,H. Zheng; Z. Chen; T. Du; X. Zhang; Y. Cheng; S. Ti; J. Wang; Y. Yu; J. Chen,Zhejiang University of Technology; Zhejiang University; Zhejiang University; Zhejiang University; Huawei International; Zhejiang University; Zhejiang University; National University of Defense Technology; Zhejiang University of Technology,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1519,1531,"Deep neural networks (DNNs) have demonstrated their outper-formance in various domains. However, it raises a social concern whether DNNs can produce reliable and fair decisions especially when they are applied to sensitive domains involving valuable re-source allocation, such as education, loan, and employment. It is crucial to conduct fairness testing before DNNs are reliably de-ployed to such sensitive domains, i.e., generating as many instances as possible to uncover fairness violations. However, the existing testing methods are still limited from three aspects: interpretabil-ity, performance, and generalizability. To overcome the challenges, we propose NeuronFair, a new DNN fairness testing framework that differs from previous work in several key aspects: (1) inter-pretable - it quantitatively interprets DNNs' fairness violations for the biased decision; (2) effective - it uses the interpretation results to guide the generation of more diverse instances in less time; (3) generic - it can handle both structured and unstructured data. Extensive evaluations across 7 datasets and the corresponding DNNs demonstrate NeuronFair's superior performance. For instance, on structured datasets, it generates much more instances (~ ×5.84) and saves more time (with an average speedup of 534.56%) compared with the state-of-the-art methods. Besides, the instances of NeuronFair can also be leveraged to improve the fairness of the biased DNNs, which helps build more fair and trustworthy deep learning systems. The code of NeuronFair is open-sourced at https:/github.com/haibinzheng/NeuronFair.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510123,"NSFC(grant numbers:62072406,62102359,61772466,62102360); Zhejiang Provincial Natural Science Foundation for Distinguished Young Scholars(grant numbers:LR19F020003); Key R&D Projects in Zhejiang Province(grant numbers:2021C01117,2022C01018); Ten Thousand Talents Program(grant numbers:2020R52011); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793943,Interpretability;fairness testing;discriminatory instance;deep learning;biased neuron,Deep learning;Neurons;Neural networks;Employment;Education;Reliability;Resource management,,16,,61,,20 Jun 2022,,,IEEE,IEEE Conferences,True
NPEX: Repairing Java Null Pointer Exceptions without Tests,J. Lee; S. Hong; H. Oh,"Korea University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1532,1544,"We present NPEX, a new technique for repairing Java null pointer exceptions (NPEs) without tests. State-of-the-art NPE repair techniques rely on test suites written by developers for patch validation. Unfortunately, however, those are typically future test cases that are unavailable at the time bugs are reported or insufficient to identify correct patches. Unlike existing techniques, NPEX does not require test cases; instead, NPEX automatically infers the repair specification of the buggy program and uses the inferred specification to validate patches. The key idea is to learn a statistical model that predicts how developers would handle NPEs by mining null-handling patterns from existing codebases, and to use a variant of symbolic execution that can infer the repair specification from the buggy program using the model. We evaluated NPEX on real-world NPEs collected from diverse open-source projects. The results show that NPEX significantly outperforms the current state-of-the-art.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510186,"Institute of Information & communications Technology Planning & Evaluation (IITP)(grant numbers:2020-0-01337,2021-0-00758); MSIT(Ministry of Science and ICT), Korea(grant numbers:IITP-2022-2020-0-01819); National Research Foundation of Korea (NRF)(grant numbers:2021R1A5A1021944); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794030,,Java;Computer bugs;Maintenance engineering;Predictive models;Behavioral sciences;Open source software;Software engineering,,1,,72,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Multilingual training for Software Engineering,T. Ahmed; P. Devanbu,"University of California, Davis Davis, California, USA; University of California, Davis Davis, California, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1443,1455,"Well-trained machine-learning models, which leverage large amounts of open-source software data, have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach, with performance gradually improving over the past several years with better models and training methods. More, and more diverse, clean, labeled data is better for training; but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean, labeled data generally have wide applicability. For some languages (e.g., Ruby) labeled data is less abundant; in others (e.g., JavaScript) the available data maybe more focused on some application domains, and thus less diverse. As a way around such data bottlenecks, we present evidence suggesting that human-written code in different languages (which performs the same function), is rather similar, and particularly preserving of identifier naming patterns; we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization, code retrieval, and function naming. We note that this data-augmenting approach is broadly compatible with different tasks, languages, and machine-learning models.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510049,"U.S. National Science Foundation(grant numbers:1414172,2107592); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794126,code summarization;code search;method name prediction;deep learning,Training;Computer languages;Codes;Natural languages;Training data;Machine learning;Syntactics,,14,,76,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
Adaptive Test Selection for Deep Neural Networks,X. Gao; Y. Feng; Y. Yin; Z. Liu; Z. Chen; B. Xu,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,73,85,"Deep neural networks (DNN) have achieved tremendous development in the past decade. While many DNN-driven software applications have been deployed to solve various tasks, they could also produce incorrect behaviors and result in massive losses. To reveal the incorrect behaviors and improve the quality of DNN-driven applications, developers often need rich labeled data for the testing and optimization of DNN models. However, in practice, collecting diverse data from application scenarios and labeling them properly is often a highly expensive and time-consuming task. In this paper, we proposed an adaptive test selection method, namely ATS, for deep neural networks to alleviate this problem. ATS leverages the difference between the model outputs to measure the behavior diversity of DNN test data. And it aims at selecting a subset with diverse tests from a massive unlabelled dataset. We experiment ATS with four well-designed DNN models and four widely-used datasets in comparison with various kinds of neuron coverage (NC). The results demonstrate that ATS can significantly outperform all test selection methods in assessing both fault detection and model improvement capability of test suites. It is promising to save the data labeling and model retraining costs for deep neural networks.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510232,"National Natural Science Foundation of China(grant numbers:62002158,61832009,61932012); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:CJGJZD20200617103001003); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793868,deep learning testing;deep neural networks;adaptive random testing;test selection,Deep learning;Adaptation models;Adaptive systems;Computational modeling;Fault detection;Neural networks;Data models,,14,,68,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Fine-grained Commit-level Vulnerability Type Prediction by CWE Tree Structure,S. Pan; L. Bao; X. Xia; D. Lo; S. Li,"College of Computer Science and Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China; Huawei, China; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,957,969,"Identifying security patches via code commits to allow early warnings and timely fixes for Open Source Software (OSS) has received increasing attention. However, the existing detection methods can only identify the presence of a patch (i.e., a binary classification) but fail to pinpoint the vulnerability type. In this work, we take the first step to categorize the security patches into fine-grained vulnerability types. Specifically, we use the Common Weakness Enumeration (CWE) as the label and perform fine-grained classification using categories at the third level of the CWE tree. We first formulate the task as a Hierarchical Multi-label Classification (HMC) problem, i.e., inferring a path (a sequence of CWE nodes) from the root of the CWE tree to the node at the target depth. We then propose an approach named TreeVul with a hierarchical and chained architecture, which manages to utilize the structure information of the CWE tree as prior knowledge of the classification task. We further propose a tree structure aware and beam search based inference algorithm for retrieving the optimal path with the highest merged probability. We collect a large security patch dataset from NVD, consisting of 6,541 commits from 1,560 GitHub OSS repositories. Experimental results show that Tree-vulsignificantly outperforms the best performing baselines, with improvements of 5.9%, 25.0%, and 7.7% in terms of weighted F1-score, macro F1-score, and MCC, respectively. We further conduct a user study and a case study to verify the practical value of TreeVul in enriching the binary patch detection results and improving the data quality of NVD, respectively.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00088,"National Key Research and Development Program of China(grant numbers:2021YFB2701102); National Science Foundation of China(grant numbers:U20A20173,61902344,62141222); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); National Research Foundation, Singapore; National University of Singapore(grant numbers:NSOE-TSS2020-02); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172785,Software Security;Vulnerability Type;CWE,Codes;Data integrity;Computer architecture;Inference algorithms;Classification algorithms;Security;Task analysis,,9,,74,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
FIRA: Fine-Grained Graph-Based Code Change Representation for Automated Commit Message Generation,J. Dong; Y. Lou; Q. Zhu; Z. Sun; Z. Li; W. Zhang; D. Hao,"Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Department of Computer Science, Purdue University West Lafayette, IN, USA; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,970,981,"Commit messages summarize code changes of each commit in nat-ural language, which help developers understand code changes without digging into detailed implementations and play an essen-tial role in comprehending software evolution. To alleviate human efforts in writing commit messages, researchers have proposed var-ious automated techniques to generate commit messages, including template-based, information retrieval-based, and learning-based techniques. Although promising, previous techniques have limited effectiveness due to their coarse-grained code change representations. This work proposes a novel commit message generation technique, FIRA, which first represents code changes via fine-grained graphs and then learns to generate commit messages automati-cally. Different from previous techniques, FIRA represents the code changes with fine-grained graphs, which explicitly describe the code edit operations between the old version and the new version, and code tokens at different granularities (i.e., sub-tokens and integral tokens). Based on the graph-based representation, FIRA generates commit messages by a generation model, which includes a graph-neural-network-based encoder and a transformer-based decoder. To make both sub-tokens and integral tokens as available ingredients for commit message generation, the decoder is further incorporated with a novel dual copy mechanism. We further per-form an extensive study to evaluate the effectiveness of FIRA. Our quantitative results show that FIRA outperforms state-of-the-art techniques in terms of BLEU, ROUGE-L, and METEOR; and our ablation analysis further shows that major components in our technique both positively contribute to the effectiveness of FIRA. In addition, we further perform a human study to evaluate the quality of generated commit messages from the perspective of developers, and the results consistently show the effectiveness of FIRA over the compared techniques.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510069,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793882,Commit Message Generation;Graph Neural Network;Code Change Representation,Vocabulary;Codes;Writing;Benchmark testing;Transformers;Software;Graph neural networks,,22,,46,,20 Jun 2022,,,IEEE,IEEE Conferences,True
DeepState: Selecting Test Suites to Enhance the Robustness of Recurrent Neural Networks,Z. Liu; Y. Feng; Y. Yin; Z. Chen,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,598,609,"Deep Neural Networks (DNN) have achieved tremendous success in various software applications. However, accompanied by outstanding effectiveness, DNN-driven software systems could also exhibit incorrect behaviors and result in some critical accidents and losses. The testing and optimization of DNN-driven software systems rely on a large number of labeled data that often require many human efforts, resulting in high test costs and low efficiency. Although plenty of coverage-based criteria have been proposed to assist in the data selection of convolutional neural networks, it is difficult to apply them on Recurrent Neural Network (RNN) models due to the difference between the working nature. In this paper, we propose a test suite selection tool DeepState towards the particular neural network structures of RNN models for reducing the data labeling and computation cost. DeepState selects data based on a stateful perspective of RNN, which identifies the possibly misclassified test by capturing the state changes of neurons in RNN models. We further design a test selection method to enable testers to obtain a test suite with strong fault detection and model improvement capability from a large dataset. To evaluate DeepState, we conduct an extensive empirical study on popular datasets and prevalent RNN models containing image and text processing tasks. The experimental results demonstrate that DeepState outperforms existing coverage-based techniques in selecting tests regarding effectiveness and the inclusiveness of bug cases. Meanwhile, we observe that the selected data can improve the robustness of RNN models effectively.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510231,"National Natural Science Foundation of China(grant numbers:62002158,61832009,61932012); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794081,deep learning testing;deep neural networks;recurrent neural networks;test selection,Recurrent neural networks;Costs;Computational modeling;Computer bugs;Software systems;Data models;Robustness,,6,,66,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Towards Understanding Fairness and its Composition in Ensemble Machine Learning,U. Gohar; S. Biswas; H. Rajan,"Dept. of Computer Science, Iowa State University, Ames, IA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1533,1545,"Machine Learning (ML) software has been widely adopted in modern society, with reported fairness implications for minority groups based on race, sex, age, etc. Many recent works have proposed methods to measure and mitigate algorithmic bias in ML models. The existing approaches focus on single classifier-based ML models. However, real-world ML models are often composed of multiple independent or dependent learners in an ensemble (e.g., Random Forest), where the fairness composes in a non-trivial way. How does fairness compose in ensembles? What are the fairness impacts of the learners on the ultimate fairness of the ensemble? Can fair learners result in an unfair ensemble? Furthermore, studies have shown that hyperparameters influence the fairness of ML models. Ensemble hyperparameters are more complex since they affect how learners are combined in different categories of ensembles. Understanding the impact of ensemble hyperparameters on fairness will help programmers design fair ensembles. Today, we do not understand these fully for different ensemble algorithms. In this paper, we comprehensively study popular real-world ensembles: Bagging, Boosting, Stacking, and Voting. We have developed a benchmark of 168 ensemble models collected from Kaggle on four popular fairness datasets. We use existing fairness metrics to understand the composition of fairness. Our results show that ensembles can be designed to be fairer without using mitigation techniques. We also identify the interplay between fairness composition and data characteristics to guide fair ensemble design. Finally, our benchmark can be leveraged for further research on fair ensembles. To the best of our knowledge, this is one of the first and largest studies on fairness composition in ensembles yet presented in the literature.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00133,"US NSF(grant numbers:CCF-19-34884,CCF-22-23812,CNS-21-20448); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172501,fairness;ensemble;machine learning;models,Training;Machine learning algorithms;Stacking;Software algorithms;Benchmark testing;Software;Software measurement,,11,,65,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Does data sampling improve deep learning-based vulnerability detection? Yeas! and Nays!,X. Yang; S. Wang; Y. Li; S. Wang,"University of Manitoba, Canada; University of Manitoba, Canada; New Jersey Institute of Technology, USA; New Jersey Institute of Technology, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2287,2298,"Recent progress in Deep Learning (DL) has sparked interest in using DL to detect software vulnerabilities automatically and it has been demonstrated promising results at detecting vulnerabilities. However, one prominent and practical issue for vulnerability detection is data imbalance. Prior study observed that the performance of state-of-the-art (SOTA) DL-based vulnerability detection (DLVD) approaches drops precipitously in real world imbalanced data and a 73% drop of F1-score on average across studied approaches. Such a significant performance drop can disable the practical usage of any DLVD approaches. Data sampling is effective in alleviating data imbalance for machine learning models and has been demonstrated in various software engineering tasks. Therefore, in this study, we conducted a systematical and extensive study to assess the impact of data sampling for data imbalance problem in DLVD from two aspects: i) the effectiveness of DLVD, and ii) the ability of DLVD to reason correctly (making a decision based on real vulnerable statements). We found that in general, oversampling outperforms undersampling, and sampling on raw data outperforms sampling on latent space, typically random oversampling on raw data performs the best among all studied ones (including advanced one SMOTE and OSS). Surprisingly, OSS does not help alleviate the data imbalance issue in DLVD. If the recall is pursued, random undersampling is the best choice. Random oversampling on raw data also improves the ability of DLVD approaches for learning real vulnerable patterns. However, for a significant portion of cases (at least 33% in our datasets), DVLD approach cannot reason their prediction based on real vulnerable statements. We provide actionable suggestions and a roadmap to practitioners and researchers.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00192,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172668,Vulnerability detection;deep learning;data sampling;interpretable AI,Deep learning;Systematics;Software;Data models;Task analysis;Software engineering,,1,,57,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Fuzz4ALL: Universal Fuzzing with Large Language Models,C. S. Xia; M. Paltenghi; J. L. Tian; M. Pradel; L. Zhang,"University of Illinois, Urbana-Champaign, USA; University of Stuttgart, Germany; University of Illinois, Urbana-Champaign, USA; University of Stuttgart, Germany; University of Illinois, Urbana-Champaign, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1547,1559,"Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4ALL, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4ALL is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are well- suited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4ALL on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java, and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4ALL has identified 98 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 64 bugs already confirmed by developers as previously unknown.",1558-1225,979-8-4007-0217-4,,"National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); European Research Council(grant numbers:851895); German Research Foundation; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548154,fuzzing;large language models;software engineering,Software libraries;Runtime;Quantum computing;Program processors;Computer bugs;Fuzzing;Programming,,1,,88,,14 Jun 2024,,,IEEE,IEEE Conferences,True
CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pretrained Models,H. Yu; B. Shen; D. Ran; J. Zhang; Q. Zhang; Y. Ma; G. Liang; Y. Li; Q. Wang; T. Xie,"School of Software and Microelectronics, Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Key Lab of HCST (PKU) MOE, SCS Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Huawei Cloud Computing Technologies Co., Ltd., China; Huawei Cloud Computing Technologies Co., Ltd., China; Huawei Cloud Computing Technologies Co., Ltd., China; School of Software and Microelectronics, Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Key Lab of HCST (PKU) MOE, SCS Peking University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,428,439,"Code generation models based on the pretraining and fine-tuning paradigm have been increasingly attempted by both academia and industry, resulting in well-known industrial models such as Codex, CodeGen, and PanGu-Coder. To evaluate the effectiveness of these models, multiple existing benchmarks (e.g., HumanEval and AiXBench) are proposed, including only cases of generating a standalone function, i.e., a function that may invoke or access only built-in functions and standard libraries. However, non-standalone functions, which typically are not included in the existing benchmarks, constitute more than 70% of the functions in popular open-source projects, and evaluating models' effectiveness on standalone functions cannot reflect these models' effectiveness on pragmatic code generation scenarios (i.e., code generation for real settings of open source or proprietary code). To help bridge the preceding gap, in this paper, we propose a benchmark named CoderEval, consisting of 230 Python and 230 Java code generation problems carefully curated from popular real-world open-source projects and a self-contained execution platform to automatically assess the functional correctness of generated code. CoderEval supports code generation problems from six levels of context dependency, where context refers to code elements such as types, APIs, variables, and consts defined outside the target function but within the dependent third-party libraries, current class, file, or project. CoderEval can be used to evaluate the effectiveness of models in generating code beyond only standalone functions. By evaluating three state-of-the-art code generation models (Code-Gen, PanGu-Coder, and ChatGPT) on CoderEval and HumanEval, we find that the effectiveness of these models in generating stan-dalone functions is substantially higher than that in generating non-standalone functions. Our analysis highlights the current progress and pinpoints future directions to further improve a model's effectiveness by leveraging contextual information for pragmatic code generation.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623322,National Key Research and Development Program(grant numbers:2021YFF0704202); National Natural Science Foundation of China(grant numbers:62161146003); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548523,Code Generation;Large Language Models;Benchmark,Industries;Codes;Benchmark testing;Chatbots;Libraries;Standards;Pragmatics,,,,30,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Supporting sustainability with software — An industrial perspective (Keynote),F. -D. Clesle,"SAP AG, Germany",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,962,962,"Summary form only given. TechnoAware research and develops technologies and solutions for ambient intelligence. Established in 2003 TechnoAware was born from the experiences and competencies of the ISIP40 research group of the University of Genova. This research group is studying and implementing video analytics algorithms since 1985 and is considered nowadays one of the major actors in this filed worldwide. Entirely made up by researchers and experts in the video analytics field, TechnoAware main principles are: proprietary technologies (highly customizable and modular solutions), scientific competencies (high quality level and performances), continuous research and technological innovation (cutting edge products).",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227254,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227254,,,,,,,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
CCTEST: Testing and Repairing Code Completion Systems,Z. Li; C. Wang; Z. Liu; H. Wang; D. Chen; S. Wang; C. Gao,"The Hong Kong University of Science and Technology, Hong Kong SAR; Harbin Institute of Technology, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong SAR; Swiss Federal Institute of Technology Lausanne, Switzerland; The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; Harbin Institute of Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1238,1250,"Code completion, a highly valuable topic in the software development domain, has been increasingly promoted for use by recent advances in large language models (LLMs). To date, visible LLM-based code completion frameworks such as GitHub Copilot and GPT are trained using deep learning over vast quantities of unstructured text and open source code. As the paramount component and the cornerstone in daily programming tasks, code completion has largely boosted professionals' efficiency in building real-world software systems. In contrast to this flourishing market, we find that code completion systems often output suspicious results, and to date, an automated testing and enhancement framework for code completion systems is not available. This research proposes CCTEST, a framework to test and repair code completion systems in black-box settings. CCTEST features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs. Then, it detects inconsistent outputs, representing possibly erroneous cases, from all the completed code cases. Moreover, CCTEST repairs the code completion outputs by selecting the output that mostly reflects the “average” appearance of all output cases, as the final output of the code completion systems. With around 18K test inputs, we detected 33,540 inputs that can trigger erroneous cases (with a true positive rate of 86%) from eight popular LLM-based code completion systems. With repairing, we show that the accuracy of code completion systems is notably increased by 40% and 67% with respect to BLEU score and Levenshtein edit similarity.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172845,,Deep learning;Codes;Source coding;Closed box;Maintenance engineering;Task analysis;Programming profession,,12,,94,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Retrieving Data Constraint Implementations Using Fine-Grained Code Patterns,J. M. Florez; J. Perry; S. Wei; A. Marcus,"The University of Texas at Dallas, Richardson, Texas, USA; The University of Texas at Dallas, Richardson, Texas, USA; The University of Texas at Dallas, Richardson, Texas, USA; The University of Texas at Dallas, Richardson, Texas, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1893,1905,"Business rules are an important part of the requirements of software systems that are meant to support an organization. These rules describe the operations, definitions, and constraints that apply to the organization. Within the software system, business rules are often translated into constraints on the values that are required or allowed for data, called data constraints. Business rules are subject to frequent changes, which in turn require changes to the corre-sponding data constraints in the software. The ability to efficiently and precisely identify where data constraints are implemented in the source code is essential for performing such necessary changes. In this paper, we introduce Lasso, the first technique that automatically retrieves the method and line of code where a given data constraint is enforced. Lasso is based on traceability link recovery approaches and leverages results from recent research that identified line-of-code level implementation patterns for data constraints. We implement three versions of Lasso that can retrieve data constraint implementations when they are implemented with any one of 13 frequently occurring patterns. We evaluate the three versions on a set of 299 data constraints from 15 real-world Java systems, and find that they improve method-level link recovery by 30%,70%, and 163%, in terms of true positives within the first 10 results, compared to their text-retrieval-based baseline. More importantly, the Lasso variants correctly identify the line of code implementing the constraint inside the methods for 68% of the 299 constraints.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510167,"US National Science Foundation(grant numbers:CCF-1955837,CCF-1910976); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793956,business rule;data constraint;traceability link recovery;empirical study;fine-grained traceability;code pattern,Java;Codes;Organizations;Software systems;Pattern matching;Software engineering,,2,,70,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Rogueone: Detecting Rogue Updates via Differential Data-Flow Analysis Using Trust Domains,R. J. Sofaer; Y. David; M. Kang; J. Yu; Y. Cao; J. Yang; J. Nieh,"Columbia University New York, NY, USA; Columbia University New York, NY, USA; Johns Hopkins University Baltimore, MD, USA; Johns Hopkins University Baltimore, MD, USA; Johns Hopkins University Baltimore, MD, USA; Columbia University New York, NY, USA; Columbia University New York, NY, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1235,1247,"Rogue updates, an important type of software supply-chain attack in which attackers conceal malicious code inside updates to benign software, are a growing problem due to their stealth and effective-ness. We design and implement Rogueone, a system for detecting rogue updates to JavaScript packages. Rogueone uses a novel dif-ferential data-flow analysis to capture how an update changes a package's interactions with external APIs. Using an efficient form of abstract interpretation that can exclude unchanged code in a pack-age, it constructs an object data-flow relationship graph (ODRG) that tracks data-flows among objects. Rogueone then maps objects to trust domains, a novel abstraction which summarizes trust relationships in a package. Objects are assigned a trust domain based on whether they originate in the target package, a dependency, or in a system API. Rogueone uses the ODRG to build a set of data-flows across trust domains. It compares data-flow sets across package versions to detect untrustworthy new interactions with external APIs. We evaluated Rogueone on hundreds of npm pack-ages, demonstrating its effectiveness at detecting rogue updates and distinguishing them from benign ones. Rogueone achieves high accuracy and can be more than seven times as effective in detecting rogue updates and avoiding false positives compared to other systems built to detect malicious packages.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639199,"NSF(grant numbers:CNS-2046361,CNS-2052947,CNS-2154404,CNS-2247370,CCF-2124080); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548976,JavaScript;Malicious updates;Malware detection;Node.js;Supply-chain security,Target tracking;Codes;Accuracy;Malware;Security;Software engineering,,,,77,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Explanation-Guided Fairness Testing through Genetic Algorithm,M. Fan; W. Wei; W. Jin; Z. Yang; T. Liu,"Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,871,882,"The fairness characteristic is a critical attribute of trusted AI systems. A plethora of research has proposed diverse methods for individual fairness testing. However, they are suffering from three major limitations, i.e., low efficiency, low effectiveness, and model-specificity. This work proposes ExpGA, an explanation-guided fairness testing approach through a genetic algorithm (GA). ExpGA employs the explanation results generated by interpretable methods to collect high-quality initial seeds, which are prone to derive discriminatory samples by slightly modifying feature values. ExpGA then adopts GA to search discriminatory sample candidates by optimizing a fitness value. Benefiting from this combination of explanation results and GA, ExpGA is both efficient and effective to detect discriminatory individuals. Moreover, ExpGA only requires prediction probabilities of the tested model, resulting in a better generalization capability to various models. Experiments on multiple real-world benchmarks, including tabular and text datasets, show that ExpGA presents higher efficiency and effectiveness than four state-of-the-art approaches.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510137,"National Key R&D Program of China(grant numbers:2018YFB1004500); National Natural Science Foundation of China(grant numbers:61902306,62002280,61632015,61602369,U1766215,61772408,61702414,61833015); China Postdoctoral Science Foundation(grant numbers:2019TQ0251,2020M673439,2020M683507); Innovative Re-search Group of the National Natural Science Foundation of China(grant numbers:61721002); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793975,Explanation result;fairness testing;genetic algorithm,Software algorithms;Predictive models;Benchmark testing;Software;Artificial intelligence;Genetic algorithms;Software engineering,,6,,43,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Bug prediction based on fine-grained module histories,H. Hata; O. Mizuno; T. Kikuno,"Osaka University, Osaka, Japan; Kyoto Institute of Technology, Kyoto, Japan; Osaka University, Osaka, Japan",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,200,210,"There have been many bug prediction models built with historical metrics, which are mined from version histories of software modules. Many studies have reported the effectiveness of these historical metrics. For prediction levels, most studies have targeted package and file levels. Prediction on a fine-grained level, which represents the method level, is required because there may be interesting results compared to coarse-grained (package and file levels) prediction. These results include good performance when considering quality assurance efforts, and new findings about the correlations between bugs and histories. However, fine-grained prediction has been a challenge because obtaining method histories from existing version control systems is a difficult problem. To tackle this problem, we have developed a fine-grained version control system for Java, Historage. With this system, we target Java software and conduct fine-grained prediction with well-known historical metrics. The results indicate that fine-grained (method-level) prediction outperforms coarse-grained (package and file levels) prediction when taking the efforts necessary to find bugs into account. Using a correlation analysis, we show that past bug information does not contribute to method-level bug prediction.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227193,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227193,bug prediction;fine-grained prediction;finegrained histories;historical metrics;effort-based evaluation,Measurement;History;Predictive models;Computer bugs;Software;Java;Complexity theory,,92,,47,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Using Reinforcement Learning for Load Testing of Video Games,R. Tufano; S. Scalabrino; L. Pascarella; E. Aghajani; R. Oliveto; G. Bavota,"SEART @ Software Institute, Università della Svizzera italiana, Switzerland; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2303,2314,"Different from what happens for most types of software systems, testing video games has largely remained a manual activity per-formed by human testers. This is mostly due to the continuous and intelligent user interaction video games require. Recently, rein-forcement learning (RL) has been exploited to partially automate functional testing. RL enables training smart agents that can even achieve super-human performance in playing games, thus being suitable to explore them looking for bugs. We investigate the pos-sibility of using RL for load testing video games. Indeed, the goal of game testing is not only to identify functional bugs, but also to examine the game's performance, such as its ability to avoid lags and keep a minimum number of frames per second (FPS) when high-demanding 3D scenes are shown on screen. We define a method-ology employing RL to train an agent able to play the game as a human while also trying to identify areas of the game resulting in a drop of FPS. We demonstrate the feasibility of our approach on three games. Two of them are used as proof-of-concept, by injecting artificial performance bugs. The third one is an open-source 3D game that we load test using the trained agent showing its potential to identify areas of the game resulting in lower FPS.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510625,European Research Council (ERC)(grant numbers:851720); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793989,Reinforcement Learning;Load Testing,Training;Three-dimensional displays;Computer bugs;Games;Reinforcement learning;Manuals;Software systems,,7,,51,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Using machine learning to enhance automated requirements model transformation,E. -V. Chioaşcă,"School of Computer Science, University of Manchester, Institute of Science and Technology, UK",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1487,1490,"Textual specification documents do not represent a suitable starting point for software development. This issue is due to the inherent problems of natural language such as ambiguity, impreciseness and incompleteness. In order to overcome these shortcomings, experts derive analysis models such as requirements models. However, these models are difficult and costly to create manually. Furthermore, the level of abstraction of the models is too low, thus hindering the automated transformation process. We propose a novel approach which uses high abstraction requirements models in the form of Object System Models (OSMs) as targets for the transformation of natural language specifications in conjunction with appropriate text mining and machine learning techniques. OSMs allow the interpretation of the textual specification based on a small set of facts and provide structural and behavioral information. This approach will allow both (1) the enhancement of minimal specifications, and in the case of comprehensive specifications (2) the determination of the most suitable structure of reusable requirements.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227055,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227055,Natural language specification;text mining;machine learning;Object System Models,Unified modeling language;Natural languages;Analytical models;Object recognition;Object oriented modeling;Containers,,5,1,13,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Fonte: Finding Bug Inducing Commits from Failures,G. An; J. Hong; N. Kim; S. Yoo,"School of Computing, KAIST, Daejeon, Republic of Korea; SAP Labs Korea, Seoul, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,589,601,"A Bug Inducing Commit (BIC) is a commit that introduces a software bug into the codebase. Knowing the relevant BIC for a given bug can provide valuable information for debugging as well as bug triaging. However, existing BIC identification techniques are either too expensive (because they require the failing tests to be executed against previous versions for bisection) or inapplicable at the debugging time (because they require post hoc artefacts such as bug reports or bug fixes). We propose Fonte, an efficient and accurate BIC identification technique that only requires test coverage. Fonte combines Fault Localisation (FL) with BIC identification and ranks commits based on the suspiciousness of the code elements that they modified. Fonte reduces the search space of BICs using failure coverage as well as a filter that detects commits that are merely style changes. Our empirical evaluation using 130 real-world BICs shows that Fonte significantly outperforms state-of-the-art BIC identification techniques based on Information Retrieval as well as neural code embedding models, achieving at least 39% higher MRR. We also report that the ranking scores produced by Fonte can be used to perform weighted bisection, further reducing the cost of BIC identification. Finally, we apply Fonte to a large-scale industry project with over 10M lines of code, and show that it can rank the actual BIC within the top five commits for 87% of the studied real batch-testing failures, and save the BIC inspection cost by 32% on average.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00059,National Research Foundation of Korea (NRF)(grant numbers:NRF-2020R1A2C1013629); Institute for Information & communications Technology Promotion; Samsung Electronics(grant numbers:10201210-07969-01); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172540,Bug Inducing Commit;Fault Localisation;Git;Weighted Bisection;Batch Testing,Industries;Costs;Codes;Computer bugs;Debugging;Syntactics;Software,,,,42,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
DeepArc: Modularizing Neural Networks for the Model Maintenance,X. Ren; Y. Lin; Y. Xue; R. Liu; J. Sun; Z. Feng; J. S. Dong,"University of Science and Technology of China, China; Shanghai Jiao Tong University, China; University of Science and Technology of China, China; National University of Singapore, Singapore; Singapore Management University, Singapore; Tianjin University, China; National University of Singapore, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1008,1019,"Neural networks are an emerging data-driven programming paradigm widely used in many areas. Unlike traditional software systems consisting of decomposable modules, a neural network is usually delivered as a monolithic package, raising challenges for some maintenance tasks such as model restructure and re-adaption. In this work, we propose DeepArc, a novel modularization method for neural networks, to reduce the cost of model maintenance tasks. Specifically, DeepArc decomposes a neural network into several consecutive modules, each of which encapsulates consecutive layers with similar semantics. The network modularization facilitates practical tasks such as refactoring the model to preserve existing features (e.g., model compression) and enhancing the model with new features (e.g., fitting new samples). The modularization and encapsulation allow us to restructure or retrain the model by only pruning and tuning a few localized neurons and layers. Our experiments show that (1) DeepArc can boost the runtime efficiency of the state-of-the-art model compression techniques by 14.8%; (2) compared to the traditional model retraining, DeepArc only needs to train less than 20% of the neurons on average to fit adversarial samples and repair under-performing models, leading to 32.85% faster training performance while achieving similar model prediction performance.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00092,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172675,architecture;modularization;neural networks,Training;Runtime;Neurons;Semantics;Predictive models;Maintenance engineering;Software systems,,3,,46,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Towards Reliable AI: Adequacy Metrics for Ensuring the Quality of System-Level Testing of Autonomous Vehicles,N. Neelofar; A. Aleti,"Monash University, Australia; Monash University, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,816,827,"AI-powered systems have gained widespread popularity in various domains, including Autonomous Vehicles (AVs). However, ensuring their reliability and safety is challenging due to their complex nature. Conventional test adequacy metrics, designed to evaluate the effectiveness of traditional software testing, are often insufficient or impractical for these systems. White-box metrics, which are specifically designed for these systems, leverage neuron coverage information. These coverage metrics necessitate access to the underlying AI model and training data, which may not always be available. Furthermore, the existing adequacy metrics exhibit weak correlations with the ability to detect faults in the generated test suite, creating a gap that we aim to bridge in this study. In this paper, we introduce a set of black-box test adequacy metrics called “Test suite Instance Space Adequacy” (TISA) metrics, which can be used to gauge the effectiveness of a test suite. The TISA metrics offer a way to assess both the diversity and coverage of the test suite and the range of bugs detected during testing. Additionally, we introduce a framework that permits testers to visualise the diversity and coverage of the test suite in a two-dimensional space, facilitating the identification of areas that require improvement. We evaluate the efficacy of the TISA metrics by examining their correlation with the number of bugs detected in system-level simulation testing of AVs. A strong correlation, coupled with the short computation time, indicates their effectiveness and efficiency in estimating the adequacy of testing AVs.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623314,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548794,,Measurement;Software testing;Correlation;Computer bugs;Training data;Software reliability;Safety,,,,87,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Repairing Brain-Computer Interfaces with Fault-Based Data Acquisition,C. Winston; C. Winston; C. N. Winston; C. Winston; C. Winston; R. P. N. Rao; R. Just,"University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1869,1880,"Brain-computer interfaces (BCls) decode recorded neural signals from the brain and/or stimulate the brain with encoded neural sig-nals. BCls span both hardware and software and have a wide range of applications in restorative medicine, from restoring movement through prostheses and robotic limbs to restoring sensation and communication through spellers. BCls also have applications in di-agnostic medicine, e.g., providing clinicians with data for detecting seizures, sleep patterns, or emotions. Despite their promise, BCls have not yet been adopted for long-term, day-to-day use because of challenges related to reliability and robustness, which are needed for safe operation in all scenarios. Ensuring safe operation currently requires hours of manual data collection and recalibration, involving both patients and clinicians. However, data collection is not targeted at eliminating specific faults in a BCI. This paper presents a new methodology for char-acterizing, detecting, and localizing faults in BCls. Specifically, it proposes partial test oracles as a method for detecting faults and slice functions as a method for localizing faults to characteristic patterns in the input data or relevant tasks performed by the user. Through targeted data acquisition and retraining, the proposed methodology improves the correctness of BCls. We evaluated the proposed methodology on five BCl applications. The results show that the proposed methodology (1) precisely localizes faults and (2) can significantly reduce the frequency of faults through retraining based on targeted, fault-based data acquisition. These results sug-gest that the proposed methodology is a promising step towards repairing faulty BCls.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3512764,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793968,Brain-computer interface;neural decoding;partial test oracles;fault localization,Software testing;Location awareness;Data acquisition;Data collection;Robot sensing systems;Brain-computer interfaces;Software,,,,37,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Comprehensive Semantic Repair of Obsolete GUI Test Scripts for Mobile Applications,S. Cao; M. Pan; Y. Pei; W. Yang; T. Zhang; L. Wang; X. Li,"State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1096,1108,"Graphical User Interface (GUI) testing is one of the primary approaches for testing mobile apps. Test scripts serve as the main carrier of GUI testing, yet they are prone to obsolescence when the GUIs change with the apps' evolution. Existing repair approaches based on GUI layouts or images prove effective when the GUI changes between the base and updated versions are minor, however, they may struggle with substantial changes. In this paper, a novel approach named COSER is introduced as a solution to re-pairing broken scripts, which is capable of addressing larger GUI changes compared to existing methods. COSER incorporates both external semantic information from the GUI elements and internal semantic information from the source code to provide a unique and comprehensive solution. The efficacy of COSER was demonstrated through experiments conducted on 20 Android apps, resulting in superior performance when compared to the state-of-the-art tools METER and GUIDER. In addition, a tool that implements the COSER approach is available for practical use and future research.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639108,"National Natural Science Foundation of China(grant numbers:62372227,62232014,62032010); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549582,GUI test script repair;Android testing;regression testing,Meters;Source coding;Semantics;Layout;Maintenance engineering;Aging;Mobile applications,,,,39,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Improving Fault Localization and Program Repair with Deep Semantic Features and Transferred Knowledge,X. Meng; X. Wang; H. Zhang; H. Sun; X. Liu,"SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; The University of Newcastle, NSW, Australia; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1169,1180,"Automatic software debugging mainly includes two tasks of fault lo-calization and automated program repair. Compared with the traditional spectrum-based and mutation-based methods, deep learning-based methods are proposed to achieve better performance for fault localization. However, the existing methods ignore the deep seman-tic features or only consider simple code representations. They do not leverage the existing bug-related knowledge from large-scale open-source projects either. In addition, existing template-based program repair techniques can incorporate project specific information better than deep-learning approaches. However, they are weak in selecting the fix templates for efficient program repair. In this work, we propose a novel approach called TRANSFER, which lever-ages the deep semantic features and transferred knowledge from open-source data to improve fault localization and program repair. First, we build two large-scale open-source bug datasets and design 11 BiLSTM-based binary classifiers and a BiLSTM-based multi-classifier to learn deep semantic features of statements for fault localization and program repair, respectively. Second, we combine semantic-based, spectrum-based and mutation-based features and use an MLP-based model for fault localization. Third, the semantic-based features are leveraged to rank the fix templates for program repair. Our extensive experiments on widely-used benchmark De-fects4J show that TRANSFER outperforms all baselines in fault localization, and is better than existing deep-learning methods in automated program repair. Compared with the typical template-based work TBar, TRANSFER can correctly repair 6 more bugs (47 in total) on Defects4J.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510147,"National Key Research and Development Program of China(grant numbers:2018YFB1306000); National Natural Science Foundation of China(grant numbers:62072017,62141209); Australian Research Council Discovery Projects(grant numbers:DP200102940,DP220103044); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794014,Fault localization;program repair;transfer learning;neural networks;software debugging,Location awareness;Codes;Semantics;Computer bugs;Maintenance engineering;Feature extraction;Software debugging,,14,,67,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Robustification of Behavioral Designs against Environmental Deviations,C. Zhang; T. Saluja; R. Meira-Góes; M. Bolton; D. Garlan; E. Kang,"Carnegie Mellon University, Pittsburgh, PA, USA; Swarthmore College, Swarthmore, PA, USA; The Pennsylvania State University, State College, PA, USA; University of Virginia, Charlottesville, VA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,423,434,"Modern software systems are deployed in a highly dynamic, uncertain environment. Ideally, a system that is robust should be capable of establishing its most critical requirements even in the presence of possible deviations in the environment. We propose a technique called behavioral robustification, which involves systematically and rigorously improving the robustness of a design against potential deviations. Given behavioral models of a system and its environment, along with a set of user-specified deviations, our robustification method produces a redesign that is capable of satisfying a desired property even when the environment exhibits those deviations. In particular, we describe how the robustification problem can be formulated as a multi-objective optimization problem, where the goal is to restrict the deviating environment from causing a violation of a desired property, while maximizing the amount of existing functionality and minimizing the cost of changes to the original design. We demonstrate the effectiveness of our approach on case studies involving the robustness of an electronic voting machine and safety-critical interfaces.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00046,National Science Foundation(grant numbers:CCF-2144860); NSA(grant numbers:H9823018D0008); Office of Naval Research(grant numbers:N00014172899); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172695,robustness;robustification;labeled transition systems,Costs;Software systems;Robustness;Behavioral sciences;Electronic voting;Optimization;Software engineering,,6,,48,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively Tuning Pre-Trained Code Models,S. Gao; W. Mao; C. Gao; L. Li; X. Hu; X. Xia; M. R. Lyu,"The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Beihang university, Beijing, China; Zhejiang university, Zhejiang, China; Zhejiang university, Zhejiang, China; The Chinese University of Hong Kong, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,969,981,"Pre-trained code models have recently achieved substantial improvements in many code intelligence tasks. These models are first pre-trained on large-scale unlabeled datasets in a task-agnostic manner using self-supervised learning, and then fine-tuned on labeled datasets in downstream tasks. However, the labeled datasets are usually limited in size (i.e., human intensive efforts), which may hinder the performance of pre-trained code models in specific tasks. To mitigate this, one possible solution is to leverage the large-scale unlabeled data in the tuning stage by pseudo-labeling, i.e., generating pseudo labels for unlabeled data and further training the pre-trained code models with the pseudo-labeled data. However, directly employing the pseudo-labeled data can bring a large amount of noise, i.e., incorrect labels, leading to suboptimal performance. How to effectively leverage the noisy pseudo-labeled data is a challenging yet under-explored problem. In this paper, we propose a novel approach named HINT to improve pre-trained code models with large-scale unlabeled datasets by better utilizing the pseudo-labeled data. HINT includes two main modules: HybrId pseudo-labeled data selection and Noise-tolerant Training. In the hybrid pseudo-data selection module, considering the robustness issue, apart from directly measuring the quality of pseudo labels through training loss, we propose to further employ a retrieval-based method to filter low-quality pseudo-labeled data. The noise-tolerant training module aims to further mitigate the influence of errors in pseudo labels by training the model with a noise-tolerant loss function and by regularizing the consistency of model predictions. We evaluate the effectiveness of HINT on three popular code intelligence tasks, including code summarization, defect detection, and assertion generation. We build our method on top of three popular open-source pre-trained code models. The experimental results show that HINT can better leverage those unlabeled data in a task-specific way and provide complementary benefits for pre-trained models, e.g., improving the best baseline model by 15.33%, 16.50%, and 8.98% on code summarization, defect detection, and assertion generation, respectively.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639216,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549593,Software and its engineering → Software development techniques,Training;Codes;Source coding;Predictive models;Data models;Task analysis;Tuning,,,,74,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Leveraging test generation and specification mining for automated bug detection without false positives,M. Pradel; T. R. Gross,"Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,288,298,"Mining specifications and using them for bug detection is a promising way to reveal bugs in programs. Existing approaches suffer from two problems. First, dynamic specification miners require input that drives a program to generate common usage patterns. Second, existing approaches report false positives, that is, spurious warnings that mislead developers and reduce the practicability of the approach. We present a novel technique for dynamically mining and checking specifications without relying on existing input to drive a program and without reporting false positives. Our technique leverages automatically generated tests in two ways: Passing tests drive the program during specification mining, and failing test executions are checked against the mined specifications. The output are warnings that show with concrete test cases how the program violates commonly accepted specifications. Our implementation reports no false positives and 54 true positives in ten well-tested Java programs.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227185,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227185,Bug detection;Specification mining;False positives,Protocols;Generators;Computer bugs;Receivers;Concrete;Runtime,,37,1,44,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Out of Context: How Important is Local Context in Neural Program Repair?,J. A. Prenner; R. Robbes,"Free University of Bozen/Bolzano, Bozen/Bolzano, Italy; CNRS, Univ. Bordeaux, Bordeaux INP, LaBRI, Talence, France",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1008,1020,"Deep learning source code models have been applied very successfully to the problem of automated program repair. One of the standing issues is the small input window of current models which often cannot fully fit the context code required for a bug fix (e.g., method or class declarations of a project). Instead, input is often restricted to the local context, that is, the lines below and above the bug location. In this work we study the importance of this local context on repair success: how much local context is needed?; is context before or after the bug location more important? how is local context tied to the bug type? To answer these questions we train and evaluate Transformer models in many different local context configurations on three datasets and two programming languages. Our results indicate that overall repair success increases with the size of the local context (albeit not for all bug types) and confirm the common practice that roughly 50-60% of the input window should be used for context leading the bug. Our results are not only relevant for researchers working on Transformer-based APR tools but also for benchmark and dataset creators who must decide what and how much context to include in their datasets.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639086,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549171,automated program repair;data-driven software engineering,Training;Deep learning;Computer languages;Source coding;Computer bugs;Maintenance engineering;Transformers,,,,49,,14 Jun 2024,,,IEEE,IEEE Conferences,True
BugRedux: Reproducing field failures for in-house debugging,W. Jin; A. Orso,"Georgia Institute of Technology, USA; Georgia Institute of Technology, USA",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,474,484,"A recent survey conducted among developers of the Apache, Eclipse, and Mozilla projects showed that the ability to recreate field failures is considered of fundamental importance when investigating bug reports. Unfortunately, the information typically contained in a bug report, such as memory dumps or call stacks, is usually insufficient for recreating the problem. Even more advanced approaches for gathering field data and help in-house debugging tend to collect either too little information, and be ineffective, or too much information, and be inefficient. To address these issues, we present BugRedux, a novel general approach for in-house debugging of field failures. BugRedux aims to synthesize, using execution data collected in the field, executions that mimic the observed field failures. We define several instances of BugRedux that collect different types of execution data and perform, through an empirical study, a cost-benefit analysis of the approach and its variations. In the study, we apply BugRedux to 16 failures of 14 real-world programs. Our results are promising in that they show that it is possible to synthesize in-house executions that reproduce failures observed in the field using a suitable set of execution data.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227168,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227168,,Computer crashes;Software;Instruments;Debugging;Optical fibers;MIMICs;Generators,,116,,42,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Detecting Dialog-Related Keyboard Navigation Failures in Web Applications,P. T. Chiou; A. S. Alotaibi; W. G. J. Halfond,"University of Southern California, USA; University of Southern California, USA; University of Southern California, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1368,1380,"The ability to navigate the Web via the keyboard interface is critical to people with various types of disabilities. However, modern websites often violate web accessibility guidelines for keyboard navigability with respect to web dialogs. In this paper, we present a novel approach for automatically detecting web accessibility bugs that prevent or hinder keyboard users' ability to navigate dialogs in web pages. An extensive evaluation of our technique on real-world subjects showed that our technique is effective in detecting these dialog-related keyboard navigation failures.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00120,National Science Foundation(grant numbers:2009045); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172835,Web Accessibility;WCAG;Software Testing;Keyboard Navigation;Dialog;Keyboard Accessibility;Web Dialog;Accessible Dialog;Dialog Accessibility,Navigation;Computer bugs;Keyboards;Web pages;Debugging;Software engineering;Guidelines,,1,,74,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Toward Improved Deep Learning-Based Vulnerability Detection,A. Sejfia; S. Das; S. Shafiq; N. Medvidović,"University of Southern California, California, USA; University of Southern California, California, USA; Johannes Kepler University, Austria; University of Southern California, California, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,741,752,"Deep learning (DL) has been a common thread across several recent techniques for vulnerability detection. The rise of large, publicly available datasets of vulnerabilities has fueled the learning process underpinning these techniques. While these datasets help the DL-based vulnerability detectors, they also constrain these detectors' predictive abilities. Vulnerabilities in these datasets have to be represented in a certain way, e.g., code lines, functions, or pro-gram slices within which the vulnerabilities exist. We refer to this representation as a base unit. The detectors learn how base units can be vulnerable and then predict whether other base units are vulnerable. We have hypothesized that this focus on individual base units harms the ability of the detectors to properly detect those vul-nerabilities that span multiple base units (or MBU vulnerabilities). For vulnerabilities such as these, a correct detection occurs when all comprising base units are detected as vulnerable. Verifying how existing techniques perform in detecting all parts of a vulnerability is important to establish their effectiveness for other downstream tasks. To evaluate our hypothesis, we conducted a study focusing on three prominent DL-based detectors: ReVeal, DeepWukong, and LineVul. Our study shows that all three detectors contain MBU vulnerabilities in their respective datasets. Further, we observed significant accuracy drops when detecting these types of vulner-abilities. We present our study and a framework that can be used to help DL-based detectors toward the proper inclusion of MBU vulnerabilities.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608141,National Science Foundation(grant numbers:182335); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549730,vulnerability detection;deep learning;software vulnerabilities;vulnerability dataets,Deep learning;Codes;Accuracy;Focusing;Detectors;Task analysis;Software engineering,,,,43,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Automated analysis of CSS rules to support style maintenance,A. Mesbah; S. Mirshokraie,"University of British Columbia, Canada; University of British Columbia, Canada",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,408,418,"CSS is a widely used language for describing the presentation semantics of HTML elements on the web. The language has a number of characteristics, such as inheritance and cascading order, which makes maintaining CSS code a challenging task for web developers. As a result, it is common for unused rules to be accumulated over time. Despite these challenges, CSS analysis has not received much attention from the research community. We propose an automated technique to support styling code maintenance, which (1) analyzes the runtime relationship between the CSS rules and DOM elements of a given web application (2) detects unmatched and ineffective selectors, overridden declaration properties, and undefined class values. Our technique, implemented in an open source tool called Cilla, has a high precision and recall rate. The results of our case study, conducted on fifteen open source and industrial web-based systems, show an average of 60% unused CSS selectors in deployed applications, which points to the ubiquity of the problem.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227174,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227174,Cascading style sheets;CSS;dynamic analysis;software maintenance;web applications,Cascading style sheets;Color;HTML;Maintenance engineering;Runtime;Layout;Browsers,,23,5,37,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Repairing Order-Dependent Flaky Tests via Test Generation,C. Li; C. Zhu; W. Wang; A. Shi,"The University of Texas at Austin, Austin, TX, USA; The University of Texas at Austin, Austin, TX, USA; The University of Texas at Austin, Austin, TX, USA; The University of Texas at Austin, Austin, TX, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1881,1892,"Flaky tests are tests that pass or fail nondeterministically on the same version of code. These tests can mislead developers concerning the quality of their code changes during regression testing. A common kind of flaky tests are order-dependent tests, whose pass/ fail outcomes depend on the test order in which they are run. Such tests have different outcomes because other tests running before them pollute shared state. Prior work has proposed repairing order-dependent tests by searching for existing tests, known as “cleaners”, that reset the shared state, allowing the order-dependent test to pass when run after a polluted shared state. The code within a cleaner represents a patch to repair the order-dependent test. However, this technique requires cleaners to already exist in the test suite. We propose ODRepair, an automated technique to repair order-dependent tests even without existing cleaners. The idea is to first determine the exact polluted shared state that results in the order-dependent test to fail and then generate code that can modify and reset the shared state so that the order-dependent test can pass. We focus on shared state through internal heap memory, in particular shared state reachable from static fields. Once we know which static field leads to the pollution, we search for reset-methods in the code-base that can potentially access and modify state reachable from that static field. We then apply an automatic test-generation tool to generate method-call sequences, targeting these reset-methods. Our evaluation on 327 order-dependent tests from a publicly available dataset shows that ODRepair automatically identifies the polluted static field for 181 tests, and it can generate patches for 141 of these tests. Compared against state-of-the-art iFixFlakies, ODRepair can generate patches for 24 tests that iFixFlakies cannot.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510173,NSF(grant numbers:CCF-1718903); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793979,flaky test;order-dependent test;test generation;automated repair,Codes;Pollution;Maintenance engineering;Test pattern generators;Testing;Software engineering,,9,,49,,20 Jun 2022,,,IEEE,IEEE Conferences,True
"Automated Program Repair, What Is It Good For? Not Absolutely Nothing!",H. Eladawy; C. L. Goues; Y. Brun,"University of Massachusetts, Amherst, MA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; University of Massachusetts, Amherst, MA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1021,1033,"Industrial deployments of automated program repair (APR), e.g., at Facebook and Bloomberg, signal a new milestone for this exciting and potentially impactful technology. In these deployments, developers use APR-generated patch suggestions as part of a human-driven debugging process. Unfortunately, little is known about how using patch suggestions affects developers during debugging. This paper conducts a controlled user study with 40 developers with a median of 6 years of experience. The developers engage in debugging tasks on nine naturally-occurring defects in real-world, open-source, Java projects, using Recoder, SimFix, and TBar, three state-of-the-art APR tools. For each debugging task, the developers either have access to the project's tests, or, also, to code suggestions that make all the tests pass. These suggestions are either developer-written or APR-generated, which can be correct or deceptive. De-ceptive suggestions, which are a common APR occurrence, make all the available tests pass but fail to generalize to the intended specification. Through a total of 160 debugging sessions, we find that access to a code suggestion significantly increases the odds of submitting a patch. Access to correct APR suggestions increase the odds of debugging success by 14,000% as compared to having access only to tests, but access to deceptive suggestions decrease the odds of success by 65%. Correct suggestions also speed up de-bugging. Surprisingly, we observe no significant difference in how novice and experienced developers are affected by APR, suggesting that APR may find uses across the experience spectrum. Overall, developers come away with a strong positive impression of APR, suggesting promise for APR-mediated, human-driven debugging, despite existing challenges in APR-generated repair quality.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639095,"National Science Foundation(grant numbers:CCF-1750116,CCF-2210243); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548723,automated program repair;debugging;human factors;user study,Java;Codes;Social networking (online);Debugging;Maintenance engineering;Task analysis;Software engineering,,,,98,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
A systematic study of automated program repair: Fixing 55 out of 105 bugs for $8 each,C. Le Goues; M. Dewey-Vogt; S. Forrest; W. Weimer,"Computer Science Department, University of Virginia, Charlottesville, VA, USA; Computer Science Department, University of Virginia, Charlottesville, VA, USA; Computer Science Department, University of New Mexico, Albuquerque, NM, USA; Computer Science Department, University of Virginia, Charlottesville, VA, USA",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,3,13,"There are more bugs in real-world programs than human programmers can realistically address. This paper evaluates two research questions: “What fraction of bugs can be repaired automatically?” and “How much does it cost to repair a bug automatically?” In previous work, we presented GenProg, which uses genetic programming to repair defects in off-the-shelf C programs. To answer these questions, we: (1) propose novel algorithmic improvements to GenProg that allow it to scale to large programs and find repairs 68% more often, (2) exploit GenProg's inherent parallelism using cloud computing resources to provide grounded, human-competitive cost measurements, and (3) generate a large, indicative benchmark set to use for systematic evaluations. We evaluate GenProg on 105 defects from 8 open-source programs totaling 5.1 million lines of code and involving 10,193 test cases. GenProg automatically repairs 55 of those 105 defects. To our knowledge, this evaluation is the largest available of its kind, and is often two orders of magnitude larger than previous work in terms of code or test suite size or defect count. Public cloud computing prices allow our 105 runs to be reproduced for $403; a successful repair completes in 96 minutes and costs $7.32, on average.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227211,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227211,genetic programming;automated program repair;cloud computing,Maintenance engineering;Computer bugs;Cloud computing;Benchmark testing;Systematics;Open source software;Genetic programming,,311,5,38,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Privacy and utility for defect prediction: Experiments with MORPH,F. Peters; T. Menzies,"Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,189,199,"Ideally, we can learn lessons from software projects across multiple organizations. However, a major impediment to such knowledge sharing are the privacy concerns of software development organizations. This paper aims to provide defect data-set owners with an effective means of privatizing their data prior to release. We explore MORPH which understands how to maintain class boundaries in a data-set. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. The value of training on this MORPHed data is tested via a 10-way within learning study and a cross learning study using Random Forests, Naive Bayes, and Logistic Regression for ten object-oriented defect datasets from the PROMISE data repository. Measured in terms of exposure of sensitive attributes, the MORPHed data was four times more private than the unMORPHed data. Also, in terms of the f-measures, there was little difference between the MORPHed and unMORPHed data (original data and data privatized by data-swapping) for both the cross and within study. We conclude that at least for the kinds of OO defect data studied in this project, data can be privatized without concerns for inference efficacy.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227194,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227194,privacy;defect prediction;data mining,Privacy;Data privacy;Companies;Software;Predictive models;Privatization,,51,,34,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
AI-based Question Answering Assistance for Analyzing Natural-language Requirements,S. Ezzini; S. Abualhaija; C. Arora; M. Sabetzadeh,"SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Deakin University, Geelong, Australia; School of Electrical Engineering and Computer Science, University of Ottawa, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1277,1289,"By virtue of being prevalently written in natural language (NL), requirements are prone to various defects, e.g., inconsistency and incompleteness. As such, requirements are frequently subject to quality assurance processes. These processes, when carried out entirely manually, are tedious and may further overlook important quality issues due to time and budget pressures. In this paper, we propose QAssist - a question-answering (QA) approach that provides automated assistance to stakeholders, including requirements engineers, during the analysis of NL requirements. Posing a question and getting an instant answer is beneficial in various quality-assurance scenarios, e.g., incompleteness detection. Answering requirements-related questions automatically is challenging since the scope of the search for answers can go beyond the given requirements specification. To that end, QAssist provides support for mining external domain-knowledge resources. Our work is one of the first initiatives to bring together QA and external domain knowledge for addressing requirements engineering challenges. We evaluate QAssist on a dataset covering three application domains and containing a total of 387 question-answer pairs. We experiment with state-of-the-art QA methods, based primarily on recent large-scale language models. In our empirical study, QAssist localizes the answer to a question to three passages within the requirements specification and within the external domain-knowledge resource with an average recall of 90.1% and 96.5%, respectively. QAssist extracts the actual answer to the posed question with an average accuracy of 84.2%.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00113,NSERC of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172663,Natural-language Requirements;Question Answering (QA);Language Models;Natural Language Processing (NLP);Natural Language Generation (NLG);BERT;T5,Knowledge engineering;Quality assurance;Terminology;Natural languages;Question answering (information retrieval);Internet;Stakeholders,,8,,87,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot,A. Mastropaolo; L. Pascarella; E. Guglielmi; M. Ciniselli; S. Scalabrino; R. Oliveto; G. Bavota,"SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland; SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland; STAKE Lab, University of Molise, Italy; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2149,2160,"Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in ∼46% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code (±28%).",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00181,European Research Council (ERC)(grant numbers:851720); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172792,Empirical Study;Recommender Systems,Deep learning;Java;Codes;Natural languages;Robustness;Generators;Encoding,,28,,67,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Using Pre-Trained Models to Boost Code Review Automation,R. Tufano; S. Masiero; A. Mastropaolo; L. Pascarella; D. Poshyvanyk; G. Bavota,"SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEMERU @ Computer Science Department, William and Mary, USA; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2291,2302,"Code review is a practice widely adopted in open source and industrial projects. Given the non-negligible cost of such a process, researchers started investigating the possibility of automating specific code review tasks. We recently proposed Deep Learning (DL) models targeting the automation of two tasks: the first model takes as input a code submitted for review and implements in it changes likely to be recommended by a reviewer; the second takes as input the submitted code and a reviewer comment posted in natural language and automatically implements the change required by the reviewer. While the preliminary results we achieved are encouraging, both models had been tested in rather simple code review scenarios, substantially simplifying the targeted problem. This was also due to the choices we made when designing both the technique and the experiments. In this paper, we build on top of that work by demonstrating that a pre-trained Text-To-Text Transfer Transformer (T5) model can outperform previous DL models for automating code review tasks. Also, we conducted our experiments on a larger and more realistic (and challenging) dataset of code review activities.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510621,"European Research Council(grant numbers:851720); NSF(grant numbers:CCF-1955853,CCF-2007246); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794027,Code Review;Empirical Study;Machine Learning on Code,Deep learning;Codes;Automation;Costs;Natural languages;Transformers;Task analysis,,36,,51,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Deeply Reinforcing Android GUI Testing with Deep Reinforcement Learning,Y. Lan; Y. Lu; Z. Li; M. Pan; W. Yang; T. Zhang; X. Li,"State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aero-nautics and Astronautics, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,854,866,"As the scale and complexity of Android applications continue to grow in response to increasing market and user demands, quality assurance challenges become more significant. While previous studies have demonstrated the superiority of Reinforcement Learning (RL) in Android GUI testing, its effectiveness remains limited, particularly in large, complex apps. This limitation arises from the ineffectiveness of Tabular RL in learning the knowledge within the large state-action space of the App Under Test (AUT) and from the suboptimal utilization of the acquired knowledge when em-ploying more advanced RL techniques. To address such limitations, this paper presents DQT, a novel automated Android GUI testing approach based on deep reinforcement learning. DQT preserves widgets' structural and semantic information with graph embedding techniques, building a robust foundation for identifying similar states or actions and distinguishing different ones. Moreover, a specially designed Deep Q-Network (DQN) effectively guides curiosity-driven exploration by learning testing knowledge from runtime interactions with the AUT and sharing it across states or actions. Experiments conducted on 30 diverse open-source apps demonstrate that DQT outperforms existing state-of-the-art testing approaches in both code coverage and fault detection, particularly for large, complex apps. The faults detected by DQT have been reproduced and reported to developers; so far, 21 of the reported issues have been explicitly confirmed, and 14 have been fixed.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623344,"National Natural Science Foundation of China(grant numbers:62032010,62232014,61972193); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549457,Android testing;deep reinforcement learning;graph embedding,Runtime;Quality assurance;Codes;Fault detection;Semantics;Buildings;Deep reinforcement learning,,,,77,,14 Jun 2024,,,IEEE,IEEE Conferences,True
DocFlow: Extracting Taint Specifications from Software Documentation,M. Tileria; J. Blasco; S. K. Dash,"Royal Holloway, University of London, United Kingdom; Universidad Politécnica de Madrid, Spain; Royal Holloway, University of London, United Kingdom",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,729,740,"Security practitioners routinely use static analysis to detect security problems and privacy violations in Android apps. The soundness of these analyses depends on how the platform is modelled and the list of sensitive methods. Collecting these methods often becomes impractical given the number of methods available, the pace at which the Android platform is updated, and the proprietary libraries Google releases on each new version. Despite the constant evolution of the Android platform, app developers cope with all these new features thanks to the documentation that comes with each new Android release. In this work, we take advantage of the rich documentation provided by platforms like Android and propose DocFlow, a framework to generate taint specifications for a platform, directly from its documentation. DocFlow models the semantics of API methods using their documentation to detect sensitive methods (sources and sinks) and assigns them semantic labels. Our approach does not require access to source code, enabling the analysis of proprietary libraries for which the code is unavailable. We evaluate DocFlow using Android platform packages and closed-source Google Play Services libraries. Our results show that our framework detects sensitive methods with high precision, adapts to new API versions, and can be easily extended to detect other method types. Our approach provides evidence that Android documentation encodes rich semantic information to categorise sensitive methods, removing the need to analyse source code or perform feature extraction.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623312,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549190,Taint analysis;Documentation;Android;Natural Language Processing,Privacy;Codes;Operating systems;Source coding;Semantics;Documentation;Static analysis,,,,63,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Vere: Verification Guided Synthesis for Repairing Deep Neural Networks,J. Ma; P. Yang; J. Wang; Y. Sun; C. -C. Huang; Z. Wang,"Hangzhou Dianzi University, Zhejiang University, Hangzhou, China; SKLCS, Institute of Software, CAS, Beijing, China; ZJU-Hangzhou Global Scientific and Technological Innovation Center, Zhejiang University, Hangzhou, China; University of Manchester, Manchester, United Kingdom; Nanjing Institute of Software Technology, ISCAS, Nanjing, China; Hangzhou Dianzi University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,64,76,"Neural network repair aims to fix the ‘bugs'11We use 'bugs' to denote different kinds of inputs that could trigger an error in the model's output. of neural networks by modifying the model's architecture or parameters. However, due to the data-driven nature of neural networks, it is difficult to explain the relationship between the internal neurons and erro-neous behaviors, making further repair challenging. While several work exists to identify responsible neurons based on gradient or causality analysis, their effectiveness heavily rely on the quality of available ‘bugged’ data and multiple heuristics in layer or neuron selection. In this work, we address the issue utilizing the power of formal verification (in particular for neural networks). Specifically, we propose Vere, a verification-guided neural network repair framework that performs fault localization based on linear relax-ation to symbolically calculate the repair significance of neurons and furthermore optimize the parameters of problematic neurons to repair erroneous behaviors. We evaluated Vere on various repair tasks, and our experimental results show that Vere can efficiently and effectively repair all neural networks without degrading the model's performance. For the task of removing backdoors, Vere successfully reduces attack success rate from 98.47% to 0.38% on average, while causing an average performance drop of 0.9%. For the task of repairing safety properties, Vere successfully repairs all the 36 tasks and achieves 99.87% generalization on average.",1558-1225,979-8-4007-0217-4,,"National Natural Science Foundation of China(grant numbers:62102359,62176080); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548054,DNN Repair;Verification Guided Synthesis;Fault Localization,Location awareness;Neurons;Artificial neural networks;Maintenance engineering;Safety;Task analysis;Biological neural networks,,,,89,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Raisin: Identifying Rare Sensitive Functions for Bug Detection,J. Huang; J. Nie; Y. Gong; W. You; B. Liang; P. Bian,"School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; Huawei Technologies CO., LTD., Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2159,2170,"Mastering the knowledge about the bug-prone functions (i.e., sensitive functions) is important to detect bugs. Some automated techniques have been proposed to identify the sensitive functions in large software systems, based on machine learning or natural Ian- guage processing. However, the existing statistics-based techniques are not directly applicable to a special kind of sensitive functions, i.e., the rare sensitive functions, which have very few invocations even in large systems. Unfortunately, the rare ones can also introduce bugs. Therefore, how to effectively identify such functions is a problem deserving attention. This study is the first to explore the identification of rare sensitive functions. We propose a context-based analogical reasoning technique to automatically infer rare sensitive functions. A 1+context scheme is devised, where a function and its context are embedded into a pair of vectors, enabling pairwise analogical reasoning. Con-sidering that the rarity of the functions may lead to low-quality embedding vectors, we propose a weighted subword embedding method that can highlight the semantics of the key subwords to facilitate effective embedding. In addition, frequent sensitive functions are utilized to filter out reasoning candidates. We implement a prototype called Raisin and apply it to identify the rare sensitive functions and detect bugs in large open-source code bases. We successfully discover thousands of previously unknown rare sensitive functions and detect 21 bugs confirmed by the developers. Some of the rare sensitive functions cause bugs even with a solitary in-vocation in the kernel. It is demonstrated that identifying them is necessary to enhance software reliability.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639165,"National Natural Science Foundation of China (NSFC)(grant numbers:62272465,62002361,U1836209); Fundamental Research Funds for the Central Universities(grant numbers:22XNKJ29); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548513,Rare sensitive function;Bug detection;Analogical reasoning;Em-bedding,Codes;Computer bugs;Semantics;Prototypes;Machine learning;Software systems;Cognition,,,,47,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Natural Attack for Pre-trained Models of Code,Z. Yang; J. Shi; J. He; D. Lo,"School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1482,1493,"Pre-trained models of code have achieved success in many important software engineering tasks. However, these powerful models are vulnerable to adversarial attacks that slightly perturb model inputs to make a victim model produce wrong outputs. Current works mainly attack models of code with examples that preserve operational program semantics but ignore a fundamental requirement for adversarial example generation: perturbations should be natural to human judges, which we refer to as naturalness requirement. In this paper, we propose ALERT (Naturalness Aware Attack), a black-box attack that adversarially transforms inputs to make victim models produce wrong outputs. Different from prior works, this paper considers the natural semantic of generated examples at the same time as preserving the operational semantic of original inputs. Our user study demonstrates that human developers consistently consider that adversarial examples generated by ALERT are more natural than those generated by the state-of-the-art work by Zhang et al. that ignores the naturalness requirement. On attacking CodeBERT, our approach can achieve attack success rates of 53.62%, 27.79%, and 35.78% across three downstream tasks: vulnerability prediction, clone detection and code authorship attribution. On GraphCodeBERT, our approach can achieve average success rates of 76.95%, 7.96% and 61.47% on the three tasks. The above outperforms the baseline by 14.07% and 18.56% on the two pretrained models on average. Finally, we investigated the value of the generated adversarial examples to harden victim models through an adversarial fine-tuning procedure and demonstrated the accuracy of CodeBERT and GraphCodeBERT against ALERT-generated adversarial examples increased by 87.59% and 92.32%, respectively.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510146,Singapore Ministry of Education (MOE); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794089,Genetic Algorithm;Adversarial Attack;Pre-Trained Models,Codes;Perturbation methods;Semantics;Cloning;Transforms;Task analysis;Software engineering,,31,,55,,20 Jun 2022,,,IEEE,IEEE Conferences,True
CCRep: Learning Code Change Representations via Pre-Trained Code Model and Query Back,Z. Liu; Z. Tang; X. Xia; X. Yang,"Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,17,29,"Representing code changes as numeric feature vectors, i.e., code change representations, is usually an essential step to automate many software engineering tasks related to code changes, e.g., commit message generation and just-in-time defect prediction. Intuitively, the quality of code change representations is crucial for the effectiveness of automated approaches. Prior work on code changes usually designs and evaluates code change representation approaches for a specific task, and little work has investigated code change encoders that can be used and jointly trained on various tasks. To fill this gap, this work proposes a novel Code Change Representation learning approach named CCRep, which can learn to encode code changes as feature vectors for diverse downstream tasks. Specifically, CCRep regards a code change as the combination of its before-change and after-change code, leverages a pre-trained code model to obtain high-quality contextual embeddings of code, and uses a novel mechanism named query back to extract and encode the changed code fragments and make them explicitly interact with the whole code change. To evaluate CCRep and demonstrate its applicability to diverse code-change-related tasks, we apply it to three tasks: commit message generation, patch correctness assessment, and just-in-time defect prediction. Experimental results show that CCRep outperforms the state-of-the-art techniques on each task.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00014,National Natural Science Foundation of China(grant numbers:62202420); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172503,code change;representation learning;commit message generation;patch correctness assessment;just-in-time defect prediction,Representation learning;Adaptation models;Codes;Feature extraction;Task analysis;Software engineering;Context modeling,,8,,70,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Constructing parser for industrial software specifications containing formal and natural language description,F. Iwama; T. Nakamura; H. Takeuchi,"IBM Research-Tokyo, IBM Japan Limited, Yamato, Kanagawa, Japan; IBM Research-Tokyo, IBM Japan Limited, Yamato, Kanagawa, Japan; IBM Research-Tokyo, IBM Japan Limited, Yamato, Kanagawa, Japan",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1012,1021,"This paper describes a novel framework for creating a parser to process and analyze texts written in a “partially structured” natural language. In many projects, the contents of document artifacts tend to be described as a mixture of formal parts (i.e. the text constructs follow specific conventions) and parts written in arbitrary free text. Formal parsers, typically defined and used to process a description with rigidly defined syntax such as program source code are very precise and efficient in processing the formal part, while parsers developed for natural language processing (NLP) are good at robustly interpreting the free-text part. Therefore, combining these parsers with different characteristics can allow for more flexible and practical processing of various project documents. Unfortunately, conventional approaches to constructing a parser from multiple small parsers were studied extensively only for formal language parsers and are not directly applicable to NLP parsers due to the differences in the way the input text is extracted and evaluated. We propose a method to configure and generate a combined parser by extending an approach based on parser combinator, the operators for composing multiple formal parsers, to support both NLP and formal parsers. The resulting text parser is based on Parsing Expression Grammars, and it benefits from the strength of both parser types. We demonstrate an application of such combined parser in practical situations and show that the proposed approach can efficiently construct a parser for analyzing project-specific industrial specification documents.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227119,Document Analysis;Parser Combinator;Parsing Expression Grammars;Requirement Engineering,Syntactics;Natural language processing;Formal languages;Grammar;Abstracts;Semantics,,5,,13,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Impact of Code Language Models on Automated Program Repair,N. Jiang; K. Liu; T. Lutellier; L. Tan,"Purdue University, West Lafayette, USA; Lynbrook High School, San Jose, USA; University of Alberta, Alberta, Canada; Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1430,1442,"Automated program repair (APR) aims to help developers improve software reliability by generating patches for buggy programs. Although many code language models (CLM) are developed and effective in many software tasks such as code completion, there has been little comprehensive, in-depth work to evaluate CLMs' fixing capabilities and to fine-tune CLMs for the APR task. Firstly, this work is the first to evaluate ten CLMs on four APR benchmarks, which shows that surprisingly, the best CLM, as is, fixes 72% more bugs than the state-of-the-art deep-learning (DL)-based APR techniques. Secondly, one of the four APR benchmarks was created by us in this paper to avoid data leaking for a fair evaluation. Thirdly, it is the first work to fine-tune CLMs with APR training data, which shows that fine-tuning brings 31%-1,267% improvement to CLMs and enables them to fix 46%-164 % more bugs than existing DL-based APR techniques. Fourthly, this work studies the impact of buggy lines, showing that CLMs, as is, cannot make good use of the buggy lines to fix bugs, yet fine-tuned CLMs could potentially over-rely on buggy lines. Lastly, this work analyzes the size, time, and memory efficiency of different CLMs. This work shows promising directions for the APR domain, such as fine-tuning CLMs with APR-specific designs, and also raises awareness of fair and comprehensive evaluations of CLMs and calls for more transparent reporting of open-source repositories used in the pre-training data to address the data leaking problem.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172517,Automated Program Repair;Code Language Model;Fine-Tuning;Deep Learning,Codes;Computer bugs;Memory management;Training data;Benchmark testing;Maintenance engineering;Software,,43,,62,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing,Z. Ma; A. R. Chen; D. J. Kim; T. -H. P. Chen; S. Wang,"Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Electrical and Computer Engineering Department, University of Alberta, Edmonton, Alberta, Canada; Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Department of Computer Science, University of Manitoba, Winnipeg, Manitoba, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1209,1221,"Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548600,Log parsing;log analysis;large language model,Training;Analytical models;Runtime;Computer architecture;Inference algorithms;Data mining;Task analysis,,1,,76,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Automating Code-Related Tasks Through Transformers: The Impact of Pre-training,R. Tufano; L. Pascarella; G. Bavota,"Software Institute - USI Universita della Svizzera italiana, Switzerland; Software Institute - USI Universita della Svizzera italiana, Switzerland; Software Institute - USI Universita della Svizzera italiana, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2425,2437,"Transformers have gained popularity in the software engineering (SE) literature. These deep learning models are usually pre-trained through a self-supervised objective, meant to provide the model with basic knowledge about a language of interest (e.g., Java). A classic pre-training objective is the masked language model (MLM), in which a percentage of tokens from the input (e.g., a Java method) is masked, with the model in charge of predicting them. Once pre-trained, the model is then fine-tuned to support the specific downstream task of interest (e.g., code summarization). While there is evidence suggesting the boost in performance provided by pre-training, little is known about the impact of the specific pre-training objective(s) used. Indeed, MLM is just one of the possible pre-training objectives and recent work from the natural language processing field suggest that pre-training objectives tailored for the specific downstream task of interest may substantially boost the model's performance. For example, in the case of code summarization, a tailored pre-training objective could be the identification of an appropriate name for a given method, considering the method name to generate as an extreme summary. In this study, we focus on the impact of pre-training objectives on the performance of trans-formers when automating code-related tasks. We start with a systematic literature review aimed at identifying the pre-training objectives used in SE. Then, we pre-train 32 transformers using both (i) generic pre-training objectives usually adopted in SE; and (ii) pre-training objectives tailored to specific code-related tasks subject of our experimentation, namely bug-fixing, code summarization, and code completion. We also compare the pre-trained models with non pre-trained ones and show the advantage brought by pre-training in different scenarios, in which more or less fine-tuning data are available. Our results show that: (i) pre-training helps in boosting performance only if the amount of fine-tuning data available is small; (ii) the MLM objective is usually sufficient to maximize the prediction performance of the model, even when comparing it with pre-training objectives specialized for the downstream task at hand.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00203,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172872,Pre-training;Code Recommenders,Java;Codes;Systematics;Training data;Predictive models;Transformers;Data models,,3,,87,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Constraint Based Program Repair for Persistent Memory Bugs,Z. Huang; C. Wang,"University of Southern California, Los Angeles, USA; University of Southern California, Los Angeles, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1109,1120,"We propose a constraint based method for repairing bugs associated with the use of persistent memory (PM) in application software. Our method takes a program execution trace and the violated property as input and returns a suggested repair, which is a combination of inserting new PM instructions and reordering these instructions to eliminate the property violation. Compared with the state-of-the-art approach, our method has three advantages. First, it can repair both durability and crash consistency bugs whereas the state-of-the-art approach can only repair the relatively-simple durability bugs. Second, our method can discover new repair strategies instead of relying on repair strategies hard-coded into the repair tool. Third, our method uses a novel symbolic encoding to model PM semantics, which allows our symbolic analysis to be more efficient than the explicit enumeration of possible scenarios and thus explore a large number of repairs quickly. We have evaluated our method on benchmark programs from the well-known Intel PMDK library as well as real applications such as Memcached, Recipe, and Redis. The results show that our method can repair all of the 41 known bugs in these benchmarks, while the state-of-the-art approach cannot repair any of the crash consistency bugs.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639204,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548530,Persistent memory;program repair;verification;debugging;testing,Analytical models;Computer bugs;Semantics;Maintenance engineering;Benchmark testing;Libraries;Encoding,,,,47,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code Representations,C. Niu; C. Li; V. Ng; J. Ge; L. Huang; B. Luo,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute University of Texas at Dallas, Richardson, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Dept. of Computer Science, Southern Methodist University, Dallas, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,01,13,"Recent years have seen the successful application of large pretrained models to code representation learning, resulting in substantial improvements on many code-related downstream tasks. But there are issues surrounding their application to SE tasks. First, the majority of the pre-trained models focus on pre-training only the encoder of the Transformer. For generation tasks that are addressed using models with the encoder-decoder architecture, however, there is no reason why the decoder should be left out during pre-training. Second, many existing pre-trained models, including state-of-the-art models such as T5-learning, simply reuse the pretraining tasks designed for natural languages. Moreover, to learn the natural language description of source code needed eventually for code-related tasks such as code summarization, existing pretraining tasks require a bilingual corpus composed of source code and the associated natural language description, which severely limits the amount of data for pre-training. To this end, we propose SPT-Code, a sequence-to-sequence pre-trained model for source code. In order to pre-train SPT-Code in a sequence-to-sequence manner and address the aforementioned weaknesses associated with existing pre-training tasks, we introduce three pre-training tasks that are specifically designed to enable SPT-Code to learn knowledge of source code, the corresponding code structure, as well as a natural language description of the code without relying on any bilingual corpus, and eventually exploit these three sources of information when it is applied to downstream tasks. Experimental results demonstrate that SPT-Code achieves state-of-the-art performance on five code-related downstream tasks after fine-tuning.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510096,"National Natural Science Foundation of China(grant numbers:61802167,61802095); Natural Science Foundation of Jiangsu Province, China(grant numbers:BK20201250); NSF(grant numbers:2034508); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793930,pre-training;code representation learning;sequence-to-sequence,Representation learning;Codes;Natural languages;Computer architecture;Transformers;Decoding;Task analysis,,25,,63,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Sedar: Obtaining High-Quality Seeds for DBMS Fuzzing via Cross-DBMS SQL Transfer,J. Fu; J. Liang; Z. Wu; Y. Jiang,"KLISS, BNRist, School of Software, Tsinghua University, China; KLISS, BNRist, School of Software, Tsinghua University, China; KLISS, BNRist, School of Software, Tsinghua University, China; KLISS, BNRist, School of Software, Tsinghua University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1799,1810,"Effective DBMS fuzzing relies on high-quality initial seeds, which serve as the starting point for mutation. These initial seeds should incorporate various DBMS features to explore the state space thoroughly. While built-in test cases are typically used as initial seeds, many DBMSs lack comprehensive test cases, making it difficult to apply state-of-the-art fuzzing techniques directly. To address this, we propose Sedar which produces initial seeds for a target DBMS by transferring test cases from other DBMSs. The underlying insight is that many DBMSs share similar functionalities, allowing seeds that cover deep execution paths in one DBMS to be adapted for other DBMSs. The challenge lies in converting these seeds to a format supported by the grammar of the target database. Sedar follows a three-step process to generate seeds. First, it executes existing SQL test cases within the DBMS they were designed for and captures the schema information during execution. Second, it utilizes large language models (LLMs) along with the captured schema information to guide the generation of new test cases based on the responses from the LLM. Lastly, to ensure that the test cases can be properly parsed and mutated by fuzzers, Sedar temporarily comments out unparsable sections for the fuzzers and uncomments them after mutation. We integrate Sedar into the DBMS fuzzers SQUIRREL and Griffin, targeting DBMSs such as Virtuoso, Mon-etDB, DuckDB, and ClickHouse. Evaluation results demonstrate significant improvements in both fuzzers. Specifically, compared to SQUIRREL and Griffin with non-transferred seeds, Sedar enhances code coverage by 72.46%-214.84% and 21.40%-194.46%; compared to SQUIRREL and Griffin with native test cases of these DBMSs as initial seeds, incorporating the transferred seeds of Sedar results in an improvement in code coverage by 4.90%-16.20% and 9.73%-28.41 %. Moreover, Sedar discovered 70 new vulnerabilities, with 60 out of them being uniquely found by Sedar with transferred seeds, and 19 of them have been assigned with CVEs.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639210,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548854,DBMS Fuzzing;Initial Seeds;Vulnerability Detection,Structured Query Language;Codes;Databases;Computer bugs;Fuzzing;Space exploration;Grammar,,,,48,,14 Jun 2024,,,IEEE,IEEE Conferences,True
EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries,J. Wang; T. Lutellier; S. Qian; H. V. Pham; L. Tan,"Purdue University, West Lafayette, USA; University of Waterloo, Waterloo, Canada; Purdue University, West Lafayette, USA; University of Waterloo, Waterloo, Canada; Purdue University, West Lafayette, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,798,810,"Testing deep learning (DL) software is crucial and challenging. Recent approaches use differential testing to cross-check pairs of implementations of the same functionality across different libraries. Such approaches require two DL libraries implementing the same functionality, which is often unavailable. In addition, they rely on a high-level library, Keras, that implements missing functionality in all supported DL libraries, which is prohibitively expensive and thus no longer maintained. To address this issue, we propose EAGLE, a new technique that uses differential testing in a different dimension, by using equivalent graphs to test a single DL implementation (e.g., a single DL library). Equivalent graphs use different Application Programming Interfaces (APIs), data types, or optimizations to achieve the same functionality. The rationale is that two equivalent graphs executed on a single DL implementation should produce identical output given the same input. Specifically, we design 16 new DL equivalence rules and propose a technique, EAGLE, that (1) uses these equivalence rules to build concrete pairs of equivalent graphs and (2) cross-checks the output of these equivalent graphs to detect inconsistency bugs in a DL library. Our evaluation on two widely-used DL libraries, i.e., Tensor Flow and PyTorch, shows that EAGLE detects 25 bugs (18 in Tensor Flow and 7 in PyTorch), including 13 previously unknown bugs.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510165,NSF(grant numbers:2006688); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794119,software testing;deep learning;differential testing;graph equivalence,Deep learning;Tensors;Computer bugs;Libraries;Software;Optimization;Testing,,6,,49,,20 Jun 2022,,,IEEE,IEEE Conferences,True
VULGEN: Realistic Vulnerability Generation Via Pattern Mining and Deep Learning,Y. Nong; Y. Ou; M. Pradel; F. Chen; H. Cai,"Washington State University, Pullman, WA, USA; The University of Texas at Dallas, Richardson, TX, USA; University of Stuttgart, Stuttgart, Germany; The University of Texas at Dallas, Richardson, TX, USA; Washington State University, Pullman, WA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2527,2539,"Building new, powerful data-driven defenses against prevalent software vulnerabilities needs sizable, quality vulnerability datasets, so does large-scale benchmarking of existing defense solutions. Automatic data generation would promisingly meet the need, yet there is little work aimed to generate much-needed quality vulnerable samples. Meanwhile, existing similar and adaptable techniques suffer critical limitations for that purpose. In this paper, we present VULGEN, the first injection-based vulnerability-generation technique that is not limited to a particular class of vulnerabilities. VULGEN combines the strengths of deterministic (pattern-based) and probabilistic (deep-learning/DL-based) program transformation approaches while mutually overcoming respective weaknesses. This is achieved through close collaborations between pattern mining/application and DL-based injection localization, which separates the concerns with how and where to inject. By leveraging large, pretrained programming language modeling and only learning locations, VULGEN mitigates its own needs for quality vulnerability data (for training the localization model). Extensive evaluations show that VULGEN significantly outperforms a state-of-the-art (SOTA) pattern-based peer technique as well as both Transformer- and GNN-based approaches in terms of the percentages of generated samples that are vulnerable and those also exactly matching the ground truth (by 38.0-430.1% and 16.3-158.2%, respectively). The VULGEN-generated samples led to substantial performance improvements for two SOTA DL-based vulnerability detectors (by up to 31.8% higher in F1), close to those brought by the ground-truth real-world samples and much higher than those by the same numbers of existing synthetic samples.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00211,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172870,Software vulnerability;data generation;bug injection;pattern mining;deep learning;vulnerability detection,Training;Location awareness;Detectors;Benchmark testing;Probabilistic logic;Transformers;Software,,4,,50,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
XPERT: Empowering Incident Management with Query Recommendations via Large Language Models,Y. Jiang; C. Zhang; S. He; Z. Yang; M. Ma; S. Qin; Y. Kang; Y. Dang; S. Rajmohan; Q. Lin; D. Zhang,"University of Michigan, Ann-Arbor, USA; Microsoft, China; Microsoft, China; Peking University, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1121,1133,"Large-scale cloud systems play a pivotal role in modern IT infrastructure. However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience. To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data. However, writing these queries can be challenging and time-consuming. This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at MICROSOFT. The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management. Building upon these valuable insights, we introduce XPERT, an end-to-end machine learning framework that automates KQL recommendation process. By leveraging historical incident data and large language models, XPERT generates customized KQL queries tailored to new incidents. Furthermore, XPERT incorporates a novel performance metric called XCORE, enabling a thorough evaluation of query quality from three comprehensive perspectives. We conduct extensive evaluations of XPERT, demonstrating its effectiveness in offline settings. Notably, we deploy XPERT in the real production environment of a large-scale incident management system in MICROSOFT, validating its efficiency in supporting incident management. To the best of our knowledge, this paper represents the first empirical study of its kind, and XPERT stands as a pioneering DSL query recommendation framework designed for incident management.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639081,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548240,Incident Management;Query Generation;Large Language Model,Measurement;Knowledge engineering;Production;Machine learning;Writing;User experience;Software reliability,,,,72,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Log-based Anomaly Detection with Deep Learning: How Far Are We?,V. -H. Le; H. Zhang,"The University of Newcastle, NSW, Australia; The University of Newcastle, NSW, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1356,1367,"Software-intensive systems produce logs for troubleshooting pur-poses. Recently, many deep learning models have been proposed to automatically detect system anomalies based on log data. These models typically claim very high detection accuracy. For example, most models report an F-measure greater than 0.9 on the commonly-used HDFS dataset. To achieve a profound understanding of how far we are from solving the problem of log-based anomaly detection, in this paper, we conduct an in-depth analysis of five state-of-the-art deep learning-based models for detecting system anomalies on four public log datasets. Our experiments focus on several aspects of model evaluation, including training data selection, data grouping, class distribution, data noise, and early detection ability. Our re-sults point out that all these aspects have significant impact on the evaluation, and that all the studied models do not always work well. The problem of log-based anomaly detection has not been solved yet. Based on our findings, we also suggest possible future work.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510155,"Australian Research Council (ARC) Discovery(grant numbers:DP200102940,DP220103044); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794117,Anomaly Detection;Log Analysis;Log Parsing;Deep Learning,Deep learning;Analytical models;Codes;Training data;Data models;Anomaly detection;Software engineering,,53,,55,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Better Automatic Program Repair by Using Bug Reports and Tests Together,M. Motwani; Y. Brun,"University of Massachusetts, Amherst, Massachusetts, USA; University of Massachusetts, Amherst, Massachusetts, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1225,1237,"Automated program repair is already deployed in industry, but concerns remain about repair quality. Recent research has shown that one of the main reasons repair tools produce incorrect (but seemingly correct) patches is imperfect fault localization (FL). This paper demonstrates that combining information from natural-language bug reports and test executions when localizing faults can have a significant positive impact on repair quality. For example, existing repair tools with such FL are able to correctly repair 7 defects in the Defects4J benchmark that no prior tools have repaired correctly. We develop, Blues, the first information-retrieval-based, statement-level FL technique that requires no training data. We further develop RAFL, the first unsupervised method for combining multiple FL techniques, which outperforms a supervised method. Using RAFL, we create SBIR by combining Blues with a spectrum-based (SBFL) technique. Evaluated on 815 real-world defects, SBIR consistently ranks buggy statements higher than its underlying techniques. We then modify three state-of-the-art repair tools, Arja, SequenceR, and SimFix, to use SBIR, SBFL, and Blues as their internal FL. We evaluate the quality of the produced patches on 689 real-world defects. Arja and SequenceR significantly benefit from SBIR: Arja using SBIR correctly repairs 28 defects, but only 21 using SBFL, and only 15 using Blues; SequenceR using SBIR correctly repairs 12 defects, but only 10 using SBFL, and only 4 using Blues. SimFix, (which has internal mechanisms to overcome poor FL), correctly repairs 30 defects using SBIR and SBFL, but only 13 using Blues. Our work is the first investigation of simultaneously using multiple software artifacts for automated program repair, and our promising findings suggest future research in this directions is likely to be fruitful.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00109,"National Science Foundation(grant numbers:CCF-1763423,CCF-2210243); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172693,Automatic Program repair;Information retrieval based fault localization;Debugging;fault localization,Location awareness;Industries;Computer bugs;Training data;Maintenance engineering;Benchmark testing;Software,,6,,32,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Enabling dynamic metamodels through constraint-driven modeling,A. Demuth,"Institute for Systems Engineering and Automation, Johannes Kepler University Linz, Austria",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,1622,1624,"Metamodels are commonly used in Model-Driven Engineering to define available model elements and structures. However, metamodels are likely to change during development for various reasons like requirement changes or evolving domain knowledge. Updating a metamodel typically leads to non-conformance issues with existing models. Hence, evolution strategies must be developed. Additionally, the tool implementation must also be updated to support the evolved metamodel. We propose the use of metamodel-independent tools with unified modeling concepts for working with all kinds of metamodels and models. By applying the Constraint-Driven Modeling approach and generating model constraints from metamodels automatically, we solve the described issues and enable dynamic, evolving metamodels. A prototype implementation has shown the feasibility of the approach and performance tests suggest that it also scales with increasing model sizes.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227223,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227223,Dynamic metamodeling;metamodel evolution;constraints;model consistency,Unified modeling language;Load modeling;Adaptation models;Runtime;Prototypes;Metamodeling,,1,,18,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Enhancing Deep Learning-based Vulnerability Detection by Building Behavior Graph Model,B. Yuan; Y. Lu; Y. Fang; Y. Wu; D. Zou; Z. Li; Z. Li; H. Jin,"School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2262,2274,"Software vulnerabilities have posed huge threats to the cyberspace security, and there is an increasing demand for automated vulnerability detection (VD). In recent years, deep learning-based (DL-based) vulnerability detection systems have been proposed for the purpose of automatic feature extraction from source code. Although these methods can achieve ideal performance on synthetic datasets, the accuracy drops a lot when detecting real-world vulnerability datasets. Moreover, these approaches limit their scopes within a single function, being not able to leverage the information between functions. In this paper, we attempt to extract the function's abstract behaviors, figure out the relationships between functions, and use this global information to assist DL-based VD to achieve higher performance. To this end, we build a Behavior Graph Model and use it to design a novel framework, namely VulBG. To examine the ability of our constructed Behavior Graph Model, we choose several existing DL-based VD models (e.g., TextCNN, ASTGRU, CodeBERT, Devign, and VulCNN) as our baseline models and conduct evaluations on two real-world datasets: the balanced $\text{FFMpeg}+\text{Qemu}$ dataset and the unbalanced $\text{Chrome} +\text{Debian}$ dataset. Experimental results indicate that VulBG enables all baseline models to detect more real vulnerabilities, thus improving the overall detection performance.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00190,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172844,Vulnerability Detection;Behavior Graph;Deep Learning,Source coding;Buildings;Cyberspace;Feature extraction;Software;Behavioral sciences;Security,,4,,61,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
DeMistify: Identifying On-Device Machine Learning Models Stealing and Reuse Vulnerabilities in Mobile Apps,P. Ren; C. Zuo; X. Liu; W. Diao; Q. Zhao; S. Guo,"School of Cyber Science and Technology, Shandong University; Ohio State University; School of Cyber Science and Technology, Shandong University; School of Cyber Science and Technology, Shandong University; City University of Hong Kong; School of Cyber Science and Technology, Shandong University",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,479,491,"Mobile apps have become popular for providing artificial intelligence (AI) services via on-device machine learning (ML) techniques. Unlike accomplishing these AI services on remote servers traditionally, these on-device techniques process sensitive information required by AI services locally, which can mitigate the severe con-cerns of the sensitive data collection on the remote side. However, these on-device techniques have to push the core of ML expertise (e.g., models) to smartphones locally, which are still subject to similar vulnerabilities on the remote clouds and servers, especially when facing the model stealing attack. To defend against these attacks, developers have taken various protective measures. Unfor-tunately, we have found that these protections are still insufficient, and on-device ML models in mobile apps could be extracted and reused without limitation. To better demonstrate its inadequate protection and the feasibility of this attack, this paper presents DeMistify, which statically locates ML models within an app, slices relevant execution components, and finally generates scripts auto-matically to instrument mobile apps to successfully steal and reuse target ML models freely. To evaluate DeMistify and demonstrate its applicability, we apply it on 1,511 top mobile apps using on-device ML expertise for several ML services based on their install numbers from Google Play and DeMistify can successfully execute 1250 of them (82.73%). In addition, an in-depth study is conducted to understand the on-device ML ecosystem in the mobile application.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623325,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548087,Android App;Machine Learning;On-device Model Reuse;Program Analysis,Analytical models;Biological system modeling;Ecosystems;Machine learning;Mobile applications;Servers;Task analysis,,1,,61,,14 Jun 2024,,,IEEE,IEEE Conferences,True
DeepFD: Automated Fault Diagnosis and Localization for Deep Learning Programs,J. Cao; M. Li; X. Chen; M. Wen; Y. Tian; B. Wu; S. -C. Cheung,"The Hong Kong University of Science and Technology, and Guangzhou HKUST Fok Ying Tung Research Institute, China; The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China; University of Waterloo, Canada, and The Hong Kong University of Science and Technology, China; MIT-IBM Watson AI Lab, U.S.; The Hong Kong University of Science and Technology, and Guangzhou HKUST Fok Ying Tung Research Institute, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,573,585,"As Deep Learning (DL) systems are widely deployed for mission-critical applications, debugging such systems becomes essential. Most existing works identify and repair suspicious neurons on the trained Deep Neural Network (DNN), which, unfortunately, might be a detour. Specifically, several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in DL programs. Besides, locating faulty neurons is not actionable for developers, while locating the faulty statements in DL programs can provide developers with more useful information for debugging. Though a few recent studies were proposed to pinpoint the faulty statements in DL programs or the training settings (e.g. too large learning rate), they were mainly designed based on predefined rules, leading to many false alarms or false negatives, especially when the faults are beyond their capabilities. In view of these limitations, in this paper, we proposed DeepFD, a learning-based fault diagnosis and localization framework which maps the fault localization task to a learning problem. In particu-lar, it infers the suspicious fault types via monitoring the runtime features extracted during DNN model training, and then locates the diagnosed faults in DL programs. It overcomes the limitations by identifying the root causes of faults in DL programs instead of neurons, and diagnosing the faults by a learning approach instead of a set of hard-coded rules. The evaluation exhibits the potential of DeepFD. It correctly diagnoses 52% faulty DL programs, compared with around half (27%) achieved by the best state-of-the-art works. Besides, for fault localization, DeepFD also outperforms the existing works, correctly locating 42% faulty programs, which almost doubles the best result (23%) achieved by the existing works.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510099,"National Natural Science Foundation of China(grant numbers:61932021,62002125); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793970,Neural Networks;Fault Diagnosis;Fault Localization;Debugging,Location awareness;Fault diagnosis;Deep learning;Training;Runtime;Neurons;Debugging,,10,,73,,20 Jun 2022,,,IEEE,IEEE Conferences,True
MirrorTaint: Practical Non-intrusive Dynamic Taint Tracking for JVM-based Microservice Systems,Y. Ouyang; K. Shao; K. Chen; R. Shen; C. Chen; M. Xu; Y. Zhang; L. Zhang,"University of Illinois, Urbana-Champaign, USA; Ant Group, Shanghai, China; Southern University of Science and Technology, Shenzhen, China; Peking University, Beijing, China; Ant Group, Shanghai, China; Ant Group, Shanghai, China; Southern University of Science and Technology, Shenzhen, China; University of Illinois, Urbana-Champaign, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2514,2526,"Taint analysis, i.e., labeling data and propagating the labels through data flows, has been widely used for analyzing program information flows and ensuring system/data security. Due to its important applications, various taint analysis techniques have been proposed, including static and dynamic taint analysis. However, existing taint analysis techniques can be hardly applied to the rising microservice systems for industrial applications. To address such a problem, in this paper, we proposed the first practical non-intrusive dynamic taint analysis technique MirrorTaint for extensively supporting microservice systems on JVMs. In particular, by instrumenting the microservice systems, MirrorTaint constructs a set of data structures with their respective policies for labeling/propagating taints in its mirrored space. Such data structures are essentially non-intrusive, i.e., modifying no program meta-data or runtime system. Then, during program execution, MirrorTaint replicates the stack-based JVM instruction execution in its mirrored space on-the-fly for dynamic taint tracking. We have evaluated MirrorTaint against state-of-the-art dynamic and static taint analysis systems on various popular open-source microservice systems. The results demonstrate that MirrorTaint can achieve better compatibility, quite close precision and higher recall (97.9%/100.0%) than state-of-the-art Phosphor (100.0%/9.9%) and FlowDroid (100%/28.2%). Also, MirrorTaint incurs lower runtime overhead than Phosphor (although both are dynamic techniques). Moreover, we have performed a case study in Ant Group, a global billion-user FinTech company, to compare MirrorTaint and their mature developer-experience-based data checking system for automatically generated fund documents. The result shows that the developer experience can be incomplete, causing the data checking system to only cover 84.0% total data relations, while MirrorTaint can automatically find 99.0% relations with 100.0% precision. Lastly, we also applied MirrorTaint to successfully detect a recently wide-spread Log4j2 security vulnerability.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00210,"National Natural Science Foundation of China(grant numbers:61902169); Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); NSF(grant numbers:CCF-2131943,CCF-2141474); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172616,dynamic taint analysis;microservice;JVM,Runtime;Instruments;Phosphors;Microservice architectures;Companies;Aerospace electronics;Benchmark testing,,1,,62,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
CC: Causality-Aware Coverage Criterion for Deep Neural Networks,Z. Ji; P. Ma; Y. Yuan; S. Wang,"The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1788,1800,"Deep neural network (DNN) testing approaches have grown fast in recent years to test the correctness and robustness of DNNs. In particular, DNN coverage criteria are frequently used to evaluate the quality of a test suite, and a number of coverage criteria based on neuron-wise, layer-wise, and path-/trace-wise coverage patterns have been published to date. However, we see that existing criteria are insufficient to represent how one neuron would influence subsequent neurons; hence, we lack a concept of how neurons, when functioning as causes and effects, might jointly make a DNN prediction. Given recent advances in interpreting DNN internals using causal inference, we present the first causality-aware DNN coverage criterion, which evaluates a test suite by quantifying the extent to which the suite provides new causal relations for testing DNNs. Performing standard causal inference on DNNs presents both theoretical and practical hurdles. We introduce CC (causal coverage), a practical and efficient coverage criterion that integrates a set of optimizations using DNN domain-specific knowledge. We illustrate the efficacy of CC using diverse, real-world inputs and adversarial inputs, such as adversarial examples (AEs) and backdoor inputs. We demonstrate that CC outperforms previous DNN criteria under various settings with moderate cost.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00153,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172609,machine learning testing;Causality Analysis;Software Engineering,Costs;Neurons;Artificial neural networks;Robustness;Optimization;Standards;Testing,,6,,58,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
A Comprehensive Study of Real-World Bugs in Machine Learning Model Optimization,H. Guan; Y. Xiao; J. Li; Y. Liu; G. Bai,"The University of Queensland, Brisbane, Australia; Southern University of Science and Technology, Shenzhen, China; Microsoft Software Technology Center Asia, Beijing, China; Southern University of Science and Technology, Shenzhen, China; The University of Queensland, Brisbane, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,147,158,"Due to the great advance in machine learning (ML) techniques, numerous ML models are expanding their application domains in recent years. To adapt for resource-constrained platforms such as mobile and Internet of Things (IoT) devices, pre-trained models are often processed to enhance their efficiency and compactness, using optimization techniques such as pruning and quantization. Similar to the optimization process in other complex systems, e.g., program compilers and databases, optimizations for ML models can contain bugs, leading to severe consequences such as system crashes and financial loss. While bugs in training, compiling and deployment stages have been extensively studied, there is still a lack of systematic understanding and characterization of model optimization bugs (MOBs). In this work, we conduct the first empirical study to identify and characterize MOBs. We collect a comprehensive dataset containing 371 MOBs from TensorFlow and PyTorch, the most extensively used open-source ML frameworks, covering the entire development time span of their optimizers (May 2019 to August 2022). We then investigate the collected bugs from various perspectives, including their symptoms, root causes, life cycles, detection and fixes. Our work unveils the status quo of MOBs in the wild, and reveals their features on which future detection techniques can be based. Our findings also serve as a warning to the developers and the users of ML frameworks, and an appeal to our research community to enact dedicated countermeasures.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00024,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172690,Machine Learning;Model Optimization;Bugs,Training;Adaptation models;Analytical models;Systematics;Computer bugs;Machine learning;Internet of Things,,5,,54,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Rete: Learning Namespace Representation for Program Repair,N. Parasaram; E. T. Barr; S. Mechtaev,"University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1264,1276,"A key challenge of automated program repair is finding correct patches in the vast search space of candidate patches. Real-world programs define large namespaces of variables that considerably contributes to the search space explosion. Existing program repair approaches neglect information about the program namespace, which makes them inefficient and increases the chance of test-overfitting. We propose Rete, a new program repair technique, that learns project-independent information about program namespace and uses it to navigate the search space of patches. Rete uses a neural network to extract project-independent information about variable CDU chains, def-use chains augmented with control flow. Then, it ranks patches by jointly ranking variables and the patch templates into which the variables are inserted. We evaluated Rete on 142 bugs extracted from two datasets, ManyBugs and BugsInPy. Our experiments demonstrate that ReTe generates six new correct patches that fix bugs that previous tools did not repair, an improvement of 31% and 59% over the existing state of the art.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172760,Program Repair;Deep Learning;Patch Prioritisation;Variable Representation,Navigation;Computer bugs;Neural networks;Maintenance engineering;Aerospace electronics;Explosions;Data mining,,4,,73,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
When and Why Test Generators for Deep Learning Produce Invalid Inputs: an Empirical Study,V. Riccio; P. Tonella,"Università della Svizzera italiana, Lugano, Switzerland; Università della Svizzera italiana, Lugano, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1161,1173,"Testing Deep Learning (DL) based systems inherently requires large and representative test sets to evaluate whether DL systems generalise beyond their training datasets. Diverse Test Input Generators (TIGs) have been proposed to produce artificial inputs that expose issues of the DL systems by triggering misbehaviours. Unfortunately, such generated inputs may be invalid, i.e., not recognisable as part of the input domain, thus providing an unreliable quality assessment. Automated validators can ease the burden of manually checking the validity of inputs for human testers, although input validity is a concept difficult to formalise and, thus, automate. In this paper, we investigate to what extent TIGs can generate valid inputs, according to both automated and human validators. We conduct a large empirical study, involving 2 different automated validators, 220 human assessors, 5 different TIGs and 3 classification tasks. Our results show that 84% artificially generated inputs are valid, according to automated validators, but their expected label is not always preserved. Automated validators reach a good consensus with humans (78% accuracy), but still have limitations when dealing with feature-rich datasets.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172704,software testing;deep learning,Deep learning;Training;Generators;Software;Quality assessment;Task analysis;Testing,,11,,61,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Disengagement in pair programming: Does it matter?,L. Plonka; H. Sharp; J. van der Linden,"Centre for Research in Computing, Open University, Milton Keynes, UK; Centre for Research in Computing, Open University, Milton Keynes, UK; Centre for Research in Computing, Open University, Milton Keynes, UK",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,496,506,"Pair Programming (PP) requires close collaboration and mutual engagement. Most existing empirical studies of PP do not focus on developers' behaviour during PP sessions, and focus instead on the effects of PP such as productivity. However, disengagement, where a developer is not focusing on solving the task or understanding the problem and allows their partner to work by themselves, can hinder collaboration between developers and have a negative effect on their performance. This paper reports on an empirical study that investigates disengagement. Twenty-one industrial pair programming sessions were video and audio recorded and qualitatively analysed to investigate circumstances that lead to disengagement. We identified five reasons for disengagement: interruptions during the collaboration, the way the work is divided, the simplicity of the task involved, social pressure on inexperienced pair programmers, and time pressure. Our findings suggest that disengagement is sometimes acceptable and agreed upon between the developers in order to speed up problem solving. However, we also found episodes of disengagement where developers “drop out” of their PP sessions and are not able to follow their partner's work nor contribute to the task at hand, thus losing the expected benefits of pairing. Analysis of sessions conducted under similar circumstances but where mutual engagement was sustained identified three behaviours that help to maintain engagement: encouraging the novice to drive, verbalisation and feedback, and asking for clarification.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227166,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227166,collaboration;agile software development;empirical study,Collaboration;Programming;Interviews;Navigation;Companies;Focusing;Video recording,,12,,31,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Decomposing Convolutional Neural Networks into Reusable and Replaceable Modules,R. Pan; H. Rajan,"Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,524,535,"Training from scratch is the most common way to build a Convolutional Neural Network (CNN) based model. What if we can build new CNN models by reusing parts from previously built CNN models? What if we can improve a CNN model by replacing (possibly faulty) parts with other parts? In both cases, instead of training, can we identify the part responsible for each output class (module) in the model(s) and reuse or replace only the desired output classes to build a model? Prior work has proposed decomposing dense-based networks into modules (one for each output class) to enable reusability and replace ability in various scenarios. However, this work is limited to the dense layers and is based on the one-to-one relationship between the nodes in consecutive layers. Due to the shared architecture in the CNN model, prior work cannot be adapted directly. In this paper, we propose to decompose a CNN model used for image classification problems into modules for each output class. These modules can further be reused or replaced to build a new model. We have evaluated our approach with CIFAR-10, CIFAR-100, and ImageNet tiny datasets with three variations of ResNet models and found that enabling decomposition comes with a small cost (1.77% and 0.85% for top-1 and top-5 accuracy, respectively). Also, building a model by reusing or replacing modules can be done with a 2.3% and 0.5% average loss of accuracy. Furthermore, reusing and replacing these modules reduces CO2e emission by ~37 times compared to training the model from scratch.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510051,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793875,deep learning;cnn;deep neural network;modularity;decomposition,Training;Adaptation models;Costs;Buildings;Computer architecture;Convolutional neural networks;Software engineering,,10,,42,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Taintmini: Detecting Flow of Sensitive Data in Mini-Programs with Static Taint Analysis,C. Wang; R. Ko; Y. Zhang; Y. Yang; Z. Lin,The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,932,944,"Mini-programs, which are programs running inside mobile super apps such as WeChat, often have access to privacy-sensitive information, such as location data and phone numbers, through APUs provided by the super apps. This access poses a risk of privacy sensitive data leaks, either accidentally from carelessly programmed mini-programs or intentionally from malicious ones. To address this concern, it is crucial to track the flow of sensitive data in mini-programs for either human analysis or automated tools. Although existing taint analysis techniques have been widely studied, they face unique challenges in tracking sensitive data flows in mini-programs, such as cross-language, cross-page, and cross-mini-program data flows. This paper presents a novel framework, Taintmini, which addresses these challenges by using a novel universal data flow graph approach that captures data flows within and across mini-programs. We have evaluated Taintminiwith 238,866 mini-programs and detect 27,184 that contain sensitive data flows. We have also applied Taintminito detect privacy leakage colluding mini-programs and identify 455 such programs from them that clearly violate privacy policy.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00086,DARPA(grant numbers:N6600120C4020); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172538,Mini-programs;Taint analysis;Privacy leaks detection;Security;Empirical Study,Privacy;Data privacy;Social networking (online);Message services;Flow graphs;Faces;Software engineering,,5,,51,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
FlakeSync: Automatically Repairing Async Flaky Tests,S. Rahman; A. Shi,"The University of Texas at Austin, Austin, Texas, USA; The University of Texas at Austin, Austin, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1673,1684,"Regression testing is an important part of the development process but suffers from the presence of flaky tests. Flaky tests nondeter-ministically pass or fail when run on the same code, misleading developers about the correctness of their changes. A common type of flaky tests are async flaky tests that flakily fail due to timing-related issues such as asynchronous waits that do not return in time or different thread interleavings during execution. Developers commonly try to repair async flaky tests by inserting or increasing some wait time, but such repairs are unreliable. We propose FlakeSync, a technique for automatically repairing async flaky tests by introducing synchronization for a specific test execution. FlakeSync works by identifying a critical point, representing some key part of code that must be executed early w.r.t. other concurrently executing code, and a barrier point, representing the part of code that should wait until the critical point has been executed. FlakeSync can modify code to check when the critical point is executed and have the barrier point keep waiting until the critical point has been executed, essentially synchronizing these two parts of code for the specific test execution. Our evaluation of FlakeSync on known flaky tests from prior work shows that FlakeSync can automatically repair 83.75% of async flaky tests, and the resulting changes add a median overhead of only 1.00X the original test runtime. We submitted 10 pull requests with our changes to developers, with 3 already accepted and none rejected.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639115,NSF(grant numbers:CCF-2145774); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548464,flaky test repair;async flaky tests,Codes;Runtime;Source coding;Software algorithms;Maintenance engineering;Delays;Synchronization,,2,,45,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors,Y. Peng; S. Gao; C. Gao; Y. Huo; M. R. Lyu,"The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,12,24,"As a dynamic programming language, Python has become increasingly popular in recent years. Although the dynamic type system of Python facilitates the developers in writing Python programs, it also brings type errors at runtime which are prevalent yet not easy to fix. There exist rule-based approaches for automatically repairing Python type errors. The approaches can generate accurate patches for the type errors covered by manually defined templates, but they require domain experts to design patch synthesis rules and suffer from low template coverage of real-world type errors. Learning-based approaches alleviate the manual efforts in designing patch synthesis rules and have become prevalent due to the recent advances in deep learning. Among the learning-based approaches, the prompt-based approach which leverages the knowledge base of code pretrained models via predefined prompts, obtains state-of-the-art performance in general program repair tasks. However, such prompts are manually defined and do not involve any specific clues for repairing Python type errors, resulting in limited effectiveness. How to automatically improve prompts with the domain knowledge for type error repair is challenging yet under-explored. In this paper, we present Typefix, a novel prompt-based approach with fix templates incorporated for repairing Python type errors. Typefix first mines generalized fix templates via a novel hierarchical clustering algorithm. The identified fix templates indicate the common edit patterns and contexts of existing type error fixes. Typefix then generates code prompts for code pretrained models by employing the generalized fix templates as domain knowledge, in which the masks are adaptively located for each type error instead of being pre-determined. Experiments on two benchmarks, including BUGSINPy and TYPEBUGS, show that Typefix successfully repairs 26 and 55 type errors, outperforming the best baseline approach by 9 and 14, respectively. Besides, the proposed fix template mining approach can cover 75% of developers' patches in both benchmarks, increasing the best rule-based approach PyTER by more than 30%.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548357,Type Error;Program Repair;Python,Codes;Runtime;Software algorithms;Clustering algorithms;Manuals;Maintenance engineering;Benchmark testing,,2,,59,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Buildsheriff: Change-Aware Test Failure Triage for Continuous Integration Builds,C. Zhang; B. Chen; X. Peng; W. Zhao,"School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,312,324,"Test failures are one of the most common reasons for broken builds in continuous integration. It is expensive to diagnose all test failures in a build. As test failures are usually caused by a few underlying faults, triaging test failures with respect to their underlying root causes can save test failure diagnosis cost. Existing failure triage methods are mostly developed for triaging crash or bug reports, and hence not ap-plicable in the context of test failure triage in continuous integration. In this paper, we first present a large-scale empirical study on 163,371 broken builds caused by test failures to characterize test failures in real-world Java projects. Then, motivated by our study, we propose a new change-aware approach, BuildSheriff, to triage test failures in each continuous integration build such that test failures with the same root cause are put in the same cluster. Our evaluation on 200 broken builds has demonstrated that BuildSheriff can significantly improve the state-of-the-art methods on the triaging effectiveness.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510132,National Natural Science Foundation of China(grant numbers:61802067); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793896,Test Failures;Failure Triage;Continuous Integration,Java;Costs;Computer bugs;Software engineering,,,,75,,20 Jun 2022,,,IEEE,IEEE Conferences,True
CIT4DNN: Generating Diverse and Rare Inputs for Neural Networks Using Latent Space Combinatorial Testing,S. Dola; R. McDaniel; M. B. Dwyer; M. L. Soffa,"University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1446,1458,"Deep neural networks (DNN) are being used in a wide range of applications including safety-critical systems. Several DNN test generation approaches have been proposed to generate fault-revealing test inputs. However, the existing test generation approaches do not systematically cover the input data distribution to test DNNs with diverse inputs, and none of the approaches investigate the relationship between rare inputs and faults. We propose CIT4DNN, an automated black-box approach to generate DNN test sets that are feature-diverse and that comprise rare inputs. CIT4DNN constructs diverse test sets by applying combinatorial interaction testing to the latent space of generative models and formulates constraints over the geometry of the latent space to generate rare and fault-revealing test inputs. Evaluation on a range of datasets and models shows that CIT4DNN generated tests are more feature diverse than the state-of-the-art, and can target rare fault-revealing testing inputs more effectively than existing methods.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639106,"National Science Foundation(grant numbers:2019239,2129824,2217071); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548914,deep neural networks;test generation;test coverage;combinatorial interaction testing,Geometry;Combinatorial testing;Closed box;Artificial neural networks;Test pattern generators;Testing;Software engineering,,,,71,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Automated repair of HTML generation errors in PHP applications using string constraint solving,H. Samimi; M. Schäfer; S. Artzi; T. Millstein; F. Tip; L. Hendren,"Computer Science Department, University of California, Los Angeles, USA; IBM T.J. Watson Research Center, Hawthorne, NY, USA; IBM T.J. Watson Research Center, Hawthorne, NY, USA; Computer Science Department, University of California, Los Angeles, USA; IBM T.J. Watson Research Center, Hawthorne, NY, USA; School of Computer Science, McGill University, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,277,287,"PHP web applications routinely generate invalid HTML. Modern browsers silently correct HTML errors, but sometimes malformed pages render inconsistently, cause browser crashes, or expose security vulnerabilities. Fixing errors in generated pages is usually straightforward, but repairing the generating PHP program can be much harder. We observe that malformed HTML is often produced by incorrect constant prints, i.e., statements that print string literals, and present two tools for automatically repairing such HTML generation errors. PHPQuickFix repairs simple bugs by statically analyzing individual prints. PHPRepair handles more general repairs using a dynamic approach. Based on a test suite, the property that all tests should produce their expected output is encoded as a string constraint over variables representing constant prints. Solving this constraint describes how constant prints must be modified to make all tests pass. Both tools were implemented as an Eclipse plugin and evaluated on PHP programs containing hundreds of HTML generation errors, most of which our tools were able to repair automatically.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227186,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227186,PHP;automated repair;string constraints,HTML;Maintenance engineering;Databases;Computer bugs;Browsers;Cascading style sheets;USA Councils,,63,,20,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Concrete Constraint Guided Symbolic Execution,Y. Sun; G. Yang; S. Lv; Z. Li; L. Sun,"Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China; The University of Queensland, Australia; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1496,1507,"Symbolic execution is a popular program analysis technique. It systematically explores all feasible paths of a program but its scalability is largely limited by the path explosion problem, which causes the number of paths proliferates at runtime. A key idea in existing methods to mitigate this problem is to guide the selection of states for path exploration, which primarily relies on the features to represent program states. In this paper, we propose concrete constraint guided symbolic execution, which aims to cover more concrete branches and ultimately improve the overall code coverage during symbolic execution. Our key insight is based on the fact that symbolic execution strives to cover all symbolic branches while concrete branches are neglected, and directing symbolic execution toward uncovered concrete branches has a great potential to improve the overall code coverage. The experimental results demonstrate that our approach can improve the ability of KLEE to both increase code coverage and find more security violations on 10 open-source C programs.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639078,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548219,Symbolic Execution;Data Dependency Analysis,Codes;Runtime;Scalability;Explosions;Security;Data mining,,,,57,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Cross-Domain Deep Code Search with Meta Learning,Y. Chai; H. Zhang; B. Shen; X. Gu,"School of Software, Shanghai Jiao Tong University, China; The University of Newcastle, Australia; School of Software, Shanghai Jiao Tong University, China; School of Software, Shanghai Jiao Tong University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,487,498,"Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Un-like cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510125,National Natural Science Foundation of China(grant numbers:62102244); CCF-Baidu Open Fund(grant numbers:2021pp15002000); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793990,Code Search;Pre-trained Code Models;Meta Learning;Few-Shot Learning;Deep Learning,Structured Query Language;Adaptation models;Solid modeling;Java;Codes;Transfer learning;Data models,,4,,45,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Reliability Assurance for Deep Neural Network Architectures Against Numerical Defects,L. Li; Y. Zhang; L. Ren; Y. Xiong; T. Xie,"Department of Computer Science, University of Illinois Urbana-Champaign; Department of Computer Sciences, University of Wisconsin-Madison; School of Computer Science, Peking University; School of Computer Science, Peking University; School of Computer Science, Peking University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1827,1839,"With the widespread deployment of deep neural networks (DNNs), ensuring the reliability of DNN-based systems is of great importance. Serious reliability issues such as system failures can be caused by numerical defects, one of the most frequent defects in DNNs. To assure high reliability against numerical defects, in this paper, we propose the RANUM approach including novel techniques for three reliability assurance tasks: detection of potential numerical defects, confirmation of potential-defect feasibility, and suggestion of defect fixes. To the best of our knowledge, RANUM is the first approach that confirms potential-defect feasibility with failure-exhibiting tests and suggests fixes automatically. Extensive experiments on the benchmarks of 63 real-world DNN architectures show that RANUM outperforms state-of-the-art approaches across the three reliability assurance tasks. In addition, when the RANUM-generated fixes are compared with developers' fixes on open-source projects, in 37 out of 40 cases, RANUM-generated fixes are equivalent to or even better than human fixes.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00156,National Natural Science Foundation of China(grant numbers:62161146003); National Key Research and Development Program of China(grant numbers:2019YFE0198100); Innovation and Technology Commission of HKSAR(grant numbers:MHP/055/19); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172602,neural network;numerical defect;testing;fix,Source coding;Artificial neural networks;Computer architecture;Benchmark testing;Reliability;Task analysis;Optimization,,1,,64,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
FAIR: Flow Type-Aware Pre-Training of Compiler Intermediate Representations,C. Niu; C. Li; V. Ng; D. Lo; B. Luo,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute University of Texas at Dallas, Richardson, Texas, USA; School of Computing and Information Systems Singapore Management University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,378,389,"While the majority of existing pre-trained models from code learn source code features such as code tokens and abstract syntax trees, there are some other works that focus on learning from compiler intermediate representations (IRs). Existing IR-based models typically utilize IR features such as instructions, control and data flow graphs (CDFGs), call graphs, etc. However, these methods confuse variable nodes and instruction nodes in a CDFG and fail to distinguish different types of flows, and the neural networks they use fail to capture long-distance dependencies and have over-smoothing and over-squashing problems. To address these weaknesses, we propose FAIR, a Flow type-Aware pre-trained model for IR that involves employing (1) a novel input representation of IR programs; (2) Graph Transformer to address over-smoothing, over-squashing and long-dependencies problems; and (3) five pre-training tasks that we specifically propose to enable FAIR to learn the semantics of IR tokens, flow type information, and the overall representation of IR. Experimental results show that FAIR can achieve state-of-the-art results on four code-related downstream tasks.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608136,"NSF(grant numbers:2034508); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); National Research Foundation, Singapore; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548636,,Codes;Source coding;Semantics;Neural networks;Syntactics;Transformers;Data models,,,,61,,14 Jun 2024,,,IEEE,IEEE Conferences,True
When Neural Code Completion Models Size up the Situation: Attaining Cheaper and Faster Completion through Dynamic Model Inference,Z. Sun; X. Du; F. Song; S. Wang; L. Li,"Beihang University, Beijing, China; Monash University Melbourne, Victoria, Australia; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; National University of Defense Technology, Changsha, China; Beijing Yunnan Key Laboratory of Software Engineering, Beihang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,906,917,"Leveraging recent advancements in large language models, modern neural code completion models have demonstrated the capability to generate highly accurate code suggestions. However, their massive size poses challenges in terms of computational costs and environmental impact, hindering their widespread adoption in practical scenarios. Dynamic inference emerges as a promising solution, as it allocates minimal computation during inference while maintaining the model's performance. In this research, we explore dynamic inference within the context of code completion. Initially, we conducted an empirical investigation on GPT-2, focusing on the inference capabilities of intermediate layers for code completion. We found that 54.4% of tokens can be accurately generated using just the first layer, signifying significant computational savings potential. Moreover, despite using all layers, the model still fails to predict 14.5% of tokens correctly, and the subsequent completions continued from them are rarely considered helpful, with only a 4.2% Acceptance Rate. These findings motivate our exploration of dynamic inference in code completion and inspire us to enhance it with a decision-making mechanism that stops the generation of incorrect code. We thus propose a novel dynamic inference method specifically tailored for code completion models. This method aims not only to produce correct predictions with largely reduced computation but also to prevent incorrect predictions proactively. Our extensive evaluation shows that it can averagely skip 1.7 layers out of 16 layers in the models, leading to an 11.2% speedup with only a marginal 1.1 % reduction in ROUGE- L.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639120,National Natural Science Foundation of China (NSFC)(grant numbers:62072309); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549258,,Codes;Accuracy;Computational modeling;Decision making;Focusing;Predictive models;Dynamic scheduling,,,,39,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Modularizing While Training: A New Paradigm for Modularizing DNN Models,B. Qi; H. Sun; H. Zhang; R. Zhao; X. Gao,"SKLSDE Lab, Beihang University, China; SKLSDE Lab, Beihang University, China; Chongqing University, China; SKLSDE Lab, Beihang University, China; SKLSDE Lab, Beihang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,353,364,"Deep neural network (DNN) models have become increasingly crucial components of intelligent software systems. However, training a DNN model is typically expensive in terms of both time and computational resources. To address this issue, recent research has focused on reusing existing DNN models - borrowing the concept of software reuse in software engineering. However, reusing an entire model could cause extra overhead or inherit the weaknesses from the undesired functionalities. Hence, existing work proposes to de-compose an already trained model into modules, i.e., modularizing-after-training, to enable module reuse. Since the trained models are not built for modularization, modularizing-after-training may incur huge overhead and model accuracy loss. In this paper, we propose a novel approach that incorporates modularization into the model training process, i.e., modularizing-while-training (MwT). We train a model to be structurally modular through two loss functions that optimize intra-module cohesion and inter-module coupling. We have implemented the proposed approach for modularizing Convolutional Neural Network (CNN) models. The evaluation results on representative models demonstrate that MwT outperforms the existing state-of-the-art modularizing-after-training approach. Specifically, the accuracy loss caused by MwT is only 1.13 percentage points, which is less than that of the existing approach. The kernel retention rate of the modules generated by MwT is only 14.58%, with a reduction of 74.31% over the existing approach. Fur-thermore, the total time cost required for training and modularizing is only 108 minutes, which is half the time required by the existing approach. Our work demonstrates that MwT is a new and more effective paradigm for realizing DNN model modularization, offering a fresh perspective on achieving model reuse.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608135,"National Natural Science Foundation of China(grant numbers:61972013,61972013); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548345,DNN Modularization;Model Reuse;Modular Training;Convolutional Neural Network,Training;Couplings;Costs;Computational modeling;Transformers;Software systems;Convolutional neural networks,,,,52,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Machine Learning is All You Need: A Simple Token-Based Approach for Effective Code Clone Detection,S. Feng; W. Suo; Y. Wu; D. Zou; Y. Liu; H. Jin,"Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2745,2757,"As software engineering advances and the code demand rises, the prevalence of code clones has increased. This phenomenon poses risks like vulnerability propagation, underscoring the growing importance of code clone detection techniques. While numerous code clone detection methods have been proposed, they often fall short in real-world code environments. They either struggle to identify code clones effectively or demand substantial time and computational resources to handle complex clones. This paper introduces a code clone detection method namely Toma using tokens and machine learning. Specifically, we extract token type sequences and employ six similarity calculation methods to generate feature vectors. These vectors are then input into a trained machine learning model for classification. To evaluate the effectiveness and scalability of Toma, we conduct experiments on the widely used BigCloneBench dataset. Results show that our tool outperforms token-based code clone detectors and most tree-based clone detectors, demonstrating high effectiveness and significant time savings.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639114,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548279,Code Clones;Machine Learning;Token,Codes;Scalability;Computational modeling;Cloning;Machine learning;Detectors;Feature extraction,,1,,70,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Jigsaw: Large Language Models meet Program Synthesis,N. Jain; S. Vaidyanath; A. Iyer; N. Natarajan; S. Parthasarathy; S. Rajamani; R. Sharma,"Microsoft Research, Bangalore, India; Stanford University, Stanford, USA; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1219,1231,"Large pre-trained language models such as GPT-3 [10], Codex [11], and Coogle's language model [7] are now capable of generating code from natural language specifications of programmer intent. We view these developments with a mixture of optimism and caution. On the optimistic side, such large language models have the potential to improve productivity by providing an automated AI pair programmer for every programmer in the world. On the cautionary side, since these large language models do not understand program semantics, they offer no guarantees about quality of the suggested code. In this paper, we present an approach to augment these large language models with post-processing steps based on program analysis and synthesis techniques, that understand the syntax and semantics of programs. Further, we show that such techniques can make use of user feedback and improve with usage. We present our experiences from building and evaluating such a tool Jigsaw, targeted at synthesizing code for using Python Pandas API using multi-modal inputs. Our experience suggests that as these large language models evolve for synthesizing code from intent, Jigsaw has an important role to play in improving the accuracy of the systems.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510203,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793546,Program Synthesis;Machine Learning,Productivity;Analytical models;Codes;Semantics;Natural languages;Buildings;Syntactics,,27,,46,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Domain-Specific Analysis of Mobile App Reviews Using Keyword-Assisted Topic Models,M. Tushev; F. Ebrahimi; A. Mahmoud,"The Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, Louisiana; The Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, Louisiana; The Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, Louisiana",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,762,773,"Mobile application (app) reviews contain valuable information for app developers. A plethora of supervised and unsupervised techniques have been proposed in the literature to synthesize useful user feedback from app reviews. However, traditional supervised classification algorithms require extensive manual effort to label ground truth data, while unsupervised text mining techniques, such as topic models, often produce suboptimal results due to the sparsity of useful information in the reviews. To overcome these limitations, in this paper, we propose a fully automatic and unsupervised approach for extracting useful information from mobile app reviews. The proposed approach is based on keyATM, a keyword-assisted approach for generating topic models. keyATM overcomes the prob-lem of data sparsity by using seeding keywords extracted directly from the review corpus. These keywords are then used to generate meaningful domain-specific topics. Our approach is evaluated over two datasets of mobile app reviews sampled from the domains of Investing and Food Delivery apps. The results show that our approach produces significantly more coherent topics than traditional topic modeling techniques.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510201,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794110,,Text mining;Analytical models;Prototypes;Data models;Software;Mobile applications;Usability,,5,,87,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Pre-training by Predicting Program Dependencies for Vulnerability Analysis Tasks,Z. Liu; Z. Tang; J. Zhang; X. Xia; X. Yang,"The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; Zhejiang University, China; Zhejiang University, China; Huawei, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1863,1875,"Vulnerability analysis is crucial for software security. Inspired by the success of pre-trained models on software engineering tasks, this work focuses on using pre-training techniques to enhance the understanding of vulnerable code and boost vulnerability analysis. The code understanding ability of a pre-trained model is highly related to its pre-training objectives. The semantic structure, e.g., control and data dependencies, of code is important for vulnerability analysis. However, existing pre-training objectives either ignore such structure or focus on learning to use it. The feasibility and benefits of learning the knowledge of analyzing semantic structure have not been investigated. To this end, this work proposes two novel pre-training objectives, namely Control Dependency Prediction (CDP) and Data Dependency Prediction (DDP), which aim to predict the statement-level control dependencies and token-level data dependencies, respectively, in a code snippet only based on its source code. During pre-training, CDP and DDP can guide the model to learn the knowledge required for analyzing fine-grained dependencies in code. After pre-training, the pre-trained model can boost the understanding of vulnerable code during fine-tuning and can directly be used to perform dependence analysis for both partial and complete functions. To demonstrate the benefits of our pre-training objectives, we pre-train a Transformer model named PDBERT with CDP and DDP, fine-tune it on three vulnerability analysis tasks, i.e., vulnerability detection, vulnerability classification, and vulnerability assessment, and also evaluate it on program dependence analysis. Experimental results show that PDBERT benefits from CDP and DDP, leading to state-of-the-art performance on the three downstream tasks. Also, PDBERT achieves F1-scores of over 99% and 94% for predicting control and data dependencies, respectively, in partial and complete functions.",1558-1225,979-8-4007-0217-4,,National Natural Science Foundation of China(grant numbers:62202420); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548173,Source Code Pre-training;Program Dependence Analysis;Vulnerability Detection;Vulnerability Classification;Vulnerability Assessment,Analytical models;Codes;Source coding;Semantics;Transformers;Software;Security,,,,70,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Causality-Based Neural Network Repair,B. Sun; J. Sun; L. H. Pham; T. Shi,Singapore Management University; Singapore Management University; Singapore Management University; Huawei Singapore,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,338,349,"Neural networks have had discernible achievements in a wide range of applications. The wide-spread adoption also raises the concern of their dependability and reliability. Similar to traditional decision-making programs, neural networks can have defects that need to be repaired. The defects may cause unsafe behaviors, raise security concerns or unjust societal impacts. In this work, we address the problem of repairing a neural network for desirable properties such as fairness and the absence of backdoor. The goal is to construct a neural network that satisfies the property by (minimally) adjusting the given neural network's parameters (i.e., weights). Specifically, we propose CARE (CAusality-based REpair), a causality-based neural network repair technique that 1) performs causality-based fault localization to identify the ‘guilty’ neurons and 2) optimizes the parameters of the identified neurons to reduce the misbehavior. We have empirically evaluated CARE on various tasks such as backdoor removal, neural network repair for fairness and safety properties. Our experiment results show that CARE is able to repair all neural networks efficiently and effectively. For fairness repair tasks, CARE successfully improves fairness by 61.91 % on average. For backdoor removal tasks, CARE reduces the attack success rate from over 98% to less than 1 %. For safety property repair tasks, CARE reduces the property violation rate to less than 1 %. Results also show that thanks to the causality-based fault localization, CARE's repair focuses on the misbehavior and preserves the accuracy of the neural networks.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510080,Huawei International(grant numbers:TC20210714014); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793926,Machine Learning with and for SE;Program Repair;Fault Localization,Location awareness;Fault diagnosis;Neurons;Maintenance engineering;Safety;Behavioral sciences;Security,,18,,73,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Verifying Data Constraint Equivalence in FinTech Systems,C. Wang; G. Fan; P. Yao; F. Pan; C. Zhang,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Ant Group, Shenzhen, China; Zhejiang University, Hangzhou, China; Ant Group, Shenzhen, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1329,1341,"Data constraints are widely used in FinTech systems for monitoring data consistency and diagnosing anomalous data manipulations. However, many equivalent data constraints are created redundantly during the development cycle, slowing down the FinTech systems and causing unnecessary alerts. We present EQDAC, an efficient decision procedure to determine the data constraint equivalence. We first propose the symbolic representation for semantic encoding and then introduce two light-weighted analyses to refute and prove the equivalence, respectively, which are proved to achieve in polynomial time. We evaluate EQDAC upon 30,801 data constraints in a FinTech system. It is shown that EQDAC detects 11,538 equivalent data constraints in three hours. It also supports efficient equivalence searching with an average time cost of 1.22 seconds, enabling the system to check new data constraints upon submission.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172850,Equivalence Verification;Data Constraints;Fin-Tech Systems,Costs;Semantics;Production;Companies;Maintenance engineering;Encoding;Monitoring,,3,,58,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
SnR: Constraint-Based Type Inference for Incomplete Java Code Snippets,Y. Dong; T. Gu; Y. Tian; C. Sun,"David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada; Alibaba Group, China; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1982,1993,"Code snippets are prevalent on websites such as Stack Overflow and are effective in demonstrating API usages concisely. However they are usually difficult to be used directly because most code snippets not only are syntactically incomplete but also lack dependency information, and thus do not compile. For example, Java snippets usually do not have import statements or required library names; only 6.88% of Java snippets on Stack Overflow include import statements necessary for compilation. This paper proposes SnR, a precise, efficient, constraint-based technique to automatically infer the exact types used in code snippets and the libraries containing the inferred types, to compile and therefore reuse the code snippets. Initially, SnR builds a knowledge base of APIs, i.e., various facts about the available APIs, from a corpus of Java libraries. Given a code snippet with missing import statements, SnR automatically extracts typing constraints from the snippet, solves the constraints against the knowledge base, and returns a set of APIs that satisfies the constraints to be imported into the snippet. We have evaluated SnR on a benchmark of 267 code snippets from Stack Overflow. SnR significantly outperforms the state-of-the-art tool Coster. SnR correctly infers 91.0% of the import statements, which makes 73.8% of the snippets compile, compared to 36.0% of the import statements and 9.0% of the snippets by Coster.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510061,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794034,type inference;constraint satisfaction;automated repair;datalog,Productivity;Java;Codes;Knowledge based systems;Transforms;Benchmark testing;Maintenance engineering,,1,,44,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models,T. Ahmed; S. Ghosh; C. Bansal; T. Zimmermann; X. Zhang; S. Rajmohan,UC Davis; Microsoft; Microsoft; Microsoft Research; Microsoft; Microsoft,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1737,1749,"Incident management for cloud services is a complex process involving several steps and has a huge impact on both service health and developer productivity. On-call engineers require significant amount of domain knowledge and manual effort for root causing and mitigation of production incidents. Recent advances in artificial intelligence has resulted in state-of-the-art large language models like GPT-3.x (both GPT-3.0 and GPT-3.5), which have been used to solve a variety of problems ranging from question answering to text summarization. In this work, we do the first large-scale study to evaluate the effectiveness of these models for helping engineers root cause and mitigate production incidents. We do a rigorous study at Microsoft, on more than 40,000 incidents and compare several large language models in zero-shot, fine-tuned and multi-task setting using semantic and lexical metrics. Lastly, our human evaluation with actual incident owners show the efficacy and future potential of using artificial intelligence for resolving cloud incidents.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00149,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172904,Incident Management;Service Quality;GPT-3.x;Large Language Models,Productivity;Knowledge engineering;Semantics;Manuals;Multitasking;Question answering (information retrieval);Distance measurement,,21,,65,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Towards Causal Deep Learning for Vulnerability Detection,M. Rahman; I. Ceka; C. Mao; S. Chakraborty; B. Ray; W. Le,"Iowa State University, Ames, IA, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Microsoft Research, Redmond, WA, USA; Columbia University, New York, NY, USA; Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1888,1898,"Deep learning vulnerability detection has shown promising results in recent years. However, an important challenge that still blocks it from being very useful in practice is that the model is not robust under perturbation and it cannot generalize well over the out-of-distribution (OOD) data, e.g., applying a trained model to unseen projects in real world. We hypothesize that this is because the model learned non-robust features, e.g., variable names, that have spurious correlations with labels. When the perturbed and OOD datasets no longer have the same spurious features, the model prediction fails. To address the challenge, in this paper, we introduced causality into deep learning vulnerability detection. Our approach CausalVul consists of two phases. First, we designed novel perturbations to discover spurious features that the model may use to make predictions. Second, we applied the causal learning algorithms, specifically, do-calculus, on top of existing deep learning models to systematically remove the use of spurious features and thus promote causal based prediction. Our results show that CausalVul consistently improved the model accuracy, robustness and OOD performance for all the state-of-the-art models and datasets we experimented. To the best of our knowledge, this is the first work that introduces do calculus based causal learning to software engineering models and shows it's indeed useful for improving the model accuracy, robustness and generalization. Our replication package is located at https://figshare.com/s/0ffda320dcb96c24gef2.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639170,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549636,vulnerability detection;causality;spurious features,Deep learning;Knowledge engineering;Correlation;Perturbation methods;Predictive models;Prediction algorithms;Feature extraction,,1,,27,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
On Calibration of Pretrained Code Models,Z. Zhou; C. Sha; X. Peng,"School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,931,943,"Pretrained code models have achieved notable success in the field of Software Engineering (SE). However, existing studies have pre-dominantly focused on improving model performance, with limited attention given to other critical aspects such as model calibration. Model calibration, which refers to the accurate estimation of predictive uncertainty, is a vital consideration in practical applications. Therefore, in order to advance the understanding of model cali-bration in SE, we conduct a comprehensive investigation into the calibration of pretrained code models in this paper. Our inves-tigation focuses on five pretrained code models and four code understanding tasks, including analyses of calibration in both in-distribution and out-of-distribution settings. Several key insights are uncovered: (1) pretrained code models may suffer from the issue of over-confidence; (2) temperature scaling and label smoothing are effective in calibrating code models in in-distribution data; (3) the issue of over-confidence in pretrained code models worsens in different out-of-distribution settings, and the effectiveness of temperature scaling and label smoothing diminishes. All materi-als used in our experiments are available at https://github.com/queserasera22/Calibration-of-Pretrained-Code-Models.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639126,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549419,Pretrained Code Models;Model Calibration;Model Reliability,Temperature distribution;Codes;Smoothing methods;Uncertainty;Reliability engineering;Data models;Calibration,,,,52,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Partial models: Towards modeling and reasoning with uncertainty,M. Famelis; R. Salay; M. Chechik,"University of Toronto, Canada; University of Toronto, Canada; University of Toronto, Canada",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,573,583,"Models are good at expressing information about software but not as good at expressing modelers' uncertainty about it. The highly incremental and iterative nature of software development nonetheless requires the ability to express uncertainty and reason with models containing it. In this paper, we build on our earlier work on expressing uncertainty using partial models, by elaborating an approach to reasoning with such models. We evaluate our approach by experimentally comparing it to traditional strategies for dealing with uncertainty as well as by conducting a case study using open source software. We conclude that we are able to reap the benefits of well-managed uncertainty while incurring minimal additional cost.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227159,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227159,,Uncertainty;Unified modeling language;Cognition;Finishing;Vocabulary;Encoding;Software,,77,,27,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
AidUI: Toward Automated Recognition of Dark Patterns in User Interfaces,S. M. Hasan Mansur; S. Salma; D. Awofisayo; K. Moran,"Department of Computer Science, George Mason University, Fairfax, VA; Department of Computer Science, George Mason University, Fairfax, VA; Department of Computer, Science Duke University, Durham, NC; Department of Computer Science, George Mason University, Fairfax, VA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1958,1970,"Past studies have illustrated the prevalence of UI dark patterns, or user interfaces that can lead end-users toward (unknowingly) taking actions that they may not have intended. Such deceptive UI designs can be either intentional (to benefit an online service) or unintentional (through complicit design practices) and can result in adverse effects on end users, such as oversharing personal information or financial loss. While significant research progress has been made toward the development of dark pattern taxonomies across different software domains, developers and users currently lack guidance to help recognize, avoid, and navigate these often subtle design motifs. However, automated recognition of dark patterns is a challenging task, as the instantiation of a single type of pattern can take many forms, leading to significant variability. In this paper, we take the first step toward understanding the extent to which common UI dark patterns can be automatically recognized in modern software applications. To do this, we introduce AidUI, a novel automated approach that uses computer vision and natural language processing techniques to recognize a set of visual and textual cues in application screenshots that signify the presence of ten unique UI dark patterns, allowing for their detection, classification, and localization. To evaluate our approach, we have constructed ContextDP, the current largest dataset of fully-localized UI dark patterns that spans 175 mobile and 83 web UI screenshots containing 301 dark pattern instances. The results of our evaluation illustrate that AidUI achieves an overall precision of 0.66, recall of 0.67, F1-score of 0.65 in detecting dark pattern instances, reports few false positives, and is able to localize detected patterns with an IoU score of 0.84. Furthermore, a significant subset of our studied dark patterns can be detected quite reliably (F1 score of over 0.82), and future research directions may allow for improved detection of additional patterns. This work demonstrates the plausibility of developing tools to aid developers in recognizing and appropriately rectifying deceptive UI patterns.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00166,"NSF(grant numbers:CCF-2132285,CCF-1955853); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172754,Dark Pattern;UI Analysis;UI Design,Location awareness;Visualization;Navigation;Taxonomy;User interfaces;Software;Pattern recognition,,5,,59,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Motorease: Automated Detection of Motor Impairment Accessibility Issues in Mobile App UIs,A. Krishnavajjala; S. H. Mansur; J. Jose; K. Moran,"George Mason University, Farifax, VA, USA; George Mason University, Fairfax, VA, USA; South Lakes High School, Reston, VA, USA; University of Central FL, Orlando, FL, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2580,2592,"Recent research has begun to examine the potential of automatically finding and fixing accessibility issues that manifest in software. However, while recent work makes important progress, it has generally been skewed toward identifying issues that affect users with certain disabilities, such as those with visual or hearing impairments. However there are other groups of users with different types of disabilities that also need software tooling support to improve their experience. As such, this paper aims to automatically identify accessibility issues that affect users with motor-impairments. To move toward this goal, this paper introduces a novel approach, called Motorease, capable of identifying accessibility issues in mobile app UIs that impact motor-impaired users. Motor-impaired users often have limited ability to interact with touch-based devices, and instead may make use of a switch or other assistive mechanism - hence UIs must be designed to support both limited touch gestures and the use of assistive devices. Motorease adapts computer vision and text processing techniques to enable a semantic understanding of app UI screens, enabling the detection of violations related to four popular, previously unexplored UI design guidelines that support motor-impaired users, including: (i) visual touch target size, (ii) expanding sections, (iii) persisting elements, and (iv) adjacent icon visual distance. We evaluate Motorease on a newly derived benchmark, called Motorcheck, that contains 555 manually annotated examples of violations to the above accessibility guidelines, across 1599 screens collected from 70 applications via a mobile app testing tool. Our experiments illustrate that Motorease is able to identify violations with an average accuracy of ≈90%, and a false positive rate of less than 9%, outperforming baseline techniques.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639167,"NSF(grant numbers:CCF-1955853,CNS-2132285); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548877,accessibility;mobile apps;screen understanding,Visualization;Design methodology;Semantics;Switches;Motors;Software;Mobile applications,,,,94,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
TRACED: Execution-Aware Pre-Training for Source Code,Y. Ding; B. Steenhoek; K. Pei; G. Kaiser; W. Le; B. Ray,"Columbia University, New York, NY, USA; Iowa State University, Ames, IA, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Iowa State University, Ames, IA, USA; Columbia University, New York, NY, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,416,427,"Most existing pretrained language models for source code focus on learning the static code text, typically augmented with static code structures (abstract syntax tree, dependency graphs, etc.). However, program semantics will not be fully exposed before the real execution. Without an understanding of the program execution, statically pretrained models fail to comprehensively capture the dynamic code properties, such as the branch coverage and the runtime variable values, and they are consequently less effective at code understanding tasks, such as retrieving semantic clones and detecting software vulnerabilities. To close the gap between the static nature of language models and the dynamic characteristics of programs, we introduce TRACED, an execution-aware pretraining strategy for source code. Specifically, we pretrain code language models with a combination of source code, executable inputs, and corresponding execution traces. Our goal is to teach code models the complicated execution logic during the pretraining, enabling the model to statically es-timate the dynamic code properties without repeatedly executing code during task-specific fine-tuning. To illustrate the effectiveness of our proposed approach, we fine-tune and evaluate TRACED on three downstream tasks: static execution estimation, clone retrieval, and vulnerability detection. The empirical results show that TRACED relatively improves the statically pretrained code models by 12.4% for complete execution path prediction and by 25.2% for runtime variable value predictions. TRACED also significantly outperforms statically pretrained models in clone retrieval and vulnerability detection across four public benchmarks.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3608140,"NSF(grant numbers:CCF-2313054,CCF-2313055,CCF-1815494,CCF-210740,CCF-1845893,IIS-2221943); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549736,,Codes;Runtime;Source coding;Semantics;Cloning;Syntactics;Predictive models,,2,,55,,14 Jun 2024,,,IEEE,IEEE Conferences,True
DEAR: A Novel Deep Learning-based Approach for Automated Program Repair,Y. Li; S. Wang; T. N. Nguyen,"New Jersey Inst. of Technology, New Jersey, USA; New Jersey Inst. of Technology, New Jersey, USA; University of Texas, Dallas, Texas, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,511,523,"The existing deep learning (DL)-based automated program repair (APR) models are limited in fixing general software defects. We present DEAR, a DL-based approach that supports fixing for the general bugs that require dependent changes at once to one or mul-tiple consecutive statements in one or multiple hunks of code. We first design a novel fault localization (FL) technique for multi-hunk, multi-statement fixes that combines traditional spectrum-based (SB) FL with deep learning and data-flow analysis. It takes the buggy statements returned by the SBFL model, detects the buggy hunks to be fixed at once, and expands a buggy statement $s$ in a hunk to include other suspicious statements around s. We design a two-tier, tree-based LSTM model that incorporates cycle training and uses a divide-and-conquer strategy to learn proper code transformations for fixing multiple statements in the suitable fixing context consisting of surrounding subtrees. We conducted several experiments to evaluate DEAR on three datasets: Defects4J (395 bugs), BigFix (+26k bugs), and CPatMiner (+44k bugs). On Defects4J dataset, DEAR outperforms the baselines from 42%-683% in terms of the number of auto-fixed bugs with only the top-1 patches. On BigFix dataset, it fixes 31–145 more bugs than existing DL-based APR models with the top-1 patches. On CPatMiner dataset, among 667 fixed bugs, there are 169 (25.3%) multi-hunk/multi-statement bugs. DEAR fixes 71 and 164 more bugs, including 52 and 61 more multi-hunk/multi-statement bugs, than the state-of-the-art, DL-based APR models.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793900,Automated Program Repair;Deep Learning;Fault Localization,Deep learning;Training;Location awareness;Analytical models;Codes;Computer bugs;Maintenance engineering,,16,,45,,20 Jun 2022,,,IEEE,IEEE Conferences,True
RUNNER: Responsible UNfair NEuron Repair for Enhancing Deep Neural Network Fairness,T. Li; Y. Cao; J. Zhang; S. Zhao; Y. Huang; A. Liu; Q. Guo; Y. Liu,"Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Beihang University, China; Institute of High Performance Computing (IHPC), Centre for Frontier AI Research (CFAR), A*STAR, Singapore; Nanyang Technological University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,77,89,"Deep Neural Networks (DNNs), an emerging software technology, have achieved impressive results in a variety of fields. However, the discriminatory behaviors towards certain groups (a.k.a. unfairness) of DNN models increasingly become a social concern, especially in high-stake applications such as loan approval and criminal risk assessment. Although there has been a number of works to improve model fairness, most of them adopt an adversary to either expand the model architecture or augment training data, which introduces excessive computational overhead. Recent work diagnoses responsible unfair neurons first and fixes them with selective retraining. Unfortunately, existing diagnosis process is time-consuming due to multi-step training sample analysis, and selective retraining may cause a performance bottleneck due to indirectly adjusting unfair neurons on biased samples. In this paper, we propose Responsible UNfair NEuron Repair (RUNNER) that improves existing works in three key aspects: (1) efficiency: we design the Importance-based Neuron Diagnosis that identifies responsible unfair neurons in one step with a novel importance criterion of neurons; (2) effectiveness: we design the Neuron Stabilizing Retraining by adding a loss term that measures the activation distance of responsible unfair neurons from different subgroups in all sources; (3) generalization: we investigate the effectiveness on both structured tabular data and large-scale unstructured image data, which is often ignored in prior studies. Our extensive experiments across 5 datasets show that RUUNER can effectively and efficiently diagnose and repair the DNNs regarding unfairness. On average, our approach significantly reduces computing overhead from 341.7s to 29.65s, and achieves improved fairness up to 79.3%. Besides, RUNNER also keeps state-of-the-art results on the unstructured dataset.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623334,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548361,Deep Learning Repair;Fairness;Model Interpretation,Training;Computational modeling;Neurons;Training data;Artificial neural networks;Maintenance engineering;Loss measurement,,,,70,,14 Jun 2024,,,IEEE,IEEE Conferences,True
MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks,S. Cao; X. Sun; L. Bo; R. Wu; B. Li; C. Tao,"Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Xiamen University, Xiamen, China; Yangzhou University, Yangzhou, China; Nanjing University of Aeronautics and Astronautics, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1456,1468,"Memory-related vulnerabilities constitute severe threats to the security of modern software. Despite the success of deep learning-based approaches to generic vulnerability detection, they are still limited by the underutilization of flow information when applied for detecting memory-related vulnerabilities, leading to high false positives. In this paper, we propose MVD, a statement-level Memory-related Vulnerability Detection approach based on flow-sensitive graph neural networks (FS-GNN). FS-GNN is employed to jointly embed both unstructured information (i.e., source code) and structured information (i.e., control- and data-flow) to capture implicit memory-related vulnerability patterns. We evaluate MVD on the dataset which contains 4,353 real-world memory-related vulnerabilities, and compare our approach with three state-of-the-art deep learning-based approaches as well as five popular static analysis-based memory detectors. The experiment results show that MVD achieves better detection accuracy, outperforming both state-of-the-art DL-based and static analysis-based approaches. Furthermore, MVD makes a great trade-off between accuracy and efficiency.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510219,"National Natural Science Foundation of China(grant numbers:61872312,61972335,62002309,61902329); Six Talent Peaks Project in Jiangsu Province(grant numbers:RJFW-053); Nanjing University(grant numbers:KFKT2020B15,KFKT2020B16); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794007,Memory-Related Vulnerability;Vulnerability Detection;Graph Neural Networks;Flow Analysis,Analytical models;Codes;Semantics;Detectors;Graph neural networks;Software;Security,,33,,72,,20 Jun 2022,,,IEEE,IEEE Conferences,True
DeepDiagnosis: Automatically Diagnosing Faults and Recommending Actionable Fixes in Deep Learning Programs,M. Wardat; B. D. Cruz; W. Le; H. Rajan,"Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,561,572,"Deep Neural Networks (DNNs) are used in a wide variety of applications. However, as in any software application, DNN-based apps are afflicted with bugs. Previous work observed that DNN bug fix patterns are different from traditional bug fix patterns. Furthermore, those buggy models are non-trivial to diagnose and fix due to inexplicit errors with several options to fix them. To support developers in locating and fixing bugs, we propose DeepDiagnosis, a novel debugging approach that localizes the faults, reports error symptoms and suggests fixes for DNN programs. In the first phase, our technique monitors a training model, periodically checking for eight types of error conditions. Then, in case of problems, it reports messages containing sufficient information to perform actionable repairs to the model. In the evaluation, we thoroughly examine 444 models - 53 real-world from GitHub and Stack Overflow, and 391 curated by AUTOTRAINER. DeepDiagnosis provides superior accuracy when compared to UMLUAT and DeepLocalize. Our technique is faster than AUTOTRAINER for fault localization. The results show that our approach can support additional types of models, while state-of-the-art was only able to handle classification ones. Our technique was able to report bugs that do not manifest as numerical errors during training. Also, it can provide actionable insights for fix whereas DeepLocalize can only report faults that lead to numerical errors during training. DeepDiagnosis manifests the best capabilities of fault detection, bug localization, and symptoms identification when compared to other approaches.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510071,"National Science Foundation(grant numbers:CNS-21-20448,CCF-19-34884); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794035,deep neural networks;fault location;debugging;program analysis;deep learning bugs,Training;Location awareness;Deep learning;Computer bugs;Neural networks;Software;Numerical models,,11,,49,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study,Q. Guo; J. Cao; X. Xie; S. Liu; X. Li; B. Chen; X. Peng,"Tianjin University, Tianjin, China; Fudan University, Shanghai, China; Singapore Management University, Singapore; Nanyang Technological University, Singapore; Tianjin University, Tianjin, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,390,402,"Code review is an essential activity for ensuring the quality and maintainability of software projects. However, it is a time-consuming and often error-prone task that can significantly impact the development process. Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive performance in various natural language processing tasks, suggesting its potential to automate code review processes. However, it is still unclear how well ChatGPT performs in code review tasks. To fill this gap, in this paper, we conduct the first empirical study to understand the capabilities of ChatGPT in code review tasks, specifically focusing on automated code refinement based on given code reviews. To conduct the study, we select the existing benchmark CodeReview and construct a new code review dataset with high quality. We use CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison with ChatGPT. Our results show that ChatGPT outperforms CodeRe-viewer in code refinement tasks. Specifically, our results show that ChatGPT achieves higher EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art method achieves only 15.50 and 62.88 on a high-quality code review dataset. We further identify the root causes for ChatGPT's underperformance and propose several strategies to mitigate these challenges. Our study provides insights into the potential of ChatGPT in automating the code review process, and highlights the potential research directions.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623306,National Key R&D Project(grant numbers:2021YFF1201102); National Natural Science Foundation of China(grant numbers:61872262); National Research Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548119,Automating Code Review;Activities Automated Code Refinement;ChatGPT Empirical Study,Codes;Reviews;Focusing;Benchmark testing;Chatbots;Software;Task analysis,,6,,46,,14 Jun 2024,,,IEEE,IEEE Conferences,True
SAPIENTML: Synthesizing Machine Learning Pipelines by Learning from Human-Written Solutions,R. K. Saha; A. Ura; S. Mahajan; C. Zhu; L. Li; Y. Hu; H. Yoshida; S. Khurshid; M. R. Prasad,"Fujitsu Research of America, Inc.; Fujitsu Ltd.; Fujitsu Research of America, Inc.; The University of Texas at Austin; University of Illinois at Urbana-Champaign; The University of Texas at Austin; Fujitsu Research of America, Inc.; The University of Texas at Austin; Fujitsu Research of America, Inc.",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1932,1944,"Automatic machine learning, or AutoML, holds the promise of truly democratizing the use of machine learning (ML), by substantially automating the work of data scientists. However, the huge combinatorial search space of candidate pipelines means that current AutoML techniques, generate sub-optimal pipelines, or none at all, especially on large, complex datasets. In this work we propose an AutoML technique SapientML, that can learn from a corpus of existing datasets and their human-written pipelines, and efficiently generate a high-quality pipeline for a predictive task on a new dataset. To combat the search space explosion of AutoML, SapientML employs a novel divide-and-conquer strategy realized as a three-stage program synthesis approach, that reasons on successively smaller search spaces. The first stage uses meta-learning to predict a set of plausible ML components to constitute a pipeline. In the second stage, this is then refined into a small pool of viable concrete pipelines using a pipeline dataflow model derived from the corpus. Dynamically evaluating these few pipelines, in the third stage, provides the best solution. We instantiate SapientML as part of a fully automated tool-chain that creates a cleaned, labeled learning corpus by mining Kaggle, learns from it, and uses the learned models to then synthesize pipelines for new predictive tasks. We have created a training corpus of 1,094 pipelines spanning 170 datasets, and evaluated SapientML on a set of 41 benchmark datasets, including 10 new, large, real-world datasets from Kaggle, and against 3 state-of-the-art AutoML tools and 4 baselines. Our evaluation shows that SapientML produces the best or comparable accuracy on 27 of the benchmarks while the second best tool fails to even produce a pipeline on 9 of the instances. This difference is amplified on the 10 most challenging benchmarks, where SapientML wins on 9 instances with the other tools failing to produce pipelines on 4 or more benchmarks.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510226,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794084,Program Synthesis;Machine Learning;AutoML;Program Analysis,Training;Pipelines;Machine learning;Benchmark testing;Predictive models;Explosions;Data mining,,1,,52,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Muffin: Testing Deep Learning Libraries via Neural Architecture Fuzzing,J. Gu; X. Luo; Y. Zhou; X. Wang,"Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1418,1430,"Deep learning (DL) techniques are proven effective in many chal-lenging tasks, and become widely-adopted in practice. However, previous work has shown that DL libraries, the basis of building and executing DL models, contain bugs and can cause severe con-sequences. Unfortunately, existing testing approaches still cannot comprehensively exercise DL libraries. They utilize existing trained models and only detect bugs in model inference phase. In this work we propose Muffin to address these issues. To this end, Muffin applies a specifically-designed model fuzzing approach, which al-lows it to generate diverse DL models to explore the target library, instead of relying only on existing trained models. Muffin makes differential testing feasible in the model training phase by tailoring a set of metrics to measure the inconsistencies between different DL libraries. In this way, Muffin can best exercise the library code to detect more bugs. To evaluate the effectiveness of Muffin, we conduct experiments on three widely-used DL libraries. The results demonstrate that Muffin can detect 39 new bugs in the latest release versions of popular DL libraries, including Tensorflow, CNTK, and Theano.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510092,National Key R&D Program of China(grant numbers:2020YFA0711400); Natural Science Foundation of Shanghai(grant numbers:22ZR1407900); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793922,Deep Learning Testing;Library Testing;Model Generation;Fuzzing,Training;Deep learning;Phase measurement;Codes;Computer bugs;Fuzzing;Libraries,,9,,55,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries,Y. Deng; C. S. Xia; C. Yang; S. D. Zhang; S. Yang; L. Zhang,"University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,841,853,"Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TITANFUZZ work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries (and beyond). However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive pretraining corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced. To fill this gap, this paper proposes FuzzGPT, the first approach to priming LLMs to synthesize unusual programs for fuzzing. Fuz-zGPT is mainly built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/ semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and Codegen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruction-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TITANFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623343,"NSF(grant numbers:CCF-2131943,CCF-2141474); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548124,,Deep learning;Image edge detection;Computer bugs;Semantics;Fuzzing;Chatbots;Libraries,,1,,87,,14 Jun 2024,,,IEEE,IEEE Conferences,True
ReClues: Representing and Indexing Failures in Parallel Debugging with Program Variables,Y. Song; X. Zhang; X. Xie; Q. Liu; R. Gao; C. Xing,"School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; Sonos Inc., Santa Barbara, USA; School of Computer Science, Wuhan University, Wuhan, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1359,1371,"Failures with different root causes can greatly disrupt multi-fault localization, therefore, categorizing failures into distinct groups according to the culprit fault is highly important. In such a failure indexing task, the crux lies in the failure proximity, which comprises two points, i.e., how to effectively represent failures (e.g., extract the signature of failures) and how to properly measure the distance between those proxies for failures. Existing research has proposed a variety of failure proximities. The majority of them extract signatures of failures from execution coverage or suspiciousness ranking lists, and accordingly employ the Euclid or the Kendall tau distances, etc. However, such strategies may not properly reflect the essential characteristics of failures, thus resulting in unsatisfactory effectiveness. In this paper, we propose a new failure proximity, namely, the program variable-based failure proximity, and further present a novel failure indexing approach, ReClues. Specifically, ReClues utilizes the run-time values of program variables to represent failures, and designs a set of rules to measure the similarity between them. Experimental results demonstrate the competitiveness of ReClues: it can achieve 44.12% and 27.59% improvements in faults number estimation, as well as 47.56% and 26.27% improvements in clustering effectiveness, compared with the state-of-the-art technique in this field, in simulated and real-world environments, respectively.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639098,"National Natural Science Foundation of China(grant numbers:62250610224,61972289,61832009); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549232,Failure proximity;Clustering;Failure indexing;Parallel debugging;Program variable,Measurement;Location awareness;Deep learning;Estimation;Debugging;Fingerprint recognition;Benchmark testing,,,,87,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Hard to Read and Understand Pythonic Idioms? Deldiom and Explain Them in Non-Idiomatic Equivalent Code,Z. Zhang; Z. Xing; D. Zhao; Q. Lu; X. Xu; L. Zhu,"Australian National University & CSIRO's Data61, Canberra, Australia; CSIRO's Data61 & Australian, National University, Canberra, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2808,2819,"The Python community strives to design pythonic idioms so that Python users can achieve their intent in a more concise and efficient way. According to our analysis of 154 questions about challenges of understanding pythonic idioms on Stack Overflow, we find that Python users face various challenges in comprehending pythonic idioms. And the usage of pythonic idioms in 7,577 GitHub projects reveals the prevalence of pythonic idioms. By using a statistical sampling method, we find pythonic idioms result in not only lexical conciseness but also the creation of variables and functions, which indicates it is not straightforward to map back to non-idiomatic code. And usage of pythonic idioms may even cause potential negative effects such as code redundancy, bugs and performance degradation. To alleviate such readability issues and negative effects, we develop a transforming tool, DeIdiom, to automatically transform idiomatic code into equivalent non-idiomatic code. We test and review over 7,572 idiomatic code instances of nine pythonic idioms (list/set/diet-comprehension, chain-comparison, truth-value-test, loop-else, assign-multi-targets, for-multi-targets, star), the result shows the high accuracy of DeIdiom. Our user study with 20 partici-pants demonstrates that explanatory non-idiomatic code generated by DeIdiom is useful for Python users to understand pythonic idioms correctly and efficiently, and leads to a more positive appre-ciation of pythonic idioms.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549697,Pythonic Idioms;Code Transformation;Program Comprehension,Codes;Reviews;Redundancy;Stars;Transforms;Sampling methods;Faces,,,,52,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
VarCLR: Variable Semantic Representation Pre-training via Contrastive Learning,Q. Chen; J. Lacomis; E. J. Schwartz; G. Neubig; B. Vasilescu; C. L. Goues,Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University Software Engineering Institute; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2327,2339,"Variable names are critical for conveying intended program behavior. Machine learning-based program analysis methods use variable name representations for a wide range of tasks, such as suggesting new variable names and bug detection. Ideally, such methods could capture semantic relationships between names beyond syntactic similarity, e.g., the fact that the names average and mean are similar. Unfortunately, previous work has found that even the best of previous representation approaches primarily capture “relatedness” (whether two variables are linked at all), rather than “similarity” (whether they actually have the same meaning). We propose Varclr, a new approach for learning semantic representations of variable names that effectively captures variable similarity in this stricter sense. We observe that this problem is an excellent fit for contrastive learning, which aims to minimize the distance between explicitly similar inputs, while maximizing the distance between dissimilar inputs. This requires labeled training data, and thus we construct a novel, weakly-supervised variable renaming dataset mined from GitHub edits. We show that Varclr enables the effective application of sophisticated, general-purpose language models like BERT, to variable name representation and thus also to related downstream tasks like variable name similarity search or spelling correction. Varclr produces models that significantly outperform the state-of-the-art on IDBENCH, an existing benchmark that explicitly captures variable similarity (as distinct from relatedness). Finally, we contribute a release of all data, code, and pre-trained models, aiming to provide a drop-in replacement for variable representations used in either existing or future program analyses that rely on variable names.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510162,"National Science Foundation(grant numbers:1815287,1910067); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793917,,Codes;Semantics;Computer bugs;Bit error rate;Training data;Syntactics;Data models,,10,,88,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
Coca: Improving and Explaining Graph Neural Network-Based Vulnerability Detection Systems,S. Cao; X. Sun; X. Wu; D. Lo; L. Bo; B. Li; W. Liu,"Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Singapore Management University, Singapore; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1911,1923,"Recently, Graph Neural Network (GNN)-based vulnerability detection systems have achieved remarkable success. However, the lack of explainability poses a critical challenge to deploy black-box models in security-related domains. For this reason, several approaches have been proposed to explain the decision logic of the detection model by providing a set of crucial statements positively contributing to its predictions. Unfortunately, due to the weakly-robust detection models and suboptimal explanation strategy, they have the danger of revealing spurious correlations and redundancy issue. In this paper, we propose Coca, a general framework aiming to 1) enhance the robustness of existing GNN-based vulnerability detection models to avoid spurious explanations; and 2) provide both concise and effective explanations to reason about the detected vulnerabilities. Coca consists of two core parts referred to as Trainer and Explainer. The former aims to train a detection model which is robust to random perturbation based on combina-torial contrastive learning, while the latter builds an explainer to derive crucial code statements that are most decisive to the detected vulnerability via dual-view causal inference as explanations. We apply Coca over three typical GNN-based vulnerability detectors. Experimental results show that Coca can effectively mitigate the spurious correlation issue, and provide more useful high-quality explanations.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639168,"National Natural Science Foundation of China(grant numbers:62202414,61972335,62002309); Six Talent Peaks Project in Jiangsu Province(grant numbers:RJFW-053); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548474,Contrastive Learning;Causal Inference;Explainability,Correlation;Codes;Perturbation methods;Redundancy;Detectors;Predictive models;Robustness,,,,83,,14 Jun 2024,,,IEEE,IEEE Conferences,True
MAFT: Efficient Model-Agnostic Fairness Testing for Deep Neural Networks via Zero-Order Gradient Search,Z. Wang; M. Zhang; J. Yang; B. Shao; M. Zhang,"East China Normal University; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University; East China Normal University; East China Normal University; East China Normal University",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1484,1495,"Deep neural networks (DNNs) have shown powerful performance in various applications and are increasingly being used in decision-making systems. However, concerns about fairness in DNNs always persist. Some efficient white-box fairness testing methods about individual fairness have been proposed. Nevertheless, the devel-opment of black-box methods has stagnated, and the performance of existing methods is far behind that of white-box methods. In this paper, we propose a novel black-box individual fairness testing method called Model-Agnostic Fairness Testing (MAFT). By leveraging MAFT, practitioners can effectively identify and address discrimination in DL models, regardless of the specific algorithm or architecture employed. Our approach adopts lightweight procedures such as gradient estimation and attribute perturbation rather than nontrivial procedures like symbol execution, rendering it significantly more scalable and applicable than existing methods. We demonstrate that MAFT achieves the same effectiveness as state-of-the-art white-box methods whilst improving the applicability to large-scale networks. Compared to existing black-box approaches, our approach demonstrates distinguished performance in discovering fairness violations w.r.t effectiveness (~ 14.69X) and efficiency (~ 32.58X).",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639181,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548533,software bias;fairness testing;test case generation;deep neural network,Gradient methods;Perturbation methods;Closed box;Symbols;Computer architecture;Artificial neural networks;Rendering (computer graphics),,,,51,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Neural Program Repair with Execution-based Backpropagation,H. Ye; M. Martinez; M. Monperrus,"KTH Royal Institute of Technology, Sweden; Université Polytechnique, France; KTH Royal Institute of Technology, Sweden",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1506,1518,"Neural machine translation (NMT) architectures have achieved promising results for automatic program repair. Yet, they have the limitation of generating low-quality patches (e.g., not compilable patches). This is because the existing works only optimize a purely syntactic loss function based on characters and tokens without incorporating program-specific information during neural network weight optimization. In this paper, we propose a novel program repair model called RewardRepair. The core novelty of RewardRepair is to improve NMT-based program repair with a loss function based on program compilation and test execution information, rewarding the network to produce patches that compile and that do not overfit. We conduct several experiments to evaluate RewardRepair showing that it is feasible and effective to use compilation and test execution results to optimize the underlying neural repair model. RewardRepair correctly repairs 207 bugs over four benchmarks. we report on repair success for 121 bugs that are fixed for the first time in the literature. Also, RewardRepair produces up to 45.3% of compilable patches, an improvement over the 39% by the state-of-the-art.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510222,Knut and Alice Wallenberg Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793856,automated program repair,Backpropagation;Training;Computer bugs;Semantics;Neural networks;Maintenance engineering;Syntactics,,36,,76,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
Template-based Neural Program Repair,X. Meng; X. Wang; H. Zhang; H. Sun; X. Liu; C. Hu,"SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; Chongqing University, Chongqing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1456,1468,"In recent years, template-based and NMT-based automated program repair methods have been widely studied and achieved promising results. However, there are still disadvantages in both methods. The template-based methods cannot fix the bugs whose types are beyond the capabilities of the templates and only use the syntax information to guide the patch synthesis, while the NMT-based methods intend to generate the small range of fixed code for better performance and may suffer from the OOV (Out-of-vocabulary) problem. To solve these problems, we propose a novel template-based neural program repair approach called TENURE to combine the template-based and NMT- based methods. First, we build two large-scale datasets for 35 fix templates from template-based method and one special fix template (single-line code generation) from NMT-based method, respectively. Second, the encoder-decoder models are adopted to learn deep semantic features for generating patch intermediate representations (IRs) for different templates. The optimized copy mechanism is also used to alleviate the OOV problem. Third, based on the combined patch IRs for different templates, three tools are developed to recover real patches from the patch IRs, replace the unknown tokens, and filter the patch candidates with compilation errors by leveraging the project-specific information. On Defects4J-vl.2, TENURE can fix 79 bugs and 52 bugs with perfect and Ochiai fault localization, respectively. It is able to repair 50 and 32 bugs as well on Defects4J-v2.0. Compared with the existing template-based and NMT-based studies, TENURE achieves the best performance in all experiments.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172686,automated program repair;fix templates;neural machine translation;deep learning,Location awareness;Codes;Source coding;Computer bugs;Semantics;Maintenance engineering;Benchmark testing,,6,,55,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Towards Automatically Repairing Compatibility Issues in Published Android Apps,Y. Zhao; L. Li; K. Liu; J. Grundy,"Monash University, Melbourne, Australia; Monash University, Melbourne, Australia; Huawei, Hangzhou, China; Monash University, Melbourne, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2142,2153,"The heavy fragmentation of the Android ecosystem has led to se-vere compatibility issues with apps, including those that crash at runtime or cannot be installed on certain devices but work well on other devices. To address this problem, various approaches have been proposed to detect and fix compatibility issues automatically. However, these all come with various limitations on fixing the com-patibility issues, e.g., can only fix one specific type of issues, cannot deal with multi-invocation issues in a single line and issues in re-leased apps. To overcome these limitations, we propose a generic approach that aims at fixing more types of compatibility issues in released Android apps. To this end, our prototype tool, Repair-Droid, provides a generic app patch description language for users to create fix templates for compatibility issues. The created tem-plates will then be leveraged by RepairDroid to automatically fix the corresponding issue at the bytecode level (e.g., right before users install the app). RepairDroid can support template creations for OS-induced, device-specific and inter-callback compatibility issues detected by three state-of-the-art approaches. Our experimental re-sults show that RepairDroid can fix 7,660 out of 8,976 compatibility issues in 1,000 randomly selected Google Play apps. RepairDroid is generic to configure new compatibility issues and outperforms the state-of-the-art on effectively repairing compatibility issues in released Android apps.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510128,"National Natural Science Foundation of China(grant numbers:62172214); National Key R&D Program of China(grant numbers:2020AAA0107704); Natural Science Foundation of Jiangsu Province, China(grant numbers:BK20210279); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794093,Android;Compatibility Issue;Automated Program Repair,Runtime;Operating systems;Ecosystems;Prototypes;Maintenance engineering;Computer crashes;Internet,,5,,58,,20 Jun 2022,,,IEEE,IEEE Conferences,True
ITER: Iterative Neural Repair for Multi-Location Patches,H. Ye; M. Monperrus,"Carnegie Mellon University, United States; KTH Royal Institute of Technology, Sweden",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,90,102,"Automated program repair (APR) has achieved promising results, especially using neural networks. Yet, the overwhelming majority of patches produced by APR tools are confined to one single location. When looking at the patches produced with neural repair, most of them fail to compile, while a few uncompilable ones go in the right direction. In both cases, the fundamental problem is to ignore the potential of partial patches. In this paper, we propose an iterative program repair paradigm called ITER founded on the concept of improving partial patches until they become plausible and correct. First, ITER iteratively improves partial single-location patches by fixing compilation errors and further refining the previously generated code. Second, ITER iteratively improves partial patches to construct multi-location patches, with fault localization re-execution. ITER is implemented for Java based on battle-proven deep neural networks and code representation. ITER is evaluated on 476 bugs from 10 open-source projects in Defects4J 2.0. ITER succeeds in repairing 15.5% of them, including 9 uniquely repaired multi-location bugs.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623337,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548352,,Location awareness;Java;Codes;Computer bugs;Refining;Artificial neural networks;Maintenance engineering,,2,,62,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Adhere: Automated Detection and Repair of Intrusive Ads,Y. Yan; Y. Zheng; X. Liu; N. Medvidovic; W. Wang,"University of Southern California, Los Angeles, CA, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; University at Buffalo, SUNY, Buffalo, NY, USA; University of Southern California, Los Angeles, CA, USA; University of Southern California, Los Angeles, CA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,486,498,"Today, more than 3 million websites rely on online advertising revenue. Despite the monetary incentives, ads often frustrate users by disrupting their experience, interrupting content, and slowing browsing. To improve ad experiences, leading media associations define Better Ads Standards for ads that are below user expectations. However, little is known about how well websites comply with these standards and whether existing approaches are sufficient for developers to quickly resolve such issues. In this paper, we propose Adhere, a technique that can detect intrusive ads that do not comply with Better Ads Standards and suggest repair proposals. Adhere works by first parsing the initial web page to a DOM tree to search for potential static ads, and then using mutation observers to monitor and detect intrusive (dynamic/static) ads on the fly. To handle ads' volatile nature, Adhere includes two detection algorithms for desktop and mobile ads to identify different ad violations during three phases of page load events. It recursively applies the detection algorithms to resolve nested layers of DOM elements inserted by ad delegations. We evaluate Adhere on Alexa Top 1 Million Websites. The results show that Adhere is effective in detecting violating ads and suggesting repair proposals. Comparing to the current available alternative, Adhere detected intrusive ads on 4,656 more mobile websites and 3,911 more desktop websites, and improved recall by 16.6% and accuracy by 4.2%.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00051,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172610,ad experience;advertising practice;Better Ads Standards,Virtual assistants;Web pages;Maintenance engineering;Observers;Media;Proposals;Detection algorithms,,1,,64,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
KnowLog: Knowledge Enhanced Pretrained Language Model for Log Understanding,L. Ma; W. Yang; B. Xu; S. Jiang; B. Fei; J. Liang; M. Zhou; Y. Xiao,"Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; School of Computer Science and Technology, Donghua University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; School of Data Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,365,377,"Logs as semi-structured text are rich in semantic information, making their comprehensive understanding crucial for automated log analysis. With the recent success of pretrained language models in natural language processing, many studies have leveraged these models to understand logs. Despite their successes, existing pretrained language models still suffer from three weaknesses. Firstly, these models fail to understand domain-specific terminol-ogy, especially abbreviations. Secondly, these models struggle to adequately capture the complete log context information. Thirdly, these models have difficulty in obtaining universal representations of different styles of the same logs. To address these challenges, we introduce KnowLog, a knowledge-enhanced pretrained language model for log understanding. Specifically, to solve the previous two challenges, we exploit abbreviations and natural language de-scriptions of logs from public documentation as local and global knowledge, respectively, and leverage this knowledge by designing novel pretraining tasks for enhancing the model. To solve the last challenge, we design a contrastive learning-based pretraining task to obtain universal representations. We evaluate KnowLog by fine-tuning it on six different log understanding tasks. Extensive experiments demonstrate that KnowLog significantly enhances log understanding and achieves state-of-the-art results compared to existing pretrained language models without knowledge enhancement. Moreover, we conduct additional experiments in transfer learning and low-resource scenarios, showcasing the substantial advantages of KnowLog. Our source code and detailed experimental data are available at https://github.com/LeaperOvO/KnowLog.",1558-1225,979-8-4007-0217-4,,National Key Research and Development Project(grant numbers:2020AAA0109302); National Natural Science Foundation of China(grant numbers:u2033209); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548568,pretrained language model;knowledge enhancement;log understanding,Knowledge engineering;Flowcharts;Source coding;Transfer learning;Semantics;Documentation;Natural language processing,,,,65,,14 Jun 2024,,,IEEE,IEEE Conferences,True
PyTy: Repairing Static Type Errors in Python,Y. W. Chow; L. Di Grazia; M. Pradel,"University of Stuttgart, Germany; University of Stuttgart, Germany; University of Stuttgart, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1058,1070,"Gradual typing enables developers to annotate types of their own choosing, offering a flexible middle ground between no type annotations and a fully statically typed language. As more and more code bases get type-annotated, static type checkers detect an increasingly large number of type errors. Unfortunately, fixing these errors requires manual effort, hampering the adoption of gradual typing in practice. This paper presents PyTy, an automated program repair approach targeted at statically detectable type errors in Python. The problem of repairing type errors deserves specific attention because it exposes particular repair patterns, offers a warning message with hints about where and how to apply a fix, and because gradual type checking serves as an automatic way to validate fixes. We addresses this problem through three contributions: (i) an empirical study that investigates how developers fix Python type errors, showing a diverse set of fixing strategies with some recurring patterns; (ii) an approach to automatically extract type error fixes, which enables us to create a dataset of 2,766 error-fix pairs from 176 GitHub repositories, named PyTyDefects; (iii) the first learning-based re-pair technique for fixing type errors in Python. Motivated by the relative data scarcity of the problem, the neural model at the core of PyTy is trained via cross-lingual transfer learning. Our evaluation shows that PyTy offers fixes for ten frequent categories of type errors, successfully addressing 85.4% of 281 real-world errors. This effectiveness outperforms state-of-the-art large language models asked to repair type errors (by 2.1x) and complements a previous technique aimed at type errors that manifest at runtime. Finally, 20 out of 30 pull requests with PyTy-suggested fixes have been merged by developers, showing the usefulness of PyTy in practice.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639184,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548748,Automatic Program Repair;Type Annotation;Transfer Learning,Deep learning;Runtime;Transfer learning;Manuals;Debugging;Maintenance engineering;Writing,,,,56,,14 Jun 2024,,,IEEE,IEEE Conferences,True
GrammarT5: Grammar-Integrated Pretrained Encoder-Decoder Neural Model for Code,Q. Zhu; Q. Liang; Z. Sun; Y. Xiong; L. Zhang; S. Cheng,"Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; Science & Technology on Integrated Information System Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; ZTE Corporation, Chengdu, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,918,930,"Pretrained models for code have exhibited promising performance across various code-related tasks, such as code summarization, code completion, code translation, and bug detection. However, despite their success, the majority of current models still represent code as a token sequence, which may not adequately capture the essence of the underlying code structure. In this work, we propose GrammarT5, a grammar-integrated encoder-decoder pretrained neural model for code. GrammarT5 employs a novel grammar-integrated representation, Tokenized Grammar Rule Sequence (TGRS), for code. TGRS is constructed based on the grammar rule sequence utilized in syntax-guided code generation and integrates syntax information with code tokens within an appropriate input length. Furthermore, we suggest at-taching language flags to help GrammarT5 differentiate between grammar rules of various programming languages. Finally, we in-troduce two novel pretraining tasks-Edge Prediction (EP), and Sub-Tree Prediction (STP) to learn syntactic information. Experiments were conducted on five code-related tasks using eleven datasets, demonstrating that GrammarT5 achieves state-of-the-art (SOTA) performance on most tasks in comparison to models of the same scale. Additionally, the paper illustrates that the proposed pretraining tasks and language flags can enhance GrammarT5 to better capture the syntax and semantics of code.",1558-1225,979-8-4007-0217-4,,"National Key Research and Development Program of China(grant numbers:2022YFB4501902); National Natural Science Foundation of China(grant numbers:62161146003,62232001,62232003); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549313,neural networks;pretrained model;text tagging,Computer languages;Codes;Semantics;Syntactics;Tagging;Predictive models;Transformers,,,,50,,14 Jun 2024,,,IEEE,IEEE Conferences,True
What Do They Capture? - A Structural Analysis of Pre-Trained Language Models for Source Code,Y. Wan; W. Zhao; H. Zhang; Y. Sui; G. Xu; H. Jin,"School of Computer Science and Technology, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China; University of Newcastle, Australia; School of Computer Science, University of Technology Sydney, Australia; School of Computer Science, University of Technology Sydney, Australia; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2377,2388,"Recently, many pre-trained language models for source code have been proposed to model the context of code and serve as a basis for downstream code intelligence tasks such as code completion, code search, and code summarization. These models leverage masked pre-training and Transformer and have achieved promising results. However, currently there is still little progress regarding interpretability of existing pre-trained code models. It is not clear why these models work and what feature correlations they can capture. In this paper, we conduct a thorough structural analysis aiming to provide an interpretation of pre-trained language models for source code (e.g., CodeBERT, and GraphCodeBERT) from three distinctive perspectives: (1) attention analysis, (2) probing on the word embedding, and (3) syntax tree induction. Through comprehensive analysis, this paper reveals several insightful findings that may inspire future studies: (1) Attention aligns strongly with the syntax structure of code. (2) Pre-training language models of code can preserve the syntax structure of code in the intermediate representations of each Transformer layer. (3) The pre-trained models of code have the ability of inducing syntax trees of code. Theses findings suggest that it may be helpful to incorporate the syntax structure of code into the process of pre-training for better code representations.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510050,National Natural Science Foundation of China(grant numbers:62102157); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794032,Code representation;deep learning;pre-trained language model;probing;attention analysis;syntax tree induction,Training;Representation learning;Analytical models;Codes;Correlation;Syntactics;Transformers,,14,,45,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Aries: Efficient Testing of Deep Neural Networks via Labeling-Free Accuracy Estimation,Q. Hu; Y. Guo; X. Xie; M. Cordy; M. Papadakis; L. Ma; Y. L. Traon,"University of Luxembourg, Luxembourg; Luxembourg Institute of Science and Technology, Luxembourg; Singapore Management University, Singapore; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Alberta, Canada; University of Luxembourg, Luxembourg",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1776,1787,"Deep learning (DL) plays a more and more important role in our daily life due to its competitive performance in industrial application domains. As the core of DL-enabled systems, deep neural networks (DNNs) need to be carefully evaluated to ensure the produced models match the expected requirements. In practice, the de facto standard to assess the quality of DNNs in the industry is to check their performance (accuracy) on a collected set of labeled test data. However, preparing such labeled data is often not easy partly because of the huge labeling effort, i.e., data labeling is labor-intensive, especially with the massive new incoming unlabeled data every day. Recent studies show that test selection for DNN is a promising direction that tackles this issue by selecting minimal representative data to label and using these data to assess the model. However, it still requires human effort and cannot be automatic. In this paper, we propose a novel technique, named Aries, that can estimate the performance of DNNs on new unlabeled data using only the information obtained from the original test data. The key insight behind our technique is that the model should have similar prediction accuracy on the data which have similar distances to the decision boundary. We performed a large-scale evaluation of our technique on two famous datasets, CIFAR-10 and Tiny-ImageNet, four widely studied DNN models including ResNetl0l and DenseNetl21, and 13 types of data transformation methods. Results show that the estimated accuracy by Aries is only 0.03% - 2.60% off the true accuracy. Besides, Aries also outperforms the state-of-the-art labeling-free methods in 50 out of 52 cases and selection-labeling-based methods in 96 out of 128 cases.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00152,"Luxembourg National Research Funds (FNR)(grant numbers:C18/IS/126697 67/STELLAR/LeTraon); JSPS KAKENHI(grant numbers:JP20H04168); JST-Mirai Program(grant numbers:JPMJMI20B8); Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2021-02549,RGPAS-2021-00034,DGECR-2021-00019); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172681,deep learning testing;performance estimation;distribution shift,Deep learning;Uncertainty;Estimation;Artificial neural networks;Predictive models;Data models;Labeling,,3,,49,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Axis: Automatically fixing atomicity violations through solving control constraints,P. Liu; C. Zhang,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,299,309,"Atomicity, a general correctness criterion in concurrency programs, is often violated in real-world applications. The violations are difficult for developers to fix, making automatic bug fixing techniques attractive. The state of the art approach aims at automating the manual fixing process but cannot provide any theoretical reasoning and guarantees. We provide an automatic approach that applies well-studied discrete control theory to guarantee deadlocks are not introduced and maximal preservation of the concurrency of the original code. Under the hood, we reduce the problem of violation fixing to a constraint solving problem using the Petri net model. Our evaluation on 13 subjects shows that the slowdown incurred by our patches is only 40% of that of the state of the art. With the deadlock-free guarantee, our patches incur moderate overhead (around 10%), which is a worthwhile cost for safety.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227184,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227184,,Equations;System recovery;Mathematical model;Vectors;Computer bugs;Concurrent computing;Cognition,,39,1,37,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Malcertain: Enhancing Deep Neural Network Based Android Malware Detection by Tackling Prediction Uncertainty,H. Li; G. Xu; L. Wang; X. Xiao; X. Luo; G. Xu; H. Wang,"Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Arizona State University, USA; The Hong Kong Polytechnic University, China; Harbin Institute of Technology, Shenzhen, China; Huazhong University of Science and Technology, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1850,1862,"The long-lasting Android malware threat has attracted significant research efforts in malware detection. In particular, by modeling malware detection as a classification problem, machine learning based approaches, especially deep neural network (DNN) based approaches, are increasingly being used for Android malware detection and have achieved significant improvements over other detection approaches such as signature-based approaches. However, as Android malware evolve rapidly and the presence of adversarial samples, DNN models trained on early constructed samples often yield poor decisions when used to detect newly emerging samples. Fundamentally, this phenomenon can be summarized as the uncertainly in the data (noise or randomness) and the weakness in the training process (insufficient training data). Overlooking these uncertainties poses risks in the model predictions. In this paper, we take the first step to estimate the prediction uncertainty of DNN models in malware detection and leverage these estimates to enhance Android malware detection techniques. Specifically, be-sides training a DNN model to predict malware, we employ several uncertainty estimation methods to train a Correction Model that de-termines whether a sample is correctly or incorrectly predicted by the DNN model. We then leverage the estimated uncertainty output by the Correction Model to correct the prediction results, improving the accuracy of the DNN model. Experimental results show that our proposed Malcertain effectively improves the accuracy of the underlying DNN models for Android malware detection by around 21% and significantly improves the detection effectiveness of adversarial Android malware samples by up to 94.38%. Our research sheds light on the promising direction that leverages prediction uncertainty to improve prediction-based software engineering tasks.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549703,Android Malware Detection;Uncertainty;DNN,Training;Measurement;Uncertainty;Accuracy;Estimation;Training data;Artificial neural networks,,1,,78,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Traces of Memorisation in Large Language Models for Code,A. Al-Kaswan; M. Izadi; A. Van Deursen,"Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,944,955,"Large language models have gained significant popularity because of their ability to generate human-like text and potential applications in various fields, such as Software Engineering. Large language models for code are commonly trained on large unsanitised corpora of source code scraped from the internet. The content of these datasets is memorised and can be extracted by attackers with data extraction attacks. In this work, we explore memorisation in large language models for code and compare the rate of memorisation with large language models trained on natural language. We adopt an existing benchmark for natural language and construct a benchmark for code by identifying samples that are vulnerable to attack. We run both benchmarks against a variety of models, and perform a data extraction attack. We find that large language models for code are vulnerable to data extraction attacks, like their natural language counterparts. From the training data that was identified to be potentially extractable we were able to extract 47% from a CodeGen-Mono-16B code completion model. We also observe that models memorise more, as their parameter count grows, and that their pretraining data are also vulnerable to attack. We also find that data carriers are memorised at a higher rate than regular code or documentation and that different model architectures memorise different samples. Data leakage has severe outcomes, so we urge the research community to further investigate the extent of this phenomenon using a wider range of models and extraction techniques in order to build safeguards to mitigate this issue.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548792,Large Language Models;Privacy;Memorisation;Data Leakage,Codes;Natural languages;Memory architecture;Training data;Games;Documentation;Benchmark testing,,1,,53,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study,Z. Li; C. Wang; P. Ma; C. Liu; S. Wang; D. Wu; C. Gao; Y. Liu,"The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Chinese University of Hong Kong, Hong Kong SAR, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; National University of Singapore, Singapore, Singapore; The Hong Kong University of Science and Technology, Hong Kong SAR, China; Nanyang Technological University, Singapore, Singapore; Harbin Institute of Technology, Shenzhen, China; Nanyang Technological University, Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,893,905,"Recent advances in large language models (LLMs) significantly boost their usage in software engineering. However, training a well-performing LLM demands a substantial workforce for data collection and annotation. Moreover, training datasets may be proprietary or partially open, and the process often requires a costly GPU cluster. The intellectual property value of commercial LLMs makes them attractive targets for imitation attacks, but creating an imitation model with comparable parameters still incurs high costs. This motivates us to explore a practical and novel direction: slicing commercial black-box LLMs using medium-sized backbone models. In this paper, we explore the feasibility of launching imitation attacks on LLMs to extract their specialized code abilities, such as “code synthesis” and “code translation:’ We systematically investigate the effectiveness of launching code ability extraction attacks under different code-related tasks with multiple query schemes, including zero-shot, in-context, and Chain-of-Thought. We also design response checks to refine the outputs, leading to an effective imitation training process. Our results show promising outcomes, demonstrating that with a reasonable number of queries, attackers can train a medium-sized backbone model to replicate specialized code behaviors similar to the target LLMs. We summarize our findings and insights to help researchers better understand the threats posed by imitation attacks, including revealing a practical attack surface for generating adversarial code examples against LLMs.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639091,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548878,Large Language Models;Imitation Attacks,Training;Codes;Costs;Annotations;Graphics processing units;Closed box;Intellectual property,,,,91,,14 Jun 2024,,,IEEE,IEEE Conferences,True
ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers,R. Serafini; C. Otto; S. A. Horstmann; A. Naiakshina,"Ruhr University Bochum, Bochum, Germany; Ruhr University Bochum, Bochum, Germany; Ruhr University Bochum, Bochum, Germany; Ruhr University Bochum, Bochum, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2231,2243,"To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47% of non-programmers while including 94.83% of programmers.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639075,"Deutsche Forschungsgemeinschaft (DFG, German Research Foundation); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549231,chatgpt;programmer screening;developer study;study protection,Visualization;Codes;Instruments;Switches;Chatbots;Security;Task analysis,,,,54,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Fairify: Fairness Verification of Neural Networks,S. Biswas; H. Rajan,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1546,1558,"Fairness of machine learning (ML) software has become a major concern in the recent past. Although recent research on testing and improving fairness have demonstrated impact on real-world software, providing fairness guarantee in practice is still lacking. Certification of ML models is challenging because of the complex decision-making process of the models. In this paper, we proposed Fairify, an SMT-based approach to verify individual fairness property in neural network (NN) models. Individual fairness ensures that any two similar individuals get similar treatment irrespective of their protected attributes e.g., race, sex, age. Verifying this fairness property is hard because of the global checking and non-linear computation nodes in NN. We proposed sound approach to make individual fairness verification tractable for the developers. The key idea is that many neurons in the NN always remain inactive when a smaller part of the input domain is considered. So, Fairify leverages white-box access to the models in production and then apply formal analysis based pruning. Our approach adopts input partitioning and then prunes the NN for each partition to provide fairness certification or counterexample. We leveraged interval arithmetic and activation heuristic of the neurons to perform the pruning as necessary. We evaluated Fairify on 25 real-world neural networks collected from four different sources, and demonstrated the effectiveness, scalability and performance over baseline and closely related work. Fairify is also configurable based on the domain and size of the NN. Our novel formulation of the problem can answer targeted verification queries with relaxations and counterexamples, which have practical implications.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00134,"NSF(grant numbers:CCF-19-34884,CCF-22-23812,CNS-21-20448); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172654,fairness;verification;machine learning,Computational modeling;Scalability;Neurons;Artificial neural networks;Production;Machine learning;Biological neural networks,,6,,74,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
ContraBERT: Enhancing Code Pre-trained Models via Contrastive Learning,S. Liu; B. Wu; X. Xie; G. Meng; Y. Liu,"Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Singapore Management University, Singapore; SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; Nanyang Technological University, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2476,2487,"Large-scale pre-trained models such as CodeBERT, GraphCodeBERT have earned widespread attention from both academia and industry. Attributed to the superior ability in code representation, they have been further applied in multiple downstream tasks such as clone detection, code search and code translation. However, it is also observed that these state-of-the-art pre-trained models are susceptible to adversarial attacks. The performance of these pre-trained models drops significantly with simple perturbations such as renaming variable names. This weakness may be inherited by their downstream models and thereby amplified at an unprecedented scale. To this end, we propose an approach namely ContraBERT that aims to improve the robustness of pre-trained models via contrastive learning. Specifically, we design nine kinds of simple and complex data augmentation operators on the programming language (PL) and natural language (NL) data to construct different variants. Furthermore, we continue to train the existing pre-trained models by masked language modeling (MLM) and contrastive pre-training task on the original samples with their augmented variants to enhance the robustness of the model. The extensive ex-periments demonstrate that ContraBERT can effectively improve the robustness of the existing pre-trained models. Further study also confirms that these robustness-enhanced models provide improvements as compared to original models over four popular downstream tasks.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00207,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172726,Code Pre-trained Models;Contrastive Learning;Model Robustness,Industries;Computer languages;Codes;Perturbation methods;Natural languages;Cloning;Data augmentation,,14,,76,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Deep Learning or Classical Machine Learning? An Empirical Study on Log-Based Anomaly Detection,B. Yu; J. Yao; Q. Fu; Z. Zhong; H. Xie; Y. Wu; Y. Ma; P. He,"School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Huawei Cloud Computing Technologies CO., LTD, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Huawei Cloud Computing Technologies CO., LTD, China; Huawei Cloud Computing Technologies CO., LTD, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,403,415,"While deep learning (DL) has emerged as a powerful technique, its benefits must be carefully considered in relation to computational costs. Specifically, although DL methods have achieved strong performance in log anomaly detection, they often require extended time for log preprocessing, model training, and model inference, hindering their adoption in online distributed cloud systems that require rapid deployment of log anomaly detection service. This paper investigates the superiority of DL methods compared to simpler techniques in log anomaly detection. We evaluate basic algorithms (e.g., KNN, SLFN) and DL approaches (e.g., CNN) on five public log anomaly detection datasets (e.g., HDFS). Our findings demonstrate that simple algorithms outperform DL methods in both time efficiency and accuracy. For instance, on the Thunderbird dataset, the K-nearest neighbor algorithm trains 1,000 times faster than NeuralLog while achieving a higher F1-Score by 0.0625. We also identify three factors contributing to this phenomenon, which are: (1) redundant log preprocessing strategies, (2) dataset simplicity, and (3) the nature of binary classification in log anomaly detection. To assess the necessity of DL, we propose LightAD, an architecture that optimizes training time, inference time, and performance score. With automated hyper-parameter tuning, LightAD allows fair comparisons among log anomaly detection models, enabling engineers to evaluate the suitability of complex DL methods. Our findings serve as a cautionary tale for the log anomaly detection community, highlighting the need to critically analyze datasets and research tasks before adopting DL approaches. Researchers proposing computationally expensive models should benchmark their work against lightweight algorithms to ensure a comprehensive evaluation.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623308,National Natural Science Foundation of China(grant numbers:62102340); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549148,Log analysis;anomaly detection;dataset;empirical study,Training;Deep learning;Computational modeling;Computer architecture;Benchmark testing;Task analysis;Anomaly detection,,2,,89,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Green AI: Do Deep Learning Frameworks Have Different Costs?,S. Georgiou; M. Kechagia; T. Sharma; F. Sarro; Y. Zou,Queen's University; University College London; Dalhousie Uninversity; University College London; Queen's University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1082,1094,"The use of Artificial Intelligence (AI), and more specifically of Deep Learning (DL), in modern software systems, is nowadays widespread and continues to grow. At the same time, its usage is energy de-manding and contributes to the increased CO2 emissions, and has a great financial cost as well. Even though there are many studies that examine the capabilities of DL, only a few focus on its green aspects, such as energy consumption. This paper aims at raising awareness of the costs incurred when using different DL frameworks. To this end, we perform a thorough empirical study to measure and compare the energy consumption and run-time performance of six different DL models written in the two most popular DL frameworks, namely PYTORCH and TENSORFLOW. We use a well-known benchmark of DL models, Deep LEARNINGEXAMPLES, created by NVIDIA, to compare both the training and inference costs of DL. Finally, we manually investigate the functions of these frameworks that took most of the time to execute in our experiments. The results of our empirical study reveal that there is a statistically significant difference between the cost incurred by the two DL frameworks in 94% of the cases studied. While Tensorflow achieves significantly better energy and run-time performance than PYTORCH, and with large effect sizes in 100% of the cases for the training phase, PYTORCH instead exhibits significantly better energy and run-time performance than TENSORFLOW in the inference phase for 66% of the cases, always, with large effect sizes. Such a large difference in performance costs does not, however, seem to affect the accuracy of the models produced, as both frameworks achieve comparable scores under the same configurations. Our manual analysis, of the documentation and source code of the functions examined, reveals that such a difference in performance costs is under-documented, in these frameworks. This suggests that developers need to improve the documentation of their DL frameworks, the source code of the functions used in these frameworks, as well as to enhance existing DL algorithms.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510221,ERC(grant numbers:741278); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793951,Energy consumption;run-time performance;deep learning;APIS,Training;Deep learning;Energy consumption;Costs;Codes;Documentation;Manuals,,25,,89,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Semantic Image Fuzzing of AI Perception Systems,T. Woodlief; S. Elbaum; K. Sullivan,"University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1958,1969,"Perception systems enable autonomous systems to interpret raw sensor readings of the physical world. Testing of perception systems aims to reveal misinterpretations that could cause system failures. Current testing methods, however, are inadequate. The cost of human interpretation and annotation of real-world input data is high, so manual test suites tend to be small. The simulation-reality gap reduces the validity of test results based on simulated worlds. And methods for synthesizing test inputs do not provide corresponding expected interpretations. To address these limitations, we developed semSensFuzz, a new approach to fuzz testing of perception systems based on semantic mutation of test cases that pair realworld sensor readings with their ground-truth interpretations. We implemented our approach to assess its feasibility and potential to improve software testing for perception systems. We used it to generate 150,000 semantically mutated image inputs for five state-of-the-art perception systems. We found that it synthesized tests with novel and subjectively realistic image inputs, and that it discovered inputs that revealed significant inconsistencies between the specified and computed interpretations. We also found that it produced such test cases at a cost that was very low compared to that of manual semantic annotation of real-world images.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510212,"University of Virginia SEAS Fellowship(grant numbers:NSF#1924777,NSF#1909414); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793988,semantic fuzzing;autonomous systems;perception,Costs;Annotations;Autonomous systems;Semantics;Manuals;Fuzzing;Artificial intelligence,,4,,44,CCBY,20 Jun 2022,,,IEEE,IEEE Conferences,True
Inferring Data Preconditions from Deep Learning Models for Trustworthy Prediction in Deployment,S. Ahmed; H. Gao; H. Rajan,"Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,440,452,"Deep learning models are trained with certain assumptions about the data during the development stage and then used for prediction in the deployment stage. It is important to reason about the trustworthiness of the model's predictions with unseen data during deployment. Existing methods for specifying and verifying traditional software are insufficient for this task, as they cannot handle the complexity of DNN model architecture and expected outcomes. In this work, we propose a novel technique that uses rules derived from neural network computations to infer data preconditions for a DNN model to determine the trustworthiness of its predictions. Our approach, DeepInfer involves introducing a novel abstraction for a trained DNN model that enables weakest precondition reasoning using Dijkstra's Predicate Transformer Semantics. By deriving rules over the inductive type of neural network abstract representation, we can overcome the matrix dimensionality issues that arise from the backward nonlinear computation from the output layer to the input layer. We utilize the weakest precondition computation using rules of each kind of activation function to compute layer-wise precondition from the given postcondition on the final output of a deep neural network. We extensively evaluated DeepInfer on 29 real-world DNN models using four different datasets collected from five different sources and demonstrated the utility, effectiveness, and performance improvement over closely related work. DeepInjer efficiently detects correct and incorrect predictions of high-accuracy models with high recall (0.98) and high F-1 score (0.84) and has significantly improved over the prior technique, Self Checker. The average runtime overhead of DeepInfer is low, 0.22 sec for all the unseen datasets. We also compared runtime overhead using the same hardware settings and found that DeepInfer is 3.27 times faster than Self Checker, the state-of-the-art in this area.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623333,"National Science Foundation(grant numbers:CCF-15-18897,CNS-15-13263,CNS-21-20448,CCF-19-34884,CCF-22-23812); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548090,Deep neural networks;weakest precondition;trustworthiness,Deep learning;Runtime;Computational modeling;Semantics;Artificial neural networks;Predictive models;Transformers,,,,76,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
An Empirical Study on Low GPU Utilization of Deep Learning Jobs,Y. Gao; Y. He; X. Li; B. Zhao; H. Lin; Y. Liang; J. Zhong; H. Zhang; J. Wang; Y. Zeng; K. Gui; J. Tong; M. Yang,"Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Peking University, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Chongqing University, Chongqing, China; Tsinghua University, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1171,1183,"Deep learning plays a critical role in numerous intelligent software applications. Enterprise developers submit and run deep learning jobs on shared, multi-tenant platforms to efficiently train and test models. These platforms are typically equipped with a large number of graphics processing units (GPUs) to expedite deep learning computations. However, certain jobs exhibit rather low utilization of the allocated GPUs, resulting in substantial resource waste and reduced development productivity. This paper presents a comprehensive empirical study on low GPU utilization of deep learning jobs, based on 400 real jobs (with an average GPU utilization of 50% or less) collected from Microsoft's internal deep learning platform. We discover 706 low-GPU-utilization issues through meticulous examination of job metadata, execution logs, runtime metrics, scripts, and programs. Furthermore, we identify the common root causes and propose corresponding fixes. Our main findings include: (1) Low GPU utilization of deep learning jobs stems from insufficient GPU computations and interruptions caused by non-GPU tasks; (2) Approximately half (46.03%) of the issues are attributed to data operations; (3) 45.18% of the issues are related to deep learning models and manifest during both model training and evaluation stages; (4) Most (84.99%) low-GPU-utilization issues could be fixed with a small number of code/script modifications. Based on the study results, we propose potential research directions that could help developers utilize GPUs better in cloud-based platforms.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639232,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548248,deep learning jobs;GPU utilization;empirical study,Deep learning;Training;Productivity;Measurement;Runtime;Computational modeling;Graphics processing units,,,,85,,14 Jun 2024,,,IEEE,IEEE Conferences,True
DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning,C. Zhang; X. Peng; C. Sha; K. Zhang; Z. Fu; X. Wu; Q. Lin; D. Zhang,"Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Microsoft Research, China; Microsoft Research, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,623,634,"A microservice system in industry is usually a large-scale dis-tributed system consisting of dozens to thousands of services run-ning in different machines. An anomaly of the system often can be reflected in traces and logs, which record inter-service interactions and intra-service behaviors respectively. Existing trace anomaly detection approaches treat a trace as a sequence of service invocations. They ignore the complex structure of a trace brought by its invocation hierarchy and parallel/asynchronous invocations. On the other hand, existing log anomaly detection approaches treat a log as a sequence of events and cannot handle microservice logs that are distributed in a large number of services with complex interactions. In this paper, we propose DeepTraLog, a deep learning based microservice anomaly detection approach. DeepTraLog uses a unified graph representation to describe the complex structure of a trace together with log events embedded in the structure. Based on the graph representation, DeepTraLog trains a GGNNs based deep SVDD model by combing traces and logs and detects anom-alies in new traces and the corresponding logs. Evaluation on a microservice benchmark shows that DeepTraLog achieves a high precision (0.93) and recall (0.97), outperforming state-of-the-art trace/log anomaly detection approaches with an average increase of 0.37 in F1-score. It also validates the efficiency of DeepTraLog, the contribution of the unified graph representation, and the impact of the configurations of some key parameters.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510180,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793918,Microservice;Anomaly Detection;Log Analysis;Tracing;Graph Neural Network;Deep Learning,Deep learning;Industries;Microservice architectures;Benchmark testing;Behavioral sciences;Time factors;Anomaly detection,,42,,44,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding,D. Wang; Z. Jia; S. Li; Y. Yu; Y. Xiong; W. Dong; X. Liao,"National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; Fudan University, Shanghai, China; National University of Defense Technology, China; National University of Defense Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,287,298,"With the great success of pre-trained models, the pretrain-then-fine tune paradigm has been widely adopted on downstream tasks for source code understanding. However, compared to costly training a large-scale model from scratch, how to effectively adapt pre-trained models to a new task has not been fully explored. In this paper, we propose an approach to bridge pre-trained models and code-related tasks. We exploit semantic-preserving transformation to enrich downstream data diversity, and help pre-trained models learn semantic features invariant to these semantically equivalent transformations. Further, we introduce curriculum learning to or-ganize the transformed data in an easy-to-hard manner to fine-tune existing pre-trained models. We apply our approach to a range of pre-trained models, and they significantly outperform the state-of-the-art models on tasks for source code understanding, such as algorithm classification, code clone detection, and code search. Our experiments even show that without heavy pre-training on code data, natural language pre-trained model RoBERTa fine-tuned with our lightweight approach could outperform or rival existing code pre-trained models fine-tuned on the above tasks, such as CodeBERT and GraphCodeBERT. This finding suggests that there is still much room for improvement in code pre-trained models.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510062,"National Natural Science Foundation of China(grant numbers:61690203,61872373,62032019,U1936213); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793959,fine-tuning;data augmentation;curriculum learning;test-time aug-mentation,Training;Adaptation models;Codes;Natural languages;Semantics;Cloning;Data models,,26,,58,,20 Jun 2022,,,IEEE,IEEE Conferences,True
An Empirical Study of Deep Learning Models for Vulnerability Detection,B. Steenhoek; M. M. Rahman; R. Jiles; W. Le,"Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,2237,2248,"Deep learning (DL) models of code have recently reported great progress for vulnerability detection. In some cases, DL-based models have outperformed static analysis tools. Although many great models have been proposed, we do not yet have a good understanding of these models. This limits the further advancement of model robustness, debugging, and deployment for the vulnerability detection. In this paper, we surveyed and reproduced 9 state-of-the-art (SOTA) deep learning models on 2 widely used vulnerability detection datasets: Devign and MSR. We investigated 6 research questions in three areas, namely model capabilities, training data, and model interpretation. We experimentally demonstrated the variability between different runs of a model and the low agreement among different models' outputs. We investigated models trained for specific types of vulnerabilities compared to a model that is trained on all the vulnerabilities at once. We explored the types of programs DL may consider “hard” to handle. We investigated the relations of training data sizes and training data composition with model performance. Finally, we studied model interpretations and analyzed important features that the models used to make predictions. We believe that our findings can help better understand model results, provide guidance on preparing training data, and improve the robustness of the models. All of our datasets, code, and results are available at https://doi.org/10.6084/m9.figshare.20791240.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00188,U.S. National Science Foundation(grant numbers:1816352); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172583,deep learning;vulnerability detection;empirical study,Deep learning;Analytical models;Codes;Training data;Static analysis;Debugging;Predictive models,,21,,47,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
On the Importance of Building High-quality Training Datasets for Neural Code Search,Z. Sun; L. Li; Y. Liu; X. Du; L. Li,"Monash University, Melbourne, Victoria, Australia; Tongji University, Shanghai, China; Tongji University, Shanghai, China; Monash University, Melbourne, Victoria, Australia; Monash University, Melbourne, Victoria, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1609,1620,"The performance of neural code search is significantly influenced by the quality of the training data from which the neural models are derived. A large corpus of high-quality query and code pairs is demanded to establish a precise mapping from the natural language to the programming language. Due to the limited availability, most widely-used code search datasets are established with compromise, such as using code comments as a replacement of queries. Our empirical study on a famous code search dataset reveals that over one-third of its queries contain noises that make them deviate from natural user queries. Models trained through noisy data are faced with severe performance degradation when applied in real-world scenarios. To improve the dataset quality and make the queries of its samples semantically identical to real user queries is critical for the practical usability of neural code search. In this paper, we propose a data cleaning framework consisting of two subsequent filters: a rule-based syntactic filter and a model-based semantic filter. This is the first framework that applies semantic query cleaning to code search datasets. Experimentally, we evaluated the effectiveness of our framework on two widely-used code search models and three manually-annotated code retrieval benchmarks. Training the popular DeepCS model with the filtered dataset from our framework improves its performance by 19.2% MRR and 21.3% Answer@l, on average with the three validation benchmarks.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510160,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793971,Code search;dataset;data cleaning;deep learning,Training;Codes;Computational modeling;Semantics;Training data;Benchmark testing;Data models,,17,,57,,20 Jun 2022,,,IEEE,IEEE Conferences,True
KNOD: Domain Knowledge Distilled Tree Decoder for Automated Program Repair,N. Jiang; T. Lutellier; Y. Lou; L. Tan; D. Goldwasser; X. Zhang,"Purdue University, West Lafayette, USA; University of Alberta, Alberta, Canada; Fudan University, Shanghai, China; Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1251,1263,"Automated Program Repair (APR) improves soft-ware reliability by generating patches for a buggy program automatically. Recent APR techniques leverage deep learning (DL) to build models to learn to generate patches from existing patches and code corpora. While promising, DL-based APR techniques suffer from the abundant syntactically or semantically incorrect patches in the patch space. These patches often disobey the syntactic and semantic domain knowledge of source code and thus cannot be the correct patches to fix a bug. We propose a DL-based APR approach KNOD, which in-corporates domain knowledge to guide patch generation in a direct and comprehensive way. KNOD has two major novelties, including (1) a novel three-stage tree decoder, which directly generates Abstract Syntax Trees of patched code according to the inherent tree structure, and (2) a novel domain-rule distillation, which leverages syntactic and semantic rules and teacher-student distributions to explicitly inject the domain knowledge into the decoding procedure during both the training and inference phases. We evaluate KNOD on three widely-used benchmarks. KNOD fixes 72 bugs on the Defects4J v1.2, 25 bugs on the QuixBugs, and 50 bugs on the additional Defects4J v2.0 benchmarks, outperforming all existing APR tools.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172873,Automated Program Repair;Abstract Syntax Tree;Deep Learning,Training;Codes;Source coding;Computer bugs;Semantics;Syntactics;Benchmark testing,,17,,65,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Many-Objective Reinforcement Learning for Online Testing of DNN-Enabled Systems,F. Ul Haq; D. Shin; L. C. Briand,"University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1814,1826,"Deep Neural Networks (DNNs) have been widely used to perform real-world tasks in cyber-physical systems such as Autonomous Driving Systems (ADS). Ensuring the correct behavior of such DNN-Enabled Systems (DES) is a crucial topic. Online testing is one of the promising modes for testing such systems with their application environments (simulated or real) in a closed loop, taking into account the continuous interaction between the systems and their environments. However, the environmental variables (e.g., lighting conditions) that might change during the systems' operation in the real world, causing the DES to violate requirements (safety, functional), are often kept constant during the execution of an online test scenario due to the two major challenges: (1) the space of all possible scenarios to explore would become even larger if they changed and (2) there are typically many requirements to test simultaneously. In this paper, we present MORLOT (Many-Objective Rein-forcement Learning for Online Testing), a novel online testing approach to address these challenges by combining Reinforcement Learning (RL) and many-objective search. MORLOT leverages RL to incrementally generate sequences of environmental changes while relying on many-objective search to determine the changes so that they are more likely to achieve any of the uncovered objectives. We empirically evaluate MORLOT using CARLA, a high-fidelity simulator widely used for autonomous driving research, integrated with Transfuser, a DNN-enabled ADS for end-to-end driving. The evaluation results show that MORLOT is significantly more effective and efficient than alternatives with a large effect size. In other words, MORLOT is a good option to test DES with dynamically changing environments while accounting for multiple safety requirements.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00155,NSERC of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172658,DNN Testing;Reinforcement learning;Many objective search;Self-driving cars;Online testing,Q-learning;Systems operation;Scalability;Lighting;Search problems;Safety;Task analysis,,13,,42,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Improving Java Deserialization Gadget Chain Mining via Overriding-Guided Object Generation,S. Cao; X. Sun; X. Wu; L. Bo; B. Li; R. Wu; W. Liu; B. He; Y. Ouyang; J. Li,Yangzhou University; Yangzhou University; Yangzhou University; Yangzhou University; Yangzhou University; Xiamen University; Yangzhou University; Ant Group; Ant Group; Ant Group,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,397,409,"Java (de)serialization is prone to causing security-critical vulnerabilities that attackers can invoke existing methods (gadgets) on the application's classpath to construct a gadget chain to perform malicious behaviors. Several techniques have been proposed to statically identify suspicious gadget chains and dynamically generate injection objects for fuzzing. However, due to their incomplete support for dynamic program features (e.g., Java runtime polymorphism) and ineffective injection object generation for fuzzing, the existing techniques are still far from satisfactory. In this paper, we first performed an empirical study to investigate the characteristics of Java deserialization vulnerabilities based on our manually collected 86 publicly known gadget chains. The empirical results show that 1) Java deserialization gadgets are usually exploited by abusing runtime polymorphism, which enables attackers to reuse serializable overridden methods; and 2) attackers usually invoke exploitable overridden methods (gadgets) via dynamic binding to generate injection objects for gadget chain construction. Based on our empirical findings, we propose a novel gadget chain mining approach, GCMiner, which captures both explicit and implicit method calls to identify more gadget chains, and adopts an overriding-guided object generation approach to generate valid injection objects for fuzzing. The evaluation results show that GCMiner significantly outperforms the state-of-the-art techniques, and discovers 56 unique gadget chains that cannot be identified by the baseline approaches.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00044,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172888,Java deserialization vulnerability;gadget chain;method overriding;exploit generation,Java;Runtime;Fuzzing;Behavioral sciences;Object recognition,,9,,67,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Utilizing Parallelism in Smart Contracts on Decentralized Blockchains by Taming Application-Inherent Conflicts,P. Garamvolgyi; Y. Liu; D. Zhou; F. Long; M. Wu,"Shanghai Tree-Graph Blockchain Research Institute, Shanghai, China; Duke University, Durham, North Carolina, USA; Tsinghua University, Beijing, China; University of Toronto Toronto, Canada Shanghai Tree-Graph Blockchain Research Institute, Shanghai, China; Shanghai Tree-Graph Blockchain Research Institute, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2315,2326,"Traditional public blockchain systems typically had very limited transaction throughput because of the bottleneck of the consensus protocol itself. With recent advances in consensus technology, the performance limit has been greatly lifted, typically to thousands of transactions per second. With this, transaction execution has become a new performance bottleneck. Exploiting parallelism in transaction execution is a clear and direct way to address this and to further increase transaction throughput. Although some recent literature introduced concurrency control mechanisms to execute smart contract transactions in parallel, the reported speedup that they can achieve is far from ideal. The main reason is that the proposed parallel execution mechanisms cannot effectively deal with the conflicts inherent in many blockchain applications. In this work, we thoroughly study the historical transaction exe-cution traces in Ethereum. We observe that application-inherent conflicts are the major factors that limit the exploitable parallelism during execution. We propose to use partitioned counters and spe-cial commutative instructions to break up the application conflict chains in order to maximize the potential speedup. When we eval-uated the maximum parallel speedup achievable, these techniques doubled this limit to an 18x overall speedup compared to serial execution, thus approaching the optimum. We also propose OCC-DA, an optimistic concurrency control scheduler with deterministic aborts, which makes it possible to use OCC scheduling in public blockchain settings.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510086,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793889,blockchain;distributed ledgers;smart contracts;parallel execution;optimistic concurrency;deterministic concurrency,Concurrent computing;Smart contracts;Parallel processing;Programming;Throughput;Concurrency control;Consensus protocol,,8,,33,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Static Inference Meets Deep learning: A Hybrid Type Inference Approach for Python,Y. Peng; C. Gao; Z. Li; B. Gao; D. Lo; Q. Zhang; M. Lyu,"The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Singapore Management University, Singapore; Georgia Institute of Technology, United States; The Chinese University of Hong Kong, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,2019,2030,"Type inference for dynamic programming languages such as Python is an important yet challenging task. Static type inference techniques can precisely infer variables with enough static constraints but are unable to handle variables with dynamic features. Deep learning (DL) based approaches are feature-agnostic, but they can-not guarantee the correctness of the predicted types. Their per-formance significantly depends on the quality of the training data (i.e., DL models perform poorly on some common types that rarely appear in the training dataset). It is interesting to note that the static and DL-based approaches offer complementary benefits. Un-fortunately, to our knowledge, precise type inference based on both static inference and neural predictions has not been exploited and remains an open challenge. In particular, it is hard to integrate DL models into the framework of rule-based static approaches. This paper fills the gap and proposes a hybrid type inference approach named Hityper based on both static inference and deep learning. Specifically, our key insight is to record type dependen-cies among variables in each function and encode the dependency information in type dependency graphs (TDGs). Based on TDGs, we can easily integrate type inference rules in the nodes to conduct static inference and type rejection rules to inspect the correctness of neural predictions. Hityper iteratively conducts static inference and DL-based prediction until the TDG is fully inferred. Experi-ments on two benchmark datasets show that Hityper outperforms state-of-the-art DL models by exactly matching 10% more human annotations. Hityper also achieves an increase of more than 30% on inferring rare types. Considering only the static part of Hityper, it infers 2× ~3× more types than existing static type inference tools. Moreover, Hityper successfully corrected seven wrong human an-notations in six GitHub projects, and two of them have already been approved by the repository owners.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510038,"Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:CUHK 14210920); National Natural Science Foundation of China(grant numbers:62002084); Shenzhen(grant numbers:GXWD20201230155427003-20200730101839009); United States National Science Foundation (NSF)(grant numbers:1917924,2114627); Defense Advanced Research Projects Agency (DARPA)(grant numbers:N66001-21-C-4024); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794008,Type Inference;AI For SE;Static Analysis,Deep learning;Training;Training data;Static analysis;Predictive models;Dynamic programming;Task analysis,,7,,62,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Fairneuron: Improving Deep Neural Network Fairness with Adversary Games on Selective Neurons,X. Gao; J. Zhai; S. Ma; C. Shen; Y. Chen; Q. Wang,"Xi'an Jiaotong University, Xi'an, China; Rutgers University, United States; Rutgers University, United States; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Wuhan University, Wuhan, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,921,933,"With Deep Neural Network (DNN) being integrated into a growing number of critical systems with far-reaching impacts on society, there are increasing concerns on their ethical performance, such as fairness. Unfortunately, model fairness and accuracy in many cases are contradictory goals to optimize during model training. To solve this issue, there has been a number of works trying to improve model fairness by formalizing an adversarial game in the model level. This approach introduces an adversary that evaluates the fairness of a model besides its prediction accuracy on the main task, and performs joint-optimization to achieve a balanced result. In this paper, we noticed that when performing backward prop-agation based training, such contradictory phenomenon are also observable on individual neuron level. Based on this observation, we propose Fairneuron, a Dnn model automatic repairing tool, to mitigate fairness concerns and balance the accuracy-fairness trade-off without introducing another model. It works on detecting neurons with contradictory optimization directions from accuracy and fairness training goals, and achieving a trade-off by selective dropout. Comparing with state-of-the-art methods, our approach is lightweight, scaling to large models and more efficient. Our eval-uation on three datasets shows that Fairneuron can effectively improve all models' fairness while maintaining a stable utility.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510087,"National Key R&D Program(grant numbers:2020YFB1406900); National Natural Science Foundation of China(grant numbers:U21B2018,62161160337,61822309,U20B2049,61773310,U1736205,61802166); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793993,fairness;path analysis;neural networks,Training;Deep learning;Neurons;Neural networks;Games;Predictive models;Search problems,,7,,73,,20 Jun 2022,,,IEEE,IEEE Conferences,True
EREBA: Black-box Energy Testing of Adaptive Neural Networks,M. Haque; Y. Yadlapalli; W. Yang; C. Liu,The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,835,846,"Recently, various Deep Neural Network (DNN) models have been proposed for environments like embedded systems with stringent energy constraints. The fundamental problem of determining the ro-bustness of a DNN with respect to its energy consumption (energy robustness) is relatively unexplored compared to accuracy-based ro-bustness. This work investigates the energy robustness of Adaptive Neural Networks (AdNNs), a type of energy-saving DNNs proposed for many energy-sensitive domains and have recently gained traction. We propose EREBA, the first black-box testing method for determining the energy robustness of an AdNN. EREBA explores and infers the relationship between inputs and the energy con-sumption of AdNN s to generate energy surging samples. Extensive implementation and evaluation using three state-of-the-art AdNNs demonstrate that test inputs generated by EREBA could degrade the performance of the system substantially. The test inputs gener-ated by EREBA can increase the energy consumption of AdNN s by 2,000% compared to the original inputs. Our results also show that test inputs generated via EREBA are valuable in detecting energy surging inputs.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510088,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793545,Green AI;AI Energy Testing;Adversarial Machine Learning,Deep learning;Energy consumption;Adaptation models;Adaptive systems;Embedded systems;Neural networks;Green products,,5,,44,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Efficiency Matters: Speeding Up Automated Testing with GUI Rendering Inference,S. Feng; M. Xie; C. Chen,"Monash University, Melbourne, Australia; Australian National University, Canberra, Australia; Monash University, Melbourne, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,906,918,"Due to the importance of Android app quality assurance, many automated GUI testing tools have been developed. Although the test algorithms have been improved, the impact of GUI rendering has been overlooked. On the one hand, setting a long waiting time to execute events on fully rendered GUIs slows down the testing process. On the other hand, setting a short waiting time will cause the events to execute on partially rendered GUIs, which negatively affects the testing effectiveness. An optimal waiting time should strike a balance between effectiveness and efficiency. We propose AdaT, a lightweight image-based approach to dynamically adjust the inter-event time based on GUI rendering state. Given the real-time streaming on the GUI, AdaT presents a deep learning model to infer the rendering state, and synchronizes with the testing tool to schedule the next event when the GUI is fully rendered. The evaluations demonstrate the accuracy, efficiency, and effectiveness of our approach. We also integrate our approach with the existing automated testing tool to demonstrate the usefulness of AdaT in covering more activities and executing more events on fully rendered GUIs.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00084,Monash FIT RSP fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172585,Efficient android GUI testing;GUI rendering;Machine Learning,Deep learning;Schedules;Quality assurance;Streaming media;Rendering (computer graphics);Real-time systems;Synchronization,,5,,87,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis,Y. Sun; D. Wu; Y. Xue; H. Liu; H. Wang; Z. Xu; X. Xie; Y. Liu,"Nanyang Technological University Singapore, Singapore; Nanyang Technological University Singapore, Singapore; MetaTrust Labs Singapore, Singapore; East China Normal University, Shanghai, China; Xi'an Jiaotong University, Xi'an, China; Nanyang Technological University Singapore, Singapore; Singapore Management University Singapore, Singapore; Nanyang Technological University Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2048,2060,"Smart contracts are prone to various vulnerabilities, leading to substantial financial losses over time. Current analysis tools mainly target vulnerabilities with fixed control- or data-flow patterns, such as re-entrancy and integer overflow. However, a recent study on Web3 security bugs revealed that about 80% of these bugs cannot be audited by existing tools due to the lack of domain-specific property description and checking. Given recent advances in Large Language Models (LLMs), it is worth exploring how Generative Pre-training Transformer (GPT) could aid in detecting logic vulnerabilities. In this paper, we propose GPTScan, the first tool combining GPT with static analysis for smart contract logic vulnerability detection. Instead of relying solely on GPT to identify vulnerabilities, which can lead to high false positives and is limited by GPT's pre-trained knowledge, we utilize GPT as a versatile code understanding tool. By breaking down each logic vulnerability type into scenarios and properties, GPTScan matches candidate vulnerabilities with GPT. To enhance accuracy, GPTScan further instructs GPT to intelligently recognize key variables and statements, which are then validated by static confirmation. Evaluation on diverse datasets with around 400 contract projects and 3K Solidity files shows that GPTScan achieves high precision (over 90%) for token contracts and acceptable precision (57.14%) for large projects like Web3Bugs. It effectively detects ground-truth logic vulnerabilities with a recall of over 70%, including 9 new vulnerabilities missed by human auditors. GPTScan is fast and cost-effective, taking an average of 14.39 seconds and 0.01 USD to scan per thousand lines of Solidity code. Moreover, static confirmation helps GPTScan reduce two-thirds of false positives.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549149,,Codes;Accuracy;Smart contracts;Computer bugs;Static analysis;Transformers;Logic,,4,,66,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Leveraging Feature Bias for Scalable Misprediction Explanation of Machine Learning Models,J. Gesi; X. Shen; Y. Geng; Q. Chen; I. Ahmed,"Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1559,1570,"Interpreting and debugging machine learning models is necessary to ensure the robustness of the machine learning models. Explaining mispredictions can help significantly in doing so. While recent works on misprediction explanation have proven promising in generating interpretable explanations for mispredictions, the state-of-the-art techniques “blindly” deduce misprediction explanation rules from all data features, which may not be scalable depending on the number of features. To alleviate this problem, we propose an efficient misprediction explanation technique named Bias Guided Misprediction Diagnoser (BGMD), which leverages two prior knowledge about data: a) data often exhibit highly-skewed feature distributions and b) trained models in many cases perform poorly on subdataset with under-represented features. Next, we propose a technique named MAPS (Mispredicted Area UPweight Sampling). MAPS increases the weights of subdataset during model retraining that belong to the group that is prone to be mispredicted because of containing under-represented features. Thus, MAPS make retrained model pay more attention to the under-represented features. Our empirical study shows that our proposed BGMD outperformed the state-of-the-art misprediction diagnoser and reduces diagnosis time by 92%. Furthermore, MAPS outperformed two state-of-the-art techniques on fixing the machine learning model's performance on mispredicted data without compromising performance on all data. All the research artifacts (i.e., tools, scripts, and data) of this study are available in the accompanying website [1].",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00135,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172677,machine learning;data imbalance;rule induction;misprediction explanation,Machine learning algorithms;Machine learning;Debugging;Predictive models;Prediction algorithms;Robustness;Data models,,3,,58,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Lost in Translation: A Study of Bugs Introduced by Large Language Models While Translating Code,R. Pan; A. R. Ibrahimzada; R. Krishna; D. Sankar; L. P. Wassi; M. Merler; B. Sobolev; R. Pavuluri; S. Sinha; R. Jabbarvand,"IBM Research, Yorktown Heights, NY, USA; University of Illinois Urbana-Champaign, Champaign, IL, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; University of Illinois Urbana-Champaign, Champaign, IL, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,995,1007,"Code translation aims to convert source code from one programming language (PL) to another. Given the promising abilities of large language models (LLMs) in code synthesis, researchers are exploring their potential to automate code translation. The prerequisite for advancing the state of LLM-based code translation is to understand their promises and limitations over existing techniques. To that end, we present a large-scale empirical study to investigate the ability of general LLMs and code LLMs for code translation across pairs of different languages, including C, C++, Go, Java, and Python. Our study, which involves the translation of 1,700 code samples from three benchmarks and two real-world projects, reveals that LLMs are yet to be reliably used to automate code translation-with correct translations ranging from 2.1% to 47.3% for the studied LLMs. Further manual investigation of unsuccessful translations identifies 15 categories of translation bugs. We also compare LLM-based code translation with traditional non-LLM-based approaches. Our analysis shows that these two classes of techniques have their own strengths and weaknesses. Finally, insights from our study suggest that providing more context to LLMs during translation can help them produce better results. To that end, we propose a prompt-crafting approach based on the symptoms of erroneous translations; this improves the performance of LLM-based code translation by 5.5% on average. Our study is the first of its kind, in terms of scale and breadth, that provides insights into the current limitations of LLMs in code translation and opportunities for improving them. Our dataset-consisting of 1,700 code samples in five PLs with 10K+ tests, 43K+ translated code, 1,748 manually labeled bugs, and 1,365 bug-fix pairs-can help drive research in this area.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639226,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548365,code translation;bug taxonomy;11m,Java;Codes;Source coding;Computer bugs;Manuals;C++ languages;Distance measurement,,2,,92,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Dataflow Analysis-Inspired Deep Learning for Efficient Vulnerability Detection,B. Steenhoek; H. Gao; W. Le,"Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,177,189,"Deep learning-based vulnerability detection has shown great performance and, in some studies, outperformed static analysis tools. However, the highest-performing approaches use token-based transformer models, which are not the most efficient to capture code semantics required for vulnerability detection. Classical program analysis techniques such as dataflow analysis can detect many types of bugs based on their root causes. In this paper, we propose to combine such causal-based vulnerability detection algorithms with deep learning, aiming to achieve more efficient and effective vulnerability detection. Specifically, we designed DeepDFA, a dataflow analysis-inspired graph learning framework and an embedding technique that enables graph learning to simulate dataflow computation. We show that DeepDFA is both performant and efficient. DeepDFA outperformed all non-transformer baselines. It was trained in 9 minutes, 75x faster than the highest-performing baseline model. When using only 50+ vulnerable and several hundreds of total examples as training data, the model retained the same performance as 100% of the dataset. DeepDFA also generalized to real-world vulnerabilities in Dbgbench; it detected 8.7 out of 17 vulnerabilities on average across folds and was able to distinguish between patched and buggy versions, while the highest-performing baseline models did not detect any vulnerabilities. By combining DeepDFA with a large language model, we surpassed the state-of-the-art vulnerability detection performance on the Big-Vul dataset with 96.46 F1 score, 97.82 precision, and 95.14 recall. Our replication package is located at https://doi.org/10.6084/m9.figshare.21225413.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3623345,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549585,vulnerability detection;deep learning;dataflow analysis;program analysis,Deep learning;Computational modeling;Semantics;Computer bugs;Training data;Static analysis;Transformers,,2,,56,CCBY,14 Jun 2024,,,IEEE,IEEE Conferences,True
Safeguarding DeFi Smart Contracts Against Oracle Deviations,X. Deng; S. M. Beillahi; C. Minwalla; H. Du; A. Veneris; F. Long,"University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; Bank of Canada, Ottawa, Canada; Bank of Canada, Ottawa, Canada; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,2111,2122,"This paper presents OVer, a framework designed to automatically analyze the behavior of decentralized finance (DeFi) protocols when subjected to a “skewed” oracle input. OVer firstly performs symbolic analysis on the given contract and constructs a model of constraints. Then, the framework leverages an SMT solver to identify parameters that allow its secure operation. Furthermore, guard statements may be generated for smart contracts that may use the oracle values, thus effectively preventing oracle manipulation attacks. Empirical results show that OVer can successfully analyze all 10 benchmarks collected, which encompass a diverse range of DeFi protocols. Additionally, this paper illustrates that current parameters utilized in the majority of benchmarks are inadequate to ensure safety when confronted with significant oracle deviations. It shows that existing ad-hoc control mechanisms such as introducing delays are often insufficient or even detrimental to protect the DeFi protocols against the oracle deviation in the real-world.",1558-1225,979-8-4007-0217-4,10.1145/3597503.3639225,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548838,Blockchain;Decentralized Finance;Smart Contracts;Oracle Deviation;Static Program Analysis;Code Summary;Parameter Optimization,Analytical models;Source coding;Smart contracts;Finance;Benchmark testing;Decentralized applications;Safety,,2,,53,,14 Jun 2024,,,IEEE,IEEE Conferences,True
REFTY: Refinement Types for Valid Deep Learning Models,Y. Gao; Z. Li; H. Lin; H. Zhang; M. Wu; M. Yang,"Microsoft Research, China; Microsoft Research, China; Microsoft Research, China; The University of Newcastle, Australia; Shanghai Tree-Graph Blockchain Research Institute, China; Microsoft Research, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1843,1855,"Deep learning has been increasingly adopted in many application areas. To construct valid deep learning models, developers must conform to certain computational constraints by carefully selecting appropriate neural architectures and hyperparameter values. For example, the kernel size hyperparameter of the 2D convolution operator cannot be overlarge to ensure that the height and width of the output tensor remain positive. Because model construction is largely manual and lacks necessary tooling support, it is possible to violate those constraints and raise type errors of deep learning models, causing either runtime exceptions or wrong output results. In this paper, we propose Refty, a refinement type-based tool for statically checking the validity of deep learning models ahead of job execution. Refty refines each type of deep learning operator with framework-independent logical formulae that describe the computational constraints on both tensors and hyperparameters. Given the neural architecture and hyperparameter domains of a model, Refty visits every operator, generates a set of constraints that the model should satisfy, and utilizes an SMT solver for solving the constraints. We have evaluated Refty on both individual operators and representative real-world models with various hyperparameter values under PyTorch and TensorFlow. We also compare it with an existing shape-checking tool. The experimental results show that Refty finds all the type errors and achieves 100% Precision and Recall, demonstrating its effectiveness.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510077,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794045,deep learning;validity checking;type error;refinement type,Deep learning;Tensors;Runtime;Convolution;Computational modeling;Computer architecture;Manuals,,2,,87,,20 Jun 2022,,,IEEE,IEEE Conferences,True
PROMAL: Precise Window Transition Graphs for Android via Synergy of Program Analysis and Machine Learning,C. Liu; H. Wang; T. Liu; D. Gu; Y. Ma; H. Wang; X. Xiao,Case Western Reserve University; Case Western Reserve University; Monash University; Peking University; Peking University; Beijing University of Posts and Telecommunications; Case Western Reserve University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,1755,1767,"Mobile apps have been an integral part in our daily life. As these apps become more complex, it is critical to provide automated analysis techniques to ensure the correctness, security, and performance of these apps. A key component for these automated analysis techniques is to create a graphical user interface (GUI) model of an app, i.e., a window transition graph (WTG), that models windows and transitions among the windows. While existing work has provided both static and dynamic analysis to build the WTG for an app, the constructed WTG misses many transitions or contains many infeasible transitions due to the coverage issues of dynamic analysis and over-approximation of the static analysis. We propose ProMal, a “tribrid” analysis that synergistically combines static analysis, dynamic analysis, and machine learning to construct a precise WTG. Specifically, ProMal first applies static analysis to build a static WTG, and then applies dynamic analysis to verify the transitions in the static WTG. For the unverified transitions, ProMal further provides machine learning techniques that leverage runtime information (i.e., screenshots, UI layouts, and text information) to predict whether they are feasible transitions. Our evaluations on 40 real-world apps demonstrate the superiority of ProMal in building WTGs over static analysis, dynamic analysis, and machine learning techniques when they are applied separately.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510037,"National Science Foundation(grant numbers:CCF-2046953,CNS-2028748); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794097,mobile apps;window transition graph;static analysis;deep learning,Analytical models;Runtime;Buildings;Static analysis;Machine learning;Windows;Performance analysis,,1,,72,,20 Jun 2022,,,IEEE,IEEE Conferences,True
ExAIS: Executable AI Semantics,R. Schumi; J. Sun,"Singapore Management University, Singapore; Singapore Management University, Singapore",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,859,870,"Neural networks can be regarded as a new programming paradigm, i.e., instead of building ever-more complex programs through (often informal) logical reasoning in the programmers' mind, complex ‘AI’ systems are built by optimising generic neural network models with big data. In this new paradigm, AI frameworks such as Ten-sorFlow and PyTorch play a key role, which is as essential as the compiler for traditional programs. It is known that the lack of a proper semantics for programming languages (such as C), i.e., a correctness specification for compilers, has contributed to many problematic program behaviours and security issues. While it is in general hard to have a correctness specification for compilers due to the high complexity of programming languages and their rapid evolution, we have a unique opportunity to do it right this time for neural networks (which have a limited set of functions, and most of them have stable semantics). In this work, we report our effort on providing a correctness specification of neural net-work frameworks such as TensorFlow. We specify the semantics of almost all TensorFlow layers in the logical programming language Prolog. We demonstrate the usefulness of the semantics through two applications. One is a fuzzing engine for TensorFlow, which features a strong oracle and a systematic way of generating valid neural networks. The other is a model validation approach which enables consistent bug reporting for TensorFlow models.",1558-1225,978-1-4503-9221-1,10.1145/3510003.3510112,"National Research Foundation, Singapore; National University of Singapore; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794011,AI frameworks;AI libraries;deep learning models;semantics;specification;test case generation;model validation;AI model generation,Deep learning;Computer languages;Program processors;Systematics;Semantics;Computer bugs;Neural networks,,,,45,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Balancing Effectiveness and Flakiness of Non-Deterministic Machine Learning Tests,C. S. Xia; S. Dutta; S. Misailovic; D. Marinov; L. Zhang,"University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,1801,1813,"Testing Machine Learning (ML) projects is challenging due to inherent non-determinism of various ML algorithms and the lack of reliable ways to compute reference results. Developers typically rely on their intuition when writing tests to check whether ML algorithms produce accurate results. However, this approach leads to conservative choices in selecting assertion bounds for comparing actual and expected results in test assertions. Because developers want to avoid false positive failures in tests, they often set the bounds to be too loose, potentially leading to missing critical bugs. We present FASER - the first systematic approach for balancing the trade-off between the fault-detection effectiveness and flakiness of non-deterministic tests by computing optimal assertion bounds. FASER frames this trade-off as an optimization problem between these competing objectives by varying the assertion bound. FASER leverages 1) statistical methods to estimate the flakiness rate, and 2) mutation testing to estimate the fault-detection effectiveness. We evaluate FASER on 87 non-deterministic tests collected from 22 popular ML projects. FASER finds that 23 out of 87 studied tests have conservative bounds and proposes tighter assertion bounds that maximizes the fault-detection effectiveness of the tests while limiting flakiness. We have sent 19 pull requests to developers, each fixing one test, out of which 14 pull requests have already been accepted.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00154,NSF(grant numbers:CCF-1763788); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172715,,Machine learning algorithms;Systematics;Limiting;Statistical analysis;Machine learning;Writing;Reliability,,,,105,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Precise Sparse Abstract Execution via Cross-Domain Interaction,X. Cheng; J. Wang; Y. Sui,"University of New South Wales, Sydney, NSW, Australia; University of New South Wales, Sydney, NSW, Australia; University of New South Wales, Sydney, NSW, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,1335,1346,"Sparse static analysis offers a more scalable solution compared to its non-sparse counterpart. The basic idea is to first conduct a fast pointer analysis that over-approximates the value-flows and prop-agates the data-flow facts sparsely along only the pre-computed value-flows instead of all control flow points. Current sparse techniques focus on improving the scalability of the main analysis while maintaining its precision. However, their pointer analyses in both the offline and main phases are inherently imprecise because they rely solely on a single memory address domain without considering values from other domains like the interval domain. Consequently, this leads to conservative alias results, like array-insensitivity, which leaves substantial room for precision improve-ment of the main data-flow analysis. This paper presents CSA, a new Cross-domain Sparse Abstract execution that interweaves correlations between values across multiple abstract domains (e.g., memory address and interval domains). Unlike traditional sparse analysis without cross-domain interaction, CSA performs correlation tracking by establishing implications of values from one domain to another. This correlation tracking enables online bidirectional refinement: CSA refines spurious alias relations using interval domain information and also enhances the precision of interval analysis with refined alias results. This con-tributes to increasingly improved precision and scalability as the main analysis progresses. To improve the efficiency of correlation tracking, we propose an equivalent correlation tracking approach that groups (virtual) memory addresses with equivalent implication results to minimize redundant value joins and storage associated. We apply CSA on two common assertion-based checking clients, buffer overflow and null dereference detection. Experimental results show that CSA outperforms five open-source tools (INFER, Cppcheck, Ikos, Sparrow and KLEE) on ten large-scale projects. CSA finds 111 real bugs with 68.51% precision, detecting 46.05% more bugs than Infer and exhibiting 12.11% more precision rate than KLEE. CSA records 96.63% less false positives on real-world projects than the version without cross-domain interaction. CSA also exhibits an average speedup of 2.47× and an average memory reduction of 6.14× with equivalent correlation tracking.",1558-1225,979-8-4007-0217-4,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549341,Abstract execution;sparse analysis;cross-domain interaction,Correlation;Scalability;Computer bugs;Memory management;Buffer overflows;Static analysis;NIST,,,,69,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Maintaining invariant traceability through bidirectional transformations,Y. Yu; Y. Lin; Z. Hu; S. Hidaka; H. Kato; L. Montrieux,"Department of Computing, Open University, Milton Keynes, UK; Department of Computer Science, University of Illinois, Urbana-Champaign, USA; National Institute of Information, Tokyo, Japan; National Institute of Information, Tokyo, Japan; National Institute of Information, Tokyo, Japan; Department of Computing, Open University, Milton Keynes, UK",2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,540,550,"Following the “convention over configuration” paradigm, model-driven development (MDD) generates code to implement the “default” behaviour that has been specified by a template separate from the input model, reducing the decision effort of developers. For flexibility, users of MDD are allowed to customise the model and the generated code in parallel. A synchronisation of changed model or code is maintained by reflecting them on the other end of the code generation, as long as the traceability is unchanged. However, such invariant traceability between corresponding model and code elements can be violated either when (a) users of MDD protect custom changes from the generated code, or when (b) developers of MDD change the template for generating the default behaviour. A mismatch between user and template code is inevitable as they evolve for their own purposes. In this paper, we propose a two-layered invariant traceability framework that reduces the number of mismatches through bidirectional transformations. On top of existing vertical (model↔code) synchronisations between a model and the template code, a horizontal (code↔code) synchronisation between user and template code is supported, aligning the changes in both directions. Our blinkit tool is evaluated using the data set available from the CVS repositories of a MDD project: Eclipse MDT/GMF.",1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227162,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227162,,Synchronization;Java;Computational modeling;Generators;Adaptation models;Educational institutions;Prototypes,,33,,36,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
Message from the General Co-Chairs International Conference on Software Engineering (ICSE) 2024,A. C. R. Paiva; R. Abreu,"Faculty of Engineering, University of Porto, Portugal; Faculty of Engineering, University of Porto / Meta Platforms, Portugal, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),14 Jun 2024,2024,,,xxxvii,xl,"Welcome to the 46th edition of the IEEE/ACM International Conference on Software Engineering - ICSE 2024, set against the vibrant backdrop of Lisbon, Portugal. Acting as General Co-Chairs for this prestigious conference has been our great privilege and an extraordinary journey. Lisbon, where tradition and innovation merge seamlessly, is a beacon for technological advancement and cultural heritage. Portugal's capital is renowned not only for its historic sites, sunny disposition, and welcoming atmosphere but also for its dynamic technological ecosystem and educational institutions at the forefront of software engineering research. With Lisbon's rich history, cuttingedge companies, and thriving start-up scene, we are thrilled to invite you to an event that promises to be a melting pot of ideas, fostering groundbreaking discussions and collaborations. Let the scenic views of the Tagus River - which you will be seeing from Centro Cultural de Belém meeting rooms - and the charming streets of Lisbon inspire you as we delve into the latest developments and challenges in software engineering. Welcome to ICSE 2024 in Lisbon - a conference that promises to be as memorable and impactful as the city itself.",1558-1225,979-8-4007-0217-4,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548336,,,,,,0,,14 Jun 2024,,,IEEE,IEEE Conferences,True
Message from the ICSE 2022 General Chair,M. B. Dwyer,"Department of Computer Science, University of Virginia, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,xxix,xxx,"On behalf of the ICSE 2022 organizing committee, I welcome you to the 44th ACM/IEEE International Conference on Software Engineering. In 2022 ICSE will be held as a hybrid conference with virtual and in-person events. Building on the success of ICSE's virtual offerings in 2020 and 2021, ICSE 2022's virtual program aims to provide a forum that is accessible to all members of the software engineering community and that promotes the ability of contributors to highlight their findings and engage the community in conversation. ICSE 2022's in-person events will be held in Pittsburgh, Pennsylvania, USA. This is the second time that ICSE will be held in Pittsburgh, but the city has transformed into a vibrant technology hub since it hosted the 11th ICSE in 1989 and this creates a great opportunity for ICSE participants to connect with local industry.",1558-1225,978-1-4503-9221-1,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793892,,,,,,,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Message from the ICSE 2023 Program Co-Chairs,L. Pollock; M. Di Penta,"University of Delaware, DE, USA; University of Sannio, Italy",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),14 Jul 2023,2023,,,xl,xliii,"Welcome to ICSE 2023! It is our great pleasure to introduce the program of the 45th IEEE/ACM International Conference on Software Engineering (ICSE 2023), which will be held in Melbourne, Australia, on May 14-20, 2023.",1558-1225,978-1-6654-5701-9,10.1109/ICSE48619.2023.00006,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172566,,,,,,,IEEE,14 Jul 2023,,,IEEE,IEEE Conferences,True
Message from the ICSE 2022 Program Chairs,D. Damian; A. Zeller,"University of Victoria, Canada; CISPA, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),20 Jun 2022,2022,,,xxxi,xxxii,"What's new with ICSE 2022 ICSE 2022 is here! Oddly enough, a third year for ICSE papers to be written or reviewed during a global pandemic. Despite additional challenges, ICSE continued strong: another record submission number (691 papers in the technical track), and a largest ever ICSE Program Committee (almost 200 members). ICSE sets the record as being the flagship conference in Software Engineering.",1558-1225,978-1-4503-9221-1,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793861,,,,,,,,20 Jun 2022,,,IEEE,IEEE Conferences,True
Message from the Chairs,,,2012 34th International Conference on Software Engineering (ICSE),28 Jun 2012,2012,,,v,vii,Presents the welcome message from the conference proceedings.,1558-1225,978-1-4673-1067-3,10.1109/ICSE.2012.6227258,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227258,,,,,,,IEEE,28 Jun 2012,,,IEEE,IEEE Conferences,True
