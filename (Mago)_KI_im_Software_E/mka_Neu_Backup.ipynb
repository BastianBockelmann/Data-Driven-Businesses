{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1697443265451,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "2hNN7WALjFYW",
    "outputId": "c4c7fcee-ca88-453b-fb35-3925a74950cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Daten...\n",
      "Verfügbare Spalten: ['Document Title', 'Authors', 'Author Affiliations', 'Publication Title', 'Date Added To Xplore', 'Publication Year', 'Volume', 'Issue', 'Start Page', 'End Page', 'Abstract', 'ISSN', 'ISBNs', 'DOI', 'Funding Information', 'PDF Link', 'Author Keywords', 'IEEE Terms', 'Mesh_Terms', 'Article Citation Count', 'Patent Citation Count', 'Reference Count', 'License', 'Online Date', 'Issue Date', 'Meeting Date', 'Publisher', 'Document Identifier', 'is_ai_related']\n",
      "\n",
      "Datensatz Größe: 642\n",
      "\n",
      "Anzahl der Abstracts: 642\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "# Deaktiviere Altair Row Limit\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "# Daten laden\n",
    "print(\"Lade Daten...\")\n",
    "df = pd.read_csv('AI_Related_Papers_Cleaned.csv')\n",
    "print(\"Verfügbare Spalten:\", df.columns.tolist())\n",
    "print(\"\\nDatensatz Größe:\", len(df))\n",
    "\n",
    "# Extrahiere Dokumente für Topic Modeling\n",
    "docs = df[\"Abstract\"].to_list()\n",
    "print(\"\\nAnzahl der Abstracts:\", len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1697443367986,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "ErdCJCWekPLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysiere Publikationstrends...\n",
      "Publikationstrend-Visualisierung gespeichert als 'publication_trends.html'\n"
     ]
    }
   ],
   "source": [
    "# 1. Publikationstrend-Analyse\n",
    "print(\"\\nAnalysiere Publikationstrends...\")\n",
    "yearly_pubs = df.groupby('Publication Year').size().reset_index(name='count')\n",
    "\n",
    "# Erstelle ein vollständiges DataFrame für alle Jahre von 1994 bis 2024\n",
    "all_years = pd.DataFrame({'Publication Year': range(1994, 2025)})\n",
    "yearly_pubs = pd.merge(all_years, yearly_pubs, on='Publication Year', how='left')\n",
    "yearly_pubs['count'] = yearly_pubs['count'].fillna(0)\n",
    "\n",
    "# Erstelle den Basis-Linienplot\n",
    "base = alt.Chart(yearly_pubs).encode(\n",
    "    x=alt.X('Publication Year:Q',\n",
    "            scale=alt.Scale(domain=[1994, 2024]),\n",
    "            axis=alt.Axis(\n",
    "                tickCount=yearly_pubs['Publication Year'].nunique(),\n",
    "                format='d'\n",
    "            ),\n",
    "            title='Jahr'),\n",
    "    y=alt.Y('count:Q',\n",
    "            title='Anzahl Publikationen')\n",
    ")\n",
    "\n",
    "# Linienplot mit Punkten\n",
    "lines = base.mark_line()\n",
    "points = base.mark_point(size=50)\n",
    "\n",
    "# Text-Labels für die Datenpunkte\n",
    "text = base.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-10  # Verschiebung nach oben\n",
    ").encode(\n",
    "    text=alt.Text('count:Q', format='.0f')  # Formatierung als ganze Zahl\n",
    ")\n",
    "\n",
    "# Kombiniere alle Elemente\n",
    "pub_trend_chart = (lines + points + text).properties(\n",
    "    title='Entwicklung der KI-Publikationen im Software Engineering',\n",
    "    width=1000,\n",
    "    height=500\n",
    ").configure_axis(\n",
    "    grid=True,\n",
    "    gridOpacity=0.3\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")\n",
    "\n",
    "pub_trend_chart.save('publication_trends.html')\n",
    "print(\"Publikationstrend-Visualisierung gespeichert als 'publication_trends.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1697443395788,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "xjXhaxSejFYe",
    "outputId": "0ef74aaa-1c2e-455b-bee9-2e2a4dc6eb56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Führe Topic Modeling durch...\n",
      "\n",
      "Gefundene Topics:\n",
      "    Topic  Count                                               Name  \\\n",
      "0      -1    171                -1_software_faults_developers_tools   \n",
      "1       0    198                    0_code_program_software_patches   \n",
      "2       1     85  1_adversarial_vulnerabilities_vulnerability_vu...   \n",
      "3       2     65  2_maintainability_software_reliability_mainten...   \n",
      "4       3     29                     3_testing_coverage_test_faults   \n",
      "5       4     26      4_metamodels_metamodel_modeling_specification   \n",
      "6       5     23                             5_apps_android_app_gui   \n",
      "7       6     22       6_concurrency_scheduling_protocols_deadlocks   \n",
      "8       7      9        7_markovian_markov_stochastic_probabilistic   \n",
      "9       8      8  8_programming_programmers_developers_collabora...   \n",
      "10      9      6                        9_icse_conference_2022_ieee   \n",
      "\n",
      "                                       Representation  \\\n",
      "0   [software, faults, developers, tools, programs...   \n",
      "1   [code, program, software, patches, automated, ...   \n",
      "2   [adversarial, vulnerabilities, vulnerability, ...   \n",
      "3   [maintainability, software, reliability, maint...   \n",
      "4   [testing, coverage, test, faults, mutants, mut...   \n",
      "5   [metamodels, metamodel, modeling, specificatio...   \n",
      "6   [apps, android, app, gui, guis, mobile, runtim...   \n",
      "7   [concurrency, scheduling, protocols, deadlocks...   \n",
      "8   [markovian, markov, stochastic, probabilistic,...   \n",
      "9   [programming, programmers, developers, collabo...   \n",
      "10  [icse, conference, 2022, ieee, 2023, acm, 2024...   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [On-board embedded software developed for spac...  \n",
      "1   [Automated program repair is the problem of au...  \n",
      "2   [Deep learning (DL) plays a more and more impo...  \n",
      "3   [In software reliability modeling, the paramet...  \n",
      "4   [The test case generation is intrinsically a m...  \n",
      "5   [Formal methods and supporting tools have a lo...  \n",
      "6   [Web applications are widely adopted and their...  \n",
      "7   [In this paper, we describe Teapot, a domain-s...  \n",
      "8   [Equivalence relations can be used to reduce t...  \n",
      "9   [Pair Programming is one of the most studied a...  \n",
      "10  [What's new with ICSE 2022 ICSE 2022 is here! ...  \n",
      "\n",
      "Erstelle Topic-Visualisierungen...\n"
     ]
    }
   ],
   "source": [
    "# 2. Topic Modeling\n",
    "print(\"\\nFühre Topic Modeling durch...\")\n",
    "# Embedding Model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# UMAP Model\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=10,\n",
    "    n_components=2,\n",
    "    min_dist=0.0,\n",
    "    metric='cosine',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# HDBSCAN Model\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=5,\n",
    "    metric='euclidean',\n",
    "    cluster_selection_method='eom',\n",
    "    prediction_data=True\n",
    ")\n",
    "\n",
    "# Topic Model\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=CountVectorizer(stop_words=[]),\n",
    "    ctfidf_model=ClassTfidfTransformer(),\n",
    "    representation_model=KeyBERTInspired()\n",
    ")\n",
    "\n",
    "# Fit Model\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "topic_model.reduce_topics(docs, nr_topics=11)\n",
    "\n",
    "# Topic Info ausgeben\n",
    "print(\"\\nGefundene Topics:\")\n",
    "print(topic_model.get_topic_info())\n",
    "\n",
    "# Topic Visualisierungen erstellen und speichern\n",
    "print(\"\\nErstelle Topic-Visualisierungen...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1697443395789,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "cfTcUTyxjFYe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokument-Visualisierung gespeichert als 'topic_visualization.html'\n"
     ]
    }
   ],
   "source": [
    "# Document Visualization\n",
    "fig_docs = topic_model.visualize_documents(\n",
    "    docs,\n",
    "    topics=list(range(-1, len(topic_model.get_topics())-1)),\n",
    "    width=1200,\n",
    "    height=1000\n",
    ")\n",
    "fig_docs.write_html(\"topic_visualization.html\")\n",
    "print(\"Dokument-Visualisierung gespeichert als 'topic_visualization.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 9507,
     "status": "ok",
     "timestamp": 1697443405284,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "lr9D6ErVjFYe",
    "outputId": "632b77be-16d5-4f78-cb94-e28f1e53b86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic-Distanz-Visualisierung gespeichert als 'topic_interdistance.html'\n"
     ]
    }
   ],
   "source": [
    "# Topic Distance Visualization\n",
    "fig_distance = topic_model.visualize_topics(\n",
    "    width=850,\n",
    "    height=650\n",
    ")\n",
    "fig_distance.write_html(\"topic_interdistance.html\")\n",
    "print(\"Topic-Distanz-Visualisierung gespeichert als 'topic_interdistance.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1697443405285,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "aPTZv-IujFYf",
    "outputId": "d19757c3-61a4-4bd4-d401-eeefbcb8c486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barchart-Visualisierung gespeichert als 'topic_barchart.html'\n"
     ]
    }
   ],
   "source": [
    "# Barchart Visualization\n",
    "fig_barchart = topic_model.visualize_barchart()\n",
    "fig_barchart.write_html(\"topic_barchart.html\")\n",
    "print(\"Barchart-Visualisierung gespeichert als 'topic_barchart.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1697443406249,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "vvMOtIfCMO7n",
    "outputId": "9cabaf3b-526d-4e1c-8f2b-58e28aa67336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap-Visualisierung gespeichert als 'topic_heatmap.html'\n"
     ]
    }
   ],
   "source": [
    "# Heatmap Visualization\n",
    "fig_heatmap = topic_model.visualize_heatmap(\n",
    "    n_clusters=3,\n",
    "    width=700,\n",
    "    height=700\n",
    ")\n",
    "fig_heatmap.write_html(\"topic_heatmap.html\")\n",
    "print(\"Heatmap-Visualisierung gespeichert als 'topic_heatmap.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1697443406249,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "B3jcLyo1ivFl",
    "outputId": "bb3cd857-6cfb-49ce-b42f-331a9f481075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysiere zeitliche Entwicklung der Topics...\n",
      "Zeitliche Entwicklung gespeichert als 'topics_over_time.html'\n"
     ]
    }
   ],
   "source": [
    "# 3. Zeitliche Entwicklung der Topics\n",
    "print(\"\\nAnalysiere zeitliche Entwicklung der Topics...\")\n",
    "timestamps = df[\"Publication Year\"].tolist()\n",
    "topics_over_time = topic_model.topics_over_time(docs, timestamps)\n",
    "fig_time = topic_model.visualize_topics_over_time(\n",
    "    topics_over_time,\n",
    "    width=1000\n",
    ")\n",
    "fig_time.write_html(\"topics_over_time.html\")\n",
    "print(\"Zeitliche Entwicklung gespeichert als 'topics_over_time.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1697443406250,
     "user": {
      "displayName": "Mr. Ben",
      "userId": "14464510081174440893"
     },
     "user_tz": -120
    },
    "id": "0_VzqpwCN4gM",
    "outputId": "f0c29fb0-4af9-47f6-cab6-5ac119bfcc9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysiere Technologie-Trends...\n",
      "Technologie-Trend-Visualisierung gespeichert als 'technology_trends.html'\n"
     ]
    }
   ],
   "source": [
    "# 4. Technologie-Trend-Analyse\n",
    "print(\"\\nAnalysiere Technologie-Trends...\")\n",
    "tech_keywords = tech_categories = {\n",
    "    'Machine Learning': ['machine learning', 'ml', 'supervised learning', 'unsupervised learning'],\n",
    "    'Deep Learning': ['deep learning', 'neural network', 'cnn', 'rnn', 'lstm'],\n",
    "    'Natural Language Processing': ['nlp', 'natural language processing', 'text analysis', 'language model'],\n",
    "    'Computer Vision': ['computer vision', 'image processing', 'object detection'],\n",
    "    'Reinforcement Learning': ['reinforcement learning', 'rl', 'q-learning'],\n",
    "    'Expert Systems': ['expert system', 'knowledge base', 'rule-based']\n",
    "}\n",
    "\n",
    "tech_trends = pd.DataFrame()\n",
    "for keyword in tech_keywords:\n",
    "    tech_trends[keyword] = df['Abstract'].str.contains(keyword, case=False).astype(int)\n",
    "\n",
    "# Aggregiere nach Jahr\n",
    "yearly_tech_trends = pd.concat([\n",
    "    df['Publication Year'],\n",
    "    tech_trends\n",
    "], axis=1).groupby('Publication Year').sum().reset_index()\n",
    "\n",
    "# Erstelle ein vollständiges DataFrame für alle Jahre von 1994 bis 2024\n",
    "all_years = pd.DataFrame({'Publication Year': range(1994, 2025)})\n",
    "yearly_tech_trends = pd.merge(all_years, yearly_tech_trends, on='Publication Year', how='left')\n",
    "yearly_tech_trends = yearly_tech_trends.fillna(0)\n",
    "\n",
    "# Erstelle eine Altair-Visualisierung\n",
    "tech_trend_chart = alt.Chart(\n",
    "    yearly_tech_trends.melt('Publication Year', var_name='Technology', value_name='Count')\n",
    ").mark_line(point=True).encode(\n",
    "    x=alt.X('Publication Year:Q',\n",
    "            scale=alt.Scale(domain=[1994, 2024]),\n",
    "            axis=alt.Axis(\n",
    "                tickCount=yearly_tech_trends['Publication Year'].nunique(),\n",
    "                format='d'  # 'd' format für ganze Zahlen\n",
    "            ),\n",
    "            title='Jahr'),\n",
    "    y=alt.Y('Count:Q', title='Anzahl der Erwähnungen'),\n",
    "    color=alt.Color('Technology:N', title='Technologie'),\n",
    "    tooltip=['Publication Year:Q', 'Technology:N', 'Count:Q']\n",
    ").properties(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    title='Entwicklung verschiedener KI-Technologien über die Zeit'\n",
    ")\n",
    "\n",
    "# Speichere die Visualisierung als HTML\n",
    "tech_trend_chart.save('technology_trends.html')\n",
    "print(\"Technologie-Trend-Visualisierung gespeichert als 'technology_trends.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Führe Zitationsanalyse durch...\n",
      "\n",
      "Top 10 meist-zitierte Papers:\n",
      "\n",
      "Titel: Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings\n",
      "Zitationen: 849.0\n",
      "Jahr: 2008\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: GenProg: A Generic Method for Automatic Software Repair\n",
      "Zitationen: 718.0\n",
      "Jahr: 2012\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: A critique of software defect prediction models\n",
      "Zitationen: 694.0\n",
      "Jahr: 1999\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: Simplifying and isolating failure-inducing input\n",
      "Zitationen: 670.0\n",
      "Jahr: 2002\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: Model-checking algorithms for continuous-time Markov chains\n",
      "Zitationen: 526.0\n",
      "Jahr: 2003\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: Change Distilling:Tree Differencing for Fine-Grained Source Code Change Extraction\n",
      "Zitationen: 452.0\n",
      "Jahr: 2007\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: Quantitative analysis of faults and failures in a complex software system\n",
      "Zitationen: 442.0\n",
      "Jahr: 2000\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: An Exploratory Study of How Developers Seek, Relate, and Collect Relevant Information during Software Maintenance Tasks\n",
      "Zitationen: 418.0\n",
      "Jahr: 2006\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: Machine Learning Testing: Survey, Landscapes and Horizons\n",
      "Zitationen: 417.0\n",
      "Jahr: 2022\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Titel: An Empirical Comparison of Model Validation Techniques for Defect Prediction Models\n",
      "Zitationen: 377.0\n",
      "Jahr: 2017\n",
      "Journal: IEEE Transactions on Software Engineering\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Zitationsanalyse\n",
    "print(\"\\nFühre Zitationsanalyse durch...\")\n",
    "\n",
    "# Top zitierte Papers\n",
    "print(\"\\nTop 10 meist-zitierte Papers:\")\n",
    "top_cited = df.nlargest(10, 'Article Citation Count')\n",
    "for idx, paper in top_cited.iterrows():\n",
    "    print(f\"\\nTitel: {paper['Document Title']}\")\n",
    "    print(f\"Zitationen: {paper['Article Citation Count']}\")\n",
    "    print(f\"Jahr: {paper['Publication Year']}\")\n",
    "    print(f\"Journal: {paper['Publication Title']}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "# Zitationsentwicklung über Zeit\n",
    "yearly_citations = df.groupby('Publication Year')['Article Citation Count'].sum().reset_index()\n",
    "\n",
    "# Visualisierung mit Altair\n",
    "citation_chart = alt.Chart(yearly_citations).mark_line(point=True).encode(\n",
    "    x=alt.X('Publication Year:Q',\n",
    "            scale=alt.Scale(domain=[1994, 2024]),\n",
    "            axis=alt.Axis(format='d'),\n",
    "            title='Jahr'),\n",
    "    y=alt.Y('Article Citation Count:Q',\n",
    "            title='Gesamtzahl der Zitationen'),\n",
    "    tooltip=['Publication Year:Q', 'Article Citation Count:Q']\n",
    ").properties(\n",
    "    title='Entwicklung der Zitationen über Zeit',\n",
    "    width=1000,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Füge Textlabels hinzu\n",
    "text = alt.Chart(yearly_citations).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-10\n",
    ").encode(\n",
    "    x='Publication Year:Q',\n",
    "    y='Article Citation Count:Q',\n",
    "    text=alt.Text('Article Citation Count:Q', format='.0f')\n",
    ")\n",
    "\n",
    "# Kombiniere Chart und Labels\n",
    "final_citation_chart = (citation_chart + text).configure_axis(\n",
    "    grid=True,\n",
    "    gridOpacity=0.3\n",
    ")\n",
    "final_citation_chart.save('citation_trends.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysiere führende Journals...\n",
      "\n",
      "Journal-Analyse abgeschlossen und gespeichert\n"
     ]
    }
   ],
   "source": [
    "# 6. Journal Analyse\n",
    "print(\"\\nAnalysiere führende Journals...\")\n",
    "journal_stats = df.groupby('Publication Title').agg({\n",
    "    'Document Title': 'count',\n",
    "    'Article Citation Count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "journal_stats.columns = ['Journal', 'Anzahl Papers', 'Gesamtzitationen']\n",
    "journal_stats['Durchschnittliche Zitationen'] = journal_stats['Gesamtzitationen'] / journal_stats['Anzahl Papers']\n",
    "journal_stats = journal_stats.sort_values('Gesamtzitationen', ascending=False)\n",
    "\n",
    "# Top 10 Journals visualisieren\n",
    "top_journals = journal_stats.head(10)\n",
    "journal_chart = alt.Chart(top_journals).mark_bar().encode(\n",
    "    y=alt.Y('Journal:N', \n",
    "            sort='-x',\n",
    "            title='Journal'),\n",
    "    x=alt.X('Gesamtzitationen:Q',\n",
    "            title='Gesamtzahl der Zitationen'),\n",
    "    tooltip=['Journal', 'Anzahl Papers', 'Gesamtzitationen', 'Durchschnittliche Zitationen']\n",
    ").properties(\n",
    "    title='Top 10 Journals nach Gesamtzitationen',\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Füge Werte an den Balken hinzu\n",
    "text = alt.Chart(top_journals).mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3\n",
    ").encode(\n",
    "    y='Journal:N',\n",
    "    x='Gesamtzitationen:Q',\n",
    "    text=alt.Text('Gesamtzitationen:Q', format='.0f')\n",
    ")\n",
    "\n",
    "final_journal_chart = (journal_chart + text).configure_axis(\n",
    "    grid=True,\n",
    "    gridOpacity=0.3\n",
    ")\n",
    "final_journal_chart.save('journal_analysis.html')\n",
    "\n",
    "print(\"\\nJournal-Analyse abgeschlossen und gespeichert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysiere Länder und Institutionen...\n",
      "\n",
      "Top 10 Länder und ihre Publikationszahlen:\n",
      "USA: 193\n",
      "China: 140\n",
      "UK: 48\n",
      "Canada: 44\n",
      "Italy: 32\n",
      "Germany: 29\n",
      "Australia: 20\n",
      "Norway: 11\n",
      "Switzerland: 10\n",
      "Spain: 9\n"
     ]
    }
   ],
   "source": [
    "# 7. Länder- und Institutionsanalyse\n",
    "print(\"\\nAnalysiere Länder und Institutionen...\")\n",
    "\n",
    "def extract_country(affiliation):\n",
    "    # Spezifische Länder und ihre Varianten\n",
    "    common_countries = {\n",
    "        'USA': ['USA', 'United States', 'U.S.A', 'United States of America', 'United States of'],\n",
    "        'UK': ['UK', 'United Kingdom', 'England', 'Scotland', 'Wales', 'Britain'],\n",
    "        'Germany': ['Germany', 'Deutschland'],\n",
    "        'China': ['China', 'P.R. China', 'People\\'s Republic of China'],\n",
    "        'Canada': ['Canada'],\n",
    "        'Japan': ['Japan'],\n",
    "        'India': ['India'],\n",
    "        'Australia': ['Australia'],\n",
    "        'France': ['France'],\n",
    "        'Italy': ['Italy'],\n",
    "        'Spain': ['Spain'],\n",
    "        'Netherlands': ['Netherlands', 'The Netherlands'],\n",
    "        'Switzerland': ['Switzerland'],\n",
    "        'South Korea': ['South Korea', 'Korea'],\n",
    "        'Singapore': ['Singapore'],\n",
    "        'Brazil': ['Brazil'],\n",
    "        'Sweden': ['Sweden'],\n",
    "        'Norway': ['Norway'],\n",
    "        'Denmark': ['Denmark'],\n",
    "        'Austria': ['Austria']\n",
    "    }\n",
    "    \n",
    "    if pd.isna(affiliation):\n",
    "        return None\n",
    "        \n",
    "    affiliation = str(affiliation).lower()\n",
    "    for country, variants in common_countries.items():\n",
    "        if any(variant.lower() in affiliation for variant in variants):\n",
    "            return country\n",
    "    return None\n",
    "\n",
    "def extract_institution(affiliation):\n",
    "    if pd.isna(affiliation):\n",
    "        return None\n",
    "    \n",
    "    # Erste Institution nehmen (falls mehrere angegeben sind)\n",
    "    institution = affiliation.split(';')[0].strip()\n",
    "    \n",
    "    # Kurze oder leere Institutionsnamen ausfiltern\n",
    "    if len(institution) < 5:\n",
    "        return None\n",
    "        \n",
    "    return institution\n",
    "\n",
    "# Länder und Institutionen extrahieren\n",
    "df['Country'] = df['Author Affiliations'].apply(extract_country)\n",
    "df['Institution'] = df['Author Affiliations'].apply(extract_institution)\n",
    "\n",
    "# Länderanalyse\n",
    "valid_countries = df['Country'].dropna().value_counts().head(10)\n",
    "country_data = pd.DataFrame({\n",
    "    'Country': valid_countries.index,\n",
    "    'Count': valid_countries.values\n",
    "})\n",
    "\n",
    "# Länder-Visualisierung\n",
    "country_chart = alt.Chart(country_data).mark_bar().encode(\n",
    "    y=alt.Y('Country:N', \n",
    "            sort='-x',\n",
    "            title='Land'),\n",
    "    x=alt.X('Count:Q',\n",
    "            title='Anzahl Publikationen'),\n",
    "    tooltip=['Country:N', 'Count:Q']\n",
    ").properties(\n",
    "    title='Top 10 Länder in der KI-Software-Engineering-Forschung',\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Text-Labels für Länder\n",
    "country_text = alt.Chart(country_data).mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3\n",
    ").encode(\n",
    "    y='Country:N',\n",
    "    x='Count:Q',\n",
    "    text=alt.Text('Count:Q', format='.0f')\n",
    ")\n",
    "\n",
    "final_country_chart = (country_chart + country_text).configure_axis(\n",
    "    grid=True,\n",
    "    gridOpacity=0.3\n",
    ")\n",
    "final_country_chart.save('country_analysis.html')\n",
    "\n",
    "\n",
    "# Statistiken ausgeben\n",
    "print(\"\\nTop 10 Länder und ihre Publikationszahlen:\")\n",
    "for country, count in valid_countries.items():\n",
    "    print(f\"{country}: {int(count)}\")\n",
    "\n",
    "# Statistiken speichern\n",
    "country_data.to_csv('country_statistics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Institutionen und ihre Publikationszahlen:\n",
      "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China: 10\n",
      "Dept. of Computer Science, Iowa State University, Ames, IA, USA: 6\n",
      "David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada: 4\n",
      "Simula Research Laboratory, Lysaker, Norway: 4\n",
      "Singapore Management University, Singapore: 3\n",
      "Monash University, Melbourne, Australia: 3\n",
      "Purdue University, West Lafayette, USA: 3\n",
      "The Chinese University of Hong Kong, Hong Kong, China: 3\n",
      "Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA: 3\n",
      "Department of Informatics, University of Oslo, Oslo, Norway: 3\n",
      "\n",
      "Ländersanalyse abgeschlossen und gespeichert\n"
     ]
    }
   ],
   "source": [
    "# 8. Institutionsanalyse\n",
    "valid_institutions = df['Institution'].dropna().value_counts().head(10)\n",
    "institution_data = pd.DataFrame({\n",
    "    'Institution': valid_institutions.index,\n",
    "    'Count': valid_institutions.values\n",
    "})\n",
    "\n",
    "# Institutions-Visualisierung\n",
    "institution_chart = alt.Chart(institution_data).mark_bar().encode(\n",
    "    y=alt.Y('Institution:N', \n",
    "            sort='-x',\n",
    "            title='Institution'),\n",
    "    x=alt.X('Count:Q',\n",
    "            title='Anzahl Publikationen'),\n",
    "    tooltip=['Institution:N', 'Count:Q']\n",
    ").properties(\n",
    "    title='Top 10 Institutionen in der KI-Software-Engineering-Forschung',\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Text-Labels für Institutionen\n",
    "institution_text = alt.Chart(institution_data).mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3\n",
    ").encode(\n",
    "    y='Institution:N',\n",
    "    x='Count:Q',\n",
    "    text=alt.Text('Count:Q', format='.0f')\n",
    ")\n",
    "\n",
    "final_institution_chart = (institution_chart + institution_text).configure_axis(\n",
    "    grid=True,\n",
    "    gridOpacity=0.3\n",
    ")\n",
    "final_institution_chart.save('institution_analysis.html')\n",
    "\n",
    "print(\"\\nTop 10 Institutionen und ihre Publikationszahlen:\")\n",
    "for institution, count in valid_institutions.items():\n",
    "    print(f\"{institution}: {int(count)}\")\n",
    "\n",
    "# Statistiken speichern\n",
    "institution_data.to_csv('institution_statistics.csv', index=False)\n",
    "print(\"\\nLändersanalyse abgeschlossen und gespeichert\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
