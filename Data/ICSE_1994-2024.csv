"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Empirically researching development of international software","M. Ressin","Centre for Internationalisation and Usability, University of West London, London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1551","1554","Software localization is an important process for international acceptance of software products. However, software development and localization does not always come together without friction. In our empirical software engineering research, we examine the interplay of software development and software localization by gathering and analyzing qualitative and quantitative data from professionals in relevant roles. Our aim is to co-validate issues and inform practice about the development of international software.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227039","empirical software engineering;industrial;practice and experience","Software;Interviews;Programming;Human factors;Cultural differences;Software engineering;Conferences","","","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Influencing the adoption of software engineering methods using social software","L. Singer; K. Schneider","Software Engineering Group, Leibniz Universität Hannover, Hanover, Germany; Software Engineering Group, Leibniz Universität Hannover, Hanover, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1325","1328","Software engineering research and practice provide a wealth of methods that improve the quality of software and lower the costs of producing it. Even though processes mandate their use, methods are not employed consequently. Software developers and development organizations thus cannot fully benefit from these methods. We propose a method that, for a given software engineering method, provides instructions on how to improve its adoption using social software. This employs the intrinsic motivation of software developers rather than prescribing behavior. As a result, we believe that software engineering methods will be applied better and more frequently.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227088","Social Software;Motivation;Adoption;Process;Virtual Communities;CSCW;Social Network Sites","Software;Software engineering;Measurement;Social network services;Systematics;Crystals;Media","","13","","16","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Five days of empirical software engineering: The PASED experience","M. Di Penta; G. Antoniol; D. M. Germán; Y. -G. Guéhéneuc; B. Adams","University of Sannio, Benevento, Italy; École Polytechnique de Montréal, Quebec, Canada; University of Victoria, Victoria, BC, Canada; École Polytechnique de Montréal, Quebec, Canada; École Polytechnique de Montréal, Quebec, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1255","1258","Acquiring the skills to plan and conduct different kinds of empirical studies is a mandatory requirement for graduate students working in the field of software engineering. These skills typically can only be developed based on the teaching and experience of the students' supervisor, because of the lack of specific, practical courses providing these skills. To fill this gap, we organized the first Canadian Summer School on Practical Analyses of Software Engineering Data (PASED). The aim of PASED is to provide — using a “learning by doing” model of teaching — a solid foundation to software engineering graduate students on conducting empirical studies. This paper describes our experience in organizing the PASED school, i.e., what challenges we encountered, how we designed the lectures and laboratories, and what could be improved in the future based on the participants' feedback.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227017","Empirical Software Engineering;Software Engineering Education","Educational institutions;Software engineering;Software;Data mining;Laboratories;Organizing","","","","13","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Toward actionable, broadly accessible contests in Software Engineering","J. Cleland-Huang; Y. Shin; E. Keenan; A. Czauderna; G. Leach; E. Moritz; M. Gethers; D. Poshyvanyk; J. H. Hayes; W. Li","Greg Leach DePaul University, Chicago, IL, USA; Greg Leach DePaul University, Chicago, IL, USA; Greg Leach DePaul University, Chicago, IL, USA; Greg Leach DePaul University, Chicago, IL, USA; Greg Leach DePaul University, Chicago, IL, USA; College of William and Mary, Williamsburg, VA, USA; College of William and Mary, Williamsburg, VA, USA; College of William and Mary, Williamsburg, VA, USA; University of Kentucky, Lexington, KY, USA; University of Kentucky, Lexington, KY, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1329","1332","Software Engineering challenges and contests are becoming increasingly popular for focusing researchers' efforts on particular problems. Such contests tend to follow either an exploratory model, in which the contest holders provide data and ask the contestants to discover “interesting things” they can do with it, or task-oriented contests in which contestants must perform a specific task on a provided dataset. Only occasionally do contests provide more rigorous evaluation mechanisms that precisely specify the task to be performed and the metrics that will be used to evaluate the results. In this paper, we propose actionable and crowd-sourced contests: actionable because the contest describes a precise task, datasets, and evaluation metrics, and also provides a downloadable operating environment for the contest; and crowd-sourced because providing these features creates accessibility to Information Technology hobbyists and students who are attracted by the challenge. Our proposed approach is illustrated using research challenges from the software traceability area as well as an experimental workbench named TraceLab.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227087","Traceability;Contest;TraceLab;Empirical Software Engineering","Measurement;Software engineering;Software;Communities;Conferences;Information retrieval;Data mining","","9","","14","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Release engineering practices and pitfalls","H. K. Wright; D. E. Perry","Department of Electrical and Computer Engineering, University of Texas, Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, University of Texas, Austin, Austin, TX, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1281","1284","The release and deployment phase of the software development process is often overlooked as part of broader software engineering research. In this paper, we discuss early results from a set of multiple semi-structured interviews with practicing release engineers. Subjects for the interviews are drawn from a number of different commercial software development organizations, and our interviews focus on why release process faults and failures occur, how organizations recover from them, and how they can be predicted, avoided or prevented in the future. Along the way, the interviews provide insight into the state of release engineering today, and interesting relationships between software architecture and release processes.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227099","release engineering;software process","Software;Interviews;Organizations;Programming;Software engineering;History;Standardization","","12","","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Goldfish bowl panel: Software development analytics","T. Menzies; T. Zimmermann","West Virginia University, Morgantown, WV, USA; Microsoft Research, Redmond, WA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1032","1033","Gaming companies now routinely apply data mining to their user data in order to plan the next release of their software. We predict that such software development analytics will become commonplace, in the near future. For example, as large software systems migrate to the cloud, they are divided and sold as dozens of smaller apps; when shopping inside the cloud, users are free to mix and match their apps from multiple vendors (e.g. Google Docs' word processor with Zoho's slide manager); to extend, or even retain, market share cloud vendors must mine their user data in order to understand what features best attract their clients. This panel will address the open issues with analytics. Issues addressed will include the following. What is the potential for software development analytics? What are the strengths and weaknesses of the current generation of analytics tools? How best can we mature those tools?","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227117","analytics;empirical software engineering;mining software repositories;industry","Software engineering;Software;Programming;Educational institutions;Data mining;Conferences;Business","","5","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"The co-evolution of socio-technical structures in sustainable software development: Lessons from the open source software communities","M. S. Zanetti","ETH Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1587","1590","Software development depends on many factors, including technical, human and social aspects. Due to the complexity of this dependence, a unifying framework must be defined and for this purpose we adopt the complex networks methodology. We use a data-driven approach based on a large collection of open source software projects extracted from online project development platforms. The preliminary results presented in this article reveal that the network perspective yields key insights into the sustainability of software development.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227030","complex networks;statistical physics;social networks;software dependency graphs;open source software;free software;quantitative analysis;mining software repositories","Software;Programming;Complex networks;Measurement;Software engineering;Communities;Collaboration","","10","","15","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software process improvement through the identification and removal of project-level knowledge flow obstacles","S. M. Mitchell; C. B. Seaman","Information Systems Department, University of Maryland Baltimore County, Baltimore, USA; Information Systems Department, University of Maryland Baltimore County, Baltimore, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1265","1268","Uncontrollable costs, schedule overruns, and poor end product quality continue to plague the software engineering field. This research investigates software process improvement (SPI) through the application of knowledge management (KM) at the software project level. A pilot study was conducted to investigate what types of obstacles to knowledge flow exist within a software development project, as well as the potential influence on SPI of their mitigation or removal. The KM technique of “knowledge mapping” was used as a research technique to characterize knowledge flow. Results show that such mitigation or removal was acknowledged by project team members as having the potential for lowering project labor cost, improving schedule adherence, and enhancing final product quality.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227103","software process;software process improvement;SPI;knowledge management;knowledge flow;software engineering","Software;Interviews;Observers;Software engineering;Knowledge management;Knowledge engineering","","3","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Refounding software engineering: The Semat initiative (Invited presentation)","M. Kajko-Mattsson; M. Striewe; M. Goedicke; I. Jacobson; I. Spence; S. Huang; P. McMahon; B. MacIsaac; B. Elvesæter; A. J. Berre; E. Seymour","ICT/KTH Royal Institute of Technology, Stockholm, Sweden; Ivar Jacobson Int'l., UK; Ivar Jacobson Int'l., UK; PEM Systems, Binghamton, NY, USA; SINTEF. Oslo, Norway; SINTEF. Oslo, Norway; University of Duisburg-Essen, Essen, Germany; University of Duisburg-Essen, Essen, Germany; SINTEF. Oslo, Norway; SINTEF. Oslo, Norway; Business & Applications Services Fujitsu, London",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1649","1650","The new software engineering initiative, Semat, is in the process of developing a kernel for software engineering that stands on a solid theoretical basis. So far, it has suggested a set of kernel elements for software engineering and basic language constructs for defining the elements and their usage. This paper describes a session during which Semat results and status will be presented. The presentation will be followed by a discussion panel.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227214","software engineering method;kernel;theoretical basis;Semat;OMG standard;practitioner","Software engineering;Kernel;Communities;Jacobian matrices;Industries;Educational institutions","","4","","8","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Multi-label software behavior learning","Y. Feng; Z. Chen","State Key Laboratory for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Software Institute, Nanjing University, Nanjing, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1305","1308","Software behavior learning is an important task in software engineering. Software behavior is usually represented as a program execution. It is expected that similar executions have similar behavior, i.e. revealing the same faults. Single-label learning has been used to assign a single label (fault) to a failing execution in the existing efforts. However, a failing execution may be caused by several faults simultaneously. Hence, it needs to assign multiple labels to support software engineering tasks in practice. In this paper, we present multi-label software behavior learning. A well-known multi-label learning algorithm ML-KNN is introduced to achieve comprehensive learning of software behavior. We conducted a preliminary experiment on two industrial programs: flex and grep. The experimental results show that multi-label learning can produce more precise and complete results than single-label learning.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227093","Software behavior learning;multi-label learning;F-measure;failure report classification;failure prediction","Software;Software engineering;Software algorithms;Supervised learning;Xenon;Training;Machine learning","","16","","14","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software Engineering Research in a World with Generative Artificial Intelligence","M. Rinard","Department of Electrical Engineering and Computer Science, Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, Massachusetts, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","3","7","Generative artificial intelligence systems such as large language models (LLMs) exhibit powerful capabilities that many see as the kind of flexible and adaptive intelligence that previously only humans could exhibit. I address directions and implications of LLMs for software engineering research.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3649399","DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548653","Software Engineering;Generative Artificial Intelligence;Large Language Models","Adaptation models;Adaptive systems;Generative AI;Software;Software engineering","","","","24","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering","S. McGuire; E. Schultz; B. Ayoola; P. Ralph","Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1996","2008","Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or “pillars”-environmental, social, economic, technical and in-dividual. However; these pillars are theoretically underdeveloped and require refinement. Objectives: The objective of this paper is to generate a better theory of SSE. Method: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified. Results: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems). Conclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172842","Sustainable development;software engineering;sustainable software engineering;scoping review;meta-synthesis","Economics;Sociotechnical systems;Systematics;Databases;Biological system modeling;Instruments;Software","","7","","74","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Automatically detecting developer activities and problems in software development work","T. Roehm; W. Maalej","Technische Universität München, Munich, Germany; Technische Universität München, Munich, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1261","1264","Detecting the current activity of developers and problems they are facing is a prerequisite for a context-aware assistance and for capturing developers' experiences during their work. We present an approach to detect the current activity of software developers and if they are facing a problem. By observing developer actions like changing code or searching the web, we detect whether developers are locating the cause of a problem, searching for a solution, or applying a solution. We model development work as recurring problem solution cycle, detect developer's actions by instrumenting the IDE, translate developer actions to observations using ontologies, and infer developer activities by using Hidden Markov Models. In a preliminary evaluation, our approach was able to correctly detect 72% of all activities. However, a broader more reliable evaluation is still needed.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227104","activity detection;task management;machine learning;ontologies;context-aware software engineering","Hidden Markov models;Search problems;Software;Context;Switches;Ontologies;Software engineering","","10","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Moving on from the Software Engineers' Gambit: An Approach to Support the Defense of Software Effort Estimates","P. G. F. Matsubara; I. Steinmacher; B. Gadelha; T. Conte","Universidade Federal do Amazonas (UFAM), Manaus, AM; Northern Arizona University, Flagstaff, AZ, USA; Universidade Federal do Amazonas (UFAM), Manaus, AM; Universidade Federal do Amazonas (UFAM), Manaus, AM",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","703","715","Pressure for higher productivity and faster delivery is increasingly pervading software organizations. This can lead software engineers to act like chess players playing a gambit—making sacrifices of their technically sound estimates, thus submitting their teams to time pressure. In turn, time pressure can have varied detrimental effects, such as poor product quality and emotional distress, decreasing productivity, which leads to more time pressure and delays: a hard-to-stop vicious cycle. This reveals a need for moving on from the more passive strategy of yielding to pressure to a more active one of defending software estimates. Therefore, we propose an approach to support software estimators in acquiring knowledge on how to carry out such defense, by introducing negotiation principles encapsulated in a set of defense lenses, presented through a digital simulation. We evaluated the proposed approach through a controlled experiment with software practitioners from different companies. We collected data on participants' attitudes, subjective norms, perceived behavioral control, and intentions to perform the defense of their estimates in light of the Theory of Planned Behavior. We employed a frequentist and a bayesian approach to data analysis. Results show improved scores among experimental group participants after engaging with the digital simulation and learning about the lenses. They were also more inclined to choose a defense action when facing pressure scenarios than a control group exposed to questions to reflect on the reasons and outcomes of pressure over estimates. Qualitative evidence reveals that practitioners perceived the set of lenses as useful in their current work environments. Collectively, these results show the effectiveness of the proposed approach and its perceived relevance for the industry, despite the low amount of time required to engage with it.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172562","Software Effort Estimation;Negotiation;Behavioral Software Engineering;Defense of Estimates","Productivity;Knowledge engineering;Digital simulation;Software;Product design;Behavioral sciences;Quality assessment","","","","46","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Social Science Theories in Software Engineering Research","T. Lorey; P. Ralph; M. Felderer","Department of Computer Science, University of Innsbruck, Innsbruck, Austria; Faculty of Computer Science, Dalhousie University, Halifax, Canada; Department of Computer Science, University of Innsbruck, Innsbruck, Austria",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1994","2005","As software engineering research becomes more concerned with the psychological, sociological and managerial aspects of software development, relevant theories from reference disciplines are in-creasingly important for understanding the field's core phenomena of interest. However, the degree to which software engineering research draws on relevant social sciences remains unclear. This study therefore investigates the use of social science theories in five influential software engineering journals over 13 years. It analyzes not only the extent of theory use but also what, how and where these theories are used. While 87 different theories are used, less than two percent of papers use a social science theory, most theories are used in only one paper, most social sciences are ignored, and the theories are rarely tested for applicability to software engineering contexts. Ignoring relevant social science theories may (1) under-mine the community's ability to generate, elaborate and maintain a cumulative body of knowledge; and (2) lead to oversimplified mod-els of software engineering phenomena. More attention to theory is needed for software engineering to mature as a scientific discipline.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793978","software engineering;theory;social science","Knowledge engineering;Analytical models;Software design;Social sciences;Psychology;Predictive models;Software","","1","","83","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Teaching software engineering and software project management: An integrated and practical approach","G. Bavota; A. De Lucia; F. Fasano; R. Oliveto; C. Zottoli","School of Science, University of Salerno, Fisciano, Salerno, Italy; School of Science, University of Salerno, Fisciano, Salerno, Italy; STAT Department, University of Molise, Pesche, Italy; School of Science, University of Salerno, Fisciano, Salerno, Italy; School of Science, University of Salerno, Fisciano, Salerno, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1155","1164","We present a practical approach for teaching two different courses of Software Engineering (SE) and Software Project Management (SPM) in an integrated way. The two courses are taught in the same semester, thus allowing to build mixed project teams composed of five-eight Bachelor's students (with development roles) and one or two Master's students (with management roles). The main goal of our approach is to simulate a real-life development scenario giving to the students the possibility to deal with issues arising from typical project situations, such as working in a team, organising the division of work, and coping with time pressure and strict deadlines.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227027","","Software;Project management;Software engineering;Education;Programming;Unified modeling language;Quality management","","27","","36","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software Engineering as the Linchpin of Responsible AI","L. Zhu","CSIRO's Data61, Sydney, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","3","4","From humanity's existential risks to safety risks in critical systems to ethical risks, responsible AI, as the saviour, has become a major research challenge with significant real-world consequences. However, achieving responsible AI remains elusive despite the plethora of high-level ethical principles, risk frameworks and progress in algorithmic assurance. In the meantime, software engineering (SE) is being upended by AI, grappling with building system-level quality and alignment from inscrutable machine learning models and code generated from natural language prompts. The upending poses new challenges and opportunities for engineering AI systems responsibly. This talk will share our experiences in helping the industry achieve responsible AI systems by inventing new SE approaches. It will dive into industry challenges (such as risk silos and principle-algorithm gaps) and research challenges (such as lack of requirements, emerging properties and inscrutable systems) and make the point that SE is the linchpin of responsible AI. But SE also requires some fundamental rethinking - shifting from building functions into AI systems to discovering and managing emerging functions from AI systems. Only by doing so can SE take on critical new roles, from understanding human intelligence to building a thriving human-AI symbiosis.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172687","Responsible AI;Ethical AI;Trustworthy AI;AI Engineering;SE4AI","Industries;Symbiosis;Ethics;Machine learning algorithms;Buildings;Software algorithms;Natural languages","","","","6","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Summary of the ICSE 2012 workshops","A. Orso; R. Reussner","Georgia Institute of Technology, Atlanta, USA; Forschungszentrum Informatik (FZI), Karlsruhe Institute of Technology, Karlsruhe, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1651","1653","The workshops of ICSE 2012 provide a forum for researchers and practitioners to exchange and discuss scientific ideas before they have matured to warrant conzference or journal publication. ICSE Workshops also serve as incubators for scientific communities that form and share a particular research agenda.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227213","","Conferences;Software engineering;Programming;Communities;Software systems;Cloning","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Graph-based analysis and prediction for software evolution","P. Bhattacharya; M. Iliofotou; I. Neamtiu; M. Faloutsos","Department of Computer Science and Engineering, University of California, Riverside, CA, USA; Department of Computer Science and Engineering, University of California, Riverside, CA, USA; Department of Computer Science and Engineering, University of California, Riverside, CA, USA; Department of Computer Science and Engineering, University of California, Riverside, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","419","429","We exploit recent advances in analysis of graph topology to better understand software evolution, and to construct predictors that facilitate software development and maintenance. Managing an evolving, collaborative software system is a complex and expensive process, which still cannot ensure software reliability. Emerging techniques in graph mining have revolutionized the modeling of many complex systems and processes. We show how we can use a graph-based characterization of a software system to capture its evolution and facilitate development, by helping us estimate bug severity, prioritize refactoring efforts, and predict defect-prone releases. Our work consists of three main thrusts. First, we construct graphs that capture software structure at two different levels: (a) the product, i.e., source code and module level, and (b) the process, i.e., developer collaboration level. We identify a set of graph metrics that capture interesting properties of these graphs. Second, we study the evolution of eleven open source programs, including Firefox, Eclipse, MySQL, over the lifespan of the programs, typically a decade or more. Third, we show how our graph metrics can be used to construct predictors for bug severity, high-maintenance software parts, and failure-prone releases. Our work strongly suggests that using graph topology analysis concepts can open many actionable avenues in software engineering research and practice.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227173","Graph science;software evolution;software quality;defect prediction;productivity metrics;empirical studies","Measurement;Software;Collaboration;Fires;Maintenance engineering;Software engineering;Topology","","110","3","52","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Teaching collaborative software development: A case study","T. Kilamo; I. Hammouda; M. A. Chatti","Department of Software Systems, Tampere University of Technology, Tampere, Finland; Department of Software Systems, Tampere University of Technology, Tampere, Finland; Informatik 9 (Learning Technologies), RWTH Aachen University, Aachen, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1165","1174","Software development is today done in teams of software developers who may be distributed all over the world. Software development has also become to contain more social aspects and the need for collaboration has become more evident. The importance of teaching development methods used in collaborative development is of importance, as skills beyond traditional software development are needed in this modern setting. A novel, student centric approach was tried out at Tampere University of Technology where a new environment called KommGame was introduced. This environment includes a reputation system to support the social aspect of the environment and thus supporting the learners collaboration with each other. In this paper, we present the KommGame environment and how it was applied on a course for practical results.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227026","collaborative software development;SE education;case study","Education;Communities;Collaborative software;Programming;Software;Software engineering","","9","","33","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Search based design of software product lines architectures","T. E. Colanzi","Computer Science Department, Federal University of Paraná, Brazil",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1507","1510","The Product-Line Architecture (PLA) is the main artifact of a Software Product Line (SPL). However, obtaining a modular, extensible and reusable PLA is a people-intensive and non-trivial task, related to different and possible conflicting factors. Hence, the PLA design is a hard problem and to find the best architecture can be formulated as an optimization problem with many factors. Similar Software Engineering problems have been efficiently solved by search-based algorithms in the field known as Search-based Software Engineering. The existing approaches used to optimize software architecture are not suitable since they do not encompass specific characteristics of SPL. To easy the SPL development and to automate the PLA design this work introduces a multi-objective optimization approach to the PLA design. The approach is now being implemented by using evolutionary algorithms. Empirical studies will be performed to validate the neighborhood operators, SPL measures and search algorithms chosen. Finally, we intend to compare the results of the proposed approach with PLAs designed by human architects.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227050","software product lines;multi-objective algorithms;software architecture optimization","Programmable logic arrays;Optimization;Software;Computer architecture;Search problems;Software architecture","","6","","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Synthesis of event-based controllers: A software engineering challenge","N. D'Ippolito","Computing Department, Imperial College London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1547","1550","Existing software engineering techniques for automatic synthesis of event-based controllers have various limitations. In the context of the world/machine approach such limitations can be seen as restrictions in the expressiveness of the controller goals and domain model specifications or in the relation between the controllable and monitorable actions. In this thesis we aim to provide techniques that overcome such limitations, e.g. supporting more expressive goal specifications, distinguishing controllable from monitorable actions or guaranteeing achievement of the desired goals, among others. Hence, improving the state of the art in the synthesis of event-based controllers. Moreover, we plan to provide efficient tools supporting the developed techniques and evaluate them by modelling known case studies from the software engineering literature. Ultimately, showing that by allowing more expressiveness of controller goals and domain model specifications, and explicitly distinguishing controllable and monitorable actions such case studies can be more accurately modelled and solutions guaranteeing satisfaction of the goals can be achieved.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227040","controller synthesis;behavioural modelling","Adaptation models;Software engineering;Context;Computational modeling;Monitoring;Context modeling;Games","","1","","25","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"When open source turns cold on innovation — The challenges of navigating licensing complexities in new research domains","C. Forbes; I. Keivanloo; J. Rilling","Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1447","1448","In this poster, we review the limitations open source licences introduce to the application of Linked Data in Software Engineering. We investigate whether open source licences support special requirements to publish source code as Linked Data on the Internet.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227071","source code;license;Linked Data;open source","Licenses;Law;Software engineering;Databases;Software;Complexity theory","","","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"On the Reproducibility of Software Defect Datasets","H. -N. Zhu; C. Rubio-González","University of California, Davis, United States of America; University of California, Davis, United States of America",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2324","2335","Software defect datasets are crucial to facilitating the evaluation and comparison of techniques in fields such as fault localization, test generation, and automated program repair. However, the reproducibility of software defect artifacts is not immune to breakage. In this paper, we conduct a study on the reproducibility of software defect artifacts. First, we study five state-of-the-art Java defect datasets. Despite the multiple strategies applied by dataset maintainers to ensure reproducibility, all datasets are prone to breakages. Second, we conduct a case study in which we systematically test the reproducibility of 1,795 software artifacts during a 13-month period. We find that 62.6% of the artifacts break at least once, and 15.3% artifacts break multiple times. We manually investigate the root causes of breakages and handcraft 10 patches, which are automatically applied to 1,055 distinct artifacts in 2,948 fixes. Based on the nature of the root causes, we propose automated dependency caching and artifact isolation to prevent further breakage. In particular, we show that isolating artifacts to eliminate external dependencies increases reproducibility to 95% or higher, which is on par with the level of reproducibility exhibited by the most reliable manually curated dataset.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00195","National Science Foundation(grant numbers:CNS-2016735); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172645","software reproducibility;software defects;software maintenance;software quality","Location awareness;Java;Maintenance engineering;Reproducibility of results;Software;Software reliability;Test pattern generators","","3","","68","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Integrating tools and frameworks in undergraduate software engineering curriculum","C. Fuhrman; R. Champagne; A. April","Department of Software and IT Engineering, ÉTS, University of Quebec, Montreal, Canada; Department of Software and IT Engineering, ÉTS, University of Quebec, Montreal, Canada; Department of Software and IT Engineering, ÉTS, University of Quebec, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1195","1204","We share our experience over the last 10 years for finding, deploying and evaluating software engineering (SE) technologies in an undergraduate program at the ÉTS in Montreal, Canada. We identify challenges and propose strategies to integrate technologies into an SE curriculum. We demonstrate how technologies are integrated throughout our program, and provide details of the integration in two specific courses.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227023","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227023","software engineering curricula;tools;frameworks;technology;integration","Educational institutions;Tutorials;Software;Industries;Context;Companies;Java","","1","","15","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Using continuous integration of code and content to teach software engineering with limited resources","J. G. Süß; W. Billingsley","University of Queensland, Brisbane, QLD, AU; National ICT Australia Limited, Brisbane, Australia",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1175","1184","Previous courses addressing the gap between student and professional programming practice have either isolated small groups' development in such a way that larger scale difficulties that motivate many professional practices do not arise, or have required significant additional staffing that would be expensive to provide in a large cohort core undergraduate software engineering course. We describe the first iteration of a course that enabled 73 students to work together to improve a large common legacy code base using professional practices and tools, staffed only by two lecturers and two undergraduate students employed as part-time tutors. The course relies on continuous integration and automated metrics, that coalesce frequently updated information in a manner that is visible to students and can be monitored by a small number of staff. The course is supported by a just-in-time teaching programme of thirty-two technical topics. We describe the constraints that determined the design of the course, and quantitative and qualitative data from the first iteration of the course.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227025","Continuous Integration;Software Engineering;Studio Course;Resource Constraints;Experience Report","Software;Educational institutions;Programming profession;Software engineering;Robots","","8","","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Stages in teaching software testing","T. Cowling","Department of Computer Science, University of Sheffield, Sheffield, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1185","1194","This paper describes how a staged approach to the development of students' abilities to engineer software systems applies to the specific issue of teaching software testing. It evaluates the courses relating to software testing in the Software Engineering volume of Computing Curriculum 2001 against a theoretical model that has been developed from a well-established programme in software engineering, from the perspectives of how well the courses support the progressive development of both students' knowledge of software testing and their ability to test software systems. It is shown that this progressive development is not well supported, and that to improve this some software testing material should be taught earlier than recommended.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227024","software engineering;software education;software development;development of skills","Software testing;Programming;Materials;Software systems;Debugging","","8","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Fine-SE: Integrating Semantic Features and Expert Features for Software Effort Estimation","Y. Li; Z. Ren; Z. Wang; L. Yang; L. Dong; C. Zhong; H. Zhang","State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute Nanjing University, Nanjing, Jiangsu, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","303","314","Reliable effort estimation is of paramount importance to software planning and management, especially in industry that requires effective and on-time delivery. Although various estimation approaches have been proposed (e.g., planning poker and analogy), they may be manual and/or subjective, which are difficult to apply to other projects. In recent years, deep learning approaches for effort estimation that rely on learning expert features or semantic features respectively have been extensively studied and have been found to be promising. Semantic features and expert features de-scribe software tasks from different perspectives, however, in the literature, the best combination of these two features has not been explored to enhance effort estimation. Additionally, there are a few studies that discuss which expert features are useful for estimating effort in the industry. To this end, we investigate the potential 13 expert features that can be used to estimate effort by interviewing 26 enterprise employees. Based on that, we propose a novel model, called Fine-SE, that leverages semantic features and expert features for effort estimation. To validate our model, a series of evaluations are conducted on more than 30,000 software tasks from 17 industrial projects of a global ICT enterprise and four open-source software (OSS) projects. The evaluation results indicate that Fine-SE provides higher performance than the baselines on evaluation measures (i.e., mean absolute error, mean magnitude of relative error, and performance indicator), particularly in industrial projects with large amounts of software tasks, which implies a significant improvement in effort estimation. In comparison with expert estimation, Fine-SE improves the performance of evaluation measures by 32.0%-45.2% in within-project estimation. In comparison with the state-of-the-art models, Deep-SE and GPT2SP, it also achieves an improvement of 8.9%-91.4% in industrial projects. The experimental results reveal the value of integrating expert features with semantic features in effort estimation.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623349","National Natural Science Foundation of China(grant numbers:62072227,62202219,62302210); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548937","Effort estimation;AI for SE;deep learning","Industries;Semantics;Measurement uncertainty;Estimation;Planning;Software reliability;Software measurement","","1","","58","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Ten tips to succeed in Global Software Engineering education","I. Crnković; I. Bosnić; M. Žagar","School of Innovation, Design and Engineering, Software Engineering Division, Mälardalen University, Vasteras, Sweden; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1225","1234","The most effective setting for training in Global Software Engineering is to provide a distributed environment for students. In such an environment, students will meet challenges in recognizing problems first-hand. Teaching in a distributed environment is, however, very demanding, challenging and unpredictable compared to teaching in a local environment. Based on nine years of experience, in this paper we present the most important issues that should be taken into consideration to increase the probability of success in teaching a Global Software Engineering course.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227020","Distrubuted software development;Education;Global software engineering","Educational institutions;Software engineering;Programming;Collaboration;Communication channels;Training","","17","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"The Classics Never Go Out of Style An Empirical Study of Downgrades from the Bazel Build Technology","M. Alfadel; S. McIntosh","Software REBELs, University of Waterloo, Canada; Software REBELs, University of Waterloo, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2881","2892","Software build systems specify how source code is transformed into deliverables. Keeping build systems in sync with the software artifacts that they build while retaining their capacity to quickly produce updated deliverables requires a serious investment of de-velopment effort. Enticed by advanced features, several software teams have migrated their build systems to a modern generation of build technologies (e.g., Bazel, Buck), which aim to reduce the maintenance and execution overhead that build systems impose on development. However, not all migrations lead to perceived improvements, ultimately culminating in abandonment of the build technology. While prior work has focused on upward migration towards more advanced technologies, so-called downgrades, i.e., abandonment of a modern build technology in favour of a traditional one, remains largely unexplored. In this paper, we perform an empirical study to better understand the abandonment of Bazel-a modern build technology with native support for multi-language software projects and (local/distributed) artifact caching. Our investigation of 542 projects that adopt Bazel reveals that (1) 61 projects (11.2%) have abandoned Bazel; and (2) abandonment tends to occur after investing in Bazel for a substantial amount of time (a median of 638 days). Thematic analysis reveals seven recurring reasons for abandonment, such as technical challenges, lack of platform integration, team coordi-nation issues, and upstream trends. After abandoning Bazel, the studied projects have adopted a broad set of alternatives, spanning from language-specific tools like Go Build, to more traditional build technologies like CMake and even pure Make. These results demonstrate that choosing a build technology involves balancing tradeoffs that are not always optimized by adopting the latest technology. This paper also lays the foundation for future work on balancing the tradeoffs that are associated with build technology choice (e.g., feature richness vs. maintenance costs) and the development of tools to support migration away from modern technologies.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639169","Natural Sciences and Engineering Research Council (NSERC) of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549374","Build Systems;Downgrades;Empirical Software Engineering","Costs;Source coding;Market research;Software;Maintenance;Synchronization;Software engineering","","1","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"On Privacy Weaknesses and Vulnerabilities in Software Systems","P. Sangaroonsilp; H. K. Dam; A. Ghose","University of Wollongong, New South Wales, Australia; University of Wollongong, New South Wales, Australia; University of Wollongong, New South Wales, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1071","1083","In this digital era, our privacy is under constant threat as our personal data and traceable online/offline activities are frequently collected, processed and transferred by many software applications. Privacy attacks are often formed by exploiting vulnerabilities found in those software applications. The Common Weakness Enumeration (CWE) and Common Vulnerabilities and Exposures (CVE) systems are currently the main sources that software engineers rely on for understanding and preventing publicly disclosed software vulnerabilities. However, our study on all 922 weaknesses in the CWE and 156,537 vulnerabilities registered in the CVE to date has found a very small coverage of privacy-related vulnerabilities in both systems, only 4.45% in CWE and 0.1% in CVE. These also cover only a small number of areas of privacy threats that have been raised in existing privacy software engineering research, privacy regulations and frameworks, and relevant reputable organisations. The actionable insights generated from our study led to the introduction of 11 new common privacy weaknesses to supplement the CWE system, making it become a source for both security and privacy vulnerabilities.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172594","Privacy;Vulnerabilities;Threats;CWE;CVE;Software","Privacy;Data privacy;Software systems;Regulation;Security;Software engineering","","","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Societal Computing","S. Sheth","Department of Computer Science, Columbia University, New York, NY, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1567","1570","Social Computing research focuses on online social behavior and using artifacts derived from it for providing recommendations and other useful community knowledge. Unfortunately, some of that behavior and knowledge incur societal costs, particularly with regards to Privacy, which is viewed quite differently by different populations as well as regulated differently in different locales. But clever technical solutions to those challenges may impose additional societal costs, e.g., by consuming substantial resources at odds with Green Computing, another major area of societal concern. We propose a new crosscutting research area, Societal Computing, that focuses on the technical tradeoffs among computational models and application domains that raise significant societal issues. This dissertation, advised by Prof. Gail Kaiser, will focus on privacy concerns in the context of Societal Computing and will aim to address research topics such as design patterns and architectures for privacy tradeoffs, better understanding of users' privacy requirements so that tradeoffs with other areas such as green computing can be dealt with in a more effective manner, and better visualization techniques for making privacy and its tradeoffs more understandable.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227035","Privacy;Green Computing;Sustainability","Privacy;Software engineering;Data privacy;Communities;Software;Conferences;Social network services","","","","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Modeling Review History for Reviewer Recommendation: A Hypergraph Approach","G. Rong; Y. Zhang; L. Yang; F. Zhang; H. Kuang; H. Zhang","State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1381","1392","Modern code review is a critical and indispensable practice in a pull-request development paradigm that prevails in Open Source Software (OSS) development. Finding a suitable reviewer in projects with massive participants thus becomes an increasingly challenging task. Many reviewer recommendation approaches (recommenders) have been developed to support this task which apply a similar strategy, i.e. modeling the review history first then followed by predicting/recommending a reviewer based on the model. Apparently, the better the model reflects the reality in review history, the higher recommender's performance we may expect. However, one typical scenario in a pull-request development paradigm, i.e. one Pull-Request (PR) (such as a revision or addition submitted by a contributor) may have multiple reviewers and they may impact each other through publicly posted comments, has not been modeled well in existing recommenders. We adopted the hypergraph technique to model this high-order relationship (i.e. one PR with multiple reviewers herein) and developed a new recommender, namely HGRec, which is evaluated by 12 OSS projects with more than 87K PRs, 680K comments in terms of accuracy and recommen-dation distribution. The results indicate that HGRec outperforms the state-of-the-art recommenders on recommendation accuracy. Besides, among the top three accurate recommenders, HGRec is more likely to recommend a diversity of reviewers, which can help to relieve the core reviewers' workload congestion issue. Moreover, since HGRec is based on hypergraph, which is a natural and interpretable representation to model review history, it is easy to accommodate more types of entities and realistic relationships in modern code review scenarios. As the first attempt, this study reveals the potentials of hypergraph on advancing the pragmatic solutions for code reviewer recommendation.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510213","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793876","Modern code review;reviewer recommendation;hypergraph","Codes;Heuristic algorithms;Software algorithms;Computer architecture;Predictive models;History;Task analysis","","8","","62","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Specification engineering and modular verification using a web-integrated verifying compiler","C. T. Cook; H. Harton; H. Smith; M. Sitaraman","School of Computing, Clemson University, Clemson, SC, USA; School of Computing, Clemson University, Clemson, SC, USA; School of Computing, Clemson University, Clemson, SC, USA; School of Computing, Clemson University, Clemson, SC, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1379","1382","This demonstration will present the RESOLVE web-integrated environment, which has been especially built to capture component relationships and allow construction and composition of verified generic components. The environment facilitates team-based software development and has been used in undergraduate CS education at multiple institutions. The environment makes it easy to simulate “what if” scenarios, including the impact of alternative specification styles on verification, and has spawned much research and experimentation. The demonstration will illustrate the issues in generic software verification and the role of higher-order assertions. It will show how logical errors are pinpointed when verification fails. Introductory video URL: http://www.youtube.com/watch?v=9vg3WuxeOkA.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227243","automation;generic components;education;specification;system description;verification;web IDE","Software;Java;Educational institutions;Software engineering;Cognition;Component architectures;Sorting","","16","","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"FOCUS: An adaptation of a SWEBOK-based curriculum for industry requirements","G. Samarthyam; G. Suryanarayana; A. K. Gupta; R. Nambiar","Siemens Corporate Research & Technologies, India; Siemens Corporate Research & Technologies, India; Siemens Corporate Development Center, India - Technology Evaluation & Competences, Siemens Technology and Services Pvt. Ltd., Bangalore, India; Siemens Corporate Development Center, India - Technology Evaluation & Competences, Siemens Technology and Services Pvt. Ltd., Bangalore, India",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1215","1224","Siemens Corporate Development Center India (CT DC IN) develops software applications for the industry, energy, health-care, and infrastructure & cities sectors of Siemens. These applications are typically critical in nature and require software practitioners who have considerable competency in the area of software engineering. To enhance the competency of engineers, CT DC IN has introduced an internal curriculum titled “FOundation CUrriculum for Software engineers” (FOCUS) which is an adapted version of IEEE's SWEBOK curriculum. The FOCUS program has been used to train more than 500 engineers in the last three years. In this experience report, we describe the motivation for FOCUS, how it was structured to address the specific needs of CT DC IN, and how the FOCUS program was rolled out within the organization. We also provide results obtained from a survey of the FOCUS participants, their managers, and FOCUS trainers that was conducted to throw light on the effectiveness of the program. We believe the insights from the survey results provide useful pointers to other organizations and academic institutions that are planning to adopt a SWEBOK-based curriculum.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227021","SWEBOK;ISO TR 19759;Software engineering education;Industry experience","Training;Software;Programming;Organizations;Software engineering;Knowledge engineering;Industries","","12","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"EVOSS: A tool for managing the evolution of free and open source software systems","D. Di Ruscio; P. Pelliccione; A. Pierantonio","Computer Science Department, University of L'Aquila, L'Aquila, Italy; Computer Science Department, University of L'Aquila, L'Aquila, Italy; Computer Science Department, University of L'Aquila, L'Aquila, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1415","1418","Software systems increasingly require to deal with continuous evolution. In this paper we present the EVOSS tool that has been defined to support the upgrade of free and open source software systems. EVOSS is composed of a simulator and of a fault detector component. The simulator is able to predict failures before they can affect the real system. The fault detector component has been defined to discover inconsistencies in the system configuration model. EVOSS improves the state of the art of current tools, which are able to predict a very limited set of upgrade faults, while they leave a wide range of faults unpredicted.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227234","Model-driven software engineering;Configuration management and deployment;Software evolution;Tools and environments","Fault detection;DSL;Analytical models;Linux;Open source software;Tagging","","","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Online sharing and integration of results from mining software repositories","I. Keivanloo","Ambient Software Evolution Group, Concordia University, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1644","1646","The mining of software repository involves the extraction of both basic and value-added information from existing software repositories. Depending on stakeholders (e.g., researchers, management), these repositories are mined several times for different application purposes. To avoid unnecessary pre-processing steps and improve productivity, sharing, and integration of extracted facts and results are needed. The motivation of this research is to introduce a novel collaborative sharing platform for software datasets that supports on-the-fly inter-datasets integration. We want to facilitate and promote a paradigm shift in the source code analysis domain, similar to the one by Wikipedia in the knowledge-sharing domain. In this paper, we present the SeCold project, which is the first online, publicly available software ecosystem Linked Data dataset. As part of this research, not only theoretical background on how to publish such datasets is provided, but also the actual dataset. SeCold contains about two billion facts, such as source code statements, software licenses, and code clones from over 18.000 software projects. SeCold is also an official member of the Linked Data cloud and one of the eight largest online Linked Data datasets available on the cloud.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227215","Linked Data;software mining;sharing;model","Software;Data mining;Data models;Communities;Licenses;XML;Cloning","","2","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"FastFix: Monitoring control for remote software maintenance","D. Pagano; M. A. Juan; A. Bagnato; T. Roehm; B. Bruegge; W. Maalej","Technical University of München, Munich, Germany; S2 Grupo, Valencia, Spain; TXT e-solutions, Milano, Italy; Technical University of München, Munich, Germany; Technical University of München, Munich, Germany; Technical University of München, Munich, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1437","1438","Software maintenance and support services are key factors to the customer perception of software product quality. The overall goal of FastFix is to provide developers with a real-time maintenance environment that increases efficiency and reduces costs, improving accuracy in identification of failure causes and facilitating their resolution. To achieve this goal, FastFix observes application execution and user interaction at runtime. We give an overview of the functionality of FastFix and present one of its main application scenarios.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227076","software maintenance;context-aware software engineering;event correlation;fault replication;self-healing","Maintenance engineering;Context;Correlation;Monitoring;Sensors;Software maintenance","","3","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"MTTM: Metamorphic Testing for Textual Content Moderation Software","W. Wang; J. -t. Huang; W. Wu; J. Zhang; Y. Huang; S. Li; P. He; M. R. Lyu","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen, Shenzhen, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2387","2399","The exponential growth of social media platforms such as Twitter and Facebook has revolutionized textual communication and textual content publication in human society. However, they have been increasingly exploited to propagate toxic content, such as hate speech, malicious advertisement, and pornography, which can lead to highly negative impacts (e.g., harmful effects on teen mental health). Researchers and practitioners have been enthusiastically developing and extensively deploying textual content moderation software to address this problem. However, we find that malicious users can evade moderation by changing only a few words in the toxic content. Moreover, modern content moderation software's performance against malicious inputs remains underexplored. To this end, we propose MTTM, a Metamorphic Testing framework for Textual content Moderation software. Specifically, we conduct a pilot study on 2, 000 text messages collected from real users and summarize eleven metamorphic relations across three perturbation levels: character, word, and sentence. MTTM employs these metamorphic relations on toxic textual contents to generate test cases, which are still toxic yet likely to evade moderation. In our evaluation, we employ MTTM to test three commercial textual content moderation software and two state-of-the-art moderation algorithms against three kinds of toxic content. The results show that MTTM achieves up to 83.9%, 51%, and 82.5% error finding rates (EFR) when testing commercial moderation software provided by Google, Baidu, and Huawei, respectively, and it obtains up to 91.2% EFR when testing the state-of-the-art algorithms from the academy. In addition, we leverage the test cases generated by MTTM to retrain the model we explored, which largely improves model robustness 0% ~ 5.9% EFR) while maintaining the accuracy on the original test set. A demo can be found in this link1.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00200","National Natural Science Foundation of China(grant numbers:62102340,62206318); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172598","Software testing;metamorphic relations;NLP software;textual content moderation","Systematics;Social networking (online);Perturbation methods;Software algorithms;Web and internet services;Software performance;Software","","9","","84","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Augmented intelligence — The new AI — Unleashing human capabilities in knowledge work","J. M. Corrigan","Department of Philosophy, Stony Brook University, Stony Brook, NY, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1285","1288","In this paper I describe a novel application of contemplative techniques to software engineering with the goal of augmenting the intellectual capabilities of knowledge workers within the field in four areas: flexibility, attention, creativity, and trust. The augmentation of software engineers' intellectual capabilities is proposed as a third complement to the traditional focus of methodologies on the process and environmental factors of the software development endeavor. I argue that these capabilities have been shown to be open to improvement through the practices traditionally used in spiritual traditions, but now used increasingly in other fields of knowledge work, such as in the medical profession and the education field. Historically, the intellectual capabilities of software engineers have been treated as a given within any particular software development effort. This is argued to be an aspect ripe for inclusion within software development methodologies.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227098","Development Methodologies;Knowledge Workers;Contemplative Practices;Contemplative Techniques;Flexibility;Attention;Creativity;Trust;Awareness;Augmented Intelligence","Humans;Software engineering;Software;Stress;Problem-solving;Productivity;Knowledge engineering","","2","","11","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software fault localization based on program slicing spectrum","W. Wen","School of Computer Science and Engineering, South East University, Nanjing, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1511","1514","During software development and maintenance stages, programmers have to frequently debug the software. One of the most difficult and complex tasks in the debugging activity is software fault localization. A commonly-used method to fix software fault is computing suspiciousness of program elements according to failed test executions and passed test executions. However, this technique does not give full consideration to dependences between program elements, thus its capacity for efficient fault localization is limited. Our research intends to introduce program slicing technique and statistical method which extracts dependencies between program elements and refines execution history, then builds program slicing spectra to rank suspicious elements by a statistical metric. We expect that our method will contribute directly to the improvement of the effectiveness and the accuracy of software fault localization and reduce the software development and maintenance effort and cost.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227049","fault localization;program slicing spectrum;software debugging","Software;Debugging;Measurement;History;Statistical analysis;Generators;Software algorithms","","21","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Knowledge Graph Driven Inference Testing for Question Answering Software","J. Wang; Y. Li; Z. Chen; L. Chen; X. Zhang; Y. Zhou","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; School of Computer Science and Technology, Soochow University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1459","1471","In the wake of developments in the field of Natural Language Processing, Question Answering (QA) software has penetrated our daily lives. Due to the data-driven programming paradigm, QA software inevitably contains bugs, i.e., misbehaving in real-world applications. Current testing techniques for testing QA software include two folds, reference-based testing and metamorphic testing. This paper adopts a different angle to achieve testing for QA software: we notice that answers to questions would have inference relations, i.e., the answers to some questions could be logically inferred from the answers to other questions. If these answers on QA software do not satisfy the inference relations, an inference bug is detected. To generate the questions with the inference relations automatically, we propose a novel testing method Knowledge Graph driven Inference Testing (KGIT), which employs facts in the Knowledge Graph (KG) as the seeds to logically construct test cases containing questions and contexts with inference relations. To evaluate the effectiveness of KGIT, we conduct an extensive empirical study with more than 2.8 million test cases generated from the large-scale KG YAGO4 and three QA models based on the state-of-the-art QA model structure. The experimental results show that our method (a) could detect a considerable number of inference bugs in all three studied QA models and (b) is helpful in retraining QA models to improve their inference ability.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639109","National Natural Science Foundation of China(grant numbers:62172202,62272221,62172205,61972082); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548933","Question Answering;Software Testing;Knowledge Graph;Inference Rules","Computer bugs;Knowledge graphs;Programming;Software;Question answering (information retrieval);Testing;Software engineering","","","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"On the analysis of evolution of software artefacts and programs","F. Jaafar","Ptidej Team-LBIT Lab, DIRO, University of Montreal, QUE, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1563","1566","The literature describes several approaches to identify the artefacts of programs that evolve together to reveal the (hidden) dependencies among these artefacts and to infer and describe their evolution trends. We propose the use of biological methods to group artefacts, to detect co-evolution among them, and to construct their phylogenic trees to express their evolution trends. First, we introduced the novel concepts of macro co-changes (MCCs), i.e., of artefacts that co-change within a large time interval and of dephase macro co-changes (DMCCs), i.e., macro co-changes that always happen with the same shifts in time. We developed an approach, Macocha, to identify these new patterns of artefacts co-evolution in large programs. Now, we are analysing the evolution of classes playing roles in design patterns and - or antipatterns. In parallel to previous work, we are detecting what classes are in macro co-change or in dephase macro co-change with the design motifs. Results try to show that classes playing roles in design motifs have specifics evolution trends. Finally, we are implementing an approach, Profilo, to achieve the analysis of the evolution of artefacts and versions of large object-oriented programs. Profilo creates a phylogenic tree of different versions of program that describes versions evolution and the relation among versions and programs. We will, also, evaluate the usefulness of our tools using lab and field studies.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227036","Software evolution;co-change;phylogenic tree;stability;change impact","Software;History;Phylogeny;Stability analysis;Association rules;Software engineering","","","1","13","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Future Software for Life in Trusted Futures","S. Pink","Monash University, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1","1","How will people, other species, software and hardware live together in as yet unknown futures? How can we work towards trusted and safe futures where human values and the environment are supported by emerging technologies? Research demonstrates that human values and everyday life priorities, ethics, routines and activities will shape our possible futures. I will draw on ethnographic research to outline how people anticipate and imagine everyday life futures with emerging technologies in their homes and neighbourhoods, and how technology workers envisage futures in their professional lives. If, as social science research shows, technologies cannot solve human and societal problems, what roles should they play in future life? What are the implications for future software? What values should underpin its design? Where should it be developed? By and in collaboration with whom? What role can software play in generating the circumstances for trusted futures?","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172776","Software Engineering and Society","Software;Software engineering;Social sciences;Smart homes;Scholarships;Industries;Indexes","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Managing evolution of software product line","C. Thao","Dept. of Electrical Engineering & Computer Science, University of Wisconsin-Milwaukee, Milwaukee, WI, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1619","1621","In software product line engineering, core assets are shared among multiple products. Core assets and products generally evolve independently. Developers need to capture evolution in both contexts and to propagate changes in both directions between the core assets and the products. We propose a version control system to support product line engineering by supporting the evolution of product line, product derivation, and change propagation from core assets to products and vice versa.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227224","software product line engineering;software product line evolution;version control","Software;Prototypes;USA Councils;Standards;Control systems;Product development;Programming","","6","","8","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering","R. Choudhuri; D. Liu; I. Steinmacher; M. Gerosa; A. Sarma","Oregon State University, Corvallis, OR, USA; Oregon State University, Corvallis, OR, USA; Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA; Oregon State University, Corvallis, OR, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2270","2282","Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639201","National Science Foundation(grant numbers:2235601,2236198,2247929,2303042,2303043); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549015","Empirical Study;Software Engineering;Generative AI;ChatGPT","Productivity;Uncertainty;Generative AI;Navigation;Chatbots;Task analysis;Standards","","1","","98","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"The impacts of software process improvement on developers: A systematic review","M. Lavallée; P. N. Robillard","Laboratoire de Recherche en Génie Logiciel, Polytechnique de Montréal, Montreal, Canada; Laboratoire de Recherche en Génie Logiciel, Polytechnique de Montréal, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","113","122","This paper presents the results of a systematic review on the impacts of Software Process Improvement (SPI) on developers. This review selected 26 studies from the highest quality journals, conferences, and workshop in the field. The results were compiled and organized following the grounded theory approach. Results from the grounded theory were further categorized using the Ishikawa (or fishbone) diagram. The Ishikawa Diagram models all the factors potentially impacting software developers, and shows both the positive and negative impacts. Positive impacts include a reduction in the number of crises, and an increase in team communications and morale, as well as better requirements and documentation. Negative impacts include increased overhead on developers through the need to collect data and compile documentation, an undue focus on technical approaches, and the fact that SPI is oriented toward management and process quality, and not towards developers and product quality. This systematic review should support future practice through the identification of important obstacles and opportunities for achieving SPI success. Future research should also benefit from the problems and advantages of SPI identified by developers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227201","software process;systematic review;impact;developer","Software;Documentation;Cause effect analysis;Standards;Systematics;Conferences","","19","","14","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Co-adapting human collaborations and software architectures","C. Dorn; R. N. Taylor","Institute for Software Research, University of California, Irvine, USA; Institute for Software Research, University of California, Irvine, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1277","1280","Human collaboration has become an integral part of large-scale systems for massive online knowledge sharing, content distribution, and social networking. Maintenance of these complex systems, however, still relies on adaptation mechanisms that remain unaware of the prevailing user collaboration patterns. Consequently, a system cannot react to changes in the interaction behavior thereby impeding the collaboration's evolution. In this paper, we make the case for a human architecture model and its mapping onto software architecture elements as fundamental building blocks for system adaptation.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227100","collaboration patterns;software architecture;adaptation;context awareness","Collaboration;Software;Humans;Software architecture;Computer architecture;Adaptation models;Runtime","","3","","18","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CodeTimeline: Storytelling with versioning data","A. Kuhn; M. Stocker","Software Practices Lab, University of British Columbia, Canada; Institute for Software, University of Applied Sciences, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1333","1336","Working with a software system typically requires knowledge of the system's history, however this knowledge is often only tribal memory of the development team. In past user studies we have observed that when being presented with collaboration views and word clouds from the system's history engineers start sharing memories linked to those visualizations. In this paper we propose an approach based on a storytelling visualization, which is designed to entice engineers to share and document their tribal memory. Sticky notes can be used to share memories of a system's lifetime events, such as past design rationales but also more casual memories like pictures from after-work beer or a hackathon. We present an early-stage prototype implementation and include two design studies created using that prototype.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227086","Software Visualization;Software Evolution;Humans and Social Aspects;Tools and Environments","Software;History;Data visualization;Tag clouds;Prototypes;Collaboration;Visualization","","7","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Effective specification of decision rights and accountabilities for better performing software engineering projects","M. Kalumbilo","Department of Computer Science, University College London, London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1503","1506","Governance of a software project involves the distribution and management of decision rights for significant decisions. A decision right grants authority to make decisions and be held accountable for decision outcomes. Though prior research indicates that the exercise and degree of ownership of decision rights has an impact on software project performance, there has been relatively little direct consideration of what the significant decisions should be or what might constitute an effective underlying specification and management of decision rights during the software project lifecycle. In this paper, a research agenda to reveal such knowledge is presented. This report represents the first output of our work in this area.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227051","decision right;decision process;software process;governance","Software;Decision making;Companies;Monitoring;Programming;Investments","","","","21","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Demystifying and Detecting Misuses of Deep Learning APIs","M. Wei; N. S. Harzevili; Y. Huang; J. Yang; J. Wang; S. Wang","York University, Toronto, Canada; York University, Toronto, Canada; Chinese Academy of Sciences, Beijing, China; Concordia University, Montreal, Canada; Chinese Academy of Sciences, Beijing, China; York University, Toronto, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2482","2493","Deep Learning (DL) libraries have significantly impacted various domains in computer science over the last decade. However, developers often face challenges when using the DL APIs, as the development paradigm of DL applications differs greatly from traditional software development. Existing studies on API misuse mainly focus on traditional software, leaving a gap in understanding API misuse within DL APIs. To address this gap, we present the first comprehensive study of DL API misuse in TensorFlow and PyTorch. Specifically, we first collected a dataset of 4,224 commits from the top 200 most-starred projects using these two libraries and manually identified 891 API misuses. We then investigated the characteristics of these misuses from three perspectives, i.e., types, root causes, and symptoms. We have also conducted an evaluation to assess the effectiveness of the current state-of-the-art API misuse detector on our 891 confirmed API misuses. Our results confirmed that the state-of-the-art API misuse detector is ineffective in detecting DL API misuses. To address the limitations of existing API misuse detection for DL APIs, we propose LLMAPIDet, which leverages Large Language Models (LLMs) for DL API misuse detection and repair. We build LLMAPIDet by prompt-tuning a chain of ChatGPT prompts on 600 out of 891 confirmed API misuses and reserve the rest 291 API misuses as the testing dataset. Our evaluation shows that LLMAPIDet can detect 48 out of the 291 DL API misuses while none of them can be detected by the existing API misuse detector. We further evaluate LLMAPIDet on the latest versions of 10 GitHub projects. The evaluation shows that LLMAPIDet can identify 119 previously unknown API misuses and successfully fix 46 of them.","1558-1225","979-8-4007-0217-4","","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549604","Software and its engineering → Software evolution;Software libraries and repositories;Computing methodologies → Machine learning;API misuse;deep learning APIs;empirical study;detection","Deep learning;Computer science;Source coding;Detectors;Maintenance engineering;Libraries;Software","","1","","57","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process","N. Nahar; S. Zhou; G. Lewis; C. Kästner","Carnegie Mellon University, Pittsburgh, PA, USA; University of Toronto, Toronto, Ontario, Canada; Carnegie Mellon Software Engineering Institute, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","413","425","The introduction of machine learning (ML) components in software projects has created the need for software engineers to collabo-rate with data scientists and other specialists. While collaboration can always be challenging, ML introduces additional challenges with its exploratory model development process, additional skills and knowledge needed, difficulties testing ML systems, need for continuous evolution and monitoring, and non-traditional quality requirements such as fairness and explainability. Through inter-views with 45 practitioners from 28 organizations, we identified key collaboration challenges that teams face when building and deploying ML systems into production. We report on common col-laboration points in the development of production ML systems for requirements, data, and integration, as well as corresponding team patterns and challenges. We find that most of these challenges center around communication, documentation, engineering, and process, and collect recommendations to address these challenges.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510209","NSF(grant numbers:1813598,2131477); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793960","Software Engineering;Machine Learning;SE4ML;SE4AI","Buildings;Collaboration;Production;Documentation;Organizations;Machine learning;Software","","19","","116","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Facilitating communication between engineers with CARES","A. Guzzi; A. Begel","Delft University of Technology, Delft, Netherlands; Microsoft Research, Redmond, WA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1367","1370","When software developers need to exchange information or coordinate work with colleagues on other teams, they are often faced with the challenge of finding the right person to communicate with. In this paper, we present our tool, called CARES (Colleagues and Relevant Engineers' Support), which is an integrated development environment-based (IDE) tool that enables engineers to easily discover and communicate with the people who have contributed to the source code. CARES has been deployed to 30 professional developers, and we interviewed 8 of them after 3 weeks of evaluation. They reported that CARES helped them to more quickly find, choose, and initiate contact with the most relevant and expedient person who could address their needs.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227246","coordination;CSCW;software engineering","Software;Electronic mail;Visualization;Companies;Programming;Availability;USA Councils","","7","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Breaking the Flow: A Study of Interruptions During Software Engineering Activities","Y. Ma; Y. Huang; K. Leach","Duke University, Durham, USA; Vanderbilt University, Nashville, USA; Vanderbilt University, Nashville, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2283","2294","In software engineering, interruptions during tasks can have significant implications for productivity and well-being. While previous studies have investigated the effect of interruptions on productivity, to the best of our knowledge, no prior work has yet distinguished the effect of different types of interruptions on software engineering activities. This study explores the impact of interruptions on software engineering tasks, analyzing in-person and on-screen interruptions with different levels of urgency and dominance. Participants completed code writing, code comprehension, and code review tasks while experiencing interruptions. We collect physiological data using the Empatica EmbracePlus wristband and self-perceived evaluations through surveys. Results show that on-screen interruptions with high dominance of requester significantly increase time spent on code comprehension. In-person and on-screen interruptions combined significantly affect the time spent on code review, with varied effects based on specific interruption combinations. Both interruption type and task significantly influence stress measures, with code comprehension and review tasks associated with lower stress measures compared to code writing. Interestingly, in-person interruptions present a positive impact on physiological measures, indicating reduced stress measures. However, participants' self-perceived stress scores do not align with physiological data, with higher stress reported during in-person interruptions despite lower physiological stress measures. These findings shed light on and emphasize the potential importance of considering the complex relationship between interruptions, objective measures, and subjective experiences in software development. We discuss insights that we hope can inform interruption management and implications on stress among software engineers. (ChatGPT was used to revise and shorten paragraphs in this manuscript.)","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639079","NSF(grant numbers:CCF-2211429); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549189","Interruptions;Productivity;Affective States","Codes;Atmospheric measurements;Reviews;Particle measurements;Physiology;Software measurement;Task analysis","","","","62","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Timely and efficient facilitation of coordination of software developers' activities","K. Blincoe","Computer Science Department, Drexel University, Philadelphia, PA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1539","1542","Work dependencies often exist between the developers of a software project. These dependencies frequently result in a need for coordination between the involved developers. However, developers are not always aware of these Coordination Requirements. Current methods which detect the need to coordinate rely on information which is available only after development work has been completed. This does not enable developers to act on their coordination needs. Furthermore, even if developers were aware of all Coordination Requirements, they likely would be overwhelmed by the large number and would not be able to effectively follow up directly with the developers involved in each dependent task. I will investigate a more timely method to determine Coordination Requirements in a software development team as they emerge and how to focus the developers attention on the most crucial ones. Further, I hope to prove that direct inter-personal communication is not always necessary to fulfill these requirements and gain insight on how we can develop tools that encourage cheaper forms of coordination.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227042","Awareness;Proximity;Management;Coordination Requirements;Socio-Technical;Task Context;Tools","Software;Tagging;Programming;Productivity;Real time systems;Current measurement;IEEE Potentials","","","","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Trends in object-oriented software evolution: Investigating network properties","A. Chatzigeorgiou; G. Melas","Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1309","1312","The rise of social networks and the accompanying interest to study their evolution has stimulated a number of research efforts to analyze their growth patterns by means of network analysis. The inherent graph-like structure of object-oriented systems calls for the application of the corresponding methods and tools to analyze software evolution. In this paper we investigate network properties of two open-source systems and observe interesting phenomena regarding their growth. Relating the observed evolutionary trends to principles and laws of software design enables a highlevel assessment of tendencies in the underlying design quality.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227092","software evolution;network analysis;object-oriented design","Communities;Object oriented modeling;Software systems;Social network services;Vegetation;Maintenance engineering","","6","","11","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Mining Pull Requests to Detect Process Anomalies in Open Source Software Development","B. Liu; H. Zhang; W. Ma; H. Kuang; Y. Yang; J. Xu; S. Gao; J. Gao","State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Nanjing, Jiangsu, China; Huawei Technologies Co., Ltd., China; Huawei Technologies Co., Ltd., China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2393","2405","Trustworthy Open Source Software (OSS) development processes are the basis that secures the long-term trustworthiness of soft-ware projects and products. With the aim to investigate the trust-worthiness of the Pull Request (PR) process, the common model of collaborative development in OSS community, we exploit process mining to identify and analyze the normal and anomalous patterns of PR processes, and propose our approach to identifying anomalies from both control-flow and semantic aspects, and then to analyze and synthesize the root causes of the identified anomalies. We analyze 17531 PRs of 18 OSS projects on GitHub, extracting 26 root causes of control-flow anomalies and 19 root causes of semantic anomalies. We find that most PRs can hardly contain both semantic anomalies and control-flow anomalies, and the internal custom rules in projects may be the key causes for the identified anomalous PRs. We further discover and analyze the patterns of normal PR processes. We find that PRs in the non-fork model (42%) are far more likely than the fork model (5%) to bypass the review process, indicating a higher potential risk. Besides, we analyzed nine poisoned projects whose PR practices were indeed worse. Given the complex and diverse PR processes in OSS community, the proposed approach can help identify and understand not only anomalous PRs but also normal PRs, which offers early risk indications of suspicious incidents (such as poisoning) to OSS supply chain.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639196","National Natural Science Foundation of China(grant numbers:62072227,62202219,62302210,72372070); National Key Research and Development Program of China(grant numbers:2019YFEOI05500); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548492","open source software development;process mining;pull request","Analytical models;Reviews;Semantics;Supply chains;Process control;Collaboration;Open source software","","","","51","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Sibyl: Improving Software Engineering Tools with SMT Selection","W. Leeson; M. B. Dwyer; A. Filieri","Department of Computer Science, University of Virginia, Charlottesville, USA; Department of Computer Science, University of Virginia, Charlottesville, USA; Department of Computing, Imperial College London, London, UK",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2185","2197","SMT solvers are often used in the back end of different software engineering tools─e.g., program verifiers, test generators, or program synthesizers. There are a plethora of algorithmic techniques for solving SMT queries. Among the available SMT solvers, each employs its own combination of algorithmic techniques that are optimized for different fragments of logics and problem types. The most efficient solver can change with small changes in the SMT query, which makes it nontrivial to decide which solver to use. Consequently, designers of software engineering tools often select a single solver, based on familiarity or convenience, and tailor their tool towards it. Choosing an SMT solver at design time misses the opportunity to optimize query solve times and, for tools where SMT solving is a bottleneck, the performance loss can be significant. In this work, we present Sibyl, an automated SMT selector based on graph neural networks (GNNs). Sibyl creates a graph representation of a given SMT query and uses GNNs to predict how each solver in a suite of SMT solvers would perform on said query. Sibyl learns to predict based on features of SMT queries that are specific to the population on which it is trained - avoiding the need for manual feature engineering. Once trained, Sibyl makes fast and accurate predictions which can substantially reduce the time needed to solve a set of SMT queries. We evaluate Sibyl in four scenarios in which SMT solvers are used: in competition, in a symbolic execution engine, in a bounded model checker, and in a program synthesis tool. We find that Sibyl improves upon the state of the art in nearly every case and provide evidence that it generalizes better than existing techniques. Further, we evaluate Sibyl's overhead and demonstrate that it has the potential to speedup a variety of different software engineering tools.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172504","graph neural networks;satisfiable modulo theories;algorithm selection","Synthesizers;Software algorithms;Buildings;Sociology;Prototypes;Predictive models;Graph neural networks","","2","","92","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"TraceLab: An experimental workbench for equipping researchers to innovate, synthesize, and comparatively evaluate traceability solutions","E. Keenan; A. Czauderna; G. Leach; J. Cleland-Huang; Y. Shin; E. Moritz; M. Gethers; D. Poshyvanyk; J. Maletic; J. H. Hayes; A. Dekhtyar; D. Manukian; S. Hossein; D. Hearn","DePaul University, Chicago, IL, USA; DePaul University, Chicago, IL, USA; DePaul University, Chicago, IL, USA; DePaul University, Chicago, IL, USA; DePaul University, Chicago, IL, USA; College of William and Mary, Williamsburg, VA, USA; College of William and Mary, Williamsburg, VA, USA; College of William and Mary, Williamsburg, VA, USA; Kent State University, Kent, OH, USA; University of Kentucky, Lexington, KY, USA; CalPoly, San Louis Obispo, CA, USA; DePaul University, Chicago, IL, USA; DePaul University, Chicago, IL, USA; DePaul University, Chicago, IL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1375","1378","TraceLab is designed to empower future traceability research, through facilitating innovation and creativity, increasing collaboration between researchers, decreasing the startup costs and effort of new traceability research projects, and fostering technology transfer. To this end, it provides an experimental environment in which researchers can design and execute experiments in TraceLab's visual modeling environment using a library of reusable and user-defined components. TraceLab fosters research competitions by allowing researchers or industrial sponsors to launch research contests intended to focus attention on compelling traceability challenges. Contests are centered around specific traceability tasks, performed on publicly available datasets, and are evaluated using standard metrics incorporated into reusable TraceLab components. TraceLab has been released in beta-test mode to researchers at seven universities, and will be publicly released via CoEST.org in the summer of 2012. Furthermore, by late 2012 TraceLab's source code will be released as open source software, licensed under GPL. TraceLab currently runs on Windows but is designed with cross platforming issues in mind to allow easy ports to Unix and Mac environments.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227244","Traceability;Instrumentation;TraceLab;Benchmarks;Experiments;eXtreme Software Engineering Lab","Measurement;Software engineering;Principal component analysis;Software;Benchmark testing;Libraries;Java","","48","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Evaluating the specificity of text retrieval queries to support software engineering tasks","S. Haiduc; G. Bavota; R. Oliveto; A. Marcus; A. De Lucia","Computer Science Department, Wayne State University, Detroit, MI, USA; School of Science, University of Salerno, Fisciano, Salerno, Italy; STAT Department, University of Molise, Pesche, Italy; Computer Science Department, Wayne State University, Detroit, MI, USA; School of Science, University of Salerno, Fisciano, Salerno, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1273","1276","Text retrieval approaches have been used to address many software engineering tasks. In most cases, their use involves issuing a textual query to retrieve a set of relevant software artifacts from the system. The performance of all these approaches depends on the quality of the given query (i.e., its ability to describe the information need in such a way that the relevant software artifacts are retrieved during the search). Currently, the only way to tell that a query failed to lead to the expected software artifacts is by investing time and effort in analyzing the search results. In addition, it is often very difficult to ascertain what part of the query leads to poor results. We propose a novel pre-retrieval metric, which reflects the quality of a query by measuring the specificity of its terms. We exemplify the use of the new specificity metric on the task of concept location in source code. A preliminary empirical study shows that our metric is a good effort predictor for text retrieval-based concept location, outperforming existing techniques from the field of natural language document retrieval.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227101","Text retrieval;Query specificity;Concept location","Correlation;Software;Measurement;Natural languages;Entropy;Context;Information retrieval","","20","","14","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"If a Human Can See It, So Should Your System: Reliability Requirements for Machine Vision Components","B. C. Hu; L. Marsso; K. Czarnecki; R. Salay; H. Shen; M. Chechik","University of Toronto, Toronto, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada; University of Waterloo, Waterloo, Ontario, Canada; University of Waterloo, Waterloo, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1145","1156","Machine Vision Components (MVC) are becoming safety-critical. Assuring their quality, including safety, is essential for their successful deployment. Assurance relies on the availability of precisely specified and, ideally, machine-verifiable requirements. MVCs with state-of-the-art performance rely on machine learning (ML) and training data, but largely lack such requirements. In this paper, we address the need for defining machine-verifiable reliability requirements for MVCs against transformations that simulate the full range of realistic and safety-critical changes in the environment. Using human performance as a baseline, we define reliability requirements as: ‘if the changes in an image do not affect a human's decision, neither should they affect the MVC's.’ To this end, we provide: (1) a class of safety-related image transformations; (2) reliability requirement classes to specify correctness-preservation and prediction-preservation for MVCs; (3) a method to instantiate machine-verifiable requirements from these requirements classes using human performance experiment data; (4) human performance experiment data for image recognition involving eight commonly used transformations, from about 2000 human participants; and (5) a method for automatically checking whether an MVC satisfies our requirements. Further, we show that our reliability requirements are feasible and reusable by evaluating our methods on 13 state-of-the-art pre-trained image classification models. Finally, we demonstrate that our approach detects reliability gaps in MVCs that other existing methods are unable to detect.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793915","Software Engineering for Artificial Intelligence;Requirements Engineering;Software Analysis","Machine vision;Training data;Object detection;Reliability engineering;Software;Software reliability;Safety","","4","","56","","20 Jun 2022","","","IEEE","IEEE Conferences"
"ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering","C. Ferrara; F. Casillo; C. Gravino; A. De Lucia; F. Palomba","University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2631","2642","Machine learning (ML) is increasingly being used as a key component of most software systems, yet serious concerns have been raised about the fairness of ML predictions. Researchers have been proposing novel methods to support the development of fair machine learning solutions. Nonetheless, most of them can only be used in late development stages, e.g., during model training, while there is a lack of methods that may provide practitioners with early fairness analytics enabling the treatment of fairness throughout the development lifecycle. This paper proposes RefAir, a novel context-aware requirements engineering framework that allows to classify sensitive features from User Stories. By exploiting natural language processing and word embedding techniques, our framework first identifies both the use case domain and the machine learning task to be performed in the system being developed; afterward, it recommends which are the context-specific sensitive features to be considered during the implementation. We assess the capabilities of RefAir by experimenting it against a synthetic dataset-which we built as part of our research-composed of 12,401 User Stories related to 34 application domains. Our findings showcase the high accuracy of RefAir, other than highlighting its current limitations.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548414","Software Fairness;Machine Learning;Requirements Engineering","Training;Analytical models;Machine learning;Software systems;Natural language processing;Requirements engineering;Task analysis","","","","66","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Using automatic static analysis to identify technical debt","A. Vetrò","Politecnico di Torino, Torino, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1613","1615","The technical debt (TD) metaphor describes a tradeoff between short-term and long-term goals in software development. Developers, in such situations, accept compromises in one dimension (e.g. maintainability) to meet an urgent demand in another dimension (e.g. delivering a release on time). Since TD produces interests in terms of time spent to correct the code and accomplish quality goals, accumulation of TD in software systems is dangerous because it could lead to more difficult and expensive maintenance. The research presented in this paper is focused on the usage of automatic static analysis to identify Technical Debt at code level with respect to different quality dimensions. The methodological approach is that of Empirical Software Engineering and both past and current achieved results are presented, focusing on functionality, efficiency and maintainability.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227226","Technical Debt;Automatic Static Analysis;Software Maintenance;Software Quality Monitoring","","","4","5","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Collaboration patterns in distributed software development projects","I. Čavrak; M. Orlić; I. Crnković","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; School of Innovation, Design and Engineering, Mälardalen University, Vasteras, Sweden",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1235","1244","The need for educating future software engineers in the field of global software engineering is recognized by many educational institutions. In this paper we outline the characteristics of an existing global software development course run over a period of nine years, and present a flexible project framework for conducting student projects in a distributed environment. Based on data collected from fourteen distributed student projects, a set of collaboration patterns is identified and their causes and implications described. Collaboration patterns are a result of the analysis of collaboration links within distributed student teams, and can assist teachers in better understanding of the dynamics found in distributed projects.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227019","Distributed software development;Teaching;Patterns;Collaboration;Teamwork","Teamwork;Educational institutions;Green products;Programming;Software engineering","","6","","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation","P. Mahbub; O. Shuvo; M. M. Rahman","Department of Computer Science, Dalhousie University, Nova Scotia, Canada; Department of Computer Science, Dalhousie University, Nova Scotia, Canada; Department of Computer Science, Dalhousie University, Nova Scotia, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","640","652","Software bugs claim ≈ 50 % of development time and cost the global economy billions of dollars. Once a bug is reported, the assigned developer attempts to identify and understand the source code responsible for the bug and then corrects the code. Over the last five decades, there has been significant research on automatically finding or correcting software bugs. However, there has been little research on automatically explaining the bugs to the developers, which is essential but a highly challenging task. In this paper, we propose Bugsplainer, a transformer-based generative model, that generates natural language explanations for software bugs by learning from a large corpus of bug-fix commits. Bugsplainer can leverage structural information and buggy patterns from the source code to generate an explanation for a bug. Our evaluation using three performance metrics shows that Bugsplainer can generate understandable and good explanations according to Google's standard, and can outperform multiple baselines from the literature. We also conduct a developer study involving 20 participants where the explanations from Bugsplainer were found to be more accurate, more precise, more concise and more useful than the baselines.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00063","Dalhousie University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172643","software bug;bug explanation;software engineering;software maintenance;natural language processing;deep learning;transformers","Measurement;Codes;Source coding;Computer bugs;Natural languages;Transformers;Software","","9","","63","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"UDesignIt: Towards social media for community-driven design","P. Greenwood; A. Rashid; J. Walkerdine","School of Computing and Communications, Lancaster University, Lancaster, UK; School of Computing and Communications, Lancaster University, Lancaster, UK; School of Computing and Communications, Lancaster University, Lancaster, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1321","1324","Online social networks are now common place in day-to-day lives. They are also increasingly used to drive social action initiatives, either led by government or communities themselves (e.g., SeeClickFix, LoveLewisham.org, mumsnet). However, such initiatives are mainly used for crowd sourcing community views or coordinating activities. With the changing global economic and political landscape, there is an ever pressing need to engage citizens on a large-scale, not only in consultations about systems that affect them, but also involve them directly in the design of these very systems. In this paper we present the UDesignIt platform that combines social media technologies with software engineering concepts to empower communities to discuss and extract high-level design features. It combines natural language processing, feature modelling and visual overlays in the form of “image clouds” to enable communities and software engineers alike to unlock the knowledge contained in the unstructured and unfiltered content of social media where people discuss social problems and their solutions. By automatically extracting key themes and presenting them in a structured and organised manner in near real-time, the approach drives a shift towards large-scale engagement of community stakeholders for system design.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227089","Software design;End-user software engineering;Humans and social aspects;Requirements engineering","Communities;Social network services;Feature extraction;Media;Semantics;Natural language processing;Visualization","","8","","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"An Empirical Study of Pre-Trained Model Reuse in the Hugging Face Deep Learning Model Registry","W. Jiang; N. Synovic; M. Hyatt; T. R. Schorlemmer; R. Sethi; Y. -H. Lu; G. K. Thiruvathukal; J. C. Davis",Purdue University; Loyola University Chicago; Loyola University Chicago; Purdue University; Loyola University Chicago; Purdue University; Loyola University Chicago; Purdue University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2463","2475","Deep Neural Networks (DNNs) are being adopted as components in software systems. Creating and specializing DNNs from scratch has grown increasingly difficult as state-of-the-art architectures grow more complex. Following the path of traditional software engineering, machine learning engineers have begun to reuse large-scale pre-trained models (PTMs) and fine-tune these models for downstream tasks. Prior works have studied reuse practices for traditional software packages to guide software engineers towards better package maintenance and dependency management. We lack a similar foundation of knowledge to guide behaviors in pre-trained model ecosystems. In this work, we present the first empirical investigation of PTM reuse. We interviewed 12 practitioners from the most popular PTM ecosystem, Hugging Face, to learn the practices and challenges of PTM reuse. From this data, we model the decision-making process for PTM reuse. Based on the identified practices, we describe useful attributes for model reuse, including provenance, reproducibility, and portability. Three challenges for PTM reuse are missing attributes, discrepancies between claimed and actual performance, and model risks. We substantiate these identified challenges with systematic measurements in the Hugging Face ecosystem. Our work informs future directions on optimizing deep learning ecosystems by automated measuring useful attributes and potential attacks, and envision future research on infrastructure and standardization for model registries.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00206","Google; Cisco; NSF(grant numbers:2107230,2229703,2107020,2104319); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172757","Software reuse;Empirical software engineering;Machine learning;Deep learning;Software supply chain;Engineering decision making;Cybersecurity;Trust","Deep learning;Systematics;Biological system modeling;Ecosystems;Decision making;Supply chains;Standardization","","19","","96","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Green mining: Investigating power consumption across versions","A. Hindle","Department of Computing Science, University of Alberta, Edmonton, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1301","1304","Power consumption is increasingly becoming a concern for not only electrical engineers, but for software engineers as well, due to the increasing popularity of new power-limited contexts such as mobile-computing, smart-phones and cloud-computing. Software changes can alter software power consumption behaviour and can cause power performance regressions. By tracking software power consumption we can build models to provide suggestions to avoid power regressions. There is much research on software power consumption, but little focus on the relationship between software changes and power consumption. Most work measures the power consumption of a single software task; instead we seek to extend this work across the history (revisions) of a project. We develop a set of tests for a well established product and then run those tests across all versions of the product while recording the power usage of these tests. We provide and demonstrate a methodology that enables the analysis of power consumption performance for over 500 nightly builds of Firefox 3.6; we show that software change does induce changes in power consumption. This methodology and case study are a first step towards combining power measurement and mining software repositories research, thus enabling developers to avoid power regressions via power consumption awareness.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227094","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227094","power;power consumption;mining software repositories;dynamic analysis;sustainable-software","Power demand;Software;Fires;Power measurement;Data mining;Green products;Air pollution","","14","","17","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Characterizing Software Maintenance Meetings: Information Shared, Discussion Outcomes, and Information Captured","A. M. Soria; T. Lopez; N. Mashhadi; A. Van der Hoek; E. Seero; E. Evans; J. Burge","Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Informatics, University of California, Irvine, Irvine, CA, U.S.A.; Department of Mathematics and Computer Science Colorado College, Colorado, CO, U.S.A.; Department of Mathematics and Computer Science Colorado College, Colorado, CO, U.S.A.; Department of Mathematics and Computer Science Colorado College, Colorado, CO, U.S.A.",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","665","677","A type of meeting that has been understudied in the software engineering literature to date is what we term the software maintenance meeting: a regularly scheduled team meeting in which emergent issues are addressed that are usually out of scope of the daily stand-up but not necessarily challenging enough to warrant an entirely separate meeting. These meetings tend to discuss a wide variety of topics and are crucial in keeping software development projects going, but little is known about these meetings and how they proceed. In this paper, we report on a single exploratory case study in which we analyzed ten consecutive maintenance meetings from a major healthcare software provider. We analyzed what kind of information is brought into the discussions held in these meetings and how, what outcomes arose from the discussions, and what information was captured for downstream use. Our findings are varied, giving rise to both practical considerations for those conducting these kinds of meetings and new research directions toward further understanding and supporting them.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623330","National Science Foundation(grant numbers:CCF-2210812,CCF-2210813); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548798","Meetings;software maintenance;information;resolution","Software maintenance;Heart beat;Conferences;Medical services;Maintenance;Software engineering;Software development management","","","","91","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Exploring Experiences with Automated Program Repair in Practice","F. N. Meem; J. Smith; B. Johnson","George Mason University, Virginia, USA; Lafayette College, Pennsylvania, USA; George Mason University, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1047","1057","Automated program repair, also known as APR, is an approach for automatically repairing software faults. There is a large amount of research on automated program repair, but very little offers in-depth insights into how practitioners think about and employ APR in practice. To learn more about practitioners' perspectives and experiences with current APR tools and techniques, we administered a survey, which received valid responses from 331 software practitioners. We analyzed survey responses to gain insights regarding factors that correlate with APR awareness, experience, and use. We established a strong correlation between APR awareness and tool use and attributes including job position, company size, total coding experience, and preferred language of software practitioners. We also found that practitioners are using other forms of support, such as co-workers and ChatGPT, more frequently than APR tools when fixing software defects. We learned about the drawbacks that practitioners encounter while utilizing existing APR tools and the impact that each drawback has on their practice. Our findings provide implications for research and practice centered on development, adoption, and use of APR.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548569","automated program repair;software bugs;software tools","Surveys;Correlation;Companies;Maintenance engineering;Chatbots;Software;Encoding","","2","","46","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"xMapper: An architecture-implementation mapping tool","Y. Zheng; R. N. Taylor","Institute for Software Research, University of California, Irvine, Irvine, CA, USA; Institute for Software Research, University of California, Irvine, Irvine, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1461","1462","xMapper is an Eclipse-based tool that implements a new architecture-implementation mapping approach called 1.x-way mapping. xMapper is able to record various architecture changes during software development, and automatically map specific kinds of architecture changes to code in specific ways. In addition, xMapper supports the mapping of behavioral architecture specifications modeled as UML-like sequence diagrams and state diagrams.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227064","software architecture;traceability;round-trip engineering","Computer architecture;Unified modeling language;Lifting equipment;Software;Programming;Software architecture;Manuals","","","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Documenting and sharing knowledge about code","A. Guzzi","Software Engineering Research Group, Delft University of Technology, Delft, Netherlands",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1535","1538","Software engineers spend a considerable amount of time on program comprehension. Current research has primarily focused on assisting the developer trying to build up his understanding of the code. This knowledge remains only in the mind of the developer and, as time elapses, often “disappears”. In this research, we shift the focus to the developer who is using her Integrated Development Environment (IDE) for writing, modifying, or reading the code, and who actually understands the code she is working with. The objective of this PhD research is to seek ways to support this developer to document and share her knowledge with the rest of the team. In particular, we investigate the full potential of micro-blogging integrated into the IDE for addressing the program comprehension problem.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227043","Program comprehension;micro-blogging;IDEs;recommender systems;CSCW","Software;USA Councils;Recommender systems;History;Context;Programming;Prototypes","","4","","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Information needs for software development analytics","R. P. L. Buse; T. Zimmermann","University of Virginia, USA; Microsoft Research, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","987","996","Software development is a data rich activity with many sophisticated metrics. Yet engineers often lack the tools and techniques necessary to leverage these potentially powerful information resources toward decision making. In this paper, we present the data and analysis needs of professional software engineers, which we identified among 110 developers and managers in a survey. We asked about their decision making process, their needs for artifacts and indicators, and scenarios in which they would use analytics. The survey responses lead us to propose several guidelines for analytics tools in software development including: Engineers do not necessarily have much expertise in data analysis; thus tools should be easy to use, fast, and produce concise output. Engineers have diverse analysis needs and consider most indicators to be important; thus tools should at the same time support many different types of artifacts and many indicators. In addition, engineers want to drill down into data based on time, organizational structure, and system architecture.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227122","","Software;Decision making;Measurement;Programming;Software engineering;Complexity theory;Guidelines","","97","","44","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"GenderMag Improves Discoverability in the Field, Especially for Women: An Multi-Year Case Study of Suggest Edit, a Code Review Feature","E. Murphy-Hill; A. Elizondo; A. Murillo; M. Harbach; B. Vasilescu; D. Carlson; F. Dessloch","Google, USA; Google, Germany; Google, Germany; Google, Germany; Google, USA; Google, Germany; Google, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2333","2344","Prior research shows that the GenderMag method can help identify and address usability barriers that are more likely to affect women software users than men. However, the evidence for the effectiveness of GenderMag is limited to small lab studies. In this case study, by combining self-reported gender data from tens of thousands of users of an internal code review tool with software logs data gathered over a five-year period, we quantitatively show that GenderMag helped a team at Google (a) correctly identify discoverability as a usability barrier more likely to affect women than men, and (b) increase discoverability by 2.4x while also achieving gender parity. That is, compared to men using the original code review tool, women and men using the system redesigned with GenderMag were both 2.4x more likely to discover the “Suggest Edit” feature at any given time. Thus, this paper contributes the first large-scale evidence of the effectiveness of GenderMag in the field.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549611","software features;feature discovery;UX design;gender;inclusion","Codes;Reviews;Design methodology;Software;Internet;Usability;Software engineering","","","","32","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Developer prioritization in bug repositories","J. Xuan; H. Jiang; Z. Ren; W. Zou","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","25","35","Developers build all the software artifacts in development. Existing work has studied the social behavior in software repositories. In one of the most important software repositories, a bug repository, developers create and update bug reports to support software development and maintenance. However, no prior work has considered the priorities of developers in bug repositories. In this paper, we address the problem of the developer prioritization, which aims to rank the contributions of developers. We mainly explore two aspects, namely modeling the developer prioritization in a bug repository and assisting predictive tasks with our model. First, we model how to assign the priorities of developers based on a social network technique. Three problems are investigated, including the developer rankings in products, the evolution over time, and the tolerance of noisy comments. Second, we consider leveraging the developer prioritization to improve three predicted tasks in bug repositories, i.e., bug triage, severity identification, and reopened bug prediction. We empirically investigate the performance of our model and its applications in bug repositories of Eclipse and Mozilla. The results indicate that the developer prioritization can provide the knowledge of developer priorities to assist software tasks, especially the task of bug triage.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227209","developer prioritization;software evolution;bug triage;severity identification;reopened bug prediction","Computer bugs;Software;Noise measurement;Programming;Noise;Social network services;Communities","","85","","40","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Predicting Bugs by Monitoring Developers During Task Execution","G. Laudato; S. Scalabrino; N. Novielli; F. Lanubile; R. Oliveto","STAKE Lab, University of Molise, Italy; STAKE Lab, University of Molise, Italy; University of Bari, Italy; University of Bari, Italy; STAKE Lab, University of Molise, Italy",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1","13","Knowing which parts of the source code will be defective can allow practitioners to better allocate testing resources. For this reason, many approaches have been proposed to achieve this goal. Most state-of-the-art predictive models rely on product and process metrics, i.e., they predict the defectiveness of a component by considering what developers did. However, there is still limited evidence of the benefits that can be achieved in this context by monitoring how developers complete a development task. In this paper, we present an empirical study in which we aim at understanding whether measuring human aspects on developers while they write code can help predict the introduction of defects. First, we introduce a new developer-based model which relies on behavioral, psychophysical, and control factors that can be measured during the execution of development tasks. Then, we run a controlled experiment involving 20 software developers to understand if our developer-based model is able to predict the introduction of bugs. Our results show that a developer-based model is able to achieve a similar accuracy compared to a state-of-the-art code-based model, i.e., a model that uses only features measured from the source code. We also observed that by combining the models it is possible to obtain the best results (84% accuracy).","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172756","bug prediction;human aspects of software engineering;biometric sensors;empirical software engineering","Training;Codes;Source coding;Computer bugs;Predictive models;Software;Behavioral sciences","","2","","81","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A Grounded Theory of Coordination in Remote-First and Hybrid Software Teams","R. E. de Souza Santos; P. Ralph","Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","25","35","While the long-term effects of the COVID-19 pandemic on software professionals and organizations are difficult to predict, it seems likely that working from home, remote-first teams, distributed teams, and hybrid (part-remote/part-office) teams will be more common. It is therefore important to investigate the challenges that software teams and organizations face with new remote and hybrid work. Consequently, this paper reports a year-long, participant-observation, constructivist grounded theory study investigating the impact of working from home on software development. This study resulted in a theory of software team coordination. Briefly, shifting from in-office to at-home work fundamentally altered coordination within software teams. While group cohesion and more effective communication appear protective, coordination is under-mined by distrust, parenting and communication bricolage. Poor coordination leads to numerous problems including misunderstandings, help requests, lower job satisfaction among team members, and more illdefined tasks. These problems, in turn, reduce overall project success and prompt professionals to alter their software development processes (in this case, from Scrum to Kanban). Our findings suggest that software organizations with many remote employees can improve performance by encouraging greater engagement within teams and supporting employees with family and childcare responsibilities.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794129","software development;COVID-19;remote work;work-from-home;coordination;agile methods;grounded theory","COVID-19;South America;Industries;Pandemics;Lead;Market research;Software","","9","","39","","20 Jun 2022","","","IEEE","IEEE Conferences"
"What Makes Effective Leadership in Agile Software Development Teams?","L. Gren; P. Ralph","Volvo Cars and Chalmers | University of Gothenburg, Gothenburg, Sweden; Dalhousie University, Halifax, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2402","2414","Effective leadership is one of the key drivers of business and project success, and one of the most active areas of management research. But how does leadership work in agile software development, which emphasizes self-management and self-organization and marginalizes traditional leadership roles? To find out, this study examines agile leadership from the perspective of thirteen professionals who identify as agile leaders, in different roles, at ten different software development companies of varying sizes. Data from semi-structured interviews reveals that leadership: (1) is dynamically shared among team members; (2) engenders a sense of belonging to the team; and (3) involves balancing competing organizational cultures (e.g. balancing the new agile culture with the old milestone-driven culture). In other words, agile leadership is a property of a team, not a role, and effectiveness depends on agile team members' identifying with the team, accepting responsibility, and being sensitive to cultural conflict.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794040","agile methods;leadership;management;culture","Leadership;Companies;Software;Cultural differences;Interviews;Software engineering;Business","","2","","81","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Ripples of a Mutation - An Empirical Study of Propagation Effects in Mutation Testing","H. Du; V. K. Palepu; J. A. Jones","University of California, Irvine, Irvine, USA; Microsoft, Silicon Valley Campus, Mountain View, USA; University of California, Irvine, Irvine, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1421","1433","The mechanics of how a fault reveals itself as a test failure is of keen interest to software researchers and practitioners alike. An improved understanding of how faults translate to failures can guide improvements in broad facets of software testing, ranging from test suite design to automated program repair, which are premised on the understanding that the presence of faults would alter some test executions. In this work, we study such effects by mutations, as applicable in mutation testing. Mutation testing enables the generation of a large corpus of faults; thereby harvesting a large pool of mutated test runs for analysis. Specifically, we analyze more than 1.1 million mutated test runs to study if and how the underlying mutations induce infections that propagate their way to observable failures. We adopt a broad-spectrum approach to analyze such a large pool of mutated runs. For every mutated test run, we are able to determine: (a) if the mutation induced a state infection; (b) if the infection propagated through the end of the test run; and (c) if the test failed in the presence of a propagated infection. By examining such infection-, propagation- and revealability-effects for more than 43,000 mutations executed across 1.1 million test runs we are able to arrive at some surprising findings. Our results find that once state infection is observed, propagation is frequently detected; however, a propagated infection does not always reveal itself as a test failure. We also find that a significant portion of survived mutants in our study could have been killed by observing propagated state infections that were left undetected. Finally, we also find that different mutation operators can demonstrate substan-tial differences in their specific impacts on the execution-to-failure ripples of the resulting mutations.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548566","software fault infection;error propagation;mutation testing;dynamic analysis;empirical study","Software testing;Maintenance engineering;Software;Distance measurement;Software engineering","","2","","51","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"ConTexter feedback system","T. Wehrmaker; S. Gärtner; K. Schneider","Software Engineering Group, Leibniz Universität Hannover, Hanover, Germany; Software Engineering Group, Leibniz Universität Hannover, Hanover, Germany; Software Engineering Group, Leibniz Universität Hannover, Hanover, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1459","1460","Today's large-scale softwareintensive systems exhibit an increasing complexity due to a broad spectrum of technical and socio-technical components. Due to the very dynamic character of such systems as well as fast evolving technologies, most requirements cannot be planned a priori. To overcome this problem, we suggest a method to gather enduser needs for requirements engineers at any time by applying a geographical deployed feedback system. End-user needs are gathered in-situ by utilizing mobile devices. In this paper, we present the implementation of our feedback system enabling end-users to submit feedback with smartphones at very low effort and cost.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227065","end-user involvement;mobile computing;requirements engineering","Mobile communication;Context;Servers;Smart phones;Software","","9","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Causality in Configurable Software Systems","C. Dubslaff; K. Weis; C. Baier; S. Apel","Centre for Tactile Internet with Human-in-the-Loop (CeTI), Technische Universität Dresden, Dresden, Germany; Saarland Informatics Campus, Saarland University, Saarbrücken, Germany; Technische Universität Dresden, Dresden, Germany; Saarland Informatics Campus, Saarland University, Saarbrücken, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","325","337","Detecting and understanding reasons for defects and inadvertent behavior in software is challenging due to their increasing complexity. In configurable software systems, the combinatorics that arises from the multitude of features a user might select from adds a further layer of complexity. We introduce the notion of feature causality, which is based on counterfactual reasoning and inspired by the seminal definition of actual causality by Halpern and Pearl. Feature causality operates at the level of system configurations and is capable of identifying features and their interactions that are the reason for emerging functional and non-functional properties. We present various methods to explicate these reasons, in particular well-established notions of responsibility and blame that we extend to the feature-oriented setting. Establishing a close connection of feature causality to prime implicants, we provide algorithms to effectively compute feature causes and causal explications. By means of an evaluation on a wide range of configurable software systems, including community benchmarks and real-world systems, we demonstrate the feasibility of our approach: We illustrate how our notion of causality facilitates to identify root causes, estimate the effects of features, and detect feature interactions.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510200","DFG; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794029","causality;configurable systems;software product lines;software analysis","Software algorithms;Benchmark testing;Software systems;Feature extraction;Cognition;Complexity theory;Software engineering","","6","","96","","20 Jun 2022","","","IEEE","IEEE Conferences"
"“STILL AROUND”: Experiences and Survival Strategies of Veteran Women Software Developers","S. Van Breukelen; A. Barcombt; S. Baltes; A. Serebrenik","Eindhoven University of Technology, The Netherlands; University of Calgary, Canada; University of Adelaide, Australia; Eindhoven University of Technology, The Netherlands",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1148","1160","The intersection of ageism and sexism can create a hostile environment for veteran software developers belonging to marginalized genders. In this study, we conducted 14 interviews to examine the experiences of people at this intersection, primar-ily women, in order to discover the strategies they employed in order to successfully remain in the field. We identified 283 codes, which fell into three main categories: Strategies, Experiences, and Perception. Several strategies we identified, such as (Deliberately) Not Trying to Look Younger, were not previously described in the software engineering literature. We found that, in some compa-nies, older women developers are recognized as having particular value, further strengthening the known benefits of diversity in the workforce. Based on the experiences and strategies, we suggest organizations employing software developers to consider the benefits of hiring veteran women software developers. For example, companies can draw upon the life experiences of older women developers in order to better understand the needs of customers from a similar demographic. While we recognize that many of the strategies employed by our study participants are a response to systemic issues, we still consider that, in the short-term, there is benefit in describing these strategies for developers who are experiencing such issues today.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172884","age;gender;intersectionality;software development;interview study;qualitative research","Industries;Codes;Engineering profession;Companies;Software;Distance measurement;Interviews","","8","","79","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Timely detection of Coordination Requirements to support collaboration among software developers","K. Blincoe","Computer Science Department, Drexel University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1601","1603","Work dependencies often exist between the developers of a software project. These dependencies frequently result in a need for coordination between the involved developers. However, developers are not always aware of these Coordination Requirements. Current methods which detect the need to coordinate rely on information which is available only after development work has been completed. This does not enable developers to act on their coordination needs. I have investigated a more timely method to determine Coordination Requirements in a software development team as they emerge.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227230","","Software;Programming;Productivity;Visualization;Collaboration;IEEE Potentials","","1","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Going global with agile service networks","D. A. Tamburri","IMSE Group, VU University Amsterdam, Amsterdam, Netherlands",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1475","1478","ASNs are emergent networks of service-based applications (nodes) which collaborate through agile (i.e. adaptable) transactions. GSE comprises the management of project teams distanced in both space and time, collaborating in the same development effort. The GSE condition poses challenges both technical (e.g. geolocalization of resources, information continuity between timezones, etc.) and social (e.g. collaboration between different cultures, fear of competition, etc.). ASNs can be used to build an adaptable social network (ASNGSE) supporting the collaborations (edges of ASNGSE) of GSE teams (nodes of ASNGSE).","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227058","Agile Service Networks;Global Software Engineering;SOA;Social Networks;Organizational Structures;Cloud Computing","Social network services;Collaboration;Business;Programming;Prototypes;Software engineering;Context","","2","","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Deep Combination of CDCl(T) and Local Search for Satisfiability Modulo Non-Linear Integer Arithmetic Theory","X. Zhang; B. Li; S. Cai","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1534","1546","Satisfiability Modulo Theory (SMT) generalizes the propositional satisfiability problem (SAT) by extending support for various first-order background theories. In this paper, we focus on the SMT problems in Non-Linear Integer Arithmetic (NIA) theory, referred to as SMT(NIA), which has wide applications in software engineering. The dominant paradigm for SMT(NIA) is the CDCL(T) framework, while recently stochastic local search (SLS) has also shown its effectiveness. However, the cooperation between the two methods has not been studied yet. Motivated by the great success of the deep cooperation of CDCL and SLS for SAT, we propose a two-layer hybrid approach for SMT(NIA). The outer-layer interleaves between the inner-layer and an independent SLS solver. In the inner-layer, we take CDCL(T) as the main body, and design DCL(T)-guided SLS solver, which is invoked at branches corresponding to skeleton solutions and returns useful information to improve the branching heuristics of CDCL(T). We implement our ideas on top of the CDCL(T) tactic of Z3 with an SLS solver called Localsmt, resulting in a hybrid solver dubbed Hv-BRIDSMT. Extensive experiments are carried out on the standard SMT(NIA) benchmarks from SMT-LIB, where most of the instances are from real-world software engineering applications of termination and non-termination analysis. Experiment results show that Hybridsmt significantly improves the CDCL(T) solver in Z3. Moreover, our solver can solve 10.36% more instances than the currently best SMT(NIA) solver, and is more efficient for software verification instances.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639105","NSFC(grant numbers:62122078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549214","SMT(NIA);CDCL(T);Local Search;Hybrid Method","Software algorithms;Benchmark testing;Search problems;Skeleton;Software;Standards;Software engineering","","","","66","","14 Jun 2024","","","IEEE","IEEE Conferences"
"On the Benefits and Limits of Incremental Build of Software Configurations: An Exploratory Study","G. A. Randrianaina; X. Tërnava; D. E. Khelladi; M. Acher","Univ Rennes, CNRS, Inria, IRISA - UMR 6074, Rennes, France; Univ Rennes, CNRS, Inria, IRISA - UMR 6074, Rennes, France; Univ Rennes, CNRS, Inria, IRISA - UMR 6074, Rennes, France; Univ Rennes, CNRS, Inria, IRISA - UMR 6074 Institut Universitaire de France (IUF), Rennes, France",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1584","1596","Software projects use build systems to automate the compilation, testing, and continuous deployment of their software products. As software becomes increasingly configurable, the build of multiple configurations is a pressing need, but expensive and challenging to implement. The current state of practice is to build independently (a.k.a., clean build) a software for a subset of configurations. While incremental build has been studied for software evolution and relatively small changes of the source code, it has surprisingly not been considered for software configurations. In this exploratory study, we examine the benefits and limits of building software configurations incrementally, rather than always building them cleanly. By using five real-life configurable systems as subjects, we explore whether incremental build works, outperforms a sequence of clean builds, is correct w.r.t. clean build, and can be used to find an optimal ordering for building configurations. Our results show that incremental build is feasible in 100% of the times in four subjects and in 78% of the times in one subject. In average, 88.5% of the configurations could be built faster with incremental build while also finding several alternatives faster incremental builds. However, only 60% of faster incremental builds are correct. Still, when considering those correct incremental builds with clean builds, we could always find an optimal order that is faster than just a collection of clean builds with a gain up to 11.76%.","1558-1225","978-1-4503-9221-1","10.1145/3510457.3513035","National Natural Science Foundation of China(grant numbers:61732019,U20A6003,62072444,61802378); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793946","Configurable software systems;build systems;configuration build","Knowledge engineering;Costs;Codes;Buildings;Pressing;Software systems;Software","","3","","54","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Restructuring unit tests with TestSurgeon","P. Estefó","Department of Computer Science (DCC), University of Chile, Santiago, Chile",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1632","1634","The software engineering community has produced great techniques for software maintainability, however, less effort is dedicated to have unit tests modular and extensible. TestSurgeon is a profiler for unit tests which collects information from tests execution. It proposes a metric for similarity between tests and provides a visualization to help developers restructure their unit tests.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227219","","Software;Measurement;Visualization;Software engineering;Educational institutions;Communities;Shape","","3","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Exploring techniques for rationale extraction from existing documents","B. Rogers; J. Gung; Y. Qiao; J. E. Burge","Department of Computer Science and Software Engineering, Miami University, Oxford, OH, USA; Department of Computer Science and Software Engineering, Miami University, Oxford, OH, USA; Department of Computer Science and Software Engineering, Miami University, Oxford, OH, USA; Department of Computer Science and Software Engineering, Miami University, Oxford, OH, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1313","1316","The rationale for a software system captures the designers' and developers' intent behind the decisions made during its development. This information has many potential uses but is typically not captured explicitly. This paper describes an initial investigation into the use of text mining and parsing techniques for identifying rationale from existing documents. Initial results indicate that the use of linguistic features results in better precision but significantly lower recall than using text mining.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227091","rationale;text mining","Ontologies;Pragmatics;Feature extraction;Text mining;Logic gates;Software engineering","","13","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"What scope is there for adopting evidence-informed teaching in SE?","D. Budgen; S. Drummond; P. Brereton; N. Holland","Durham University, Durham, Durham, GB; School of Engineering & Computing Sciences Durham University, Durham, U.K.; School of Computing & Maths Keele University, U.K.; School of Computing & Maths Keele University, U.K.",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1205","1214","Context: In teaching about software engineering we currently make little use of any empirical knowledge. Aim: To examine the outcomes available from the use of Evidence-Based Software Engineering (EBSE) practices, so as to identify where these can provide support for, and inform, teaching activities. Method: We have examined all known secondary studies published up to the end of 2009, together with those published in major journals to mid-2011, and identified where these provide practical results that are relevant to student needs. Results: Starting with 145 candidate systematic literature reviews (SLRs), we were able to identify and classify potentially useful teaching material from 43 of them. Conclusions: EBSE can potentially lend authority to our teaching, although the coverage of key topics is uneven. Additionally, mapping studies can provide support for research-led teaching.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227022","empirical;education;evidence-based","Education;Software engineering;Software;Guidelines;Data mining;Systematics;Materials","","10","","28","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Training Data Debugging for the Fairness of Machine Learning Software","Y. Li; L. Meng; L. Chen; L. Yu; D. Wu; Y. Zhou; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; Momenta, Suzhou, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2215","2227","With the widespread application of machine learning (ML) software, especially in high-risk tasks, the concern about their unfairness has been raised towards both developers and users of ML software. The unfairness of ML software indicates the software behavior affected by the sensitive features (e.g., sex), which leads to biased and illegal decisions and has become a worthy problem for the whole software engineering community. According to the “data-driven” programming paradigm of ML software, we consider the root cause of the unfairness as biased features in training data. Inspired by software debugging, we propose a novel method, Linear-regression based Training Data Debugging (LTDD), to debug feature values in training data, i.e., (a) identify which features and which parts of them are biased, and (b) exclude the biased parts of such features to recover as much valuable and unbiased information as possible to build fair ML software. We conduct an extensive study on nine data sets and three classifiers to evaluate the effect of our method LTDD compared with four baseline methods. Experimental results show that (a) LTDD can better improve the fairness of ML software with less or comparable damage to the performance, and (b) LTDD is more actionable for fairness improvement in realistic scenarios.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510091","National Natural Science Foundation of China(grant numbers:62172202,61872177,61772259,62172205,61832009,61772263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794106","Debugging;Fairness;ML Software;Training Data","Training;Linear regression;Training data;Machine learning;Debugging;Programming;Software","","7","","50","","20 Jun 2022","","","IEEE","IEEE Conferences"
"DLInfer: Deep Learning with Static Slicing for Python Type Inference","Y. Yan; Y. Feng; H. Fan; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2009","2021","Python programming language has gained enor-mous popularity in the past decades. While its flexibility signifi-cantly improves software development productivity, the dynamic typing feature challenges software maintenance and quality assurance. To facilitate programming and type error checking, the Python programming language has provided a type hint mechanism enabling developers to annotate type information for variables. However, this manual annotation process often requires plenty of resources and may introduce errors. In this paper, we propose a deep learning type inference technique, namely DLInfer, to automatically infer the type infor-mation for Python programs. DLInfer collects slice statements for variables through static analysis and then vectorizes them with the Unigram Language Model algorithm. Based on the vectorized slicing features, we designed a bi-directional gated recurrent unit model to learn the type propagation information for inference. To validate the effectiveness of DLInfer, we conduct an extensive empirical study on 700 open-source projects. We evaluate its accuracy in inferring three kinds of fundamental types, including built-in, library, and user-defined types. By training with a large-scale dataset, DLInfer achieves an average of 98.79% Top-1 accuracy for the variables that can get type information through static analysis and manual annotation. Further, DLInfer achieves 83.03% type inference accuracy on average for the variables that can only obtain the type information through dynamic analysis. The results indicate DLInfer is highly effective in inferring types. It is promising to apply it to assist in various software engineering tasks for Python programs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00170","National Natural Science Foundation of China(grant numbers:62172209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172544","type inference;Python;static slicing","Deep learning;Training;Software maintenance;Quality assurance;Annotations;Static analysis;Manuals","","3","","76","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A First Look at the Inheritance-Induced Redundant Test Execution","D. J. Kim; T. -H. P. Chen; J. Yang","Software PErformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Software PErformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1397","1408","Inheritance, a fundamental aspect of object-oriented design, has been leveraged to enhance code reuse and facilitate efficient software development. However, alongside its benefits, inheritance can introduce tight coupling and complex relationships between classes, posing challenges for software maintenance. Although there are many studies on inheritance in source code, there is limited study on using inheritance in test code. In this paper, we take the first step by studying inheritance in test code, with a focus on redundant test executions caused by inherited test cases. We empirically study the prevalence of test inheritance and its characteristics. We also propose a hybrid approach that combines static and dynamic analysis to identify and locate inheritance-induced redundant test cases. Our findings reveal that (1) inheritance is widely utilized in the test code, (2) inheritance-induced redundant test executions are prevalent, accounting for 13% of all execution test cases, (3) bypassing these redundancies can help reduce 14% of the test execution time, and finally, (4) our study highlights the need for careful refactoring decisions to minimize redundant test cases and identifies the need for further research on test code quality.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549633","Software Testing;Software Evolution;Software Maintenance","Couplings;Software maintenance;Java;Codes;Source coding;Redundancy;Maintenance","","","","54","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Architectural task allocation in distributed environment: A traceability perspective","S. Imtiaz","Department of Computer Science and Software Engineering, International Islamic University, Islamabad, Pakistan",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1515","1518","Task allocation in distributed development is a challenging task due to intricate dependencies between distributed sites/teams and prior need of multifaceted information. Literature performs task allocation between distributed sites on limited criteria irrespective of the communication and coordination needs of the people. Conway's law relates product architecture with the communication and coordination needs of the people. Product architecture consists of multiple views based on different perspectives. Task allocation needs information about different architectural views and their interrelationships. Task allocation is also dependent on other factors not depicted in product architecture such as temporal, knowledge and cultural dependencies between distributed sites mentioned as external factors in the research. A well-conceived task allocation strategy will reduce communication and coordination dependency between sites/teams resulting in reduced time delay and smooth distributed development. The research aims to develop and validate a task allocation strategy based on information of system architecture for distributed environment. The strategy would consider all important factors during task allocation resulting in reduced communication and coordination overhead and time delay.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227048","Task Allocation;Distributed Development;Product Architecture","Resource management;Computer architecture;Software;Software engineering;Cultural differences;Delay effects;Programming","","2","","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Data Quality for Software Vulnerability Datasets","R. Croft; M. A. Babar; M. M. Kholoosi","School of Computer Science, CREST, University of Adelaide, Australia; School of Computer Science, CREST, University of Adelaide, Australia; School of Computer Science, CREST, University of Adelaide, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","121","133","The use of learning-based techniques to achieve automated software vulnerability detection has been of longstanding interest within the software security domain. These data-driven solutions are enabled by large software vulnerability datasets used for training and benchmarking. However, we observe that the quality of the data powering these solutions is currently ill-considered, hindering the reliability and value of produced outcomes. Whilst awareness of software vulnerability data preparation challenges is growing, there has been little investigation into the potential negative impacts of software vulnerability data quality. For instance, we lack confirmation that vulnerability labels are correct or consistent. Our study seeks to address such shortcomings by inspecting five inherent data quality attributes for four state-of-the-art software vulnerability datasets and the subsequent impacts that issues can have on software vulnerability prediction models. Surprisingly, we found that all the analyzed datasets exhibit some data quality problems. In particular, we found 20–71% of vulnerability labels to be inaccurate in real-world datasets, and 17-99% of data points were duplicated. We observed that these issues could cause significant impacts on downstream models, either preventing effective model training or inflating benchmark performance. We advocate for the need to overcome such challenges. Our findings will enable better consideration and assessment of software vulnerability data quality in the future.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172650","software vulnerability;data quality;machine learning","Training;Data integrity;Benchmark testing;Predictive models;Software;Data models;Software reliability","","33","","73","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"An Exploratory Study of Productivity Perceptions in Software Teams","A. Ruvimova; A. Lill; J. Gugler; L. Howe; E. Huang; G. Murphy; T. Fritz","University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of British Columbia, Vancouver, Canada; University of Zurich, Zurich, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","99","111","Software development is a collaborative process requiring a careful balance of focused individual effort and team coordination. Though questions of individual productivity have been widely examined in past literature, less is known about the interplay between developers' perceptions of their own productivity as opposed to their team's. In this paper, we present an analysis of 624 daily surveys and 2899 self-reports from 25 individuals across five software teams in North America and Europe, collected over the course of three months. We found that developers tend to operate in fluid team constructs, which impacts team awareness and complicates gauging team productivity. We also found that perceived individual productivity most strongly predicted perceived team productivity, even more than the amount of team interactions, unplanned work, and time spent in meetings. Future research should explore how fluid team structures impact individual and organizational productivity.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793555","Team;Productivity;Software Developer;User Study","Productivity;Fluids;Collaboration;Europe;Software;North America;Software engineering","","1","","56","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"MorphQ: Metamorphic Testing of the Qiskit Quantum Computing Platform","M. Paltenghi; M. Pradel","Department of Computer Science, University of Stuttgart, Stuttgart, Germany; Department of Computer Science, University of Stuttgart, Stuttgart, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2413","2424","As quantum computing is becoming increasingly popular, the underlying quantum computing platforms are growing both in ability and complexity. Unfortunately, testing these platforms is challenging due to the relatively small number of existing quantum programs and because of the oracle problem, i.e., a lack of specifications of the expected behavior of programs. This paper presents MorphQ, the first metamorphic testing approach for quantum computing platforms. Our two key contributions are (i) a program generator that creates a large and diverse set of valid (i.e., non-crashing) quantum programs, and (ii) a set of program transformations that exploit quantum-specific metamorphic relationships to alleviate the oracle problem. Evaluating the approach by testing the popular Qiskit platform shows that the approach creates over 8k program pairs within two days, many of which expose crashes. Inspecting the crashes, we find 13 bugs, nine of which have already been confirmed. MorphQ widens the slim portfolio of testing techniques of quantum computing platforms, helping to create a reliable software stack for this increasingly important field.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172716","quantum computing;metamorphic testing;software engineering;compiler testing;quantum computing platforms;quantum bugs;Qiskit;MorphQ;quantum software reliability;quality assurance;quantum program generator;differential testing;fuzz testing","Quantum computing;Automatic programming;Computer bugs;Full stack;Fuzzing;Reliability engineering;Software","","9","","40","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Development in Times of Hype: How Freelancers Explore Generative AI?","M. Dolata; N. Lange; G. Schwabe","Department of Informatics, University of Zurich, Zurich, Switzerland; Entschleunigung Norbert Lange, Kassel, Germany; Department of Informatics, University of Zurich, Zurich, Switzerland",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2257","2269","The rise of generative AI has led many companies to hire freelanc-ers to harness its potential. However, this technology presents unique challenges to developers who have not previously engaged with it. Freelancers may find these challenges daunting due to the absence of organizational support and their reliance on positive client feedback. In a study involving 52 freelance developers, we identified multiple challenges associated with developing solutions based on generative AI. Freelancers often struggle with as-pects they perceive as unique to generative AI such as unpredict-ability of its output, the occurrence of hallucinations, and the in-consistent effort required due to trial-and-error prompting cycles. Further, the limitations of specific frameworks, such as token lim-its and long response times, add to the complexity. Hype-related issues, such as inflated client expectations and a rapidly evolving technological ecosystem, further exacerbate the difficulties. To address these issues, we propose Software Engineering for Generative AI (SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the software engineering community can provide effective guidance. This support is essential for freelancers working with generative AI and other emerging technologies.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548766","Generative AI;AI-based Systems;Challenges;Freelancers;Hype;SE for Generative AI;SE4GenAI;Hype-Induced SE;Hype-SE;Fashion;Product;Paradigm;Novelty;Qualitative Research","Generative AI;Ecosystems;Companies;Complexity theory;Time factors;Software engineering","","","","64","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"WorkItemExplorer: Visualizing software development tasks using an interactive exploration environment","C. Treude; P. Gorman; L. Grammel; M. -A. Storey","Department of Computer Science, University of Victoria, Victoria, BC, Canada; Department of Computer Science, University of Victoria, Victoria, BC, Canada; Department of Computer Science, University of Victoria, Victoria, BC, Canada; Department of Computer Science, University of Victoria, Victoria, BC, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1399","1402","This demo introduces WorkItemExplorer, an interactive environment to visually explore data from software development tasks. WorkItemExplorer enables developers and managers to investigate activity and correlations in their task management system by making data exploration flexible and interactive, and by utilizing multiple coordinated views. Our preliminary evaluation shows that WorkItemExplorer is able to answer questions that developers ask, while also enabling them to gain new insights through the free exploration of data.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227238","visualization;coordinated views;task management","Data visualization;Usability;Programming;Bars;Heating;Software engineering","","3","","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Commit Message Matters: Investigating Impact and Evolution of Commit Message Quality","J. Li; I. Ahmed","University of California, Irvine, Irvine, CA, USA; University of California, Irvine, Irvine, CA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","806","817","Commit messages play an important role in communication among developers. To measure the quality of commit messages, researchers have defined what semantically constitutes a Good commit message: it should have both the summary of the code change (What) and the motivation/reason behind it (Why). The presence of the issue report/pull request links referenced in a commit message has been treated as a way of providing Why information. In this study, we found several quality issues that could hamper the links' ability to provide Why information. Based on this observation, we developed a machine learning classifier for automatically identifying whether a commit message has What and Why information by considering both the commit messages and the link contents. This classifier outperforms state-of-the-art machine learning classifiers by 12 percentage points improvement in the F1 score. With the improved classifier, we conducted a mixed method empirical analysis and found that: (1) Commit message quality has an impact on software defect proneness, and (2) the overall quality of the commit messages decreases over time, while developers believe they are writing better commit messages. All the research artifacts (i.e., tools, scripts, and data) of this study are available on the accompanying website [2].","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172825","Commit message quality;software defect proneness;empirical analysis","Codes;Machine learning;Writing;Software;Software engineering","","7","","71","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Lightweight Approaches to DNN Regression Error Reduction: An Uncertainty Alignment Perspective","Z. Li; M. Zhang; J. Xu; Y. Yao; C. Cao; T. Chen; X. Ma; J. Lü","Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science, Birkbeck, University of London, UK; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China; Department of Computer Science and Technology, State Key Lab of Novel Software Technology, Nanjing University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1187","1199","Regression errors of Deep Neural Network (DNN) models refer to the case that predictions were correct by the old-version model but wrong by the new-version model. They frequently occur when upgrading DNN models in production systems, causing disproportionate user experience degradation. In this paper, we propose a lightweight regression error reduction approach with two goals: 1) requiring no model retraining and even data, and 2) not sacrificing the accuracy. The proposed approach is built upon the key insight rooted in the unmanaged model uncertainty, which is intrinsic to DNN models, but has not been thoroughly explored especially in the context of quality assurance of DNN models. Specifically, we propose a simple yet effective ensemble strategy that estimates and aligns the two models' uncertainty. We show that a Pareto improvement that reduces the regression errors without compromising the overall accuracy can be guaranteed in theory and largely achieved in practice. Comprehensive experiments with various representative models and datasets confirm that our approaches significantly outperform the state-of-the-art alternatives.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00106","National Natural Science Foundation of China(grant numbers:62025202,62172199); State Key Laboratory of Novel Software Technology(grant numbers:KFKT2022A03); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172764","Software regression;deep neural networks;uncertainty alignment;model ensemble","Degradation;Production systems;Uncertainty;Quality assurance;Artificial neural networks;Predictive models;Software","","","","77","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"iTree: Efficiently discovering high-coverage configurations using interaction trees","C. Song; A. Porter; J. S. Foster","Computer Science Department, University of Maryland, College Park, USA; Computer Science Department, University of Maryland, College Park, USA; Computer Science Department, University of Maryland, College Park, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","903","913","Software configurability has many benefits, but it also makes programs much harder to test, as in the worst case the program must be tested under every possible configuration. One potential remedy to this problem is combinatorial interaction testing (CIT), in which typically the developer selects a strength t and then computes a covering array containing all t-way configuration option combinations. However, in a prior study we showed that several programs have important high-strength interactions (combinations of a subset of configuration options) that CIT is highly unlikely to generate in practice. In this paper, we propose a new algorithm called interaction tree discovery (iTree) that aims to identify sets of configurations to test that are smaller than those generated by CIT, while also including important high-strength interactions missed by practical applications of CIT. On each iteration of iTree, we first use low-strength CIT to test the program under a set of configurations, and then apply machine learning techniques to discover new interactions that are potentially responsible for any new coverage seen. By repeating this process, iTree builds up a set of configurations likely to contain key high-strength interactions. We evaluated iTree by comparing the coverage it achieves versus covering arrays and randomly generated configuration sets. Our results strongly suggest that iTree can identify high-coverage sets of configurations more effectively than traditional CIT or random sampling.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227129","Empirical Software Engineering;Software Configurations;Software Testing and Analysis","Arrays;Testing;Instruments;Software engineering;Machine learning;Clustering algorithms;Decision trees","","18","","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"From Organizations to Individuals: Psychoactive Substance Use By Professional Programmers","K. Newman; M. Endres; W. Weimer; B. Johnson","Computer Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Computer Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Computer Science and Engineering, University of Michigan, Ann Arbor, Michigan, USA; Department of Computer Science, George Mason University, Fairfax, Virginia, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","665","677","Psychoactive substances, which influence the brain to alter perceptions and moods, have the potential to have positive and negative effects on critical software engineering tasks. They are widely used in software, but that use is not well understood. We present the results of the first qualitative investigation of the experiences of, and challenges faced by, psychoactive substance users in professional software communities. We conduct a the-matic analysis of hour-long interviews with 26 professional pro-grammers who use psychoactive substances at work. Our results provide insight into individual motivations and impacts, including mental health and the relationships between various substances and productivity. Our findings elaborate on socialization effects, including soft skills, stigma, and remote work. The analysis also highlights implications for organizational policy, including positive and negative impacts on recruitment and retention. By exploring individual usage motivations, social and cultural ramifications, and organizational policy, we demonstrate how substance use can permeate all levels of software development.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00065","National Science Foundation(grant numbers:2211749); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172897","software engineering;mental health;drug use;productivity;qualitative methods","Productivity;Mental health;Debugging;Software;Remote working;Interviews;Task analysis","","3","","41","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Inferring developer expertise through defect analysis","T. T. Nguyen; T. N. Nguyen; E. Duesterwald; T. Klinger; P. Santhanam","Iowa State University, USA; Iowa State University, USA; IBM Thomas J. Watson Research Center, USA; IBM Thomas J. Watson Research Center, USA; IBM Thomas J. Watson Research Center, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1297","1300","Fixing defects is an essential software development activity. For commercial software vendors, the time to repair defects in deployed business-critical software products or applications is a key quality metric for sustained customer satisfaction. In this paper, we report on the analysis of about 1,500 defect records from an IBM middle-ware product collected over a five-year period. The analysis includes a characterization of each repaired defect by topic and a ranking of developers by inferred expertise on each topic. We find clear evidence that defect resolution time is strongly influenced by a specific developer and his/her expertise in the defect's topic. To validate our approach, we conducted interviews with the product's manager who provided us with his own ranking of developer expertise for comparison. We argue that our automated developer expertise ranking can be beneficial in the planning of a software project and is applicable beyond software support in the other phases of the software lifecycle.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227095","Bug Fixing;Mining Software Repositories","Software;Maintenance engineering;Organizations;Planning;Predictive models;Programming","","11","1","11","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Bridging the divide between software developers and operators using logs","W. Shang","Oftware Analysis and Intelligence Laboratory (SAIL), Queen's University, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1583","1586","There is a growing gap between the software development and operation worlds. Software developers rarely divulge development knowledge about the software to operators, while operators rarely communicate field knowledge to developers. To improve the quality and reduce the operational cost of large-scale software systems, bridging the gap between these two worlds is essential. This thesis proposes the use of logs as mechanism to bridge the gap between these two worlds. Logs are messages generated from statements inserted by developers in the source code and are often used by operators for monitoring the field operation of a system. However, the rich knowledge in logs has not yet been fully used because of their non-structured nature, their large scale, and the use of the ad hoc log analysis techniques. Through case studies on large commercial and open source systems, we plan to demonstrate the value of logs as a tool to support developers and operators.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227031","","History;Software systems;Biological system modeling;Testing;Computer bugs;Bridges","","16","1","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Evidence Profiles for Validity Threats in Program Comprehension Experiments","M. M. Barón; M. Wyrich; D. Graziotin; S. Wagner","Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany; Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany; Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany; Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1907","1919","Searching for clues, gathering evidence, and reviewing case files are all techniques used by criminal investigators to draw sound conclusions and avoid wrongful convictions. Medicine, too, has a long tradition of evidence-based practice, in which administering a treatment without evidence of its efficacy is considered malpractice. Similarly, in software engineering (SE) research, we can develop sound methodologies and mitigate threats to validity by basing study design decisions on evidence. Echoing a recent call for the empirical evaluation of design decisions in program comprehension experiments, we conducted a 2-phases study consisting of systematic literature searches, snowballing, and thematic synthesis. We found out (1) which validity threat categories are most often discussed in primary studies of code comprehension, and we collected evidence to build (2) the evidence profiles for the three most commonly reported threats to validity. We discovered that few mentions of validity threats in primary studies (31 of 409) included a reference to supporting evidence. For the three most commonly mentioned threats, namely the influence of programming experience, program length, and the selected comprehension measures, almost all cited studies (17 of 18) did not meet our criteria for evidence. We show that for many threats to validity that are currently assumed to be influential across all studies, their actual impact may depend on the design and context of each specific study. Researchers should discuss threats to validity within the context of their particular study and support their discussions with evidence. The present paper can be one resource for evidence, and we call for more meta-studies of this type to be conducted, which will then inform design decisions in primary studies. Further, although we have applied our methodology in the context of program comprehension, our approach can also be used in other SE research areas to enable evidence-based experiment design decisions and meaningful discussions of threats to validity.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172547","program comprehension;threats to validity;empirical software engineering","Road transportation;Codes;Systematics;Sociology;Programming;Reproducibility of results;Task analysis","","3","","52","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Bots for Pull Requests: The Good, the Bad, and the Promising","M. Wessel; A. Abdellatif; I. Wiese; T. Conte; E. Shihab; M. A. Gerosa; I. Steinmacher","Delft University of Technology, Netherlands; Concordia University, Canada; Universidade Tecnologica Federal do Parana, Brazil; Federal University of Amazonas, Brazil; Concordia University, Canada; Northern Arizona University, USA; Universidade Tecnologica Federal do Parana, Brazil",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","274","286","Software bots automate tasks within Open Source Software (OSS) projects' pull requests and save reviewing time and effort (“the good”). However, their interactions can be disruptive and noisy and lead to information overload (“the bad”). To identify strategies to overcome such problems, we applied Design Fiction as a participatory method with 32 practitioners. We elicited 22 design strategies for a bot mediator or the pull request user interface (“the promising”). Participants envisioned a separate place in the pull request interface for bot interactions and a bot mediator that can summarize and customize other bots' actions to mitigate noise. We also collected participants' perceptions about a prototype implementing the envisioned strategies. Our design strategies can guide the development of future bots and social coding platforms.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3512765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793907","Software Bots;GitHub Bots;Human-bot Interaction;Open Source Software;Automation;Collaborative Development;Design Fiction","Bot (Internet);Prototypes;User interfaces;Encoding;Noise measurement;Task analysis;Open source software","","7","","69","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Mozi: Discovering DBMS Bugs via Configuration-Based Equivalent Transformation","J. Liang; Z. Wu; J. Fu; M. Wang; C. Sun; Y. Jiang","KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; Cheriton School of Computer Science, University of Waterloo, Waterloo, Canada; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1661","1672","Testing database management systems (DBMSs) is a complex task. Traditional approaches, such as metamorphic testing, need a precise comprehension of the SQL specification to create diverse inputs with equivalent semantics. The vagueness and intricacy of the SQL specification make it challenging to accurately model query semantics, thereby posing difficulties in testing the correctness and performance of DBMSs. To address this, we propose Mozi, a framework that finds DBMS bugs via configuration-based equivalent transformation. The key idea behind Mozi is to compare the results of equivalent DBMSs with different configurations, rather than between semantically equivalent queries. The framework involves analyzing the query plan, changing configurations to transform the DBMS to an equivalent one, and re-executing the query to compare the results using various test oracles. For example, detecting differences in query results indicates correctness bugs, while observing faster execution times on the optimization-closed DBMS suggests performance bugs. We demonstrate the effectiveness of Mozi by evaluating it on four widely used DBMSs, namely MySQL, MariaDB, Clickhouse, and PostgreSQL. In the continuous testing, Mozi found a total of 101 previously unknown bugs, including 49 correctness and 52 performance bugs in four DBMSs. Among them, 90 bugs are confirmed and 57 bugs have been fixed. In addition, Mozi can be extended to other DBMS fuzzers for testing various types of bugs. With Mozi, testing DBMSs becomes simpler and more effective, potentially saving time and effort that would otherwise be spent on precisely modeling SQL specifications for testing purposes.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639112","NSFC(grant numbers:62302256,62022046,92167101,62021002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548205","Software and its engineering → Software testing and debugging;DBMS Testing;Configuration;Test Oracle","Software testing;Computer bugs;Semantics;Transforms;Software;Database systems;Task analysis","","","","62","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Practitioners' Expectations on Automated Code Comment Generation","X. Hu; X. Xia; D. Lo; Z. Wan; Q. Chen; T. Zimmermann","School of Software Technology, Zhejiang University, Ningbo, China; Zhejiang University, Hangzhou, China; Singapore Management University, Singapore; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Microsoft Research, Seattle, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1693","1705","Good comments are invaluable assets to software projects, as they help developers understand and maintain projects. However, due to some poor commenting practices, comments are often missing or inconsistent with the source code. Software engineering practitioners often spend a significant amount of time and effort reading and understanding programs without or with poor comments. To counter this, researchers have proposed various techniques to au-tomatically generate code comments in recent years, which can not only save developers time writing comments but also help them better understand existing software projects. However, it is unclear whether these techniques can alleviate comment issues and whether practitioners appreciate this line of research. To fill this gap, we performed an empirical study by interviewing and surveying practitioners about their expectations of research in code comment generation. We then compared what practitioners need and the current state-of-the-art research by performing a literature review of papers on code comment generation techniques pub-lished in the premier publication venues from 2010 to 2020. From this comparison, we highlighted the directions where researchers need to put effort to develop comment generation techniques that matter to practitioners.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510152","National Science Foundation of China(grant numbers:62141222,U20A20173); National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793950","Code Comment Generation;Empirical Study;Practitioners' Expectations","Codes;Bibliographies;Software;Software engineering","","10","","53","","20 Jun 2022","","","IEEE","IEEE Conferences"
"On Debugging the Performance of Configurable Software Systems: Developer Needs and Tailored Tool Support","M. Velez; P. Jamshidi; N. Siegmund; S. Apel; C. Kästner",Carnegie Mellon University; University of South Carolina; Leipzig University; Saarland Informatics Campus - Saarland University; Carnegie Mellon University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1571","1583","Determining whether a configurable software system has a performance bug or it was misconfigured is often challenging. While there are numerous debugging techniques that can support developers in this task, there is limited empirical evidence of how useful the techniques are to address the actual needs that developers have when debugging the performance of configurable software systems; most techniques are often evaluated in terms of technical accuracy instead of their usability. In this paper, we take a human-centered approach to identify, design, implement, and evaluate a solution to support developers in the process of debugging the performance of configurable software systems. We first conduct an exploratory study with 19 developers to identify the information needs that developers have during this process. Subsequently, we design and implement a tailored tool, adapting techniques from prior work, to support those needs. Two user studies, with a total of 20 developers, validate and confirm that the information that we provide helps developers debug the performance of configurable software systems.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794001","","Adaptation models;Computer bugs;Debugging;Software systems;Usability;Task analysis;Software engineering","","6","","90","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Recommending Good First Issues in GitHub OSS Projects","W. Xiao; H. He; W. Xu; X. Tan; J. Dong; M. Zhou","Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China; School of Computer Science and Technology, Soochow University, Suzhou, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1830","1842","Attracting and retaining newcomers is vital for the sustainability of an open-source software project. However, it is difficult for new-comers to locate suitable development tasks, while existing “Good First Issues” (GFI) in GitHub are often insufficient and inappropriate. In this paper, we propose RECGFI, an effective practical approach for the recommendation of good first issues to newcomers, which can be used to relieve maintainers' burden and help newcomers onboard. RECGFI models an issue with features from multiple dimensions (content, background, and dynamics) and uses an XGBoost classifier to generate its probability of being a GFI. To evaluate RECGFI, we collect 53,510 resolved issues among 100 GitHub projects and care-fully restore their historical states to build ground truth datasets. Our evaluation shows that RECGFI can achieve up to 0.853 AUC in the ground truth dataset and outperforms alternative models. Our interpretable analysis of the trained model further reveals in-teresting observations about GFI characteristics. Finally, we report latest issues (without GFI-signaling labels but recommended as GFI by our approach) to project maintainers among which 16 are confirmed as real GFIs and five have been resolved by a newcomer.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510196","National Key R&D Program of China(grant numbers:2018YFB1004201); National Natural Science Foundation of China(grant numbers:61825201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793998","open-source software;onboarding;good first issues","Bot (Internet);Analytical models;Machine learning;Task analysis;Sustainable development;Open source software;Software development management","","9","","67","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"BOMs Away! Inside the Minds of Stakeholders: A Comprehensive Study of Bills of Materials for Software Systems","T. Stalnaker; N. Wintersgill; O. Chaparro; M. Di Penta; D. M. German; D. Poshyvanyk","William & Mary, Williamsburg, Virginia, USA; William & Mary, Williamsburg, Virginia, USA; William & Mary, Williamsburg, Virginia, USA; University of Sannio, Benevento, Italy; University of Victoria, BC, Canada; William & Mary, Williamsburg, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","517","529","Software Bills of Materials (SBOMs) have emerged as tools to fa-cilitate the management of software dependencies, vulnerabilities, licenses, and the supply chain. While significant effort has been devoted to increasing SBOM awareness and developing SBOM for-mats and tools, recent studies have shown that SBOMs are still an early technology not yet adequately adopted in practice. Expanding on previous research, this paper reports a comprehensive study that investigates the current challenges stakeholders encounter when creating and using SBOMs. The study surveyed 138 practitioners belonging to five stakeholder groups (practitioners familiar with SBOMs, members of critical open source projects, AI/ML, cyber-physical systems, and legal practitioners) using differentiated questionnaires, and interviewed 8 survey respondents to gather further insights about their experience. We identified 12 major challenges facing the creation and use of SBOMs, including those related to the SBOM content, deficiencies in SBOM tools, SBOM maintenance and verification, and domain-specific challenges. We propose and dis-cuss 4 actionable solutions to the identified challenges and present the major avenues for future research and development.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623347","NSF(grant numbers:CCF-2217733); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548562","Software Bill of Materials;Survey;Interviews;Software Supply Chain;Open Source Software","Surveys;Law;Bills of materials;Sociology;Software systems;Maintenance;Complexity theory","","3","","132","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Shedding Light on Software Engineering-Specific Metaphors and Idioms","M. M. Imran; P. Chatterjee; K. Damevski","Virginia Commonwealth University, Richmond, Virginia, USA; Drexel University, Philadelphia, Pennsylvania, USA; Virginia Commonwealth University, Richmond, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2555","2567","Use of figurative language, such as metaphors and idioms, is common in our daily-life communications, and it can also be found in Software Engineering (SE) channels, such as comments on GitHub. Automatically interpreting figurative language is a challenging task, even with modern Large Language Models (LLMs), as it often involves subtle nuances. This is particularly true in the SE domain, where figurative language is frequently used to convey technical concepts, often bearing developer affect (e.g., 'spaghetti code). Sur-prisingly, there is a lack of studies on how figurative language in SE communications impacts the performance of automatic tools that focus on understanding developer communications, e.g., bug prior-itization, incivility detection. Furthermore, it is an open question to what extent state-of-the-art LLMs interpret figurative expressions in domain-specific communication such as software engineering. To address this gap, we study the prevalence and impact of figurative language in SE communication channels. This study contributes to understanding the role of figurative language in SE, the potential of LLMs in interpreting them, and its impact on automated SE communication analysis. Our results demonstrate the effectiveness of fine-tuning LLMs with figurative language in SE and its potential impact on automated tasks that involve affect. We found that, among three state-of-the-art LLMs, the best improved fine-tuned versions have an average improvement of 6.66% on a GitHub emotion classification dataset, 7.07% on a GitHub incivility classification dataset, and 3.71% on a Bugzilla bug report prioritization dataset.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548029","Figurative Language;Large Language Models;Affect Analysis;Emotion Classification;Incivility Classification;Bug Prioritization;Repository Mining","Analytical models;Error analysis;Computer bugs;Communication channels;Software;Data mining;Task analysis","","","","106","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Egidio: A non-invasive approach for synthesizing organizational models","S. Astromskis; A. Janes; A. R. Mahdiraji","Free University of Bolzano-Bozen, Bolzano, Italy; Free University of Bolzano-Bozen, Bolzano, Italy; Free University of Bolzano-Bozen, Bolzano, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1465","1466","To understand and improve processes in organizations, six key questions need to be answered, namely, what, how, where, who, when, why. Organizations with established processes have IT system(s) that gather(s) information about some or all of the key questions. Software organizations usually have defined processes, but they usually lack information about how processes are actually executed. Moreover, there is no explicit information about process instances and activities. Existing process mining techniques face problems in coping with such environment. We propose a tool, Egidio, which uses non-invasively collected data and builds organizational models. In particular, we explain the tool within a software company, which is able to extract different aspects of development processes. The main contribution of Egidio is the ability to mine processes and organizational models from fine-grained data collected in a non-invasive manner, without interrupting the developers' work.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227062","Software Organizational models;Processes;Non-invasive Data Collection;Process mining","Software;Data mining;PROM;Computer architecture;Companies;Data models","","2","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software regression as change of input partitioning","M. Böhme","School of Computing, National University of Singapore, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1523","1526","It has been known for more than 20 years. If the subdomains are not homogeneous, partition testing strategies, such as branch or statement testing, do neither perform significantly better than random input generation nor do they inspire confidence when a test suite succeeds. Yet, measuring the adequacy of test suites in terms of code coverage is still considered a common practice. The main target of our research is to develop strategies for the automatic evolution of a test suite that does inspire confidence. When the program is changed, test cases shall be augmented that witness changed output for the same input (test suite augmentation). If two test cases witness the same partition, one is to be discarded (test suite reduction).","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227046","Partition Testing;Software Evolution;Reliability;Automated Test Generation","Testing;Software;Semantics;Partitioning algorithms;Software engineering;Educational institutions;Debugging","","1","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A bidirectional model-driven spreadsheet environment","J. Cunha; J. P. Fernandes; J. Mendes; J. Saraiva","HASLab, INESC TEC, Universidade do Minho, Portugal; Departamento de Engenharia Informática, Universidade do Porto, Portugal; HASLab, INESC TEC, Universidade do Minho, Portugal; HASLab, INESC TEC, Universidade do Minho, Portugal",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1443","1444","In this extended abstract we present a bidirectional model-driven framework to develop spreadsheets. By being model driven, our approach allows to evolve a spreadsheet model and automatically have the data co-evolved. The bidirectional component achieves precisely the inverse, that is, to evolve the data and automatically obtain a new model to which the data conforms.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227073","Model-driven Engineering;Bidirectional Transformations;Software Evolution;Model Evolution;Spreadsheets","Data models;Object oriented modeling;Visualization;Computational modeling;Abstracts;Software engineering;Software","","5","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Identifying Affected Libraries and Their Ecosystems for Open Source Software Vulnerabilities","S. Wu; W. Song; K. Huang; B. Chen; X. Peng","School of Computer Science Fudan University, Shanghai, China; School of Computer Science Fudan University, Shanghai, China; School of Computer Science Fudan University, Shanghai, China; School of Computer Science Fudan University, Shanghai, China; School of Computer Science Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1996","2007","Software composition analysis (SCA) tools have been widely adopted to identify vulnerable libraries used in software applications. Such SCA tools depend on a vulnerability database to know affected libraries of each vulnerability. However, it is labor-intensive and error prone for a security team to manually maintain the vulnerability database. While several approaches adopt extreme multi-label learning to predict affected libraries for vulnerabilities, they are practically ineffective due to the limited library labels and the unawareness of ecosystems. To address these problems, we first conduct an empirical study to assess the quality of two fields, i.e., affected libraries and their ecosystems, for four vulnerability databases. Our study reveals notable inconsistency and inaccuracy in these two fields. Then, we propose HOLMES to identify affected libraries and their ecosystems for vulnerabilities via a learning-to-rank technique. The key idea of HOLMES is to gather various evidences about affected libraries and their ecosystems from multiple sources, and learn to rank a pool of libraries based on their relevance to evidences. Our extensive experiments have shown the effectiveness, efficiency and usefulness of HOLMES.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639582","National Natural Science Foundation of China(grant numbers:62332005,62372114); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548627","open source software;vulnerability quality;affected libraries","Databases;Ecosystems;Libraries;Security;Open source software;Software engineering","","","","62","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Unraveling the Drivers of Sense of Belonging in Software Delivery Teams: Insights from a Large-Scale Survey","B. Trinkenreich; M. Gerosa; I. Steinmacher","Oregon State University Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2345","2356","Feeling part of a group is a basic human need that significantly influences an individual's behavior, long-term engagement, and job satisfaction. A strong sense of belonging holds particular importance within software delivery teams, which grapple with challenges related to well-being and employee retention. However, the specific factors closely associated with the sense of belonging in the context of software delivery teams remain largely unknown. Without a clear understanding of these factors, organizations' efforts to promote a sense of belonging and diversity and inclusion more broadly may prove ineffective. Based on existing literature, we identified key factors potentially relevant to the sense of belonging in software delivery teams, such as work appreciation and psychological safety, and investigated the interrelation among these factors. We surveyed members of software delivery teams (n=10,781) of a major software delivery organization and used Partial Least Squares-Structural Equation Modeling (PLS-SEM) to evaluate a theoretical model to understand the factors that might contribute to a sense of belonging to the team. We also conducted a multi-group analysis to evaluate how the associations change based on individuals' leadership involvement and an importance-performance map analysis to find the most critical indicators of belongingness. Our findings indicate a positive association between psychological safety and work appreciation and belonging to the team. Women feel less belonging than men, especially those not in leadership positions. Authoritativeness is negatively associated with belonging, and tenure is positively associated with belonging regardless of the role. Through this research, we seek to provide insights into the sense of belonging to the team and foster a more inclusive and cohesive work environment.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639119","National Science Foundation(grant numbers:2236198,2247929,2303042,2303612); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549640","diversity and inclusion;software engineering;sense of belonging;psychological safety;work appreciation","Surveys;Productivity;Leadership;Psychology;Software;Mathematical models;Safety","","","","77","","14 Jun 2024","","","IEEE","IEEE Conferences"
"ModX: Binary Level Partially Imported Third-Party Library Detection via Program Modularization and Semantic Matching","C. Yang; Z. Xu; H. Chen; Y. Liu; X. Gong; B. Liu","School of Cyber Security, UCAS; School of Computer Science and Engineering, NTU; Huawei Technologies Co., Ltd.; School of Computer Science and Engineering, NTU; School of Cyber Security, UCAS; School of Cyber Security, UCAS",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1393","1405","With the rapid growth of software, using third-party libraries (TPLs) has become increasingly popular. The prosperity of the library us-age has provided the software engineers with a handful of methods to facilitate and boost the program development. Unfortunately, it also poses great challenges as it becomes much more difficult to manage the large volume of libraries. Researches and studies have been proposed to detect and understand the TPLs in the soft-ware. However, most existing approaches rely on syntactic features, which are not robust when these features are changed or deliber-ately hidden by the adversarial parties. Moreover, these approaches typically model each of the imported libraries as a whole, there-fore, cannot be applied to scenarios where the host software only partially uses the library code segments. To detect both fully and partially imported TPLs at the semantic level, we propose Modx, a framework that leverages novel program modularization techniques to decompose the program into fine-grained functionality-based modules. By extracting both syntactic and semantic features, it measures the distance between modules to detect similar library module reuse in the program. Experimental results show that Modx outperforms other modularization tools by distinguishing more coherent program modules with 353% higher module quality scores and beats other TPL detection tools with on average 17% better in precision and 8% better in recall.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510627","Natural Science Foundation of China(grant numbers:61802404,61802394); National Research Foundation, Singapore(grant numbers:AISG2-RP-2020-019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793894","Third-Party Library Detection;Program Modularization;Semantic Matcing","Codes;Semantics;Software algorithms;Reverse engineering;Syntactics;Feature extraction;Libraries","","9","","68","","20 Jun 2022","","","IEEE","IEEE Conferences"
"ChatGPT Incorrectness Detection in Software Reviews","M. H. Tanzil; J. Y. Khan; G. Uddin","University of Calgary, Calgary, Alberta, Canada; University of Calgary, Calgary, Alberta, Canada; York University, Toronto, Ontario, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2219","2230","We conducted a survey of 135 software engineering (SE) practitioners to understand how they use Generative Al-based chatbots like ChatGPT for SE tasks. We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses. We developed a suite of techniques and a tool called CID (ChatGPT Incorrectness Detector) to automatically test and detect the incorrectness in ChatGPT re-sponses. CID is based on the iterative prompting to ChatGPT by asking it contextually similar but textually divergent questions (using an approach that utilizes metamorphic relationships in texts). The underlying principle in CID is that for a given question, a response that is different from other responses (across multiple incarnations of the question) is likely an incorrect response. In a benchmark study of library selection, we show that CID can detect incorrect responses from ChatGPT with an Fl-score of 0.74 - 0.75.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549751","Large language model;ChatGPT;Hallucination;Testing","Surveys;Software reviews;Software libraries;Detectors;Benchmark testing;Chatbots;Iterative methods","","","","78","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Improving failure-inducing changes identification using coverage analysis","K. Yu","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1604","1606","Delta debugging has been proposed for failure-inducing changes identification. Despite promising results, there are two practical factors that thwart the application of delta debugging: large number of tests and misleading false positives. To address the issues, we present a combination of coverage analysis and delta debugging that automatically isolates failure-inducing changes. Evaluations on twelve real regressions in GNU software demonstrate both the speed gain and effectiveness improvements.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227229","regression faults;delta debugging;coverage analysis;software evolution;automated debugging","Debugging;Software;Software engineering;Computer bugs;Programming;Educational institutions;Fault diagnosis","","","","16","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Source Code Recommender Systems: The Practitioners' Perspective","M. Ciniselli; L. Pascarella; E. Aghajani; S. Scalabrino; R. Oliveto; G. Bavota","SEART @ Software Institute, Universitá della Svizzera italiana (USI), Switzerland; SEART @ Software Institute, Universitá della Svizzera italiana (USI), Switzerland; SEART @ Software Institute, Universitá della Svizzera italiana (USI), Switzerland; STAKE Lab @ University of Molise, Italy; STAKE Lab @ University of Molise, Italy; SEART @ Software Institute, Universitá della Svizzera italiana (USI), Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2161","2172","The automatic generation of source code is one of the long-lasting dreams in software engineering research. Several techniques have been proposed to speed up the writing of new code. For example, code completion techniques can recommend to developers the next few tokens they are likely to type, while retrieval-based approaches can suggest code snippets relevant for the task at hand. Also, deep learning has been used to automatically generate code statements starting from a natural language description. While research in this field is very active, there is no study investigating what the users of code recommender systems (i.e., software practitioners) actually need from these tools. We present a study involving 80 software developers to investigate the characteristics of code recommender systems they consider important. The output of our study is a taxonomy of 70 “requirements” that should be considered when designing code recommender systems. For example, developers would like the recommended code to use the same coding style of the code under development. Also, code recommenders being “aware” of the developers' knowledge (e.g., what are the framework/libraries they already used in the past) and able to customize the recommendations based on this knowledge would be appreciated by practitioners. The taxonomy output of our study points to a wide set of future research directions for code recommenders.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172343","Code Recommender Systems;Empirical Study;Practitioners' Survey","Surveys;Deep learning;Codes;Source coding;Taxonomy;Natural languages;Software","","6","","62","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Is It Enough to Recommend Tasks to Newcomers? Understanding Mentoring on Good First Issues","X. Tan; Y. Chen; H. Wu; M. Zhou; L. Zhang","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; ShenYuan Honors College, Beihang University, Beijing, China; ShenYuan Honors College, Beihang University, Beijing, China; Key Laboratory of High Confidence Software Technologies Ministry of Education, School of Computer Science, Peking University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","653","664","Newcomers are critical for the success and continuity of open source software (OSS) projects. To attract newcomers and facilitate their onboarding, many OSS projects recommend tasks for newcomers, such as good first issues (GFIs). Previous studies have preliminarily investigated the effects of GFIs and techniques to identify suitable GFIs. However, it is still unclear whether just recommending tasks is enough and how significant mentoring is for newcomers. To better understand mentoring in OSS communities, we analyze the resolution process of 48,402 GFIs from 964 repositories through a mix-method approach. We investigate the extent, the mentorship structures, the discussed topics, and the relevance of expert involvement. We find that ~70% of GFIs have expert participation, with each GFI usually having one expert who makes two comments. Half of GFIs will receive their first expert comment within 8.5 hours after a newcomer comment. Through analysis of the collaboration networks of newcomers and experts, we observe that community mentorship presents four types of structure: centralized mentoring, decentralized mentoring, collaborative mentoring, and distributed mentoring. As for discussed topics, we identify 14 newcomer challenges and 18 expert mentoring content. By fitting the generalized linear models, we find that expert involvement positively correlates with newcomers' successful contributions but negatively correlates with newcomers' retention. Our study manifests the status and significance of mentoring in the OSS projects, which provides rich practical implications for optimizing the mentoring process and helping newcomers contribute smoothly and suecessfully,","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00064","National Natural Science Foundation of China(grant numbers:62202022,62141209,61825201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172703","newcomer;mentoring;open source;good first issue","Fitting;Collaboration;Mentoring;Task analysis;Open source software;Software engineering","","2","","53","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"On the Self-Governance and Episodic Changes in Apache Incubator Projects: An Empirical Study","L. Yin; X. Zhang; V. Filkov","University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","678","689","Sustainable Open Source Software (OSS) projects are characterized by the ability to attract new project members and maintain an energetic project community. Building sustainable OSS projects from a nascent state requires effective project governance and socio-technical structure to be interleaved, in a complex and dynamic process. Although individual disciplines have studied each separately, little is known about how governance and software development work together in practice toward sustainability. Prior work has shown that many OSS projects experience large, episodic changes over short periods of time, which can propel them or drag them down. However, sustainable projects typically manage to come out unscathed from such changes, while others do not. The natural questions arise: Can we identify the back-and-forth between governance and socio-technical structure that lead to sustainability following episodic events? And, how about those that do not lead to sustainability? From a data set of social, technical, and policy digital traces from 262 sustainability-labeled ASF incubator projects, here we employ a large-scale empirical study to characterize episodic changes in socio-technical aspects measured by Change Intervals (CI), governance rules and regulations in a form of Institutional Statements (IS), and the temporal relationships between them. We find that sustainable projects during episodic changes can adapt themselves to institutional statements more efficiently, and that institutional discussions can lead to episodic changes intervals in socio-technical aspects of the projects, and vice versa. In practice, these results can provide timely guidance beyond socio-technical considerations, adding rules and regulations in the mix, toward a unified analytical framework for OSS project sustainability.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172708","Open Source Software;Sustainability;Governance;Apache Software Foundation","Analytical models;Buildings;Collaboration;Propulsion;Regulation;Sustainable development;Open source software","","1","","54","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"An integrated bug processing framework","X. Zhang; M. Lin; K. Yu","School of Computer Science and Engineering, State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; School of Computer Science and Engineering, State Key Laboratory of Software Development Environment, Beihang University, Beijing, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1469","1470","Software debugging starts with bug reports. Test engineers confirm bugs and determine the corresponding developers to fix them. However, the analysis of bug reports is time-consuming and manual inspection is difficult and tedious. To improve the efficiency of the whole process, we propose a bug processing framework that integrates bug report analysis and fault localization. An instance of the framework is implemented for regression faults. Preliminary results on a large open source application demonstrate both efficiency and effectiveness.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227060","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227060","","Debugging;Data mining;Educational institutions;Software;Computer bugs;Isolators;Google","","1","","5","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software analytics in practice: Mini tutorial","D. Zhang; T. Xie","Microsoft Research Asia, Beijing, China; North Carolina State University, Raleigh, NC, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","997","997","Summary form only given. A huge wealth of various data exists in the software development process, and hidden in the data is information about the quality of software and services as well as the dynamics of software development. With various analytic and computing technologies, software analytics is to enable software practitioners to performance data exploration and analysis in order to obtain insightful and actionable information for data-driven tasks around software and services [1].","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227121","","","","10","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Language modularity with the MPS language workbench","M. Voelter; V. Pech","Itemis / voelter ingenieurbuero fuer softwaretechnologie, Germany; JetBrains, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1449","1450","JetBrains MPS is a comprehensive environment for language engineering. New languages can be defined as standalone languages or as modular extensions of existing languages. Since MPS is a projectional editor, syntactic forms other than text are possible, including tables or mathematical symbols. This demo will show MPS based on mbeddr C, a novel approach for embedded software development that makes use of incremental language extension on the basis of C.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227070","language engineering;language extension;language composition","Syntactics;Embedded software;Software engineering;Software systems;Concrete;Grammar;Licenses","","33","","2","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"On the Effectiveness of Function-Level Vulnerability Detectors for Inter-Procedural Vulnerabilities","Z. Li; N. Wang; D. Zou; Y. Li; R. Zhang; S. Xu; C. Zhang; H. Jin","National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab; Department of Computer Science, University of Colorado Colorado Springs, Colorado Springs, Colorado, USA; Institute for Network Sciences and Cyberspace, Tsinghua University, Beijing, China; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, Cluster and Grid Computing Lab",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1935","1946","Software vulnerabilities are a major cyber threat and it is important to detect them. One important approach to detecting vulnerabilities is to use deep learning while treating a program function as a whole, known as function-level vulnerability detectors. However, the limitation of this approach is not understood. In this paper, we investigate its limitation in detecting one class of vulnerabilities known as inter-procedural vulnerabilities, where the to-be-patched statements and the vulnerability-triggering statements belong to different functions. For this purpose, we create the first Inter -Procedural Vulnerability Dataset (InterPVD) based on C/C++ open-source software, and we propose a tool dubbed VulTrigger for identifying vulnerability-triggering statements across functions. Experimental results show that VulTrigger can effectively identify vulnerability-triggering statements and inter-procedural vulnerabilities. Our findings include: (i) inter-procedural vulnerabilities are prevalent with an average of 2.8 inter-procedural layers; and (ii) function-level vulner-ability detectors are much less effective in detecting to-be-patched functions of inter-procedural vulnerabilities than detecting their counterparts of intra-procedural vulnerabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639218","National Natural Science Foundation of China(grant numbers:62272187); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548679","Vulnerability detection;inter-procedural vulnerability;vulnerability type;patch","Deep learning;Detectors;Open source software;Software engineering","","1","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Conflict-aware Inference of Python Compatible Runtime Environments with Domain Knowledge Graph","W. Cheng; X. Zhu; W. Hu","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","451","461","Code sharing and reuse is a widespread use practice in software engineering. Although a vast amount of open-source Python code is accessible on many online platforms, programmers often find it difficult to restore a successful runtime environment. Previous studies validated automatic inference of Python dependencies using pre-built knowledge bases. However, these studies do not cover sufficient knowledge to accurately match the Python code and also ignore the potential conflicts between their inferred dependencies, thus resulting in a low success rate of inference. In this paper, we propose PyCRE, a new approach to automatically inferring Python compatible runtime environments with domain knowledge graph (KG). Specifically, we design a domain-specific ontology for Python third-party packages and construct KGs for over 10,000 popular packages in Python 2 and Python 3. PyCRE discovers candidate libraries by measuring the matching degree between the known libraries and the third-party resources used in target code. For the NP-complete problem of dependency solving, we propose a heuristic graph traversal algorithm to efficiently guarantee the compatibility between packages. PyCRE achieves superior performance on a real-world dataset and efficiently resolves nearly half more import errors than previous methods.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510078","National Natural Science Foundation of China(grant numbers:61872172); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794028","Python;Runtime environment inference;Knowledge graph;Conflict resolution;Dependency solving;Configuration management","Knowledge engineering;Runtime environment;Codes;Software algorithms;Ontologies;Libraries;NP-complete problem","","7","","25","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Mining input sanitization patterns for predicting SQL injection and cross site scripting vulnerabilities","L. K. Shar; H. B. K. Tan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1293","1296","Static code attributes such as lines of code and cyclomatic complexity have been shown to be useful indicators of defects in software modules. As web applications adopt input sanitization routines to prevent web security risks, static code attributes that represent the characteristics of these routines may be useful for predicting web application vulnerabilities. In this paper, we classify various input sanitization methods into different types and propose a set of static code attributes that represent these types. Then we use data mining methods to predict SQL injection and cross site scripting vulnerabilities in web applications. Preliminary experiments show that our proposed attributes are important indicators of such vulnerabilities.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227096","defect prediction;data mining;static code attributes;web security vulnerabilities;input sanitization","Security;Predictive models;Data mining;Software;Complexity theory;HTML;Data models","","31","","14","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Enhancing architecture-implementation conformance with change management and support for behavioral mapping","Y. Zheng; R. N. Taylor","Institute for Software Research, University of California, Irvine, Irvine, CA, USA; Institute for Software Research, University of California, Irvine, Irvine, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","628","638","It is essential for software architecture to be consistent with implementation during software development. Existing architecture-implementation mapping approaches are not sufficient due to a variety of reasons, including lack of support for change management and mapping of behavioral architecture specification. A new approach called 1.x-way architecture-implementation mapping is presented in this paper to address these issues. Its contribution includes deep separation of generated and non-generated code, an architecture change model, architecture-based code regeneration, and architecture change notification. The approach is implemented in ArchStudio 4, an Eclipse-based architecture development environment. To evaluate its utility, we refactored the code of ArchStudio, and replayed changes that had been made to ArchStudio in two research projects by redoing them with the developed tool.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227154","software architecture;architecture change management;architecture-implementation mapping","Computer architecture;Unified modeling language;Software architecture;Software;Programming;Registers;Manuals","","21","","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Overcoming the challenges in cost estimation for distributed software projects","N. Ramasubbu; R. K. Balan","School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","91","101","We describe how we studied, in-situ, the operational processes of three large high process maturity distributed software development companies and discovered three common problems they faced with respect to early stage project cost estimation. We found that project managers faced significant challenges to accurately estimate project costs because the standard metrics-based estimation tools they used (a) did not effectively incorporate diverse distributed project configurations and characteristics, (b) required comprehensive data that was not fully available for all starting projects, and (c) required significant domain experience to derive accurate estimates. To address these challenges, we collaborated with practitioners at the three firms and developed a new learning-oriented and semi-automated early-stage cost estimation solution that was specifically designed for globally distributed software projects. The key idea of our solution was to augment the existing metrics-driven estimation methods with a case repository that stratified past incidents related to project effort estimation issues from the historical project databases at the firms into several generalizable categories. This repository allowed project managers to quickly and effectively “benchmark” their new projects to all past projects across the firms, and thereby learn from them. We deployed our solution at each of our three research sites for real-world field-testing over a period of six months. Project managers of 219 new large globally distributed projects used both our method to estimate the cost of their projects as well as the established metrics-based estimation approaches they were used to. Our approach achieved significantly reduced estimation errors (of up to 60%). This resulted in more than 20% net cost savings, on average, per project - a massive total cost savings across all projects at the three firms!","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227203","Globally distributed software development;software engineering economics;cost estimation;case-based reasoning;analogies;project management;learning","Estimation;Software;Measurement;Benchmark testing;Companies;Cognition;Databases","","26","","31","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A Qualitative Study on the Implementation Design Decisions of Developers","J. T. Liang; M. Arab; M. Ko; A. J. Ko; T. D. LaToza","School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Information School, University of Washington, Seattle, WA, USA; Department of Computer Science, George Mason University, Fairfax, VA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","435","447","Decision-making is a key software engineering skill. Developers constantly make choices throughout the software development process, from requirements to implementation. While prior work has studied developer decision-making, the choices made while choosing what solution to write in code remain understudied. In this mixed-methods study, we examine the phenomenon where developers select one specific way to implement a behavior in code, given many potential alternatives. We call these decisions implementation design decisions. Our mixed-methods study includes 46 survey responses and 14 semi-structured interviews with professional developers about their decision types, considerations, processes, and expertise for implementation design decisions. We find that implementation design decisions, rather than being a natural outcome from higher levels of design, require constant monitoring of higher level design choices, such as requirements and architecture. We also show that developers have a consistent general structure to their implementation decision-making process, but no single process is exactly the same. We discuss the implications of our findings on research, education, and practice, including insights on teaching developers how to make implementation design decisions.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00047","National Science Foundation(grant numbers:1539179,1703734,1703304,1836813,1845508,2031265,2100296,2122950,2137834,2137312); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172559","implementation design decisions;software design","Surveys;Codes;Decision making;Education;Computer architecture;Software;Interviews","","3","","65","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Unveiling the Life Cycle of User Feedback: Best Practices from Software Practitioners","Z. S. Li; N. N. Arony; K. Devathasan; M. Sihag; N. Ernst; D. Damian","University of Victoria, Victoria, Canada; University of Victoria, Victoria, Canada; University of Victoria, Victoria, Canada; University of Victoria, Victoria, Canada; University of Victoria, Victoria, Canada; University of Victoria, Victoria, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","641","653","User feedback has grown in importance for organizations to improve software products. Prior studies focused primarily on feed-back collection and reported a high-level overview of the processes, often overlooking how practitioners reason about, and act upon this feedback through a structured set of activities. In this work, we conducted an exploratory interview study with 40 practitioners from 32 organizations of various sizes and in several domains such as e-commerce, analytics, and gaming. Our findings indicate that organizations leverage many different user feedback sources. Social media emerged as a key category of feedback that is increasingly critical for many organizations. We found that organizations actively engage in a number of non-trivial activities to curate and act on user feedback, depending on its source. We synthesize these activities into a life cycle of managing user feedback. We also report on the best practices for managing user feedback that we distilled from responses of practitioners who felt that their organization effectively understood and addressed their users' feedback. We present actionable empirical results that organizations can leverage to increase their understanding of user perception and behavior for better products thus reducing user attrition.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548263","user feedback;requirements engineering;social media analysis;product management","Social networking (online);Organizations;Media;Software;Electronic commerce;Interviews;Best practices","","3","","60","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Sound empirical evidence in software testing","G. Fraser; A. Arcuri","Saarland University, Saarbrücken, Germany; Certus Software V & V Center, Simula Research Laboratory, Lysaker, Norway",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","178","188","Several promising techniques have been proposed to automate different tasks in software testing, such as test data generation for object-oriented software. However, reported studies in the literature only show the feasibility of the proposed techniques, because the choice of the employed artifacts in the case studies (e.g., software applications) is usually done in a non-systematic way. The chosen case study might be biased, and so it might not be a valid representative of the addressed type of software (e.g., internet applications and embedded systems). The common trend seems to be to accept this fact and get over it by simply discussing it in a threats to validity section. In this paper, we evaluate search-based software testing (in particular the EvoSuite tool) when applied to test data generation for open source projects. To achieve sound empirical results, we randomly selected 100 Java projects from SourceForge, which is the most popular open source repository (more than 300,000 projects with more than two million registered users). The resulting case study not only is very large (8,784 public classes for a total of 291,639 bytecode level branches), but more importantly it is statistically sound and representative for open source projects. Results show that while high coverage on commonly used types of classes is achievable, in practice environmental dependencies prohibit such high coverage, which clearly points out essential future research directions. To support this future research, our SF100 case study can serve as a much needed corpus of classes for test generation.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227195","test case generation;unit testing;search-based software engineering;class corpus;security exception;environment","Software;Java;Containers;Software testing;Security;Context","","78","","54","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Blaze","J. -P. Krämer; J. Kurz; T. Karrer; J. Borchers","RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany; RWTH Aachen University, Aachen, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1457","1458","Understanding source code is crucial for successful software maintenance. To understand source code, navigation in the call graph has been shown to be particularly important. Programmers often employ a two-phased strategy for effective call graph exploration. We present Blaze, a source code exploration tool designed to explicitly support this strategy. In a study, we show that call graph exploration tools significantly increase success rates in typical software maintenance tasks and that using Blaze significantly reduces task completion times compared to using the Call Hierarchy or Xcode.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227066","Tools and environments;Software visualization;Program comprehension","Navigation;Software maintenance;Visualization;Maintenance engineering;Educational institutions;Computer bugs","","","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"GitHub Sponsors: Exploring a New Way to Contribute to Open Source","N. Shimada; T. Xiao; H. Hata; C. Treude; K. Matsumoto","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Shinshu University, Japan; University of Melbourne, Australia; Nara Institute of Science and Technology, Japan",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1058","1069","GitHub Sponsors, launched in 2019, enables donations to individual open source software (OSS) developers. Financial support for OSS maintainers and developers is a major issue in terms of sustaining OSS projects, and the ability to donate to individuals is expected to support the sustainability of developers, projects, and community. In this work, we conducted a mixed-methods study of GitHub Sponsors, including quantitative and qualitative analyses, to understand the characteristics of developers who are likely to receive donations and what developers think about donations to individuals. We found that: (1) sponsored developers are more active than non-sponsored developers, (2) the possibility to receive donations is related to whether there is someone in their community who is donating, and (3) developers are sponsoring as a new way to contribute to OSS. Our findings are the first step towards data-informed guidance for using GitHub Sponsors, opening up avenues for future work on this new way of financially sustaining the OSS community.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794031","GitHub Sponsors;Open Source;Sponsorship","Focusing;Sustainable development;Open source software;Software development management;Software engineering","","2","","33","","20 Jun 2022","","","IEEE","IEEE Conferences"
"What Makes a Good Commit Message?","Y. Tian; Y. Zhang; K. -J. Stol; L. Jiang; H. Liu","Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; University College Cork and Lero, School of Computer Science and IT, Cork, Ireland; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2389","2401","A key issue in collaborative software development is communication among developers. One modality of communication is a commit message, in which developers describe the changes they make in a repository. As such, commit messages serve as an “audit trail” by which developers can understand how the source code of a project has changed-and why. Hence, the quality of commit messages affects the effectiveness of communication among developers. Commit messages are often of poor quality as developers lack time and motivation to craft a good message. Several automatic approaches have been proposed to generate commit messages. However, these are based on uncurated datasets including considerable proportions of poorly phrased commit messages. In this multi-method study, we first define what constitutes a “good” commit message, and then establish what proportion of commit messages lack information using a sample of almost 1,600 messages from five highly active open source projects. We find that an average of circa 44% of messages could be improved, suggesting the use of uncurated datasets may be a major threat when commit message generators are trained with such data. We also observe that prior work has not considered semantics of commit messages, and there is surprisingly little guidance available for writing good commit messages. To that end, we develop a taxonomy based on recurring patterns in commit messages' expressions. Finally, we investigate whether “good” commit messages can be automatically identified; such automation could prompt developers to write better commit messages.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510205","National Natural Science Foundation of China(grant numbers:62141209,61690205,62172037,61772071); Science Foundation Ireland(grant numbers:15/SIRG/3293,13/RC/2094-P2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794134","Commit-based software development;open collaboration;commit message quality","Codes;Collaborative software;Taxonomy;Semantics;Writing;Maintenance engineering;Software","","18","","83","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automated Testing of Software that Uses Machine Learning APIs","C. Wan; S. Liu; S. Xie; Y. Liu; H. Hoffmann; M. Maire; S. Lu",University of Chicago; University of Chicago; Whitney Young High School; University of Chicago; University of Chicago; University of Chicago; University of Chicago,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","212","224","An increasing number of software applications incorporate machine learning (ML) solutions for cognitive tasks that statistically mimic human behaviors. To test such software, tremendous human effort is needed to design image/text/audio inputs that are relevant to the software, and to judge whether the software is processing these inputs as most human beings do. Even when misbehavior is exposed, it is often unclear whether the culprit is inside the cognitive ML API or the code using the API. This paper presents Keeper, a new testing tool for software that uses cognitive ML APIs. Keeper designs a pseudo-inverse function for each ML API that reverses the corresponding cognitive task in an empirical way (e.g., an image search engine pseudo-reverses the image-classification API), and incorporates these pseudo-inverse functions into a symbolic execution engine to automatically gener-ate relevant image/text/audio inputs and judge output correctness. Once misbehavior is exposed, Keeper attempts to change how ML APIs are used in software to alleviate the misbehavior. Our evalu-ation on a variety of open-source applications shows that Keeper greatly improves the branch coverage, while identifying many pre-viously unknown bugs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510068","NSF(grant numbers:CNSI764039,CNS1956180,CCF1837120,CCF2119184,CNS1952050,CCFI823032); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793999","software testing;machine learning;machine learning API","Codes;Computer bugs;Web pages;Machine learning;Search engines;Software;Test pattern generators","","6","","108","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Improving information retrieval-based concept location using contextual relationships","T. Dilshener","Center for Research in Computing, Department of Computing, Open University, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1499","1502","For software engineers to find all the relevant program elements implementing a business concept, existing techniques based on information retrieval (IR) fall short in providing adequate solutions. Such techniques usually only consider the conceptual relations based on lexical similarities during concept mapping. However, it is also fundamental to consider the contextual relationships existing within an application's business domain to aid in concept location. As an example, this paper proposes to use domain specific ontological relations during concept mapping and location activities when implementing business requirements.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227052","concept mapping;domain specific ontologies;concept location;contextual relations","Ontologies;Business;Semantics;Context;Correlation;Information retrieval;Software","","","","11","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Cneps: A Precise Approach for Examining Dependencies Among Third-Party C/C++ Open-Source Components","Y. Na; S. Woo; J. Lee; H. Lee","Korea University, Seoul, Republic of Korea; Korea University, Seoul, Republic of Korea; Korea University, Seoul, Republic of Korea; Korea University, Seoul, Republic of Korea",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2918","2929","The rise in open-source software (OSS) reuse has led to intricate de-pendencies among third-party components, increasing the demand for precise dependency analysis. However, owing to the presence of reused files that are difficult to identify the originating components (i.e., indistinguishable files) and duplicated components, precisely identifying component dependencies is becoming challenging. In this paper, we present Cneps, a precise approach for examining dependencies in reused C/C++ OSS components. The key idea of Cneps is to use a novel granularity called a module, which represents a minimum unit (i.e., set of source files) that can be reused as a library from another project. By examining dependencies based on modules instead of analyzing single reused files, Cneps can precisely identify dependencies in the target projects, even in the presence of indistinguishable files. To differentiate duplicated components, Cneps examines the cloned paths and originating projects of each component, enabling precise identification of dependencies associated with them. Experimental results on top 100 C/C++ soft-ware show that Cneps outperforms a state-of-the-art approach by identifying twice as many dependencies. Cneps could identify 435 dependencies with 89.9% precision and 93.2% recall in less than 10 seconds per application on average, whereas the existing approach hardly achieved 63.5% precision and 42.5% recall.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549710","Open Source Software Reuse;Supply Chain Security;Third-party Library Dependency;Software Bill of Materials (SBOM)","Source coding;Ecosystems;Bills of materials;Libraries;Open source software;Software engineering","","","","48","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Engineering and verifying requirements for programmable self-assembling nanomachines","R. Lutz; J. Lutz; J. Lathrop; T. Klinge; E. Henderson; D. Mathur; D. A. Sheasha","Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Genetics, Development, and Cell Biology, Iowa State University, Ames, IA, USA; Department of Genetics, Development, and Cell Biology, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1361","1364","We propose an extension of van Lamsweerde's goal-oriented requirements engineering to the domain of programmable DNA nanotechnology. This is a domain in which individual devices (agents) are at most a few dozen nanometers in diameter. These devices are programmed to assemble themselves from molecular components and perform their assigned tasks. The devices carry out their tasks in the probabilistic world of chemical kinetics, so they are individually error-prone. However, the number of devices deployed is roughly on the order of a nanomole (a 6 followed by fourteen 0s), and some goals are achieved when enough of these agents achieve their assigned subgoals. We show that it is useful in this setting to augment the AND/OR goal diagrams to allow goal refinements that are mediated by threshold functions, rather than ANDs or ORs. We illustrate this method by engineering requirements for a system of molecular detectors (DNA origami “pliers” that capture target molecules) invented by Kuzuya, Sakai, Yamazaki, Xu, and Komiyama (2011). We model this system in the Prism probabilistic symbolic model checker, and we use Prism to verify that requirements are satisfied, provided that the ratio of target molecules to detectors is neither too high nor too low. This gives prima facie evidence that software engineering methods can be used to make DNA nanotechnology more productive, predictable and safe.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227079","Requirements engineering;validation and verification;safety;DNA nanotechnology;molecular programming","DNA;Self-assembly;Nanobioscience;Shape;Probabilistic logic;Nanoscale devices","","4","","15","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Locating features in dynamically configured avionics software","M. Ouellet; E. Merlo; N. Sozen; M. Gagnon","Computer and Software Engineering Department, École Polytechnique de Montréal, Montreal, Canada; Computer and Software Engineering Department, École Polytechnique de Montréal, Montreal, Canada; CMC Electronics, Inc., Saint-Laurent, Canada; CMC Electronics, Inc., Saint-Laurent, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1453","1454","Locating features in software is an important activity for program comprehension and to support software reengineering. We present a novel automated approach to locate features in source code based on static analysis and model checking. The technique is aimed at dynamically configured software, which is software in which the activation of specific features is controlled by configuration variables. The approach is evaluated on an industrial avionics system.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227068","Feature;Feature Location;Feature Mapping;Reengineering;Program Comprehension","Software;Aerospace electronics;Analytical models;Security;Aircraft;Information retrieval;Feature extraction","","1","","8","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"An Exploratory Study of Deep learning Supply Chain","X. Tan; K. Gao; M. Zhou; L. Zhang","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering Beihang University, Beijing, China; School of Software & Microelectronics, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, School of Computer Science, Peking University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering Beihang University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","86","98","Deep learning becomes the driving force behind many contemporary technologies and has been successfully applied in many fields. Through software dependencies, a multi-layer supply chain (SC) with a deep learning framework as the core and substantial down-stream projects as the periphery has gradually formed and is constantly developing. However, basic knowledge about the structure and characteristics of the SC is lacking, which hinders effective support for its sustainable development. Previous studies on software SC usually focus on the packages in different registries without paying attention to the SCs derived from a single project. We present an empirical study on two deep learning SCs: TensorFlow and PyTorch SCs. By constructing and analyzing their SCs, we aim to understand their structure, application domains, and evolutionary factors. We find that both SCs exhibit a short and sparse hierarchy structure. Overall, the relative growth of new projects increases month by month. Projects have a tendency to attract downstream projects shortly after the release of their packages, later the growth becomes faster and tends to stabilize. We propose three criteria to identify vulnerabilities and identify 51 types of packages and 26 types of projects involved in the two SCs. A comparison reveals their similarities and differences, e.g., TensorFlow SC provides a wealth of packages in experiment result analysis, while PyTorch SC contains more specific framework packages. By fitting the GAM model, we find that the number of dependent packages is significantly negatively associated with the number of downstream projects, but the relationship with the number of authors is nonlinear. Our findings can help further open the “black box” of deep learning SCs and provide insights for their healthy and sustainable development.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510199","National Natural Science Foundation of China(grant numbers:62141209,61825201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793893","software supply chain;deep learning;open source;software structure;software evolution","Deep learning;Industries;Supply chains;Force;Fitting;Ecosystems;Software","","10","","46","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Improving PSP education by pairing: An empirical study","G. Rong; H. Zhang; M. Xie; D. Shao","State Key Laboratory for Novel, Software Technology, Software Institute, Nanjing University, Nanjing, China; National ICT Australia, University of New South Wales, NSW, Australia; Software Institute, Nanjing University, Nanjing, China; Software Institute, Nanjing University, Nanjing, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1245","1254","Handling large-sized classes and maintaining students' involvement are two of the major challenges in Personal Software Process (PSP) education in universities. In order to tackle these two challenges, we adapted and incorporated some typical practices of Pair Programming (PP) into the PSP class at summer school in Software Institute of Nanjing University in 2010, and received positive results, such as higher students' involvement and conformity of process discipline, as well as (half) workload reduction in evaluating assignments. However, the experiment did not confirm the improved performance of the paired students as expected. Based on the experience and feedbacks, we improved this approach in our PSP course in 2011. Accordingly, by analyzing the previous experiment results, we redesigned the experiment with a number of improvements, such as lab environment, evaluation methods and student selection, to further investigate the effects of this approach in PSP education, in particular students' performance. We also introduced several new metrics to enable the comparison analysis of the data collected from both paired students and solo students. The new experiment confirms the value of pairing practices in PSP education. The results show that in PSP class, compared to solo students, paired students can achieve better performance in terms of program quality and exam scores.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227018","personal software process;collaborative learning","Educational institutions;Software;Estimation;Training;Programming profession","","7","","25","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A study on improving static analysis tools: Why are we not using them?","B. Johnson","Department of Computer Science, North Carolina State University, Raleigh, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1607","1609","Using static analysis tools for automating code inspections can be beneficial for software engineers. Despite the benefits of using static analysis tools, research suggests that these tools are underused. In this research, we propose to investigate why developers are not widely using static analysis tools and how current tools could potentially be improved to increase usage.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227228","static analysis;tool development;tool evaluation","Interviews;Computer bugs;Software;Analytical models;Industries;Encoding;Programming","","3","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"On the Temporal Relations between Logging and Code","Z. Ding; Y. Tang; Y. Li; H. Li; W. Shang","Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Beijing University of Posts and Telecommunications, Beijing, China; Polytechnique Montréal, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","843","854","Prior work shows that misleading logging texts (i.e., the textual descriptions in logging statements) can be counterproductive for developers during their use of logs. One of the most important types of information provided by logs is the temporal information of the recorded system behavior. For example, a logging text may use a perfective aspect to describe a fact that an important system event has finished. Although prior work has performed extensive studies on automated logging suggestions, few of these studies investigate the temporal relations between logging and code. In this work, we make the first attempt to comprehensively study the temporal relations between logging and its corresponding source code. In particular, we focus on two types of temporal relations: (1) logical temporal relations, which can be inferred from the execution order between the logging statement and the corresponding source code; and (2) semantic temporal relations, which can be inferred based on the semantic meaning of the logging text. We first perform qualitative analyses to study these two types of logging-code temporal relations and the inconsistency between them. As a result, we derive rules to detect these two types of temporal relations and their inconsistencies. Based on these rules, we propose a tool named TempoLo to automatically detect the issues of temporal inconsistencies between logging and code. Through an evaluation of four projects, we find that TempoLo can effectively detect temporal inconsistencies with a small number of false positives. To gather developers' feedback on whether such inconsistencies are worth fixing, we report 15 detected instances from these projects to developers. 13 instances from three projects are confirmed and fixed, while two instances of the remaining project are pending at the time of this writing. Our work lays the foundation for describing temporal relations between logging and code and demonstrates the potential for a deeper understanding of the relationship between logging and code.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172750","software logging;logging text;temporal relations","Codes;Source coding;Semantics;Writing;Software;Behavioral sciences;Task analysis","","3","","50","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges","J. T. Liang; C. Yang; B. A. Myers","Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","616","628","The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot. However, in practice, developers do not accept AI programming assistants' initial suggestions at a high frequency. This leaves a number of open questions related to the usability of these tools. To understand developers' practices while using these tools and the important usability challenges they face, we administered a survey to a large population of developers and received responses from a diverse set of 410 developers. Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. We also found the most important reasons why developers do not use these tools are because these tools do not output code that addresses certain functional or non-functional requirements and because developers have trouble controlling the tool to generate the desired output. Our findings have implications for both creators and users of AI programming assistants, such as designing minimal cognitive effort interactions with these tools to reduce distractions for users while they are programming.","1558-1225","979-8-4007-0217-4","","National Science Foundation(grant numbers:DGE1745016,DGE2140739,IIS-1856641); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548213","Software and its engineering → Software notations and tools;• Human-centered computing → Empirical studies in HCI;• Computing methodologies → Natural language processing;AI programming assistants;usability study","Surveys;Programming;Syntactics;Software;Artificial intelligence;Usability;Task analysis","","4","","62","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Change Is the Only Constant: Dynamic Updates for Workflows","D. Sokolowski; P. Weisenburger; G. Salvaneschi","University of St. Gallen, Switzerland; University of St. Gallen, Switzerland; University of St. Gallen, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","350","362","Software systems must be updated regularly to address changing requirements and urgent issues like security-related bugs. Traditionally, updates are performed by shutting down the system to replace certain components. In modern software organizations, updates are increasingly frequentup to multiple times per dayhence, shutting down the entire system is unacceptable. Safe dynamic software updating (DSU) enables component updates while the system is running by determining when the update can occur without causing errors. Safe DSU is crucial, especially for long-running or frequently executed asynchronous transactions (workflows), e.g., user-interactive sessions or order fulfillment processes. Unfortu-nately, previous research is limited to synchronous transaction models and does not address this case. In this work, we propose a unified model for safe DSU in work-flows. We discuss how state-of-the-art DSU solutions fit into this model and show that they incur significant overhead. To improve the performance, we introduce Essential Safety, a novel safe DSU approach that leverages the notion of non-essential changes, i.e., semantics preserving updates. In 106 realistic BPMN workflows, Essential Safety reduces the delay of workflow completions, on average, by 47.8 % compared to the state of the art. We show that the distinction of essential and non-essential changes plays a cru-cial role in this reduction and that, as suggested in the literature, non-essential changes are frequent: at least 60 % and often more than 90 % of systems' updates in eight monorepos we analyze.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793884","Software Evolution;Dynamic Software Updating;Workflows","Analytical models;Semantics;Computer bugs;Collaboration;Organizations;Software systems;Software","","","","61","","20 Jun 2022","","","IEEE","IEEE Conferences"
"What Challenges Do Developers Face About Checked-in Secrets in Software Artifacts?","S. K. Basak; L. Neil; B. Reaves; L. Williams","North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1635","1647","Throughout 2021, GitGuardian's monitoring of public GitHub repositories revealed a two-fold increase in the number of secrets (database credentials, API keys, and other credentials) exposed compared to 2020, accumulating more than six million secrets. To our knowledge, the challenges developers face to avoid checked-in secrets are not yet characterized. The goal of our paper is to aid researchers and tool developers in understanding and prioritizing opportunities for future research and tool automation for mitigating checked-in secrets through an empirical investigation of challenges and solutions related to checked-in secrets. We extract 779 questions related to checked-in secrets on Stack Exchange and apply qualitative analysis to determine the challenges and the solutions posed by others for each of the challenges. We identify 27 challenges and 13 solutions. The four most common challenges, in ranked order, are: (i) store/version of secrets during deployment; (ii) store/version of secrets in source code; (iii) ignore/hide of secrets in source code; and (iv) sanitize VCS history. The three most common solutions, in ranked order, are: (i) move secrets out of source code/version control and use template config file; (ii) secret management in deployment; and (iii) use local environment variables. Our findings indicate that the same solution has been mentioned to mitigate multiple challenges. However, our findings also identify an increasing trend in questions lacking accepted solutions substantiating the need for future research and tool automation on managing secrets.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00141","National Science Foundation(grant numbers:2055554); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172600","secrets;credentials;developers;software secret management;challenges;empirical study;stack exchange","Automation;Databases;Source coding;Market research;Software;History;Faces","","1","","90","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Autonomy Is An Acquired Taste: Exploring Developer Preferences for GitHub Bots","A. Ghorbani; N. Cassee; D. Robinson; A. Alami; N. A. Ernst; A. Serebrenik; A. Wąsowski","University of Victoria, Canada; University of Victoria, Canada; University of Victoria, Canada; Aalborg University, Denmark; University of Victoria, Canada; Eindhoven University of Technology, The Netherlands; IT University of Copenhagen, Denmark",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1405","1417","Software bots fulfill an important role in collective software development, and their adoption by developers promises increased productivity. Past research has identified that bots that communicate too often can irritate developers, which affects the utility of the bot. However, it is not clear what other properties of human-bot collaboration affect developers' preferences, or what impact these properties might have. The main idea of this paper is to explore characteristics affecting developer preferences for interactions between humans and bots, in the context of GitHub pull requests. We carried out an exploratory sequential study with interviews and a subsequent vignette-based survey. We find developers generally prefer bots that are personable but show little autonomy, however, more experienced developers tend to prefer more autonomous bots. Based on this empirical evidence, we recommend bot developers increase configuration options for bots so that individual developers and projects can configure bots to best align with their own preferences and project cultures.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172895","Software Bot;Pull Request;Human Aspects","Surveys;Productivity;Collaboration;Chatbots;Software;Interviews;Software development management","","4","","55","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs","M. M. Imran; P. Chatterjee; K. Damevski","Virginia Commonwealth University, Richmond, Virginia, USA; Drexel University, Philadelphia, Pennsylvania, USA; Virginia Commonwealth University, Richmond, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2244","2256","Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by ‘delays in merging pull requests’) can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue com-ments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels. In this paper, we explore zero-shot LLMs that are pretrained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frus-tration in the last year of development of a popular open-source project, revealing several interesting insights.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549466","Emotion Cause Extraction;Emotion Classification;Zero-Shot Prompting;Large Language Model;GPT-4;ChatGPT","Emotion recognition;Automation;Merging;Collaboration;Machine learning;Chatbots;Software","","1","","102","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Does organizing security patterns focus architectural choices?","K. Yskout; R. Scandariato; W. Joosen","IBBT-DistriNet KU Leuven, Heverlee, Belgium; IBBT-DistriNet KU Leuven, Heverlee, Belgium; IBBT-DistriNet KU Leuven, Heverlee, Belgium",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","617","627","Security patterns can be a valuable vehicle to design secure software. Several proposals have been advanced to improve the usability of security patterns. They often describe extra annotations to be included in the pattern documentation. This paper presents an empirical study that validates whether those proposals provide any real benefit for software architects. A controlled experiment has been executed with 90 master students, who have performed several design tasks involving the hardening of a software architecture via security patterns. The results show that annotations produce benefits in terms of a reduced number of alternatives that need to be considered during the selection of a suitable pattern. However, they do not reduce the time spent in the selection process.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227155","secure software engineering;experiment;security patterns;software architecture","Security;Catalogs;Computer architecture;Proposals;Software;Software architecture;Context","","15","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Are Prompt Engineering and TODO Comments Friends or Foes? An Evaluation on GitHub Copilot","D. OBrien; S. Biswas; S. M. Imtiaz; R. Abdalkareem; E. Shihab; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; School of Computer Science Carnegie Mellon University, Pittsburgh, PA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Omar Al-Mukhtar University, Elbyda, JK, Libya; Concordia University, Montreal, QC, Canada; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2707","2719","Code intelligence tools such as GitHub Copilot have begun to bridge the gap between natural language and programming language. A frequent software development task is the management of technical debts, which are suboptimal solutions or unaddressed issues which hinder future software development. Developers have been found to “self-admit” technical debts (SATD) in software artifacts such as source code comments. Thus, is it possible that the information present in these comments can enhance code generative prompts to repay the described SATD? Or, does the inclusion of such comments instead cause code generative tools to reproduce the harmful symptoms of described technical debt? Does the modification of SATD impact this reaction? Despite the heavy maintenance costs caused by technical debt and the recent improvements of code intelligence tools, no prior works have sought to incorporate SATD towards prompt engineering. Inspired by this, this paper contributes and analyzes a dataset consisting of 36,381 TODO comments in the latest available revisions of their respective 102,424 repositories, from which we sample and manually generate 1,140 code bodies using GitHub Copilot. Our experiments show that GitHub Copilot can generate code with the symptoms of SATD, both prompted and unprompted. Moreover, we demonstrate the tool's ability to automatically repay SATD under different circumstances and qualitatively investigate the characteristics of successful and unsuccessful comments. Finally, we discuss gaps in which GitHub Copilot's successors and future researchers can improve upon code intelligence tasks to facilitate AI-assisted software maintenance.","1558-1225","979-8-4007-0217-4","","National Science Foundation(grant numbers:CCF-15-18897,CNS-15-13263,CNS-21-20448,CCF-19-34884,CCF-22-23812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549612","technical debt;GitHub Copilot;LLM;code generation","Software maintenance;Computer languages;Codes;Costs;Source coding;Natural languages;Maintenance","","","","57","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Co-Creation in Fully Remote Software Teams","V. Jackson; A. Van Der Hoek; R. Prikladnicki","University of California, Irvine, Irvine, CA, USA; University of California, Irvine, Irvine, CA, USA; Pontifícia Universidade do Rio Grande do Sul, Porto Alegre, RS, Brazil",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","604","615","In this paper, we use the lens of co-creation-a concept originally coined and applied in the fields of management and design that denotes how groups of people collaboratively create something of meaning through an orchestration of people, activities, and tools-to study how fully remote software teams co-create digital artifacts that can be considered as a form of documentation. We report on the results of a qualitative, interview-based study with 25 software professionals working in remote teams. Our primary findings are the definition of four models of co-creation, examples of sequencing these models into work chains to produce artifacts, factors that influence how developers match tasks to models and chains, and insights into tool support for co-creation. Together, our findings illustrate how co-creation is an intentional activity that has a significant role in how remote software teams' choose to structure their collaborative activities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623297","National Science Foundation(grant numbers:CCF-2210812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548458","Collaboration;Remote software development;Developer tools;Virtual software teams;Software team practices","Industries;Sequential analysis;Market research;Software;Remote working;Task analysis;Creativity","","","","61","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"How software engineering can benefit from traditional industries — A practical experience report (Invited industrial talk)","T. Sprenger","AdNovum Informatik, Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1000","1000","To be competitive in today's market, the IT industry faces many challenges in the development and maintenance of enterprise information systems. Engineering these largescaled systems efficiently requires making decisions about a number of issues. In addition, customers expectations imply continuous software delivery in predictable quality. The operation such systems demands for transparency of the software in regard to lifecycle, change and incident management as well as cost efficiency. Addressing these challenges, we learned how to benefit from traditional industries. Contrary to the fact that the IT business calls itself gladly an industry, the industrialization of software engineering in most cases moves on a rather modest level. Industrialization means not only to build a solution or product on top of managed and well-defined processes, but also to have access to structured information about the current conditions of manufacturing at any time. Comparably with test series and assembly lines of the automobile industry, each individual component and each step from the beginning of manufacturing up to the final product should be equipped with measuring points for quality and progress. Even one step further the product itself, after it has left the factory, should be able to continuously provide analytic data for diagnostic reasons. Information is automatically collected and builds the basic essentials for process control, optimization and continuous improvement of the software engineering process. This presentation shows by means of a practical experience report how AdNovum managed to build its software engineering based on a well-balanced system of processes, continuous measurement and control — as well as a healthy portion of pragmatism. We implemented an efficient and predictable software delivery pipeline based on five cornerstones that enables us to ship more than 1500 customer deliveries per year.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227249","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A large scale exploratory analysis of software vulnerability life cycles","M. Shahzad; M. Z. Shafiq; A. X. Liu","Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","771","781","Software systems inherently contain vulnerabilities that have been exploited in the past resulting in significant revenue losses. The study of vulnerability life cycles can help in the development, deployment, and maintenance of software systems. It can also help in designing future security policies and conducting audits of past incidents. Furthermore, such an analysis can help customers to assess the security risks associated with software products of different vendors. In this paper, we conduct an exploratory measurement study of a large software vulnerability data set containing 46310 vulnerabilities disclosed since 1988 till 2011. We investigate vulnerabilities along following seven dimensions: (1) phases in the life cycle of vulnerabilities, (2) evolution of vulnerabilities over the years, (3) functionality of vulnerabilities, (4) access requirement for exploitation of vulnerabilities, (5) risk level of vulnerabilities, (6) software vendors, and (7) software products. Our exploratory analysis uncovers several statistically significant findings that have important implications for software development and deployment.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227141","vulnerability;disclosure;patch;exploit;NVD;OSVDB","Computer hacking;Complexity theory;Aggregates;Measurement;Open source software","","102","1","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Recommending source code for use in rapid software prototypes","C. McMillan; N. Hariri; D. Poshyvanyk; J. Cleland-Huang; B. Mobasher","College of William and Mary, Williamsburg, VA, USA; De Paul University, Chicago, IL, USA; College of William and Mary, Williamsburg, VA, USA; De Paul University, Chicago, IL, USA; De Paul University, Chicago, IL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","848","858","Rapid prototypes are often developed early in the software development process in order to help project stakeholders explore ideas for possible features, and to discover, analyze, and specify requirements for the project. As prototypes are typically thrown-away following the initial analysis phase, it is imperative for them to be created quickly with little cost and effort. Tool support for finding and reusing components from open-source repositories offers a major opportunity to reduce this manual effort. In this paper, we present a system for rapid prototyping that facilitates software reuse by mining feature descriptions and source code from open-source repositories. Our system identifies and recommends features and associated source code modules that are relevant to the software product under development. The modules are selected such that they implement as many of the desired features as possible while exhibiting the lowest possible levels of external coupling. We conducted a user study to evaluate our approach and the results indicated that our proposed system returned packages that implemented more features and were considered more relevant than the state-of-the-art approach.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227134","software prototyping;domain analysis;recommender systems","Feature extraction;Prototypes;Couplings;Software;Search engines;Portfolios;Java","","37","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Unveiling Memorization in Code Models","Z. Yang; Z. Zhao; C. Wang; J. Shi; D. Kim; D. Han; D. Lo","School of Computing and Information Systems, Singapore Management University, Singapore; Department of Computer Science, University of Copenhagen, Copenhagen, Denmark; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computer Science and Engineering, Kyungpook National University, Daegu, South Korea; Department of Computer Science, Royal Holloway, University of London, London, UK; School of Computing and Information Systems, Singapore Management University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","867","879","The availability of large-scale datasets, advanced architectures, and powerful computational resources have led to effective code models that automate diverse software engineering activities. The datasets usually consist of billions of lines of code from both open-source and private repositories. A code model memorizes and produces source code verbatim, which potentially contains vulnerabilities, sensitive information, or code with strict licenses, leading to potential security and privacy issues. This paper investigates an important problem: to what extent do code models memorize their training data? We conduct an empirical study to explore memorization in large pre-trained code models. Our study highlights that simply extracting 20,000 outputs (each having 512 tokens) from a code model can produce over 40,125 code snippets that are memorized from the training data. To provide a better understanding, we build a taxonomy of memorized contents with 3 categories and 14 subcategories. The results show that the prompts sent to the code models affect the distribution of memorized contents. We identify several key factors of memorization. Specifically, given the same architecture, larger models suffer more from memorization problem. A code model produces more memorization when it is allowed to generate longer outputs. We also find a strong positive correlation between the number of an output's occurrences in the training data and that in the generated outputs, which indicates that a potential way to reduce memorization is to remove duplicates in the training data. We then identify effective metrics that infer whether an output contains memorization accurately. We also make suggestions to deal with memorization.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639074","National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); National Research Foundation, Singapore; National Research Foundation of Korea (NRF)(grant numbers:2021R1A5A1021944,2021R1I1A3048013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549662","Software and its engineering → Software development techniques;Computing methodologies → Artificial intelligence;Security and privacy;Open-Source Software;Memorization;Code Generation","Codes;Computational modeling;Source coding;Taxonomy;Training data;Computer architecture;Data models","","1","","74","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Recovering Trace Links Between Software Documentation And Code","J. Keim; S. Corallo; D. Fuchß; T. Hey; T. Telge; A. Koziolek","Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2655","2667","Introduction Software development involves creating various arti-facts at different levels of abstraction and establishing relationships between them is essential. Traceability link recovery (TLR) automates this process, enhancing software quality by aiding tasks like maintenance and evolution. However, automating TLR is challenging due to semantic gaps resulting from different levels of abstraction. While automated TLR approaches exist for requirements and code, architecture documentation lacks tailored solutions, hindering the preservation of architecture knowledge and design decisions. Methods This paper presents our approach TransArC for TLR between architecture documentation and code, using component-based architecture models as intermediate artifacts to bridge the semantic gap. We create transitive trace links by combining the existing approach ArDoCo for linking architecture documentation to models with our novel approach ArCoTL for linking architecture models to code. Results We evaluate our approaches with five open-source projects, comparing our results to baseline approaches. The model-to-code TLR approach achieves an average $\mathrm{F}_{1}$ -score of 0.98, while the documentation-to-code TLR approach achieves a promising average $\mathrm{F}_{1}$-score of 0.82, significantly outperforming baselines. Conclusion Combining two specialized approaches with an interme-diate artifact shows promise for bridging the semantic gap. In future research, we will explore further possibilities for such transitive approaches.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548994","software traceability;software architecture;transitive links;intermediate artifacts;information retrieval","Bridges;Codes;Semantics;Computer architecture;Documentation;Software quality;Maintenance","","","","68","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"On the proactive and interactive visualization for feature evolution comprehension: An industrial investigation","R. Novais; C. Nunes; C. Lima; E. Cirilo; F. Dantas; A. Garcia; M. Mendonça","Software Engineering Lab, Computer Science Department, Federal University of Bahia, Bahia, Brazil; Opus Research Group, Software Engineering Lab, Informatics Department, PUC-Rio, Rio de Janeiro, Brazil; Software Engineering Lab, Computer Science Department, Federal University of Bahia, Bahia, Brazil; Opus Research Group, Software Engineering Lab, Informatics Department, PUC-Rio, Rio de Janeiro, Brazil; Opus Research Group, Software Engineering Lab, Informatics Department, PUC-Rio, Rio de Janeiro, Brazil; Opus Research Group, Software Engineering Lab, Informatics Department, PUC-Rio, Rio de Janeiro, Brazil; Software Engineering Lab, Computer Science Department, Federal University of Bahia, Bahia, Brazil",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1044","1053","Program comprehension is a key activity through maintenance and evolution of large-scale software systems. The understanding of a program often requires the evolution analysis of individual functionalities, so-called features. The comprehension of evolving features is not trivial as their implementations are often tangled and scattered through many modules. Even worse, existing techniques are limited in providing developers with direct means for visualizing the evolution of features' code. This work presents a proactive and interactive visualization strategy to enable feature evolution analysis. It proactively identifies code elements of evolving features and provides multiple views to present their structure under different perspectives. The novel visualization strategy was compared to a lightweight visualization strategy based on a tree-structure. We ran a controlled experiment with industry developers, who performed feature evolution comprehension tasks on an industrial-strength software. The results showed that the use of the proposed strategy presented significant gains in terms of correctness and execution time for feature evolution comprehension tasks.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227115","program comprehension;feature evolution;software visualization;experimental evaluation","Visualization;Color;Industries;Software systems;History;Context","","5","","33","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Using structural and semantic information to support software refactoring","G. Bavota","School of Science, University of Salerno, Fisciano, Salerno, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1479","1482","In the software life cycle the internal structure of the system undergoes continuous modifications. These changes push away the source code from its original design, often reducing its quality. In such cases refactoring techniques can be applied to improve the design quality of the system. Approaches existing in literature mainly exploit structural relationships present in the source code, e.g., method calls, to support the software engineer in identifying refactoring solutions. However, also semantic information is embedded in the source code by the developers, e.g., the terms used in the comments. This research investigates about the usefulness of combining structural and semantic information to support software refactoring.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227057","refactoring;semantic information","Semantics;Software;Couplings;Atmospheric measurements;Particle measurements;Weight measurement","","5","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"An Empirical Study on Software Bill of Materials: Where We Stand and the Road Ahead","B. Xia; T. Bi; Z. Xing; Q. Lu; L. Zhu","CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2630","2642","The rapid growth of software supply chain attacks has attracted considerable attention to software bill of materials (SBOM). SBOMs are a crucial building block to ensure the transparency of software supply chains that helps improve software supply chain security. Although there are significant efforts from academia and industry to facilitate SBOM development, it is still unclear how practitioners perceive SBOMs and what are the challenges of adopting SBOMs in practice. Furthermore, existing SBOM-related studies tend to be ad-hoc and lack software engineering focuses. To bridge this gap, we conducted the first empirical study to interview and survey SBOM practitioners. We applied a mixed qualitative and quantitative method for gathering data from 17 interviewees and 65 survey respondents from 15 countries across five continents to understand how practitioners perceive the SBOM field. We summarized 26 statements and grouped them into three topics on SBOM's states of practice. Based on the study results, we derived a goal model and highlighted future directions where practitioners can put in their effort.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172696","software bill of materials;SBOM;bill of materials;responsible AI;empirical study","Surveys;Industries;Roads;Supply chains;Bills of materials;Software;Security","","26","","48","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"PILAR: Studying and Mitigating the Influence of Configurations on Log Parsing","H. Dai; Y. Tang; H. Li; W. Shang","Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Polytechnique Montréal, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","818","829","The significance of logs has been widely acknowledged with the adoption of various log analysis techniques that assist in software engineering tasks. Many log analysis techniques require structured logs as input while raw logs are typically unstructured. Automated log parsing is proposed to convert unstructured raw logs into structured log templates. Some log parsers achieve promising accuracy, yet they rely on significant efforts from the users to tune the parameters to achieve optimal results. In this paper, we first conduct an empirical study to understand the influence of the configurable parameters of six state-of-the-art log parsers on their parsing results on three aspects: 1) varying the parameters while using the same dataset, 2) keeping the same parameters while using different datasets, and 3) using different samples from the same dataset. Our results show that all these parsers are sensitive to the parameters, posing challenges to their adoption in practice. To mitigate such challenges, we propose PILAR (Parameter Insensitive Log Parser), an entropy-based log parsing approach. We compare PILAR with the existing log parsers on the same three aspects and find that PILAR is the most parameter-insensitive one. In addition, PILAR achieves the second highest parsing accuracy and efficiency among all the state-of-the-art log parsers. This paper paves the road for easing the adoption of log analysis in software engineer practices.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172821","","Roads;Software;Task analysis;Software engineering","","2","","32","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Development of auxiliary functions: Should you be agile? An empirical assessment of pair programming and test-first programming","O. A. L. Lemos; F. C. Ferrari; F. F. Silveira; A. Garcia","Science and Technology Department, Federal University of Sao Paulo, Sao Jose dos Campos, Brazil; Computing Department, Federal University of Sāo Carlos UFSCar, Brazil; Science and Technology Department, Federal University of Sao Paulo, Sao Jose dos Campos, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro, Brazil",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","529","539","A considerable part of software systems is comprised of functions that support the main modules, such as array or string manipulation and basic math computation. These auxiliary functions are usually considered less complex, and thus tend to receive less attention from developers. However, failures in these functions might propagate to more critical modules, thereby affecting the system's overall reliability. Given the complementary role of auxiliary functions, a question that arises is whether agile practices, such as pair programming and test-first programming, can improve their correctness without affecting time-to-market. This paper presents an empirical assessment comparing the application of these agile practices with more traditional approaches. Our study comprises independent experiments of pair versus solo programming, and test-first versus test-last programming. The first study involved 85 novice programmers who applied both traditional and agile approaches in the development of six auxiliary functions within three different domains. Our results suggest that the agile practices might bring benefits in this context. In particular, pair programmers delivered correct implementations much more often, and test-first programming encouraged the production of larger and higher coverage test sets. On the downside, the main experiment showed that both practices significantly increase total development time. A replication of the test-first experiment with professional developers shows similar results.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227163","pair programming;test-first programming;TDD;experimental software engineering;agile methods","Programming profession;Arrays;Reliability;Software testing;Measurement","","11","","48","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software as an engineering material: How the affordances of programming have changed and what to do about it (Invited industrial talk)","K. Braithwaite","Züuhlke Engineering, London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","998","998","Summary form only given. A huge wealth of various data exist in the practice of software development. Further rich data are produced by modern software and services in operation, many of which tend to be data-driven and/or data-producing in nature. Hidden in the data is information about the quality of software and services and the dynamics of software development. Software analytics is to develop and apply data exploration and analysis technologies, such as pattern recognition, machine learning, and information visualization, on software data to obtain insightful and actionable information for modern software and services. This tutorial presents latest research and practice on principles, techniques, and applications of software analytics in practice, highlighting success stories in industry, research achievements that are transferred to industrial practice, and future research and practice directions in software analytics. The attendees can acquire the skills and knowledge needed to perform industrial research or conduct industrial practice in the field of software analytics and to integrate analytics in their own industrial research, practice, and training.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227251","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Detecting Isolation Bugs via Transaction Oracle Construction","W. Dou; Z. Cui; Q. Dai; J. Song; D. Wang; Y. Gao; W. Wang; J. Wei; L. Chen; H. Wang; H. Zhong; T. Huang","State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; Inspur Software Group Co., Ltd.; Inspur Software Group Co., Ltd.; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Lab of Computer Science, Institute of Software, Chinese Academy of Sciences",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1123","1135","Transactions are used to maintain the data integrity of databases, and have become an indispensable feature in modern Database Management Systems (DBMSs). Despite extensive efforts in testing DBMSs and verifying transaction processing mechanisms, isolation bugs still exist in widely-used DBMSs when these DBMSs violate their claimed transaction isolation levels. Isolation bugs can cause severe consequences, e.g., incorrect query results and database states. In this paper, we propose a novel transaction testing approach, Transaction oracle construction (Troc), to automatically detect isolation bugs in DBMSs. The core idea of Troc is to decouple a transaction into independent statements, and execute them on their own database views, which are constructed under the guidance of the claimed transaction isolation level. Any divergence between the actual transaction execution and the independent statement execution indicates an isolation bug. We implement and evaluate Troc on three widely-used DBMSs, i.e., MySQL, MariaDB, and TiDB. We have detected 5 previously-unknown isolation bugs in the latest versions of these DBMSs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00101","National Key R&D Program of China(grant numbers:2021YFB1716000); National Natural Science Foundation of China(grant numbers:62072444); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172773","Database system;transaction;isolation;oracle","Data integrity;Computer bugs;Database systems;Testing;Software engineering;IEEE transactions","","7","","81","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Exploiting Input Sanitization for Regex Denial of Service","E. Barlas; X. Du; J. C. Davis","Purdue University, West Lafayette, Indiana, USA; Purdue University, West Lafayette, Indiana, USA; Purdue University, West Lafayette, Indiana, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","883","895","Web services use server-side input sanitization to guard against harmful input. Some web services publish their sanitization logic to make their client interface more usable, e.g., allowing clients to debug invalid requests locally. However, this usability practice poses a security risk. Specifically, services may share the regexes they use to sanitize input strings - and regex-based denial of service (ReDoS) is an emerging threat. Although prominent service outages caused by ReDoS have spurred interest in this topic, we know little about the degree to which live web services are vulnerable to ReDoS. In this paper, we conduct the first black-box study measuring the extent of ReDoS vulnerabilities in live web services. We apply the Consistent Sanitization Assumption: that client-side sanitization logic, including regexes, is consistent with the sanitization logic on the server-side. We identify a service's regex-based input sanitization in its HTML forms or its API, find vulnerable regexes among these regexes, craft ReDoS probes, and pinpoint vulnerabilities. We analyzed the HTML forms of 1,000 services and the APIs of 475 services. Of these, 355 services publish regexes; 17 services publish unsafe regexes; and 6 services are vulnerable to ReDoS through their APIs (6 domains; 15 subdomains). Both Microsoft and Amazon Web Services patched their web services as a result of our disclosure. Since these vulnerabilities were from API specifications, not HTML forms, we proposed a ReDoS defense for a popular API validation library, and our patch has been merged. To summarize: in client-visible sanitization logic, some web services advertise Re-DoS vulnerabilities in plain sight. Our results motivate short-term patches and long-term fundamental solutions. “Make measurable what cannot be measured.” -Galileo Galilei","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794049","Empirical software engineering;regular expressions;ReDoS;web security;denial of service;algorithmic complexity attacks","Web services;Software;Libraries;Servers;Security;Usability;Probes","","3","","115","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Twins or False Friends? A Study on Energy Consumption and Performance of Configurable Software","M. Weber; C. Kaltenecker; F. Sattler; S. Apel; N. Siegmund","Leipzig University, Germany; Saarland University, Germany; Saarland University, Germany; Saarland University, Germany; Leipzig University, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2098","2110","Reducing energy consumption of software is an increasingly important objective, and there has been extensive research for data centers, smartphones, and embedded systems. However, when it comes to software, we lack working tools and methods to directly reduce energy consumption. For performance, we can resort to configuration options for tuning response time or throughput of a software system. For energy, it is still unclear whether the underlying assumption that runtime performance correlates with energy consumption holds, especially when it comes to optimization via configuration. To evaluate whether and to what extent this assumption is valid for configurable software systems, we conducted the largest empirical study of this kind to date. First, we searched the literature for reports on whether and why runtime performance correlates with energy consumption. We obtained a mixed, even contradicting picture from positive to negative correlation, and that configurability has not been considered yet as a factor for this variance. Second, we measured and analyzed both the runtime performance and energy consumption of 14 real-world software systems. We found that, in many cases, it depends on the software system's configuration whether runtime performance and energy consumption correlate and that, typically, only few configuration options influence the degree of correlation. A fine-grained analysis at the function level revealed that only few functions are relevant to obtain an accurate proxy for energy consumption and that, knowing them, allows one to infer individual transfer factors between runtime performance and energy consumption.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00177","German Research Foundation(grant numbers:SI 2171/3-1,SI 2171/2-2,AP 206/11-1,AP 206/11-2,389792660); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172770","energy consumption;performance;configurability;correlation","Energy consumption;Runtime;Correlation;Energy measurement;Software systems;Time measurement;Software measurement","","4","","54","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Analysing the Impact of Workloads on Modeling the Performance of Configurable Software Systems","S. Mühlbauer; F. Sattler; C. Kaltenecker; J. Dorn; S. Apel; N. Siegmund","Leipzig University; Saarland Informatics Campus, Saarland University; Saarland Informatics Campus, Saarland University; Leipzig University; Saarland Informatics Campus, Saarland University; ScaDS.AI Dresden, Leipzig University, Leipzig",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2085","2097","Modern software systems often exhibit numerous configuration options to tailor them to user requirements, including the system's performance behavior. Performance models derived via machine learning are an established approach for estimating and optimizing configuration-dependent software performance. Most existing approaches in this area rely on software performance measurements conducted with a single workload (i.e., input fed to a system). This single workload, however, is often not representative of a software system's real-world application scenarios. Understanding to what extent configuration and workload-individually and combined-cause a software system's performance to vary is key to understand whether performance models are generalizable across different configurations and workloads. Yet, so far, this aspect has not been systematically studied. To fill this gap, we conducted a systematic empirical study across 25 258 configurations from nine real-world configurable software systems to investigate the effects of workload variation at system-level performance and for individual configuration options. We explore driving causes for workload-configuration interactions by enriching performance observations with option-specific code coverage information. Our results demonstrate that workloads can induce substantial performance variation and interact with configuration options, often in non-monotonous ways. This limits not only the generalizability of single-workload models, but also challenges assumptions for existing transfer-learning techniques. As a result, workloads should be considered when building performance prediction models to maintain and improve representativeness and reliability.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172849","","Codes;Systematics;Sensitivity;System performance;Software performance;Predictive models;Software systems","","4","","73","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Testing Database Systems via Differential Query Execution","J. Song; W. Dou; Z. Cui; Q. Dai; W. Wang; J. Wei; H. Zhong; T. Huang","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2072","2084","Database Management Systems (DBMSs) provide efficient data retrieval and manipulation for many applications through Structured Query Language (SQL). Incorrect implementations of DBMSs can result in logic bugs, which cause SELECT queries to fetch incorrect results, or UPDATE and DELETE queries to generate incorrect database states. Existing approaches mainly focus on detecting logic bugs in SELECT queries. However, logic bugs in UPDATE and DELETE queries have not been tackled. In this paper, we propose a novel and general approach, which we have termed Differential Query Execution (DQE), to detect logic bugs in SELECT, UPDATE and DELETE queries of DBMSs. The core idea of DQE is that different SQL queries with the same predicate usually access the same rows in a database. For example, a row updated by an UPDATE query with a predicate φ should also be fetched by a SELECT query with the same predicate φ, If not, a logic bug is revealed in the target DBMS. To evaluate the effectiveness and generality of DQE, we apply DQE on five production-level DBMSs, i.e., MySQL, MariaDB, TiDB, CockroachDB and SQLite. In total, we have detected 50 unique bugs in these DBMSs, 41 of which have been confirmed, and 11 have been fixed. We expect that the simplicity and generality of DQE can greatly improve the reliability of DBMSs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172736","Database system;DBMS testing;logic bug","Structured Query Language;Computer bugs;Reliability engineering;Database systems;Software reliability;Testing;Software engineering","","8","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"TRIAD: Automated Traceability Recovery based on Biterm-enhanced Deduction of Transitive Links among Artifacts","H. Gao; H. Kuang; W. K. G. Assunção; C. Mayr-Dorn; G. Rong; H. Zhang; X. Ma; A. Egyed","State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China; CSC, North Carolina State University, Raleigh, USA; ISSE, Johannes Kepler University, Linz, Austria; State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab of Novel Software Technology, Nanjing University, Nanjing, China; ISSE, Johannes Kepler University, Linz, Austria",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2668","2680","Traceability allows stakeholders to extract and comprehend the trace links among software artifacts introduced across the software life cycle, to provide significant support for software engineering tasks. Despite its proven benefits, software traceability is challenging to recover and maintain manually. Hence, plenty of approaches for automated traceability have been proposed. Most rely on textual similarities among software artifacts, such as those based on Information Retrieval (IR). However, artifacts in different abstraction levels usually have different textual descriptions, which can greatly hinder the performance of IR-based approaches (e.g., a requirement in natural language may have a small textual similarity to a Java class). In this work, we leverage the consensual biterms and transitive relationships (i.e., inner- and outer-transitive links) based on intermediate artifacts to improve IR-based traceability recovery. We first extract and filter biterms from all source, intermediate, and target artifacts. We then use the consensual biterms from the intermediate artifacts to enrich the texts of both source and target artifacts, and finally deduce outer and inner-transitive links to adjust text similarities between source and target artifacts. We conducted a comprehensive empirical evaluation based on five systems widely used in other literature to show that our approach can outperform four state-of-the-art approaches in Average Precision over 15% and Mean Average Precision over 10% on average.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639164","National Natural Science Foundation of China(grant numbers:62025202,72371125,62072227,62202219,62302210); China Scholarship Council(grant numbers:202206190172); Jiangsu Provincial Key Research and Development Program(grant numbers:BE2021002-2); Austrian Science Fund (FWF)(grant numbers:P31989,P34805-N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548121","Software Traceability;Information Retrieval;Transitive Links","Measurement;Bridges;Java;Natural languages;Information retrieval;Software;Filling","","","","72","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated Assertion Generation via Information Retrieval and Its Integration with Deep learning","H. Yu; Y. Lou; K. Sun; D. Ran; T. Xie; D. Hao; Y. Li; G. Li; Q. Wang","School of Software and Microelectronics, Peking University, China; Department of Computer Science, Purdue University, USA; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; National Research Center of Software Engineering, Peking University, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, China; Huawei Technologies CO., LTD., China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","163","174","Unit testing could be used to validate the correctness of basic units of the software system under test. To reduce manual efforts in conducting unit testing, the research community has contributed with tools that automatically generate unit test cases, including test inputs and test oracles (e.g., assertions). Recently, ATLAS, a deep learning (DL) based approach, was proposed to generate assertions for a unit test based on other already written unit tests. Despite promising, the effectiveness of ATLAS is still limited. To improve the effectiveness, in this work, we make the first attempt to leverage Information Retrieval (IR) in assertion generation and propose an IR-based approach, including the technique of IR-based assertion retrieval and the technique of retrieved-assertion adaptation. In addition, we propose an integration approach to combine our IR-based approach with a DL-based approach (e.g., ATLAS) to further improve the effectiveness. Our experimental results show that our IR-based approach outperforms the state-of-the-art DL-based ap-proach, and integrating our IR-based approach with the DL-based approach can further achieve higher accuracy. Our results convey an important message that information retrieval could be competitive and worthwhile to pursue for software engineering tasks such as assertion generation, and should be seriously considered by the research community given that in recent years deep learning solutions have been over-popularly adopted by the research community for software engineering tasks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510149","National Natural Science Foundation of China(grant numbers:62161146003,62072007,62192733); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793891","Unit Testing;Information Retrieval;Test Assertion;Deep Learning","Deep learning;Manuals;Information retrieval;Software systems;Task analysis;Software engineering;Testing","","11","","58","","20 Jun 2022","","","IEEE","IEEE Conferences"
"On-Demand Security Requirements Synthesis with Relational Generative Adversarial Networks","V. Koscinski; S. Hashemi; M. Mirakhorli","Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1609","1621","Security requirements engineering is a manual and error-prone activity that is often neglected due to the knowledge gap between cybersecurity professionals and software requirements engineers. In this paper, we aim to automate the process of recommending and synthesizing security requirements specifications and therefore supporting requirements engineers in soliciting and specifying security requirements. We investigate the use of Relational Generative Adversarial Networks (GANs) in automatically synthesizing security requirements specifications. We evaluate our approach using a real case study of the Court Case Management System (CCMS) developed for the Indiana Supreme Court's Division of State Court Administration. We present an approach based on RelGAN to generate security requirements specifications for the CCMS. We show that RelGAN is practical for synthesizing security requirements specifications as indicated by subject matter experts. Based on this study, we demonstrate promising results for the use of GANs in the software requirements synthesis domain. We also provide a baseline for synthesizing requirements, highlight limitations and weaknesses of RelGAN and define opportunities for further investigations.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00139","US National Science Foundation(grant numbers:CCF-1943300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172729","Software Security Requirements;Requirements Engineering;Generative Adversarial Networks","Knowledge engineering;Education;Medical services;Manuals;Generative adversarial networks;Software;Security","","2","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Decomposing Software Verification into Off-the-Shelf Components: An Application to CEGAR","D. Beyer; J. Haltermann; T. Lemberger; H. Wehrheim","LMU Munich, Munich, Germany; University of Oldenburg, Oldenburg, Germany; LMU Munich, Munich, Germany; University of Oldenburg, Oldenburg, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","536","548","Techniques for software verification are typically realized as cohesive units of software with tightly coupled components. This makes it difficult to reuse components, and the potential for workload distribution is limited. Innovations in software verification might find their way into practice faster if provided in smaller, more specialized components. In this paper, we propose to strictly decompose software verification: the verification task is split into independent subtasks, implemented by only loosely coupled components communicating via clearly defined interfaces. We apply this decomposition concept to one of the most frequently employed techniques in software verification: counterexample-guided abstraction refinement (CEGAR). CEGAR is a technique to iteratively compute an abstract model of the system. We develop a decomposition of CEGAR into independent components with clearly defined interfaces that are based on existing, standardized exchange formats. Its realization component-based CEGAR (C-CEGAR) concerns the three core tasks of CEGAR: abstract-model exploration, feasibility check, and precision refinement. We experimentally show that - despite the necessity of exchanging complex data via interfaces - the efficiency thereby only reduces by a small constant factor while the precision in solving verification tasks even increases. We furthermore illustrate the advantages of C-CEGAR by experimenting with different implementations of components, thereby further increasing the overall effectiveness and testing that substitution of components works well.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793863","Software engineering;Software verification;Abstraction refine-ment;CEGAR;Decomposition;Cooperative verification","Computer science;Technological innovation;Computational modeling;Software;Complexity theory;Time factors;Feeds","","2","","103","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Novelty Begets Long-Term Popularity, But Curbs Participation: A Macroscopic View of the Python Open-Source Ecosystem","H. Fang; J. Herbsleb; B. Vasilescu","Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","654","664","Who creates the most innovative open-source software projects? And what fate do these projects tend to have? Building on a long history of research to understand innovation in business and other domains, as well as recent advances towards modeling innovation in scientific research from the science of science field, in this paper we adopt the analogy of innovation as emerging from the novel recombination of existing bits of knowledge. As such, we consider as innovative the software projects that recombine existing soft-ware libraries in novel ways, i.e., those built on top of atypical combinations of packages as extracted from import statements. We then report on a large-scale quantitative study of innovation in the Python open-source software ecosystem. Our results show that higher levels of innovativeness are statistically associated with higher GitHub star counts, i.e., novelty begets popularity. At the same time, we find that controlling for project size, the more in-novative projects tend to involve smaller teams of contributors, as well as be at higher risk of becoming abandoned in the long term. We conclude that innovation and open source sustainability are closely related and, to some extent, antagonistic.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608142","NSF(grant numbers:1901311,2107298,2120323); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548547","Open-source software;innovation","Technological innovation;Ecosystems;Stars;Particle measurements;Software measurement;Sustainable development;Open source software","","","","49","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"MDSheet: A framework for model-driven spreadsheet engineering","J. Cunha; J. P. Fernandes; J. Mendes; J. Saraiva","HASLab / INESC TEC, Universidade do Minho, Portugal; Departamento de Engenharia Informática, Universidade do Porto, Portugal; HASLab / INESC TEC, Universidade do Minho, Portugal; HASLab / INESC TEC, Universidade do Minho, Portugal",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1395","1398","In this paper, we present MDSheet, a framework for the embedding, evolution and inference of spreadsheet models. This framework offers a model-driven software development mechanism for spreadsheet users.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227239","Spreadsheets;Model-Driven Engineering (MDE);Software Evolution;Embedded DSLs;Model Inference","Object oriented modeling;Unified modeling language;Data models;Business;Visualization;Synchronization;Layout","","41","","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Continuous social screencasting to facilitate software tool discovery","E. Murphy-Hill","Department of Computer Science, North Carolina State University, Raleigh, NC, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1317","1320","The wide variety of software development tools available today have a great potential to improve the way developers make software, but that potential goes unfulfilled when developers are not aware of useful tools. In this paper, I introduce the idea of continuous social screencasting, a novel mechanism to help developers gain awareness of relevant tools by enabling them to learn remotely and asychronously from their peers. The idea builds on the strength of several existing techniques that developers already use for discovering new tools, including screencasts and online social networks.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227090","","Software;Communities;Servers;Blogs;Monitoring;Programming;Buildings","","14","","8","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"ConcernReCS: Finding code smells in software aspectization","P. Alves; D. Santana; E. Figueiredo","Computer Science Department, Federal University of Minas Gerais, Belo Horizonte, Brazil; Computer Science Department, Federal University of Minas Gerais, Belo Horizonte, Brazil; Computer Science Department, Federal University of Minas Gerais, Belo Horizonte, Brazil",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1463","1464","Refactoring object-oriented (OO) code to aspects is an error-prone task. To support this task, this paper presents ConcernReCS, an Eclipse plug-in to help developers to avoid recurring mistakes during software aspectization. Based on a map of concerns, ConcernReCS automatically finds and reports error-prone scenarios in OO source code; i.e., before the concerns have been refactored to aspects.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227063","AOP;Code Smells;Programming Mistakes","Software;Programming;Conferences;Educational institutions;Organizations;Tutorials","","1","","5","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Demystifying Issues, Challenges, and Solutions for Multilingual Software Development","H. Yang; W. Lian; S. Wang; H. Cai","Washington State University, Pullman, WA, USA; Washington State University, Pullman, WA, USA; University of Manitoba, Winnipeg, Canada; Washington State University, Pullman, WA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1840","1852","Developing a software project using multiple languages together has been a dominant practice for years. Yet it remains unclear what issues developers encounter during the development, which challenges cause the issues, and what solutions developers receive. In this paper, we aim to answer these questions via a study on developer discussions on Stack Overflow. By manually analyzing 586 highly relevant posts spanning 14 years, we observed a large variety (11 categories) of issues, dominated by those with interfacing and data handling among different languages. Behind these issues, we found that a major challenge developers faced is the diversity and complexity in multilingual code building and interoperability. Another key challenge lies in developers' lack of particular technical background on the diverse features of various languages (e.g., threading and memory management mechanisms). Meanwhile, Stack Overflow itself served as a key source of solutions to these challenges-the majority (73%) of the posts received accepted answers eventually, and most in a week (36.5% within 24 hours and 25% in the next 6 days). Based on our findings on these issues, challenges, and solutions, we provide actionable insights and suggestions for both multi-language software researchers and developers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172841","Multilingual software;development issues;language interfacing;software build;data format;interoperability","Codes;Instruction sets;Data handling;Memory management;Buildings;Software;Complexity theory","","1","","67","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Hiding Critical Program Components via Ambiguous Translation","C. Jung; D. Kim; A. Chen; W. Wang; Y. Zheng; K. H. Lee; Y. Kwon","University of Virginia, Charlottesville, VA; University of Tennessee, Knoxville, Knoxville, TN; University of Georgia, Athens, GA; University at Buffalo, SUNY, Buffalo, NY; IBM Research, Yorktown Heights, NY; University of Georgia, Athens, GA; University of Virginia, Charlottesville, VA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1120","1132","Software systems may contain critical program components such as patented program logic or sensitive data. When those components are reverse-engineered by adversaries, it can cause significantly damage (e.g., financial loss or operational failures). While protecting critical program components (e.g., code or data) in software systems is of utmost importance, existing approaches, unfortunately, have two major weaknesses: (1) they can be reverse-engineered via various program analysis techniques and (2) when an adversary obtains a legitimate-looking critical program component, he or she can be sure that it is genuine. In this paper, we propose Ambitr, a novel technique that hides critical program components. The core of Ambitr is Ambiguous Translator that can generate the critical program components when the input is a correct secret key. The translator is ambiguous as it can accept any inputs and produces a number of legitimate-looking outputs, making it difficult to know whether an input is correct secret key or not. The executions of the translator when it processes the correct secret key and other inputs are also indistinguishable, making the analysis inconclusive. Our evaluation results show that static, dynamic and symbolic analysis techniques fail to identify the hidden information in Ambitr. We also demonstrate that manual analysis of Ambitr is extremely challenging.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510139","NSF(grant numbers:1916499,1908021,2047980,1850392,1853374,1924777,2145616,2047980); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794005","program translation;software protection;reverse engineering","Codes;Manuals;Software systems;Performance analysis;Software engineering","","","","83","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Simulation-based abstractions for software product-line model checking","M. Cordy; A. Classen; G. Perrouin; P. -Y. Schobbens; P. Heymans; A. Legay","PReCISE Research Center, University of Namur, Belgium; PReCISE Research Center, University of Namur, Belgium; PReCISE Research Center, University of Namur, Belgium; PReCISE Research Center, University of Namur, Belgium; PReCISE Research Center, University of Namur, Belgium; INRIA Rennes, IRISA, France",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","672","682","Software Product Line (SPL) engineering is a software engineering paradigm that exploits the commonality between similar software products to reduce life cycle costs and time-to-market. Many SPLs are critical and would benefit from efficient verification through model checking. Model checking SPLs is more difficult than for single systems, since the number of different products is potentially huge. In previous work, we introduced Featured Transition Systems (FTS), a formal, compact representation of SPL behaviour, and provided efficient algorithms to verify FTS. Yet, we still face the state explosion problem, like any model checking-based verification. Model abstraction is the most relevant answer to state explosion. In this paper, we define a novel simulation relation for FTS and provide an algorithm to compute it. We extend well-known simulation preservation properties to FTS and thus lay the theoretical foundations for abstraction-based model checking of SPLs. We evaluate our approach by comparing the cost of FTS-based simulation and abstraction with respect to product-by-product methods. Our results show that FTS are a solid foundation for simulation-based model checking of SPL.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227150","Model Checking;Software Product Lines;Formal methods;Simulation;Abstraction;Feature","Computational modeling;Radio frequency;Software;Abstracts;Silicon;Semantics;Educational institutions","","32","","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"The Road Toward Dependable AI Based Systems","P. Tonella","Software Institute, Università della Svizzera italiana (USI), Lugano, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2","2","With the advent of deep learning, AI components have achieved unprecedented performance on complex, human competitive tasks, such as image, video, text and audio processing. Hence, they are increasingly integrated into sophisticated software systems, some of which (e.g., autonomous vehicles) are required to deliver certified dependability warranties. In this talk, I will consider the unique features of AI based systems and of the faults possibly affecting them, in order to revise the testing fundamentals and redefine the overall goal of testing, taking a statistical view on the dependability warranties that can be actually delivered. Then, I will consider the key elements of a revised testing process for AI based systems, including the test oracle and the test input generation problems. I will also introduce the notion of runtime supervision, to deal with unexpected error conditions that may occur in the field. Finally, I will identify the future steps that are essential to close the loop from testing to operation, proposing an empirical framework that reconnects the output of testing to its original goals.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172847","Software Testing;Deep Learning;Reliability and Dependability","Testing;Warranties;Indexes;Deep learning;Task analysis;Software testing;Software systems","","1","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Fairness Improvement with Multiple Protected Attributes: How Far Are We?","Z. Chen; J. M. Zhang; F. Sarro; M. Harman","University College London, London, United Kingdom; King's College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1971","1983","Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on F1-score when handling two protected attributes is about twice that of a single attribute. This has important implications for future fairness research: reporting only accuracy as the ML performance metric, which is currently common in the literature, is inadequate.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548849","Fairness improvement;machine learning;protected attributes;intersectional fairness","Measurement;Analytical models;Correlation;Machine learning;Benchmark testing;Software;Software engineering","","","","67","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"“This Is Damn Slick!” Estimating the Impact of Tweets on Open Source Project Popularity and New Contributors","H. Fang; H. Lamba; J. Herbsleb; B. Vasilescu","Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2116","2129","Twitter is widely used by software developers. But how effective are tweets at promoting open source projects? How could one use Twitter to increase a project's popularity or attract new contributors? In this paper we report on a mixed-methods empirical study of 44,544 tweets containing links to 2,370 open-source GitHub repositories, looking for evidence of causal effects of these tweets on the projects attracting new GitHub stars and contributors, as well as characterizing the high-impact tweets, the people likely being attracted by them, and how they differ from contributors attracted otherwise. Among others, we find that tweets have a statistically significant and practically sizable effect on obtaining new stars and a small average effect on attracting new contributors. The popularity, content of the tweet, as well as the identity of tweet authors all affect the scale of the attraction effect. In addition, our qualitative analysis suggests that forming an active Twitter community for an open source project plays an important role in attracting new committers via tweets. We also report that developers who are new to GitHub or have a long history of Twitter usage but few tweets posted are most likely to be attracted as contributors to the repositories mentioned by tweets. Our work contributes to the literature on open source sustainability.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510121","NSF(grant numbers:1546393,1633083,1717415,1901311); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794070","Open source software;GitHub;Twitter;Promotion","Social networking (online);Blogs;Stars;History;Sustainable development;Open source software;Software development management","","3","","73","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Socio-Technical Anti-Patterns in Building ML-Enabled Software: Insights from Leaders on the Forefront","A. Mailach; N. Siegmund","ScaDS.AI, Leipzig University, Dresden/Leipzig; ScaDS.AI, Leipzig University, Dresden/Leipzig",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","690","702","Although machine learning (ML)-enabled software systems seem to be a success story considering their rise in economic power, there are consistent reports from companies and practitioners struggling to bring ML models into production. Many papers have focused on specific, and purely technical aspects, such as testing and pipelines, but only few on socio-technical aspects. Driven by numerous anecdotes and reports from practitioners, our goal is to collect and analyze socio-technical challenges of productionizing ML models centered around and within teams. To this end, we conducted the largest qualitative empirical study in this area, involving the manual analysis of 66 hours of talks that have been recorded by the MLOps community. By analyzing talks from practitioners for practitioners of a community with over 11,000 members in their Slack workspace, we found 17 anti-patterns, often rooted in organizational or management problems. We further list recommendations to overcome these problems, ranging from technical solutions over guidelines to organizational restructuring. Finally, we contextu-alize our findings with previous research, confirming existing results, validating our own, and highlighting new insights.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00067","German Research Foundation(grant numbers:SI 2171/2-2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172624","","Economics;Biological system modeling;Pipelines;Production;Manuals;Machine learning;Software systems","","4","","102","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A Theory of Scientific Programming Efficacy","E. Pertseva; M. Chang; U. Zaman; M. Coblenz","Stanford University, Stanford, California, USA; Canyon Crest Academy, San Diego, California, USA; University of California Irvine, Irvine, California, USA; University of California San Diego, La Jolla, California, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2369","2380","Scientists write and maintain software artifacts to construct, validate, and apply scientific theories. Despite the centrality of software in their work, their practices differ significantly from those of professional software engineers. We sought to understand what makes scientists effective at their work and how software engineering practices and tools can be adapted to fit their workflows. We interviewed 25 scientists and support staff to understand their work. Then, we constructed a theory that relates six factors that contribute to their efficacy in creating and maintaining software systems. We present the theory in the form of a cycle of scientific computing efficacy and identify opportunities for improvement based on the six contributing factors.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549486","Scientific programming;qualitative study of programmers","Smoothing methods;Scientific computing;Education;Collaboration;Writing;Software systems;Encoding","","","","51","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Improving Testing Behavior by Gamifying IntelliJ","P. Straubinger; G. Fraser","University of Passau, Passau, Germany; University of Passau, Passau, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","578","590","Testing is an important aspect of software development, but unfor-tunately, it is often neglected. While test quality analyses such as code coverage or mutation analysis inform developers about the quality of their tests, such reports are viewed only sporadically during continuous integration or code review, if they are considered at all, and their impact on the developers' testing behavior therefore tends to be negligible. To actually influence developer behavior, it may rather be necessary to motivate developers directly within their programming environment, while they are coding. We introduce IntelliGame, a gamified plugin for the popular IntelliJ Java Inte-grated Development Environment, which rewards developers for positive testing behavior using a multi-level achievement system: A total of 27 different achievements, each with incremental levels, provide affirming feedback when developers exhibit commendable testing behavior, and provide an incentive to further continue and improve this behavior. A controlled experiment with 49 participants given a Java programming task reveals substantial differences in the testing behavior triggered by IntelliGame: Incentivized developers write more tests, achieve higher coverage and mutation scores, run their tests more often, and achieve functionality earlier.","1558-1225","979-8-4007-0217-4","","DFG(grant numbers:FR 2955/2-1); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548175","CCS CONCEPTS;Software and its engineering → Software testing and debug-ging;Integrated and visual development environments;Gamification;IDE;IntelliJ;Software Testing","Software testing;Java;Visualization;Codes;Reviews;Source coding;Software","","","","60","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Using Reactive Synthesis: An End-to-End Exploratory Case Study","D. Ma'ayan; S. Maoz","Tel Aviv University, Israel; Tel Aviv University, Israel",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","742","754","Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. Despite its attractiveness and major research progress in the past decades, reactive synthesis is still in early-stage and has not gained popularity outside academia. We conducted an exploratory case study in which we followed students in a semester-long university workshop class on their end-to-end use of a reactive synthesizer, from writing the specifications to executing the synthesized controllers. The data we collected includes more than 500 versions of more than 80 specifications, as well as more than 2500 Slack messages, all written by the class participants. Our grounded theory analysis reveals that the use of reactive synthesis has clear benefits for certain tasks and that adequate specification language constructs assist in the specification writing process. However, inherent issues such as unrealizabilty, non-well-separation, the gap of knowledge between the users and the synthesizer, and considerable running times prevent reactive synthesis from fulfilling its promise. Based on our analysis, we propose action items in the directions of language and specification quality, tools for analysis and execution, and process and methodology, all towards making reactive synthesis more applicable for software engineers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00071","European Research Council(grant numbers:101069165); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172599","Reactive synthesis;Formal specifications","Synthesizers;Conferences;Metals;Debugging;Writing;Software;Specification languages","","2","","76","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"How Are Paid and Volunteer Open Source Developers Different? A Study of the Rust Project","Y. Zhang; M. Qin; K. -J. Stol; M. Zhou; H. Liu","Beijing Institute of Technology School of Computer Science & Technology, Beijing, China; Beijing Institute of Technology School of Computer Science & Technology, Beijing, China; University College Cork and Lero School of Computer Science and IT, Cork, Ireland; Peking University School of Computer Science, Beijing, China; Beijing Institute of Technology School of Computer Science & Technology, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2406","2418","It is now commonplace for organizations to pay developers to work on specific open source software (OSS) projects to pursue their business goals. Such paid developers work alongside voluntary contributors, but given the different motivations of these two groups of developers, conflict may arise, which may pose a threat to a project's sustainability. This paper presents an empirical study of paid developers and volunteers in Rust, a popular open source programming language project. Rust is a particularly interesting case given considerable concerns about corporate participation. We compare volunteers and paid developers through contribution characteristics and long-term participation, and solicit volunteers' perceptions on paid developers. We find that core paid developers tend to contribute more frequently; commits contributed by onetime paid developers have bigger sizes; peripheral paid developers implement more features; and being paid plays a positive role in becoming a long-term contributor. We also find that volunteers do have some prejudices against paid developers. This study suggests that the dichotomous view of paid vs. volunteer developers is too simplistic and that further subgroups can be identified. Companies should become more sensitive to how they engage with OSS communities, in certain ways as suggested by this study.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639197","National Natural Science Foundation of China(grant numbers:62141209,62202048,61825201,62232003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549186","Open source software;paid developers;volunteers;sustainability","Computer languages;Companies;Sustainable development;Open source software;Software engineering","","","","95","","14 Jun 2024","","","IEEE","IEEE Conferences"
"DeepStability: A Study of Unstable Numerical Methods and Their Solutions in Deep Learning","E. Kloberdanz; K. G. Kloberdanz; W. Le","Department of Computer Science, Iowa State University; Cape Privacy; Department of Computer Science, Iowa State University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","586","597","Deep learning (DL) has become an integral part of solutions to various important problems, which is why ensuring the quality of DL systems is essential. One of the challenges of achieving reliability and robustness of DL software is to ensure that algorithm implementations are numerically stable. DL algorithms require a large amount and a wide variety of numerical computations. A naive implementation of numerical computation can lead to errors that may result in incorrect or inaccurate learning and results. A numerical algorithm or a mathematical formula can have several implementations that are mathematically equivalent, but have different numerical stability properties. Designing numerically stable algorithm implementations is challenging, because it requires an interdisciplinary knowledge of software engineering, DL, and numerical analysis. In this paper, we study two mature DL libraries PyTorch and Tensorflow with the goal of identifying unstable numerical methods and their solutions. Specifically, we investigate which DL algorithms are numerically unstable and conduct an in-depth analysis of the root cause, manifestation, and patches to numerical instabilities. Based on these findings, we launch DeepStability, the first database of numerical stability issues and solutions in DL. Our findings and DeepStability provide future references to developers and tool builders to prevent, detect, localize and fix numerically unstable algorithm implementations. To demonstrate that, using DeepStability we have located numerical stability issues in Tensorflow, and submitted a fix which has been accepted and merged in.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794088","numerical stability;deep learning;numerical algorithms","Deep learning;Knowledge engineering;Databases;Software algorithms;Software;Robustness;Libraries","","3","","28","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"A Grounded Theory Based Approach to Characterize Software Attack Surfaces","S. Moshtari; A. Okutan; M. Mirakhorli","Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","13","24","The notion of Attack Surface refers to the critical points on the boundary of a software system which are accessible from outside or contain valuable content for attackers. The ability to identify attack surface components of software system has a significant role in effectiveness of vulnerability analysis approaches. Most prior works focus on vulnerability techniques that use an approximation of attack surfaces and there have not been many attempts to create a comprehensive list of attack surface components. Although limited number of studies have focused on attack surface analysis, they defined attack surface components based on project specific hypotheses to evaluate security risk of specific types of software applications. In this study, we leverage a qualitative analysis approach to empirically identify an extensive list of attack surface components. To this end, we conduct a Grounded Theory (GT) analysis on 1444 previously published vulnerability reports and weaknesses with a team of three software developers and security experts. We extract vulnerability information from two publicly available repositories: 1) Common Vulnerabilities and Exposures (CVE) and 2) Common Weakness Enumeration (CWE). We ask three key questions: where the attacks come from, what they target, and how they emerge, and to help answer these questions we define three core categories for attack surface components: Entry points, Targets, and Mechanisms. We extract attack surface concepts related to each category from collected vulnerability information using the GT analysis and provide a comprehensive categorization that represents attack surface components of software systems from various perspectives. The paper introduces 254 new attack surface components that did not exist in the literature. The comparison of the proposed attack surface model with prior works indicates that only 6.7% of the identified Code level attack surface components are studied before.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794016","Software Security;Attack Surface;Grounded Theory;Qualitative Analysis","Analytical models;Codes;Systematics;Bibliographies;Software systems;Security;Data mining","","","","39","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Did We Miss Something Important? Studying and Exploring Variable-Aware Log Abstraction","Z. Li; C. Luo; T. -H. Chen; W. Shang; S. He; Q. Lin; D. Zhang","Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Microsoft Research, China; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada; Microsoft Research, China; Microsoft Research, China; Microsoft Research, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","830","842","Due to the sheer size of software logs, developers rely on automated techniques for log analysis. One of the first and most important steps of automated log analysis is log abstraction, which parses the raw logs into a structured format. Prior log abstraction techniques aim to identify and abstract all the dynamic variables in logs and output a static log template for automated log analysis. However, these abstracted dynamic variables may also contain important information that is useful to different tasks in log analysis. In this paper, we investigate the characteristics of dynamic variables and their importance in practice, and explore the potential of a variable-aware log abstraction technique. Through manual investigations and surveys with practitioners, we find that different categories of dynamic variables record various information that can be important depending on the given tasks, the distinction of dynamic variables in log abstraction can further assist in log analysis. We then propose a deep learning based log abstraction approach, named VALB, which can identify different categories of dynamic variables and preserve the value of specified categories of dynamic variables along with the log templates (i.e., variable-aware log abstraction). Through the evaluation on a widely used log abstraction benchmark, we find that VALB outperforms other state-of-the-art log abstraction techniques on general log abstraction (i.e., when abstracting all the dynamic variables) and also achieves a high variable-aware log abstraction accuracy that further identifies the category of the dynamic variables. Our study highlights the potential of leveraging the important information recorded in the dynamic variables to further improve the process of log analysis.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172652","software logs;log abstraction;deep learning","Surveys;Deep learning;Manuals;Benchmark testing;Software;Task analysis;Software engineering","","8","","69","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Generating range fixes for software configuration","Y. Xiong; A. Hubaux; S. She; K. Czarnecki","Generative Software Development Lab, University of Waterloo, Canada; PReCISE Research Centre, University of Namur, Belgium; Generative Software Development Lab, University of Waterloo, Canada; Generative Software Development Lab, University of Waterloo, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","58","68","To prevent ill-formed configurations, highly configurable software often allows defining constraints over the available options. As these constraints can be complex, fixing a configuration that violates one or more constraints can be challenging. Although several fix-generation approaches exist, their applicability is limited because (1) they typically generate only one fix, failing to cover the solution that the user wants; and (2) they do not fully support non-Boolean constraints, which contain arithmetic, inequality, and string operators. This paper proposes a novel concept, range fix, for software configuration. A range fix specifies the options to change and the ranges of values for these options. We also design an algorithm that automatically generates range fixes for a violated constraint. We have evaluated our approach with three different strategies for handling constraint interactions, on data from five open source projects. Our evaluation shows that, even with the most complex strategy, our approach generates complete fix lists that are mostly short and concise, in a fraction of a second.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227206","","Semantics;Algorithm design and analysis;Software;Linux;Reactive power;Concrete;Navigation","","33","1","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Evaluating Code Summarization Techniques: A New Metric and an Empirical Characterization","A. Mastropaolo; M. Ciniselli; M. Di Penta; G. Bavota","SEART @ Software Institute, Università della Svizzera Italiana, Lugano, CH, Switzerland; SEART @ Software Institute, Università della Svizzera Italiana, Lugano, CH, Switzerland; Dept. of Engineering, University of Sannio, Benevento, IT, Italy; SEART @ Software Institute, Università della Svizzera Italiana, Lugano, CH, Switzerland",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2694","2706","Several code summarization techniques have been proposed in the literature to automatically document a code snippet or a function. Ideally, software developers should be involved in assessing the quality of the generated summaries. However, in most cases, researchers rely on automatic evaluation metrics such as BLEU, ROUGE, and METEOR. These metrics are all based on the same assumption: The higher the textual similarity between the generated summary and a reference summary written by developers, the higher its quality. However, there are two reasons for which this assumption falls short: (i) reference summaries, e.g., code comments collected by mining software repositories, may be of low quality or even outdated; (ii) generated summaries, while using a different wording than a reference one, could be semantically equivalent to it, thus still being suitable to document the code snippet. In this paper, we perform a thorough empirical investigation on the complementarity of different types of metrics in capturing the quality of a generated summary. Also, we propose to address the limitations of existing metrics by considering a new dimension, capturing the extent to which the generated summary aligns with the semantics of the documented code snippet, independently from the reference summary. To this end, we present a new metric based on contrastive learning to capture said aspect. We empirically show that the inclusion of this novel dimension enables a more effective representation of developers' evaluations regarding the quality of automatically generated summaries.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639174","European Research Council (ERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548808","Software and its engineering → Documentation;Code Summarization;Contrastive Learning","Measurement;Codes;Semantics;Focusing;Documentation;Software;Meteors","","1","","97","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Integrated impact analysis for managing software changes","M. Gethers; B. Dit; H. Kagdi; D. Poshyvanyk","Computer Science Department, The College of William and Mary, Williamsburg, VA, USA; Computer Science Department, The College of William and Mary, Williamsburg, VA, USA; Department of Computer Science, Wichita State University, Wichita, KS, USA; Computer Science Department, The College of William and Mary, Williamsburg, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","430","440","The paper presents an adaptive approach to perform impact analysis from a given change request to source code. Given a textual change request (e.g., a bug report), a single snapshot (release) of source code, indexed using Latent Semantic Indexing, is used to estimate the impact set. Should additional contextual information be available, the approach configures the best-fit combination to produce an improved impact set. Contextual information includes the execution trace and an initial source code entity verified for change. Combinations of information retrieval, dynamic analysis, and data mining of past source code commits are considered. The research hypothesis is that these combinations help counter the precision or recall deficit of individual techniques and improve the overall accuracy. The tandem operation of the three techniques sets it apart from other related solutions. Automation along with the effective utilization of two key sources of developer knowledge, which are often overlooked in impact analysis at the change request level, is achieved. To validate our approach, we conducted an empirical evaluation on four open source software systems. A benchmark consisting of a number of maintenance issues, such as feature requests and bug fixes, and their associated source code changes was established by manual examination of these systems and their change history. Our results indicate that there are combinations formed from the augmented developer contextual information that show statistically significant improvement over standalone approaches.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227172","","Software;Couplings;Data mining;Maintenance engineering;History;Information retrieval;Automation","","76","4","35","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"High Expectations: An Observational Study of Programming and Cannabis Intoxication","W. He; M. Parikh; W. Weimer; M. Endres","University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2381","2392","Anecdotal evidence of cannabis use by professional programmers abounds. Recent studies have found that some professionals regularly use cannabis while programming, even for work-related tasks. However, accounts of the impacts of cannabis on programming vary widely and are often contradictory. For example, some programmers claim that it impairs their ability to generate correct solutions, while others claim it enhances creativity and focus. There remains a need for an empirical understanding of the true impacts of cannabis on programming. This paper presents the first controlled observational study of cannabis's effects on programming ability. Based on a within-subjects design with over 70 participants, we find that, at ecologically valid dosages, cannabis significantly impairs programming performance. Programs implemented while high contain more bugs and take longer to write $(p < 0.05)$-a small to medium effect $(0.22\ \leq d \leq 0.44)$. We also did not find any evidence that high programmers generate more divergent solutions. However, programmers can accurately assess differences in their programming performance $(r=0.59)$ even when under the influence of cannabis. We hope that this research will facilitate evidence-based policies and help developers make informed decisions regarding cannabis use while programming.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549469","programming preferences;cannabis;controlled user study;drug policy;preregistered hypotheses","Computer bugs;Software;History;Task analysis;Programming profession;Creativity;Software engineering","","","","54","","14 Jun 2024","","","IEEE","IEEE Conferences"
"“My GitHub Sponsors Profile is Live!” Investigating the Impact of Twitter/X Mentions on GitHub Sponsors","Y. Fan; T. Xiao; H. Hata; C. Treude; K. Matsumoto","Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Shinshu University, Japan; University of Melbourne, Australia; Nara Institute of Science and Technology, Japan",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2357","2368","GitHub Sponsors was launched in 2019, enabling donations to open-source software developers to provide financial support, as per GitHub's slogan: “Invest in the projects you depend on”. However, a 2022 study on GitHub Sponsors found that only two-fifths of developers who were seeking sponsorship received a donation. The study found that, other than internal actions (such as offering perks to sponsors), developers had advertised their GitHub Spon-sors profiles on social media, such as Twitter (also known as X). Therefore, in this work, we investigate the impact of tweets that contain links to GitHub Sponsors profiles on sponsorship, as well as their reception on Twitter/X. We further characterize these tweets to understand their context and find that (1) such tweets have the impact of increasing the number of sponsors acquired, (2) compared to other donation platforms such as Open Collective and Patreon, GitHub Sponsors has significantly fewer interactions but is more visible on Twitter/X, and (3) developers tend to contribute more to open-source software during the week of posting such tweets. Our findings are the first step toward investigating the impact of social media on obtaining funding to sustain open-source software.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548089","Open-source Software;Sponsorship;Social Media","Social networking (online);Ecosystems;Blogs;Media;Sustainable development;Open source software;Software development management","","","","49","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Understanding the impact of Pair Programming on developers attention: A case study on a large industrial experimentation","A. Sillitti; G. Succi; J. Vlasenko","Center for Applied Software Engineering, Free University of Bolzano-Bozen, Bozen/Bolzano, Italy; Center for Applied Software Engineering, Free University of Bolzano-Bozen, Bozen/Bolzano, Italy; Center for Applied Software Engineering, Free University of Bolzano-Bozen, Bozen/Bolzano, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1094","1101","Pair Programming is one of the most studied and debated development techniques. However, at present, we do not have a clear, objective, and quantitative understanding of the claimed benefits of such development approach. All the available studies focus on the analysis of the effects of Pair Programming (e.g., code quality, development speed, etc.) with different findings and limited replicability of the experiments. This paper adopts a different approach that could be replicated in an easier way: it investigates how Pair Programming affects the way developers write code and interact with their development machine. In particular, the paper focuses on the effects that Pair Programming has on developers' attention and productivity. The study was performed on a professional development team observed for ten months and it finds out that Pair Programming helps developers to eliminate distracting activities and to focus on productive activities.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227110","Software development process;productivity;pair programming","Switches;Visualization;Browsers;Programming profession;PROM;Productivity","","37","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"How Do Developers' Profiles and Experiences Influence their Logging Practices? An Empirical Study of Industrial Practitioners","G. Rong; S. Gu; H. Shen; H. Zhang; H. Kuang","State Key Laboratory For Novel Software Technology, Nonjing University, Nanjing, China; State Key Laboratory For Novel Software Technology, Nonjing University, Nanjing, China; HilstLab, Peter Faber Business School, Australian Catholic University, Sydney, Australia; State Key Laboratory For Novel Software Technology, Nonjing University, Nanjing, China; State Key Laboratory For Novel Software Technology, Nonjing University, Nanjing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","855","867","Logs record the behavioral data of running programs and are typically generated by executing log statements. Software developers generally carry out logging practices with clear intentions and associated concerns (I&Cs). However, I&Cs may not be properly fulfilled in source code as log placement - specifically determination of a log statement's context and content - is often susceptible to an individual's profile and experience. Some industrial studies have been conducted to discern developers' main logging I&Cs and the way I&Cs are fulfilled. However, the findings are only based on the developers from a single company in each individual study and hence have limited generalizability. More importantly, there lacks a comprehensive and deep understanding of the relationships between developers' profiles and experiences and their logging practices from a wider perspective. To fill this significant gap, we conducted an empirical study using mixed methods comprising questionnaire surveys, semi-structured interviews, and code analyses with practitioners from a wide range of companies across a variety of industrial domains. Results reveal that while developers share common logging I&Cs and conduct logging practices mainly in the coding stage, their profiles and experiences profoundly influence their logging I&Cs and the way the I&Cs are fulfilled. These findings pave the way to facilitate the acceptance of important logging I&Cs and the adoption of good logging practices by developers","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172853","Logging practice;Intention;Concern;Fulfill","Training;Surveys;Systematics;Source coding;Companies;Software systems;Behavioral sciences","","","","42","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Combining functional and imperative programming for multicore software: An empirical study evaluating Scala and Java","V. Pankratius; F. Schmidt; G. Garretón","Karlsruhe Institute of Technology, Karlsruhe, Germany; Oracle Laboratories, Oracle Corporation, Redwood Shores, CA, USA; Oracle Laboratories, Oracle Corporation, Redwood Shores, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","123","133","Recent multi-paradigm programming languages combine functional and imperative programming styles to make software development easier. Given today's proliferation of multicore processors, parallel programmers are supposed to benefit from this combination, as many difficult problems can be expressed more easily in a functional style while others match an imperative style. Due to a lack of empirical evidence from controlled studies, however, important software engineering questions are largely unanswered. Our paper is the first to provide thorough empirical results by using Scala and Java as a vehicle in a controlled comparative study on multicore software development. Scala combines functional and imperative programming while Java focuses on imperative shared-memory programming. We study thirteen programmers who worked on three projects, including an industrial application, in both Scala and Java. In addition to the resulting 39 Scala programs and 39 Java programs, we obtain data from an industry software engineer who worked on the same project in Scala. We analyze key issues such as effort, code, language usage, performance, and programmer satisfaction. Contrary to popular belief, the functional style does not lead to bad performance. Average Scala run-times are comparable to Java, lowest run-times are sometimes better, but Java scales better on parallel hardware. We confirm with statistical significance Scala's claim that Scala code is more compact than Java code, but clearly refute other claims of Scala on lower programming effort and lower debugging effort. Our study also provides explanations for these observations and shows directions on how to improve multi-paradigm languages in the future.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227200","","Java;Debugging;Multicore processing;Software;Testing;Parallel programming","","29","1","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Multi-Intention-Aware Configuration Selection for Performance Tuning","H. He; Z. Jia; S. Li; Y. Yu; C. Zhou; Q. Liao; J. Wang; X. Liao","National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; Harbin Institute of Technology, Shenzhen, China; National University of Defense Technology, China; National University of Defense Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1431","1442","Automatic configuration tuning helps users who intend to improve software performance. However, the auto-tuners are limited by the huge configuration search space. More importantly, they fo-cus only on performance improvement while being unaware of other important user intentions (e.g., reliability, security). To re-duce the search space, researchers mainly focus on pre-selecting performance-related parameters which requires a heavy stage of dynamically running under different configurations to build per-formance models. Given that other important user intentions are not paid attention to, we focus on guiding users in pre-selecting performance-related parameters in general while warning about side-effects on non-performance intentions. We find that the con-figuration document often, if it does not always, contains rich in-formation about the parameters' relationship with diverse user intentions, but documents might also be long and domain-specific. In this paper, we first conduct a comprehensive study on 13 representative software containing 7,349 configuration parame-ters, and derive six types of ways in which configuration parame-ters may affect non-performance intentions. Guided by this study, we design SAFETUNE, a multi-intention-aware method that pre-selects important performance-related parameters and warns about their side-effects on non-performance intentions. Evaluation on target software shows that SAFETUNE correctly identifies 22–26 performance-related parameters that are missed by state-of-the-art tools but have significant performance impact (up to 14.7x). Furthermore, we illustrate eight representative cases to show that SAFETUNE can effectively prevent real-world and critical side-effects on other user intentions.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510094","National Natural Science Foundation of China(grant numbers:61872373); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793958","Performance tuning;user intention;non-performance property","Software performance;Software systems;Software reliability;Security;Tuning;Software engineering","","2","","61","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Data Quality Matters: A Case Study of Obsolete Comment Detection","S. Xu; Y. Yao; F. Xu; T. Gu; J. Xu; X. Ma","State Key Lab for Novel Software Technology, Nanjing University, China; State Key Lab for Novel Software Technology, Nanjing University, China; State Key Lab for Novel Software Technology, Nanjing University, China; Tiktok, USA; State Key Lab for Novel Software Technology, Nanjing University, China; State Key Lab for Novel Software Technology, Nanjing University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","781","793","Machine learning methods have achieved great success in many software engineering tasks. However, as a data-driven paradigm, how would the data quality impact the effectiveness of these methods remains largely unexplored. In this paper, we explore this problem under the context of just-in-time obsolete comment detection. Specifically, we first conduct data cleaning on the existing benchmark dataset, and empirically observe that with only 0.22% label corrections and even 15.0% fewer data, the existing obsolete comment detection approaches can achieve up to 10.7% relative accuracy improvement. To further mitigate the data quality issues, we propose an adversarial learning framework to simultaneously estimate the data quality and make the final predictions. Experimental evaluations show that this adversarial learning framework can further improve the relative accuracy by up to 18.1% compared to the state-of-the-art method. Although our current results are from the obsolete comment detection problem, we believe that the proposed two-phase solution, which handles the data quality issues through both the data aspect and the algorithm aspect, is also generalizable and applicable to other machine learning based software engineering tasks.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172689","Obsolete comment detection;machine learning for software engineering;data quality","Data integrity;Software algorithms;Semantics;Training data;Adversarial machine learning;Encoding;Cleaning","","2","","62","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"BugListener: Identifying and Synthesizing Bug Reports from Collaborative Live Chats","L. Shi; F. Mu; Y. Zhang; Y. Yang; J. Chen; X. Chen; H. Jiang; Z. Jiang; Q. Wang","Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; College of Intelligence and Computing, Tianjin University, Tianjin, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","299","311","In community-based software development, developers frequently rely on live-chatting to discuss emergent bugs/errors they encounter in daily development tasks. However, it remains a challenging task to accurately record such knowledge due to the noisy nature of interleaved dialogs in live chat data. In this paper, we first formulate the task of identifying and synthesizing bug reports from commu-nity live chats, and propose a novel approach, named BugListener, to address the challenges. Specifically, BugListener automates three sub-tasks: 1) Disentangle the dialogs from massive chat logs by using a Feed-Forward neural network; 2) Identify the bug-report dialogs from separated dialogs by leveraging the Graph neural net-work to learn the contextual information; 3) Synthesize the bug reports by utilizing Transfer Learning techniques to classify the sentences into: observed behaviors (OB), expected behaviors (EB), and steps to reproduce the bug (SR). BugListener is evaluated on six open source projects. The results show that: for bug report identification, BugListener achieves the average Fl of 77.74%, im-proving the best baseline by 12.96%; and for bug report synthesis task, BugListener could classify the OB, EB, and SR sentences with the F1 of 84.62%, 71.46%, and 73.13%, improving the best baselines by 9.32%,12.21%,10.91%, respectively. A human evaluation study also confirms the effectiveness of Bug Listener in generating relevant and accurate bug reports. These demonstrate the significant potential of applying BugListener in community-based software development, for promoting bug discovery and quality improvement.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510108","National Key Research and Development Program of China(grant numbers:2018YFB1403400); National Science Foundation of China(grant numbers:61802374,62002348,62072442,614220920020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793897","Bug Report Generation;Live Chats Mining;Open Source","Computer bugs;Transfer learning;Neural networks;Collaboration;Predictive models;Software;Behavioral sciences","","1","","80","","20 Jun 2022","","","IEEE","IEEE Conferences"
"MalwareTotal: Multi-Faceted and Sequence-Aware Bypass Tactics Against Static Malware Detection","S. He; C. Fu; H. Hu; J. Chen; J. Lv; S. Jiang","School of Cyber Science and Engineering, Huazhong Science and technology University, China; School of Cyber Science and Engineering, Huazhong Science and technology University, China; Pennsylvania State University, United States; School of Cyber Science and Engineering, Huazhong Science and technology University, China; School of Cyber Science and Engineering, Huazhong Science and technology University, China; School of Cyber Science and Engineering, Huazhong Science and technology University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2123","2134","Recent methods have demonstrated that machine learning (ML) based static malware detection models are vulnerable to adversarial attacks. However, the generated malware often fails to generalize to production-level anti-malware software (AMS), as they usually involve multiple detection methods. This calls for universal solutions to the problem of malware variants generation. In this work, we demonstrate how the proposed method, MalwareTotal, has allowed malware variants to continue to abound in ML-based, signature-based, and hybrid anti-malware software. Given a malicious binary, we develop sequential bypass tactics that enable malicious behavior to be concealed within multi-faceted manipulations. Through 12 experiments on real-world malware, we demonstrate that an attacker can consistently bypass detection (98.67%, and 100% attack success rate against ML-based methods EMBER and MalConv, respectively; 95.33%, 92.63%, and 98.52% attack success rate against production-level anti-malware software ClamAV, AMS A, and AMS B, respectively) without modifying the malware functionality. We further demonstrate that our approach outperforms state-of-the-art adversarial malware generation techniques both in attack success rate and query consumption (the number of queries to the target model). Moreover, the samples generated by our method have demonstrated transferability in the real-world integrated malware detector, VirusTotal. In addition, we show that common mitigation such as adversarial training on known attacks cannot effectively defend against the proposed attack. Finally, we investigate the value of the generated adversarial examples as a means of hardening victim models through an adversarial training procedure, and demonstrate that the accuracy of the retrained model against generated adversarial examples increases by 88.51 percentage points.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639141","National Natural Science Foundation of China(grant numbers:62072200); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548910","Anti-malware software robustness;black-box attacks;binary manipulation","Training;Pipelines;Detectors;Pressing;Software systems;Malware;Space exploration","","","","73","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Prompting Is All You Need: Automated Android Bug Replay with Large Language Models","S. Feng; C. Chen","Monash University, Melbourne, Australia; Monash University, Melbourne, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","803","815","Bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while using the software. As such, researchers have committed considerable resources toward automating bug replay to expedite the process of software maintenance. Nonetheless, the success of current au-tomated approaches is largely dictated by the characteristics and quality of bug reports, as they are constrained by the limitations of manually-crafted patterns and predefined vocabulary lists. In-spired by the success of Large Language Models (LLMs) in natural language understanding, we propose AdbGPT, a new lightweight approach to automatically reproduce the bugs from bug reports through prompt engineering, without any training and hard-coding effort. AdbGPT leverages few-shot learning and chain-of-thought reasoning to elicit human knowledge and logical reasoning from LLMs to accomplish the bug replay in a manner similar to a devel-oper. Our evaluations demonstrate the effectiveness and efficiency of our AdbGPT to reproduce 81.3% of bug reports in 253.6 seconds, outperforming the state-of-the-art baselines and ablation studies. We also conduct a small-scale user study to confirm the usefulness of AdbGPT in enhancing developers' bug replay capabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548487","automated bug replay;large language model;prompt engineering","Training;Software maintenance;Vocabulary;Computer bugs;Manuals;Cognition;Natural language processing","","8","","86","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Test Selection for Unified Regression Testing","S. Wang; X. Lian; D. Marinov; T. Xu","University of Illinois at Urbana-Champaign, Urbana, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1687","1699","Today's software failures have two dominating root causes: code bugs and misconfigurations. To combat failure-inducing software changes, unified regression testing (URT) is needed to synergistically test the changed code and all changed production configurations for deployment reliability. However, URT could incur high cost, as it needs to run a large number of tests under multiple configurations. Regression test selection (RTS) can reduce regression testing cost. Unfortunately, no existing RTS technique reasons about code and configuration changes collectively. We introduce Unified Regression Test Selection (uRTS) to effectively reduce the cost of URT. uRTS supports project changes on 1) code only, 2) configurations only, and 3) both code and configurations. It selects regular tests and configuration tests with a unified selection algorithm. The uRTS algorithm analyzes code and configuration dependencies of each test across runs and across configurations. uRTS provides the same safety guarantee as the state-of-the-art RTS while selecting fewer tests and, more importantly, reducing the end-to-end testing time. We implemented uRTS on top of Ekstazi (a RTS tool for code changes) and Ctest (a configuration testing framework). We evaluate uRTS on hundreds of code revisions and dozens of configurations of five large projects. The results show that uRTS reduces the end-to-end testing time, on average, by 3.64X compared to executing all tests and 1.87X compared to a competitive reference solution that directly extends RTS for URT.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00145","NSF(grant numbers:CCF-1763788,CCF-1956374,CNS-2145295); Microsoft; Qualcomm; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172797","","Codes;Costs;Computer bugs;Production;Reliability engineering;Software;Software reliability","","1","","89","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"The Art and Practice of Data Science Pipelines: A Comprehensive Study of Data Science Pipelines In Theory, In-The-Small, and In-The-Large","S. Biswas; M. Wardat; H. Rajan","Iowa State University, Ames, IA, USA; Iowa State University, Ames, IA, USA; Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2091","2103","Increasingly larger number of software systems today are including data science components for descriptive, predictive, and prescriptive analytics. The collection of data science stages from acquisition, to cleaning/curation, to modeling, and so on are referred to as data science pipelines. To facilitate research and practice on data science pipelines, it is essential to understand their nature. What are the typical stages of a data science pipeline? How are they connected? Do the pipelines differ in the theoretical representations and that in the practice? Today we do not fully understand these architectural characteristics of data science pipelines. In this work, we present a three-pronged comprehensive study to answer this for the state-of-the-art, data science in-the-small, and data science in-the-large, Our study analyzes three datasets: a collection of 71 proposals for data science pipelines and related concepts in theory, a collection of over 105 implementations of curated data science pipelines from Kaggle competitions to understand data science in-the-small, and a collection of 21 mature data science projects from GitHub to understand data science in-the-large. Our study has led to three representations of data science pipelines that capture the essence of our subjects in theory, in-the-small, and in-the-large.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793883","data science pipelines;data science processes;descriptive;predictive","Feedback loop;Art;Pipelines;Data science;Software systems;Data models;Proposals","","9","","96","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"The Extent of Orphan Vulnerabilities from Code Reuse in Open Source Software","D. Reid; M. Jahanshahi; A. Mockus","University of Tennessee, Knoxville, TN, USA; University of Tennessee, Knoxville, TN, USA; University of Tennessee, Knoxville, TN, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2104","2115","Motivation: A key premise of open source software is the ability to copy code to other open source projects (white-box reuse). Such copying accelerates development of new projects, but the code flaws in the original projects, such as vulnerabilities, may also spread even if fixed in the projects from where the code was appropriated. The extent of the spread of vulnerabilities through code reuse, the potential impact of such spread, or avenues for mitigating risk of these secondary vulnerabilities has not been studied in the context of a nearly complete collection of open source code. Aim: We aim to find ways to detect the white-box reuse induced vulnerabilities, determine how prevalent they are, and explore how they may be addressed. Method: We rely on World of Code infrastructure that provides a curated and cross-referenced collection of nearly all open source software to conduct a case study of a few known vulnerabilities. To conduct our case study we develop a tool, VDiOS, to help identify and fix white-box-reuse-induced vulnerabilities that have been already patched in the original projects (orphan vulnerabilities). Results: We find numerous instances of orphan vulnerabilities even in currently active and in highly popular projects (over 1K stars). Even apparently inactive projects are still publicly available for others to use and spread the vulnerability further. The often long delay in fixing orphan vulnerabilities even in highly popular projects increases the chances of it spreading to new projects. We provided patches to a number of project maintainers and found that only a small percentage accepted and applied the patch. We hope that VDiOS will lead to further study and mitigation of risks from orphan vulnerabilities and other orphan code flaws.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510216","NSF(grant numbers:1633437,1901102,1925615,2120429); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794064","code reuse;CVE;security vulnerabilities;git","Codes;Costs;Computer bugs;Stars;Delays;Security;Open source software","","5","","47","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Specification patterns from research to industry: A case study in service-based applications","D. Bianculli; C. Ghezzi; C. Pautasso; P. Senti","Faculty of Informatics, University of Lugano, Lugano, Switzerland; DEEPSE group-DEI, Politecnico di Milano, Milano, Italy; Faculty of Informatics, University of Lugano, Lugano, Switzerland; Information Technology, Credit Suisse AG, Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","968","976","Specification patterns have proven to help developers to state precise system requirements, as well as formalize them by means of dedicated specification languages. Most of the past work has focused its applicability area to the specification of concurrent and real-time systems, and has been limited to a research setting. In this paper we present the results of our study on specification patterns for service-based applications (SBAs). The study focuses on industrial SBAs in the banking domain. We started by performing an extensive analysis of the usage of specification patterns in published research case studies - representing almost ten years of research in the area of specification, verification, and validation of SBAs. We then compared these patterns with a large body of specifications written by our industrial partner over a similar time period. The paper discusses the outcome of this comparison, indicating that some needs of the industry, especially in the area of requirements specification languages, are not fully met by current software engineering research.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227125","specification patterns;specification languages;requirements specifications;services","Pattern matching;Industries;Software engineering;Real time systems;Time factors;Software;Context","","33","","30","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Hashing It Out: A Survey of Programmers' Cannabis Usage, Perception, and Motivation","M. Endres; K. Boehnke; W. Weimer","University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1107","1119","Cannabis is one of the most common mind-altering substances. It is used both medicinally and recreationally and is enmeshed in a complex and changing legal landscape. Anecdotal evidence suggests that some software developers may use cannabis to aid some programming tasks. At the same time, anti-drug policies and tests remain common in many software engineering environments, sometimes leading to hiring shortages for certain jobs. Despite these connections, little is actually known about the prevalence of, and motivation for, cannabis use while programming. In this paper, we report the results of the first large-scale survey of cannabis use by programmers. We report findings about 803 developers' (in-cluding 450 full-time programmers') cannabis usage prevalence, perceptions, and motivations. For example, we find that some programmers do regularly use cannabis while programming: 35% of our sample has tried programming while using cannabis, and 18% currently do so at least once a month. Furthermore, this cannabis usage is primarily motivated by a perceived enhancement to cer-tain software development skills (such as brainstorming or getting into a programming zone) rather than medicinal reasons (such as pain relief). Finally, we find that cannabis use while programming occurs at similar rates for programming employees, managers, and students despite differences in cannabis perceptions and visibility. Our results have implications for programming job drug policies and motivate future research into cannabis use while programming.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510156","NSF(grant numbers:CCF 1908633,CCF 1763674); National Institute on Drug Abuse of the National Institutes of Health(grant numbers:K01DA049219); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793986","Software Development Process;Cannabis;Corporate Drug Policy","Drugs;Social networking (online);Pain;Law;Employment;Software;Task analysis","","5","","66","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Security testing of web applications: A research plan","A. Avancini","Fondazione Bruno Kessler (FBK), Trento, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1491","1494","Cross-site scripting (XSS) vulnerabilities are specific flaws related to web applications, in which missing input validation can be exploited by attackers to inject malicious code into the application under attack. To guarantee high quality of web applications in terms of security, we propose a structured approach, inspired by software testing. In this paper we present our research plan and ongoing work to use security testing to address problems of potentially attackable code. Static analysis is used to reveal candidate vulnerabilities as a set of execution conditions that could lead to an attack. We then resort to automatic test case generation to obtain those input values that make the application execution satisfy such conditions. Eventually, we propose a security oracle to assess whether such test cases are instances of successful attacks.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227054","","Security;Genetic algorithms;HTML;USA Councils;Conferences;Software testing","","6","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Predicting Open Source Contributor Turnover from Value-Related Discussions: An Analysis of GitHub Issues","J. Jamieson; N. Yamashita; E. Foong","NTT Communication Science Labs, Kyoto, Japan; NTT Communication Science Labs, Kyoto, Japan; Tokyo College, the University of Tokyo, Tokyo, Japan",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","678","690","Discussions about project values are important for engineering soft-ware that meets diverse human needs and positively impacts society. Because value-related discussions involve deeply held beliefs, they can lead to conflicts or other outcomes that may affect motivations to continue contributing to open source projects. However, it is unclear what kind of value-related discussions are associated with significant changes in turnover. We address this gap by identifying discussions related to important project values and investigating the extent to which those discussions predict project turnover in the following months. We collected logs of GitHub issues and commits from 52 projects that share similar ethical commitments and were identified as part of the DWeb (Decentralized Web) community. We identify issues related to DWeb's core values of respectfulness, free-dom, broadmindedness, opposing centralized social power, equity & equality, and protecting the environment. We then use Granger causality analysis to examine how changes in the proportion of discussions related to those values might predict changes in incoming and outgoing turnover. We found multiple significant relationships between value-related discussions and turnover, including that discussions about respectfulness predict an increase in contributors leaving and a decrease in new contributors, while discussions about social power predicted better contributor retention. Understanding these antecedents of contributor turnover is important for man-aging open source projects that incorporate human-centric issues. Based on the results, we discuss implications for open source maintainers and for future research.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548732","Human Values;turnover;open source;GitHub","Ethics;Buildings;Collaboration;Cause effect analysis;Software;Standards;Software development management","","","","80","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Code Bubbles: A practical working-set programming environment","S. P. Reiss; J. N. Bott; J. J. LaViola","Department of Computer Science, Brown University, Providence, RI, USA; Department of EECS, University of Central Florida, Orlando, FL, USA; Department of EECS, University of Central Florida, Orlando, FL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1411","1414","Our original work on the Code Bubbles environment demonstrated that a working-set based framework for software development showed promise. We have spent the past several years extending the underlying concepts into a fully-functional system. In our demonstration, we will show the current Code Bubbles environment for Java, how it works, how it can be used, and why we prefer it over more traditional programming environments. We will also show how we have extended the framework to enhance software development tasks such as complex debugging, testing, and collaboration. This paper describes the features we will demonstrate.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227235","integrated development environments;working sets;debugging;collaborative tools","Debugging;Context;Programming;Testing;Collaboration;History;Software engineering","","5","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CrashTranslator: Automatically Reproducing Mobile Application Crashes Directly from Stack Trace","Y. Huang; J. Wang; Z. Liu; Y. Wang; S. Wang; C. Chen; Y. Hu; Q. Wang","Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China; York University, Toronto, Canada; Monash University, Melbourne, Australia; Institute of Software, Chinese Academy of Sciences, Beijing, China; Institute of Software, Chinese Academy of Sciences, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","190","202","Crash reports are vital for software maintenance since they allow the developers to be informed of the problems encountered in the mobile application. Before fixing, developers need to reproduce the crash, which is an extremely time-consuming and tedious task. Existing studies conducted the automatic crash reproduction with the natural language described reproducing steps. Yet we find a non-neglectable portion of crash reports only contain the stack trace when the crash occurs. Such stack-trace-only crashes merely reveal the last GUI page when the crash occurs, and lack step-by-step guidance. Developers tend to spend more effort in understanding the problem and reproducing the crash, and existing techniques cannot work on this, thus calling for a greater need for automatic support. This paper proposes an approach named CrashTranslator to automatically reproduce mobile application crashes directly from the stack trace. It accomplishes this by leveraging a pre-trained Large Language Model to predict the exploration steps for triggering the crash, and designing a reinforcement learning based technique to mitigate the inaccurate prediction and guide the search holistically. We evaluate CrashTranslator on 75 crash reports involving 58 popular Android apps, and it successfully reproduces 61.3% of the crashes, outperforming the state-of-the-art baselines by 109% to 206%. Besides, the average reproducing time is 68.7 seconds, out-performing the baselines by 302% to 1611%. We also evaluate the usefulness of CrashTranslator with promising results.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548840","Bug reproduction;Stack trace;Mobile application testing","Software maintenance;Computer bugs;Reinforcement learning;Computer crashes;Mobile applications;Task analysis;Optimization","","","","74","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"HARPPIE: Hyper algorithmic recipe for productive parallelism intensive endeavors","P. Monteiro","CITI, Departamento de Informática, Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1559","1562","Over the last few years, Parallelism has been gaining increasing importance and multicore processing is now common. Massification of parallelism is driving research and development of novel techniques to overcome current limits of Parallel Computing. However, the scope of parallelization research focuses mainly on ever-increasing performance and much still remains to be accomplished regarding improving productivity in the development of parallel software. This PhD research aims to develop methods and tools to dilute parallel programming complexity and enable nonexpert programmer to fully benefit from a new generation of parallelism-driven programming platforms. Although much work remains to be done to reduce the skill requirements for parallel programming to become within reach of medium-skill programming workforces, it is our belief that this research will help bridge that gap.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227037","Parallelism;Concurrency;Model-driven software engineering;Generative programming","Parallel processing;Parallel programming;Productivity;Software;Algorithm design and analysis;Measurement","","","","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A tactic-centric approach for automating traceability of quality concerns","M. Mirakhorli; Y. Shin; J. Cleland-Huang; M. Cinar","School of Computing, De Paul University, Chicago, IL, USA; School of Computing, De Paul University, Chicago, IL, USA; School of Computing, De Paul University, Chicago, IL, USA; School of Computing, De Paul University, Chicago, IL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","639","649","The software architectures of business, mission, or safety critical systems must be carefully designed to balance an exacting set of quality concerns describing characteristics such as security, reliability, and performance. Unfortunately, software architectures tend to degrade over time as maintainers modify the system without understanding the underlying architectural decisions. Although this problem can be mitigated by manually tracing architectural decisions into the code, the cost and effort required to do this can be prohibitively expensive. In this paper we therefore present a novel approach for automating the construction of traceability links for architectural tactics. Our approach utilizes machine learning methods and lightweight structural analysis to detect tactic-related classes. The detected tactic-related classes are then mapped to a Tactic Traceability Information Model. We train our trace algorithm using code extracted from fifteen performance-centric and safety-critical open source software systems and then evaluate it against the Apache Hadoop framework. Our results show that automatically generated traceability links can support software maintenance activities while helping to preserve architectural qualities.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227153","Architecture;traceability;tactics;traceability information models","Heart beat;Training;Authentication;Open source software;Fault tolerance","","62","","31","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Hot clones: Combining search-driven development, clone management, and code provenance","N. Schwarz","University of Bern, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1628","1629","Code duplication is common in current programming-practice: programmers search for snippets of code, incorporate them into their projects and then modify them to their needs. In today's practice, no automated scheme is in place to inform both parties of any distant changes of the code. As code snippets continue to evolve both on the side of the user and on the side of the author, both may wish to benefit from remote bug fixes or refinements - authors may be interested in the actual usage of their code snippets, and researchers could gather information on clone usage. We propose to maintain a link between software clones across repositories and outline how the links can be created and maintained.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227221","clone detection;software maintenance;corrective clone management","Cloning;Software;Search engines;Computer bugs;USA Councils;Social network services;Databases","","1","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Rules of Engagement: Why and How Companies Participate in OSS","M. Guizani; A. A. Castro-Guzman; A. Sarma; I. Steinmacher","EECS. Oregon State University, Oregon, USA; Oregon State University, Oregon, USA; EECS. Oregon State University, Oregon, USA; Northern Arizona University, Arizona, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2617","2629","Company engagement in open source (OSS) is now the new norm. From large technology companies to startups, companies are participating in the OSS ecosystem by open-sourcing their technology, sponsoring projects through funding or paid developer time. However, our understanding of the OSS ecosystem is rooted in the “old world” model where individual contributors sustain OSS projects. In this work, we create a more comprehensive understanding of the hybrid OSS landscape by investigating what motivates companies to contribute and how they contribute to OSS. We conducted interviews with 20 participants who have different roles (e.g., CEO, OSPO Lead, Ecosystem Strategist) at 17 different companies of different sizes from large companies (e.g. Microsoft, RedHat, Google, Spotify) to startups. Data from semi-structured interviews reveal that company motivations can be categorized into four levels (Founders' Vision, Reputation, Business Advantage, and Reciprocity) and companies participate through different mechanisms (e.g., Developers' Time, Mentoring Time, Advocacy & Promotion Time), each of which tie to the different types of motivations. We hope our findings nudge more companies to participate in the OSS ecosystem, helping make it robust, diverse, and sustainable.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172804","Open Source;OSS;companies in open source;motivations;diversity","Ecosystems;Companies;Lead;Internet;Mentoring;Interviews;Software engineering","","2","","78","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"How Do We Read Formal Claims? Eye-Tracking and the Cognition of Proofs about Algorithms","H. Ahmad; Z. Karas; K. Diaz; A. Kamil; J. -B. Jeannin; W. Weimer","University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","208","220","Formal methods are used successfully in high-assurance software, but they require rigorous mathematical and logical training that practitioners often lack. As such, integrating formal methods into software has been associated with numerous challenges. While educators have placed emphasis on formalisms in undergraduate theory courses, such courses often struggle with poor student outcomes and satisfaction. In this paper, we present a controlled eye-tracking human study (n = 34) investigating the problem-solving strategies employed by students with different levels of incoming preparation (as assessed by theory coursework taken and pre-screening performance on a proof comprehension task), and how educators can better prepare low-outcome students for the rigorous logical reasoning that is a core part of formal methods in software engineering. Surprisingly, we find that incoming preparation is not a good predictor of student outcomes for formalism comprehension tasks, and that student self-reports are not accurate at identifying factors associated with high outcomes for such tasks. Instead, and importantly, we find that differences in outcomes can be attributed to performance for proofs by induction and recursive algorithms, and that better-performing students exhibit significantly more attention switching behaviors, a result that has several implications for pedagogy in terms of the design of teaching materials. Our results suggest the need for a substantial pedagogical intervention in core theory courses to better align student outcomes with the objectives of mastery and retaining the material, and thus bettering preparing students for high-assurance software engineering.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172680","formalism comprehension;student cognition;eye-tracking;facial behavior analysis;human study","Training;Software algorithms;Gaze tracking;Switches;Prediction algorithms;Software;Cognition","","1","","76","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Improving early detection of software merge conflicts","M. L. Guimarães; A. R. Silva","Department of Computer Science and Engineering, INESC-ID, IST, Technical University of Lisbon, Lisboa, Portugal; Department of Computer Science and Engineering, INESC-ID, IST, Technical University of Lisbon, Lisboa, Portugal",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","342","352","Merge conflicts cause software defects which if detected late may require expensive resolution. This is especially true when developers work too long without integrating concurrent changes, which in practice is common as integration generally occurs at check-in. Awareness of others' activities was proposed to help developers detect conflicts earlier. However, it requires developers to detect conflicts by themselves and may overload them with notifications, thus making detection harder. This paper presents a novel solution that continuously merges uncommitted and committed changes to create a background system that is analyzed, compiled, and tested to precisely and accurately detect conflicts on behalf of developers, before check-in. An empirical study confirms that our solution avoids overloading developers and improves early detection of conflicts over existing approaches. Similarly to what happened with continuous compilation, this introduces the case for continuous merging inside the IDE.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227180","version control;merge conflicts;awareness;continuous merging","Merging;Programming;Software;Animals;Semantics;Servers;Computer languages","","50","6","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Formal correctness, safety, dependability, and performance analysis of a satellite","M. -A. Esteve; J. -P. Katoen; V. Y. Nguyen; B. Postma; Y. Yushtein","Software Systems Engineering Section, European Space Research and Technology Centre-European Space Agency, Netherlands; Formal Methods and Tools Group, University of Twente, Netherlands; Software Modeling and Verification Group, RWTH Aachen University, Germany; Formal Methods and Tools Group, University of Twente, Netherlands; Software Systems Engineering Section, European Space Research and Technology Centre-European Space Agency, Netherlands",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1022","1031","This paper reports on the usage of a broad palette of formal modeling and analysis techniques on a regular industrial-size design of an ultra-modern satellite platform. These efforts were carried out in parallel with the conventional software development of the satellite platform. The model itself is expressed in a formalized dialect of AADL. Its formal nature enables rigorous and automated analysis, for which the recently developed COMPASS toolset was used. The whole effort revealed numerous inconsistencies in the early design documents, and the use of formal analyses provided additional insight on discrete system behavior (comprising nearly 50 million states), on hybrid system behavior involving discrete and continuous variables, and enabled the automated generation of large fault trees (66 nodes) for safety analysis that typically are constructed by hand. The model's size pushed the computational tractability of the algorithms underlying the formal analyses, and revealed bottlenecks for future theoretical research. Additionally, the effort led to newly learned practices from which subsequent formal modeling and analysis efforts shall benefit, especially when they are injected in the conventional software development lifecycle. The case demonstrates the feasibility of fully capturing a system-level design as a single comprehensive formal model and analyze it automatically using a toolset based on (probabilistic) model checkers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227118","formal methods;satellite;modelling;model checking;AADL;safety;dependability;performance;FDIR;fault management","Satellites;Analytical models;Space vehicles;Compass;Safety;Satellite broadcasting;Software","","47","","18","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Winbook: A social networking based framework for collaborative requirements elicitation and WinWin negotiations","N. Kukreja","Center for Systems and Software Engineering (CSSE), University of Southern California, Los Angeles, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1610","1612","Easy-to-use groupware for diverse stakeholder negotiation has been a continuing challenge [7, 8, 9]. USC's fifth-generation wiki-based win-win negotiation support tool [1] was not as successful in improving over the previous four generations [2] as hoped - it encountered problems with non-technical stakeholder usage. The popularity of Facebook and Gmail ushered in a new era of widely-used social networking capabilities that I have been using to develop and experiment with a new way for collaborative requirements elicitation and management - marrying the way people collaborate on Facebook and organize their emails on Gmail to come up with a social networking-like platform to help achieve better usage of the WinWin negotiation framework [4]. Initial usage results on 14 small projects involving non-technical stakeholders have shown profound implications on the way requirements are negotiated and used, through the system and software definition and development processes. Subsequently, Winbook has also been adopted as a part of a project to bridge requirements and architecting for a major US government organization.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227227","collaborative requirements elicitation;WinWin negotiations;social networking","Software engineering;Facebook;Collaboration;Organizations;Electronic mail;Image color analysis","","6","","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Towards Bidirectional Live Programming for Incomplete Programs","X. Zhang; Z. Hu","Key Laboratory of High Confidence Software Technologies, MoE School of Computer Science, Peking University; Key Laboratory of High Confidence Software Technologies, MoE School of Computer Science, Peking University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2154","2164","Bidirectional live programming not only allows software developers to see continuous feedback on the output as they write the program, but also allows them to modify the program by directly manipulating the output, so that the modified program can get the output that was directly manipulated. Despite the appealing of existing bidirectional live programming systems, there is a big limitation: they cannot deal with incomplete programs where code blanks exist in the source programs. In this paper, we propose a framework to support bidirectional live programming for incomplete programs, by extending the output value structure, introducing hole binding, and formally defining bidirectional evaluators that are well-behaved. To illustrate the usefulness of the framework, we realize the core bidirectional evaluations of incomplete programs in a tool called Bidirectional Preview. Our experimental results show that our extended back-ward evaluation for incomplete programs is as efficient as that for complete programs in that it is only $21 ms$ slower on a program with 10 holes than that on its full program, and our extended forward evaluation makes no difference. Furthermore, we use quick sort and student grades, two nontrivial examples of incomplete programs, to demonstrate its usefulness in algorithm teaching and program debugging.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794025","live programming;bidirectional evaluation;direct manipulation;hole bindings;hole closures","Codes;Education;Software algorithms;Debugging;Programming;Software;Software engineering","","","","16","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Manas: Mining Software Repositories to Assist AutoML","G. Nguyen; M. J. Islam; R. Pan; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1368","1380","Today deep learning is widely used for building software. A software engineering problem with deep learning is that finding an appropriate convolutional neural network (CNN) model for the task can be a challenge for developers. Recent work on AutoML, more precisely neural architecture search (NAS), embodied by tools like Auto-Keras aims to solve this problem by essentially viewing it as a search problem where the starting point is a default CNN model, and mutation of this CNN model allows exploration of the space of CNN models to find a CNN model that will work best for the problem. These works have had significant success in producing high-accuracy CNN models. There are two problems, however. First, NAS can be very costly, often taking several hours to complete. Second, CNN models produced by NAS can be very complex that makes it harder to understand them and costlier to train them. We propose a novel approach for NAS, where instead of starting from a default CNN model, the initial model is selected from a repository of models extracted from GitHub. The intuition being that developers solving a similar problem may have developed a better starting point compared to the default model. We also analyze common layer patterns of CNN models in the wild to understand changes that the developers make to improve their models. Our approach uses commonly occurring changes as mutation operators in NAS. We have extended Auto-Keras to implement our approach. Our evaluation using 8 top voted problems from Kaggle for tasks including image classification and image regression shows that given the same search time, without loss of accuracy, Manas produces models with 42.9% to 99.6% fewer number of parameters than Auto-Keras' models. Benchmarked on GPU, Manas' models train 30.3% to 641.6% faster than Auto-Keras' models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794122","Deep Learning;AutoML;Mining Software Repositories;MSR","Deep learning;Training;Analytical models;Search problems;Software;Space exploration;Convolutional neural networks","","7","","62","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"How do professional developers comprehend software?","T. Roehm; R. Tiarks; R. Koschke; W. Maalej","Technical University of München, Munich, Germany; Technical University of München, Munich, Germany; Technical University of München, Munich, Germany; Technical University of München, Munich, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","255","265","Research in program comprehension has considerably evolved over the past two decades. However, only little is known about how developers practice program comprehension under time and project pressure, and which methods and tools proposed by researchers are used in industry. This paper reports on an observational study of 28 professional developers from seven companies, investigating how developers comprehend software. In particular we focus on the strategies followed, information needed, and tools used. We found that developers put themselves in the role of end users by inspecting user interfaces. They try to avoid program comprehension, and employ recurring, structured comprehension strategies depending on work context. Further, we found that standards and experience facilitate comprehension. Program comprehension was considered a subtask of other maintenance tasks rather than a task by itself. We also found that face-to-face communication is preferred to documentation. Overall, our results show a gap between program comprehension research and practice as we did not observe any use of state of the art comprehension tools and developers seem to be unaware of them. Our findings call for further careful analysis and for reconsidering research agendas.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227188","program comprehension;empirical studies;software documentation;maintenance;context awareness","Software;Interviews;Companies;Documentation;Java;Content management;Visualization","","125","","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"ReMoS: Reducing Defect Inheritance in Transfer Learning via Relevant Model Slicing","Z. Zhang; Y. Li; J. Wang; B. Liu; D. Li; Y. Guo; X. Chen; Y. Liu","Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China; Microsoft Research, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1856","1868","Transfer learning is a popular software reuse technique in the deep learning community that enables developers to build custom mod-els (students) based on sophisticated pretrained models (teachers). However, like vulnerability inheritance in traditional software reuse, some defects in the teacher model may also be inherited by students, such as well-known adversarial vulnerabilities and backdoors. Re-ducing such defects is challenging since the student is unaware of how the teacher is trained and/or attacked. In this paper, we propose ReMoS, a relevant model slicing technique to reduce defect inheri-tance during transfer learning while retaining useful knowledge from the teacher model. Specifically, ReMoS computes a model slice (a subset of model weights) that is relevant to the student task based on the neuron coverage information obtained by profiling the teacher model on the student task. Only the relevant slice is used to fine-tune the student model, while the irrelevant weights are retrained from scratch to minimize the risk of inheriting defects. Our experi-ments on seven DNN defects, four DNN models, and eight datasets demonstrate that ReMoS can reduce inherited defects effectively (by 63% to 86% for CV tasks and by 40% to 61 % for NLP tasks) and efficiently with minimal sacrifice of accuracy (3% on average).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793881","Program slicing;deep neural networks;relevant slicing","Deep learning;Computational modeling;Transfer learning;Neurons;Task analysis;Software reusability;Biological neural networks","","9","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Information-Theoretic Testing and Debugging of Fairness Defects in Deep Neural Networks","V. Monjezi; A. Trivedi; G. Tan; S. Tizpaz-Niari",University of Texas at El Paso; University of Colorado Boulder; Pennsylvania State University; University of Texas at El Paso,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1571","1582","The deep feedforward neural networks (DNNs) are increasingly deployed in socioeconomic critical decision support software systems. DNNs are exceptionally good at finding min-imal, sufficient statistical patterns within their training data. Consequently, DNNs may learn to encode decisions-amplifying existing biases or introducing new ones-that may disadvantage protected individuals/groups and may stand to violate legal protections. While the existing search based software testing approaches have been effective in discovering fairness defects, they do not supplement these defects with debugging aids-such as severity and causal explanations-crucial to help developers triage and decide on the next course of action. Can we measure the severity of fairness defects in DNNs? Are these defects symptomatic of improper training or they merely reflect biases present in the training data? To answer such questions, we present Dice: an information-theoretic testing and debugging framework to discover and localize fairness defects in DNNs. The key goal of Dice is to assist software developers in triaging fairness defects by ordering them by their severity. Towards this goal, we quantify fairness in terms of protected information (in bits) used in decision making. A quantitative view of fairness defects not only helps in ordering these defects, our empirical evaluation shows that it improves the search efficiency due to resulting smoothness of the search space. Guided by the quan-titative fairness, we present a causal debugging framework to localize inadequately trained layers and neurons responsible for fairness defects. Our experiments over ten DNNs, developed for socially critical tasks, show that Dice efficiently characterizes the amounts of discrimination, effectively generates discriminatory instances (vis-a-vis the state-of-the-art techniques), and localizes layers/neurons with significant biases.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00136","NSF(grant numbers:DGE-2043250); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172902","Algorithmic Fairness;Information Theory;Software Testing;Fairness Defect Localization;Bias Mitigation","Training;Software testing;Software algorithms;Decision making;Training data;Debugging;Software systems","","11","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Smartmark: Software Watermarking Scheme for Smart Contracts","T. Kim; Y. Jang; C. Lee; H. Koo; H. Kim","Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","283","294","A smart contract is a self-executing program on a blockchain to ensure an immutable and transparent agreement without the involvement of intermediaries. Despite its growing popularity for many blockchain platforms like Ethereum, no technical means is available even when a smart contract requires to be protected from being copied. One promising direction to claim a software ownership is software watermarking. However, applying existing software watermarking techniques is challenging because of the unique properties of a smart contract, such as a code size constraint, non-free execution cost, and no support for dynamic allocation under a virtual machine environment. This paper introduces a novel software watermarking scheme, dubbed Smartmark, aiming to protect the ownership of a smart contract against a pirate activity. Smartmark builds the control flow graph of a target contract runtime bytecode, and locates a collection of bytes that are randomly elected for representing a watermark. We implement a full-fledged prototype for Ethereum, applying Smartmark to 27,824 unique smart contract bytecodes. Our empirical results demonstrate that Smartmark can effectively embed a watermark into a smart contract and verify its presence, meeting the requirements of credibility and imperceptibility while incurring an acceptable performance degradation. Besides, our security analysis shows that Smartmark is resilient against viable watermarking corruption attacks; e.g., a large number of dummy opcodes are needed to disable a watermark effectively, resulting in producing an illegitimate smart contract clone that is not economical.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172692","Smart contract;Software watermarking;Blockchain;Software copyrights","Resistance;Costs;Runtime;Smart contracts;Prototypes;Watermarking;Software","","2","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Uncover the Premeditated Attacks: Detecting Exploitable Reentrancy Vulnerabilities by Identifying Attacker Contracts","S. Yang; J. Chen; M. Huang; Z. Zheng; Y. Huang","Sun Yat-sen University, Zhuhai, China; Sun Yat-sen University, Zhuhai, China; Sun Yat-sen University, Zhuhai, China; Sun Yat-sen University, Zhuhai, China; Sun Yat-sen University, Zhuhai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1573","1584","Reentrancy, a notorious vulnerability in smart contracts, has led to millions of dollars in financial loss. However, current smart contract vulnerability detection tools suffer from a high false positive rate in identifying contracts with reentrancy vulnerabilities. Moreover, only a small portion of the detected reentrant contracts can actually be exploited by hackers, making these tools less effective in securing the Ethereum ecosystem in practice. In this paper, we propose BlockWatchdog, a tool that focuses on detecting reentrancy vulnerabilities by identifying attacker contracts. These attacker contracts are deployed by hackers to exploit vulnerable contracts automatically. By focusing on attacker contracts, BlockWatchdog effectively detects truly exploitable reentrancy vulnerabilities by identifying reentrant call flow. Additionally, BlockWatchdog is capable of detecting new types of reentrancy vulnerabilities caused by poor designs when using ERC tokens or user-defined interfaces, which cannot be detected by current rulebased tools. We implement BlockWatchdog using cross-contract static dataflow techniques based on attack logic obtained from an empirical study that analyzes attacker contracts from 281 attack incidents. BlockWatchdog is evaluated on 421,889 Ethereum contract bytecodes and identifies 113 attacker contracts that target 159 victim contracts, leading to the theft of Ether and tokens valued at approximately 908.6 million USD. Notably, only 18 of the identified 159 victim contracts can be reported by current reentrancy detection tools.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639153","National Key R&D Program of China(grant numbers:2022YFB2702203); National Natural Science Foundation of China(grant numbers:62302534,62332004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549650","Software and its engineering →Software verification and validation;Smart Contract;Dataflow Analysis;Reentrancy;Attacker Identification;Ethereum","Computer hacking;Smart contracts;Ecosystems;Focusing;Software;Contracts;Software engineering","","","","61","","14 Jun 2024","","","IEEE","IEEE Conferences"
"A history-based matching approach to identification of framework evolution","S. Meng; X. Wang; L. Zhang; H. Mei","School of Electronics Engineering and Computer Science, Peking University, Beijing, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","353","363","In practice, it is common that a framework and its client programs evolve simultaneously. Thus, developers of client programs may need to migrate their programs to the new release of the framework when the framework evolves. As framework developers can hardly always guarantee backward compatibility during the evolution of a framework, migration of its client program is often time-consuming and error-prone. To facilitate this migration, researchers have proposed two categories of approaches to identification of framework evolution: operation-based approaches and matching-based approaches. To overcome the main limitations of the two categories of approaches, we propose a novel approach named HiMa, which is based on matching each pair of consecutive revisions recorded in the evolution history of the framework and aggregating revision-level rules to obtain framework-evolution rules. We implemented our HiMa approach as an Eclipse plug-in targeting at frameworks written in Java using SVN as the version-control system. We further performed an experimental study on HiMa together with a state-of-art approach named AURA using six tasks based on three subject Java frameworks. Our experimental results demonstrate that HiMa achieves higher precision and higher recall than AURA in most circumstances and is never inferior to AURA in terms of precision and recall in any circumstances, although HiMa is computationally more costly than AURA.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227179","framework evolution;software migration;mining version history;natural language processing","Natural language processing;History;Software;Java;Control systems;Aggregates","","44","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Strategies, Benefits and Challenges of App Store-inspired Requirements Elicitation","A. Ferrari; P. Spoletini","ISTI-CNR; Kennesaw State University, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1290","1302","App store-inspired elicitation is the practice of exploring competitors' apps, to get inspiration for requirements. This activity is common among developers, but little insight is available on its practical use, advantages and possible issues. This paper aims to empirically analyse this technique in a realistic scenario, in which it is used to extend the requirements of a product that were initially captured by means of more traditional requirements elicitation interviews. Considering this scenario, we conduct an experimental simulation with 58 analysts and collect qualitative data. We perform thematic analysis of the data to identify strategies, benefits, and challenges of app store-inspired elicitation, as well as differences with respect to interviews in the considered elicitation setting. Our results show that: (1) specific guidelines and procedures are required to better conduct app store-inspired elicitation; (2) current search features made available by app stores are not suitable for this practice, and more tool support is required to help analysts in the retrieval and evaluation of competing products; (3) while interviews focus on the why dimension of requirements engineering (i.e., goals), app store-inspired elicitation focuses on how (i.e., solutions), offering indications for implementation and improved usability. Our study provides a framework for researchers to address existing challenges and suggests possible benefits to fostering app store-inspired elicitation among practitioners.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00114","National Science Foundation(grant numbers:CCF-1718377); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172539","app store inspired elicitation;app store analysis;requirements elicitation;interviews;qualitative study;experimental simulation","Surveys;Industries;Analytical models;Systematics;Data models;Requirements engineering;Interviews","","3","","67","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SemParser: A Semantic Parser for Log Analytics","Y. Huo; Y. Su; C. Lee; M. R. Lyu","Computer Science & Engineering Dept., The Chinese University of Hong Kong, Hong Kong, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; Computer Science & Engineering Dept., The Chinese University of Hong Kong, Hong Kong, China; Computer Science & Engineering Dept., The Chinese University of Hong Kong, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","881","893","Logs, being run-time information automatically generated by software, record system events and activities with their timestamps. Before obtaining more insights into the run-time status of the software, a fundamental step of log analysis, called log parsing, is employed to extract structured templates and parameters from the semi-structured raw log messages. However, current log parsers are all syntax-based and regard each message as a character string, ignoring the semantic information included in parameters and templates. Thus, we propose the first semantic-based parser SemParser to unlock the critical bottleneck of mining semantics from log messages. It contains two steps, an end-to-end semantics miner and a joint parser. Specifically, the first step aims to identify explicit semantics inside a single log, and the second step is responsible for jointly inferring implicit semantics and computing structural outputs according to the contextual knowledge base of the logs. To analyze the effectiveness of our semantic parser, we first demonstrate that it can derive rich semantics from log messages collected from six widely-applied systems with an average F1 score of 0.985. Then, we conduct two representative downstream tasks, showing that current downstream models improve their performance with appropriately extracted semantics by 1.2%-11.7% and 8.65% on two anomaly detection datasets and a failure identification dataset, respectively. We believe these findings provide insights into semantically understanding log messages for the log analysis community.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00082","National Natural Science Foundation of China(grant numbers:62202511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172666","log parsing;semantic parser;log analytics","Codes;Semantics;Knowledge based systems;Software;Task analysis;Anomaly detection;Software engineering","","13","","52","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Coupled evolution of model-driven spreadsheets","J. Mendes","HASLab / INESC TEC, Universidade do Minho, Portugal",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1616","1618","Spreadsheets are increasingly used as programming languages, in the construction of large and complex systems. The fact is that spreadsheets, being a highly flexible framework, lack important programming language features such as abstraction or encapsulation. This flexibility, however, comes with a price: spreadsheets are populated with significant amounts of errors. One of the approaches that try to overcome this problem advocates the use of model-driven spreadsheet development: a spreadsheet model is defined, from which a concrete spreadsheet is generated. Although this approach has been proved effective in other contexts, still it needs to accommodate for future evolution of both the model and its instance, so that they remain synchronized at all moments. In this paper, we propose a pair of transformation sets, one working at the model level and the other at the instance level, such that each transformation in one set is related to a transformation in the other set. With our approach, we ensure model/data compliance while allowing for model and data evolution.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227225","Spreadsheets;Model-Driven Engineering (MDE);Software Evolution","Data models;Object oriented modeling;Unified modeling language;Software;Visualization;Business;Context","","3","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Characterizing and Detecting Bugs in WeChat Mini-Programs","T. Wang; Q. Xu; X. Chang; W. Dou; J. Zhu; J. Xie; Y. Deng; J. Yang; J. Yang; J. Wei; T. Huang","State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; Tencent, Inc., Guangzhou, China; Tencent, Inc., Guangzhou, China; Tencent, Inc., Guangzhou, China; Tencent, Inc., Guangzhou, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences University of Chinese Academy of Sciences, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","363","375","Built on the WeChat social platform, WeChat Mini-Programs are widely used by more than 400 million users every day. Consequently, the reliability of Mini-Programs is particularly crucial. However, WeChat Mini-Programs suffer from various bugs related to execution environment, lifecycle management, asynchronous mechanism, etc. These bugs have seriously affected users' experience and caused serious impacts. In this paper, we conduct the first empirical study on 83 WeChat Mini-Program bugs, and perform an in-depth analysis of their root causes, impacts and fixes. From this study, we obtain many interesting findings that can open up new research directions for combating WeChat Mini-Program bugs. Based on the bug patterns found in our study, we further develop WeDetector to detect WeChat Mini-Program bugs. Our evaluation on 25 real-world Mini-Programs has found 11 previously unknown bugs, and 7 of them have been confirmed by developers.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510114","National Natural Science Foundation of China(grant numbers:61732019,U20A6003,62072444,61802378); Youth Innovation Promotion Association at Chinese Academy of Sciences(grant numbers:2018142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793947","WeChat Mini-Programs;empirical study;bug detection","Social networking (online);Computer bugs;Message service;User experience;Reliability;Software engineering","","2","","110","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Detecting metadata bugs on the fly","M. Song; E. Tilevich","Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1455","1456","Programmers are spending a large and increasing amount of their time writing and modifying metadata, such as Java annotations and XML deployment descriptors. And yet, automatic bug finding tools cannot find metadata-related bugs introduced during program refactoring and enhancement. To address this shortcoming, we have created metadata invariants, a new programming abstraction that expresses naming and typing relationships between metadata and the main source code of a program. A paper that appears in the main technical program of ICSE 2012 describes the idea, concept, and prototype of metadata invariants [4]. The goal of this demo is to supplement that paper with a demonstration of our Eclipse plugin, Metadata Bug Finder (MBF). MBF takes as input a script written in our domain-specific language that describes a set of metadata coding conventions the programmer wishes to enforce. Then after each file save operation, MBF checks the edited codebase for the presence of any violations of the given metadata programming conventions. These violations are immediately reported to the programmer as potential metadata-related bugs. By making the programmer aware of these potential bugs, MBF prevents them from seeping into production, thereby improving the overall correctness of the edited codebase.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227067","software maintenance;bug finding;refactoring;enhancement;frameworks;domain-specific languages;metadata;invariants","Encoding;Computer bugs;Java;XML;Software;Testing;Programming","","","","5","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Cross-Domain Requirements Linking via Adversarial-based Domain Adaptation","Z. Chang; M. Li; Q. Wang; S. Li; J. Wang","Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1596","1608","Requirements linking is the core of software system maintenance and evolution, and it is critical to assuring software quality. In practice, however, the requirements links are frequently absent or incorrectly labeled, and reconstructing such ties is time-consuming and error-prone. Numerous learning-based approaches have been put forth to address the problem. However, these approaches will lose effectiveness for the Cold-Start projects with few labeled samples. To this end, we propose RADIATION, an adversarial-based domain adaptation approach for cross-domain requirements linking. Generally, RADIATION firstly adopts an IDF-based Masking strategy to filter the domain-specific features. Then it pre-trains a linking model in the source domain with sufficient labeled samples and adapts the model to target domains using a distance-enhanced adversarial technique without using any labeled target samples. Evaluation on five public datasets shows that RADIATION could achieve 66.4% precision, 89.2% recall, and significantly outperform state-of-the-art baselines by 13.4% -42.9% F1. In addition, the designed components, i.e., IDF-based Masking and Distance-enhanced Loss, could significantly improve performance.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00138","National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172688","Cross-Domain Requirements Linking;Domain Adaptation;Adversarial Learning","Adaptation models;Source coding;Unified modeling language;Software quality;Maintenance engineering;Software systems;Usability","","","","61","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Using the GPGPU for scaling up Mining Software Repositories","R. Nagano; H. Nakamura; Y. Kamei; B. Adams; K. Hisazumi; N. Ubayashi; A. Fukuda","Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; MCIS, École Polytechnique de Montréal, Canada; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1435","1436","The Mining Software Repositories (MSR) field integrates and analyzes data stored in repositories such as source control and bug repositories to support practitioners. Given the abundance of repository data, scaling up MSR analyses has become a major challenge. Recently, researchers have experimented with conventional techniques like a supercomputer or cloud computing, but these are either too expensive or too hard to configure. This paper proposes to scale up MSR analysis using “general-purpose computing on graphics processing units” (GPGPU) on off-the-shelf video cards. In a representative MSR case study to measure co-change on version history of the Eclipse project, we find that the GPU approach is up to a factor of 43.9 faster than a CPU-only approach.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227077","","Graphics processing unit;Data mining;History;Supercomputers;Arrays;Computer bugs","","1","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"An Exploratory Investigation of Log Anomalies in Unmanned Aerial Vehicles","D. Wang; S. Li; G. Xiao; Y. Liu; Y. Sui; P. He; M. R. Lyu","University of Technology Sydney, Australia; The Chinese University of Hong Kong, China; Nanjing University of Aeronautics and Astronautics, China; Department of Computer Science and Engineering, Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, China; The University of New South Wales, Australia; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; The Chinese University of Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2593","2605","Unmanned aerial vehicles (UAVs) are becoming increasingly ubiqui-tous in our daily lives. However, like many other complex systems, UAVs are susceptible to software bugs that can lead to abnormal system behaviors and undesirable consequences. It is crucial to study such software bug-induced UAV anomalies, which are often mani-fested in flight logs, to help assure the quality and safety of UAV systems. However, there has been limited research on investigating the code-level patterns of software bug-induced UAV anomalies. This impedes the development of effective tools for diagnosing and localizing bugs within UAV system code. To bridge the research gap and deepen our understanding of UAV anomalies, we carried out an empirical study on this subject. We first collected 178 real-world abnormal logs induced by soft-ware bugs in two popular open-source UAV platforms, i.e., PX4 and Ardupilot. We then examined each of these abnormal logs and com-piled their common patterns. In particular, we investigated the most severe anomalies that led to UAV crashes, and identified their features. Based on our empirical findings, we further summarized the challenges of localizing bugs in system code by analyzing anoma-lous UAV flight data, which can offer insights for future research in this field.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:61932021,62002163,62102340); Natural Science Foundation of Jiangsu Province(grant numbers:BK20200441); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548587","UAV Anomaly;Software Bug;Crash;Code Pattern;Empirical Study","Bridges;Codes;Computer bugs;Autonomous aerial vehicles;Software;Safety;Complex systems","","","","98","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Search-based Diverse Sampling from Real-world Software Product Lines","Y. Xiang; H. Huang; Y. Zhou; S. Li; C. Luo; Q. Lin; M. Li; X. Yang","South China University of Technology, Guangzhou, China; South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-Sen University, Guangzhou, China; South China University of Technology, Guangzhou, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; University of Birmingham, Birmingham, UK; South China University of Technology, Guangzhou, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1945","1957","Real-world software product lines (SPLs) often encompass enormous valid configurations that are impossible to enumerate. To understand properties of the space formed by all valid configurations, a feasible way is to select a small and valid sample set. Even though a number of sampling strategies have been proposed, they either fail to produce diverse samples with respect to the number of selected features (an important property to characterize behaviors of configurations), or achieve diverse sampling but with limited scalability (the handleable configuration space size is limited to 1013). To resolve this dilemma, we propose a scalable diverse sampling strategy, which uses a distance metric in combination with the novelty search algorithm to produce diverse samples in an incremental way. The distance metric is carefully designed to measure similarities between configurations, and further diversity of a sample set. The novelty search incrementally improves diversity of samples through the search for novel configurations. We evaluate our sampling algorithm on 39 real-world SPLs. It is able to generate the required number of samples for all the SPLs, including those which cannot be counted by sharpSAT, a state-of-the-art model counting solver. Moreover, it performs better than or at least competitively to state-of-the-art samplers regarding diversity of the sample set. Experimental results suggest that only the proposed sampler (among all the tested ones) achieves scalable diverse sampling.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510053","National Natural Science Foundation of China(grant numbers:61906069,61876207); Science and Technology Program of Guangzhou(grant numbers:202002030355,201802010007); Fundamental Research Funds for the Central Universities(grant numbers:2020ZYGXZR014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794052","Software product lines;diverse sampling;novelty search;distance metric","Measurement;Scalability;Software algorithms;Search problems;Prediction algorithms;Software;Behavioral sciences","","1","","57","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Ambient awareness of build status in collocated software teams","J. Downs; B. Plimmer; J. G. Hosking","Department of Computing and Information Systems, University of Melbourne, Melbourne, Australia; Department of Computer Science, University of Auckland, Auckland, New Zealand; ANU College of Engineering and Computer Science, Australian National University, Canberra, Australia",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","507","517","We describe the evaluation of a build awareness system that assists agile software development teams to understand current build status and who is responsible for any build breakages. The system uses ambient awareness technologies, providing a separate, easily perceived communication channel distinct from standard team workflow. Multiple system configurations and behaviours were evaluated. An evaluation of the system showed that, while there was no significant change in the proportion of build breakages, the overall number of builds increased substantially, and the duration of broken builds decreased. Team members also reported an increased sense of awareness of, and responsibility for, broken builds and some noted the system dramatically changed their perception of the build process making them more cognisant of broken builds.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227165","software teams;continuous integration;ambient awareness;build processes;status information","Prototypes;Monitoring;Servers;Universal Serial Bus;Software;Electronic mail;Educational institutions","","26","","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Barriers for Students During Code Change Comprehension","J. Middleton; J. -P. Ore; K. T. Stolee","Department of Computer Science, North Carolina State University, USA; Department of Computer Science, North Carolina State University, USA; Department of Computer Science, North Carolina State University, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2419","2431","Modern code review (MCR) is a key practice for many software engineering organizations, so undergraduate software engineering courses often teach some form of it to prepare students. However, research on MCR describes how many its professional implementations can fail, to say nothing on how these barriers manifest under students' particular contexts. To uncover barriers students face when evaluating code changes during review, we combine inter-views and surveys with an observational study. In a junior-level software engineering course, we first interviewed 29 undergrad-uate students about their experiences in code review. Next, we performed an observational study that presented 44 students from the same course with eight code change comprehension activities. These activities provided students with pull requests of potential refactorings in a familiar code base, collecting feedback on accuracy and challenges. This was followed by a reflection survey. Building on these methods, we combine (1) a qualitative analy-sis of the interview transcripts, activity comments, and reflection survey with (2) a quantitative assessment of their performance in identifying behavioral changes in order to outline the barriers that students face during code change comprehension. Our results reveal that students struggle with a number of facets around a program: the context for review, the review tools, the code itself, and the implications of the code changes. These findings - along with our result that student developers tend to overestimate behavioral similarity during code comparison - have implications for future support to help student developers have smoother code review experiences. We motivate a need for several interventions, including sentiment analysis on pull request comments to flag tox-icity, scaffolding for code comprehension while reviewing large changes, and behavioral diffing to contrast the evolution of syntax and semantics.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548475","","Surveys;Sentiment analysis;Codes;Reviews;Semantics;Organizations;Syntactics","","1","","51","","14 Jun 2024","","","IEEE","IEEE Conferences"
"RAT: A Refactoring-Aware Traceability Model for Bug Localization","F. Niu; W. K. G. Assunção; L. Huang; C. Mayr-Dorn; J. Ge; B. Luo; A. Egyed","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Institute for Software Systems Engineering, Johannes Kepler University, Linz, Austria; Department of Computer Science and Engineering, Southern Methodist University, Dallas, Texas, USA; Institute for Software Systems Engineering, Johannes Kepler University, Linz, Austria; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Institute for Software Systems Engineering, Johannes Kepler University, Linz, Austria",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","196","207","A large number of bug reports are created during the evolution of a software system. Locating the source code files that need to be changed in order to fix these bugs is a challenging task. Information retrieval-based bug localization techniques do so by correlating bug reports with historical information about the source code (e.g., previously resolved bug reports, commit logs). These techniques have shown to be efficient and easy to use. However, one flaw that is nearly omnipresent in all these techniques is that they ignore code refactorings. Code refactorings are common during software system evolution, but from the perspective of typical version control systems, they break the code history. For example, a class when renamed then appears as two separate classes with separate histories. Obviously, this is a problem that affects any technique that leverages code history. This paper proposes a refactoring-aware traceability model to keep track of the code evolution history. With this model, we reconstruct the code history by analyzing the impact of code refactorings to correctly stitch together what would otherwise be a fragmented history. To demonstrate that a refactoring aware history is indeed beneficial, we investigated three widely adopted bug localization techniques that make use of code history, which are important components in existing approaches. Our evaluation on 11 open source projects shows that taking code refactorings into account significantly improves the results of these bug localization techniques without significant changes to the techniques themselves. The more refactorings are used in a project, the stronger the benefit we observed. Based on our findings, we believe that much of the state of the art leveraging code history should benefit from our work.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00028","Natural Science Foundation of Jiangsu Province, China(grant numbers:BK20201250); NSF(grant numbers:2034508); Austrian Science Fund(grant numbers:P31989-N31,P34805-N); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172549","bug localization;bug report similarity;code refactoring;traceability;commit history;information retrieval","Location awareness;Analytical models;Codes;Source coding;Computer bugs;Software systems;Control systems","","7","","39","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Fast Changeset-based Bug Localization with BERT","A. Ciborowska; K. Damevski","Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA; Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","946","957","Automatically localizing software bugs to the changesets that induced them has the potential to improve software developer efficiency and to positively affect software quality. To facilitate this automation, a bug report has to be effectively matched with source code changes, even when a significant lexical gap exists between natural language used to describe the bug and identifier naming practices used by developers. To bridge this gap, we need techniques that are able to capture software engineering-specific and project-specific semantics in order to detect relatedness between the two types of documents that goes beyond exact term matching. Popular transformer-based deep learning architectures, such as BERT, excel at leveraging contextual information, hence appear to be a suitable candidate for the task. However, BERT-like models are computationally expensive, which precludes them from being used in an environment where response time is important. In this paper, we describe how BERT can be made fast enough to be applicable to changeset-based bug localization. We also explore several design decisions in using BERT for this purpose, including how best to encode changesets and how to match bug reports to individual changes for improved accuracy. We compare the accuracy and performance of our model to a non-contextual baseline (i.e., vector space model) and BERT-based architectures previously used in software engineering. Our evaluation results demonstrate advantages in using the proposed BERT model compared to the baselines, especially for bug reports that lack any hints about related code elements.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794003","bug localization;changesets;information retrieval;BERT","Location awareness;Codes;Computer bugs;Bit error rate;Semantics;Computer architecture;Transformers","","14","","64","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"On-demand test suite reduction","D. Hao; L. Zhang; X. Wu; H. Mei; G. Rothermel","Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Computer Science and Engineering, University of Nebraska, Lincolnshire, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","738","748","Most test suite reduction techniques aim to select, from a given test suite, a minimal representative subset of test cases that retains the same code coverage as the suite. Empirical studies have shown, however, that test suites reduced in this manner may lose fault detection capability. Techniques have been proposed to retain certain redundant test cases in the reduced test suite so as to reduce the loss in fault-detection capability, but these still do concede some degree of loss. Thus, these techniques may be applicable only in cases where loose demands are placed on the upper limit of loss in fault-detection capability. In this work we present an on-demand test suite reduction approach, which attempts to select a representative subset satisfying the same test requirements as an initial test suite conceding at most l% loss in fault-detection capability for at least c% of the instances in which it is applied. Our technique collects statistics about loss in fault-detection capability at the level of individual statements and models the problem of test suite reduction as an integer linear programming problem. We have evaluated our approach in the contexts of three scenarios in which it might be used. Our results show that most test suites reduced by our approach satisfy given fault detection capability demands, and that the approach compares favorably with an existing test suite reduction approach.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227144","software testing;test suite reduction;on-demand","Fault detection;Testing;Computational modeling;Integer linear programming;Educational institutions;Software","","39","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A generic methodology to derive domain-specific performance feedback for developers","D. Westermann","SAP Research, Karlsruhe, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1527","1530","The performance of a system directly influences business critical metrics like total cost of ownership (TCO) and user satisfaction. However, building responsive, resource efficient and scalable applications is a challenging task. Thus, software engineering approaches are required to support software architects and developers in meeting these challenges. In this PhD research abstract, we propose a novel performance evaluation process applied during the software development phase. The goal is to increase the performance awareness of developers by providing feedback with respect to performance properties that is integrated in the every day development process. The feedback is based on domain-specific prediction functions derived by a generic methodology that executes a series of systematic measurements. We apply and validate the approach in different development scenarios at SAP.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227045","","Performance evaluation;Software performance;Predictive models;Systematics;Time measurement","","2","","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"LibvDiff: Library Version Difference Guided OSS Version Identification in Binaries","C. Dong; S. Li; S. Yang; Y. Xiao; Y. Wang; H. Li; Z. Li; L. Sun","Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security; Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","791","802","Open-source software (OSS) has been extensively employed to expedite software development, inevitably exposing downstream software to the peril of potential vulnerabilities. Precisely identifying the version of OSS not only facilitates the detection of vulnerabilities associated with it but also enables timely alerts upon the release of 1-day vulnerabilities. However, current methods for identifying OSS versions rely heavily on version strings or constant features, which may not be present in compiled OSS binaries or may not be representative when only function code changes are made. As a result, these methods are often imprecise in identifying the version of OSS binaries being used. To this end, we propose Libvdiff, a novel approach for identifying open-source software versions. It detects subtle differences through precise symbol information and function-level code changes using binary code similarity detection. Libvdiff introduces a candidate version filter based on a novel version coordinate system to improve efficiency by quantifying gaps between versions and rapidly identifying potential versions. To speed up the code similarity detection process, Libvdiff proposes a function call-based anchor path filter to minimize the number of functions compared in the target binary. We evaluate the performance of Libvdiff through comprehensive experiments under various compilation settings and two datasets (one with version strings, and the other without version strings), which demonstrate that our approach achieves 94.5% and 78.7% precision in two datasets, outperforming state-of-the-art works (including both academic methods and industry tools) by an average of 54.2% and 160.3%, respectively. By identifying and analyzing OSS binaries in real-world firmware images, we make several interesting findings, such as developers having significant differences in their updates to different OSS, and different vendors may also utilize identical OSS binaries.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548834","Open-source software;Version identification;Vulnerability detection;Firmware analysis","Semantics;Symbols;Binary codes;Information filters;Libraries;Security;Open source software","","","","55","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Combining Structured Static Code Information and Dynamic Symbolic Traces for Software Vulnerability Prediction","H. Wang; Z. Tang; S. H. Tan; J. Wang; Y. Liu; H. Fang; C. Xia; Z. Wang","Northwest University, China; Northwest University, China; Concordia University, Canada; Northwest University, China; Northwest University, China; Northwest University, China; University of Leeds, U. K.; University of Leeds, U. K.",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2085","2097","Deep learning (DL) has emerged as a viable means for identifying software bugs and vulnerabilities. The success of DL relies on having a suitable representation of the problem domain. However, existing DL-based solutions for learning program representations have limitations - they either cannot capture the deep, precise program semantics or suffer from poor scalability. We present Con-coction, the first DL system to learn program presentations by combining static source code information and dynamic program execution traces. Concoction employs unsupervised active learning techniques to determine a subset of important paths to collect dynamic symbolic execution traces. By implementing a focused symbolic execution solution, Concoction brings the benefits of static and dynamic code features while reducing the expensive sym-bolic execution overhead. We integrate Concoction with fuzzing techniques to detect function-level code vulnerabilities in C pro-grams from 20 open-source projects. In 200 hours of automated concurrent test runs, Concoction has successfully uncovered vul-nerabilities in all tested projects, identifying 54 unique vulnera-bilities and yielding 37 new, unique CVE IDs. Concoction also significantly outperforms 16 prior methods by providing higher accuracy and lower false positive rates.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639212","National Natural Science Foundation of China (NSFC)(grant numbers:61972314,62372373); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549407","Software vulnerability detection;Deep learning;Symbolic execution","Codes;Accuracy;Source coding;Scalability;Computer bugs;Supervised learning;Semantics","","","","88","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"A requirements-based approach for the design of adaptive systems","V. E. S. Souza","Department of Information Engineering and Computer Science, University of Trento, Trento, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1635","1637","Complexity is now one of the major challenges for the IT industry [1]. Systems might become too complex to be managed by humans and, thus, will have to be self-managed: Self-configure themselves for operation, self-protect from attacks, self-heal from errors and self-tune for optimal performance [2]. (Self-)Adaptive systems evaluate their own behavior and change it when the evaluation indicates that it is not accomplishing the software's purpose or when better functionality and performance are possible [3]. To that end, we need to monitor the behavior of the running system and compare it to an explicit formulation of requirements and domain assumptions [4]. Feedback loops (e.g., the MAPE loop [2]) constitute an architectural solution for this and, as proposed by past research [5], should be a first class citizen in the design of such systems. We advocate that adaptive systems should be designed this way from as early as Requirements Engineering and that reasoning over requirements is fundamental for run-time adaptation. We therefore propose an approach for the design of adaptive systems based on requirements and inspired in control theory [6]. Our proposal is goal-oriented and targets softwareintensive socio-technical systems [7], in an attempt to integrate control-loop approaches with decentralized agents inspired approaches [8]. Our final objective is a set of extensions to state-of-the-art goal-oriented modeling languages that allow practitioners to clearly specify the requirements of adaptive systems and a run-time framework that helps developers implement such requirements. In this 2-page abstract paper, we summarize this approach.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227218","","Adaptive systems;Adaptation models;Proposals;Solid modeling;Conferences;Runtime","","5","","26","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Regression Fuzzing for Deep Learning Systems","H. You; Z. Wang; J. Chen; S. Liu; S. Li","College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","82","94","Deep learning (DL) Systems have been widely used in various domains. Similar to traditional software, DL system evolution may also incur regression faults. To find the regression faults between versions of a DL system, we propose a novel regression fuzzing technique called DRFuzz, which facilitates generating inputs that trigger diverse regression faults and have high fidelity. To enhance the diversity of the found regression faults, DRFuzz proposes a diversity-oriented test criterion to explore as many faulty behaviors as possible. Then, DRFuzz incorporates the GAN model to guarantee the fidelity of generated test inputs. We conduct an extensive study on four subjects in four regression scenarios of DL systems. The experimental results demonstrate the superiority of DRFuzz over the two compared state-of-the-art approaches, with an average improvement of 1,177% and 539% in terms of the number of detected regression faults.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00019","National Natural Science Foundation of China(grant numbers:61872263,62232001,62002256); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172506","Regression;Fuzzing;Deep Learning","Deep learning;Fuzzing;Software;Behavioral sciences;Regression tree analysis;Software engineering","","10","","89","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Efficient reuse of domain-specific test knowledge: An industrial case in the smart card domain","N. Devos; C. Ponsard; J. -C. Deprez; R. Bauvin; B. Moriau; G. Anckaerts","Software and System Engineering, CETIC research center, Charleroi, Belgium; Software and System Engineering, CETIC research center, Charleroi, Belgium; Software and System Engineering, CETIC research center, Charleroi, Belgium; Quality, Security and Control, STMicroelectronics Belgium, Zaventem, Belgium; Quality, Security and Control, STMicroelectronics Belgium, Zaventem, Belgium; Quality, Security and Control, STMicroelectronics Belgium, Zaventem, Belgium",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1123","1132","While testing is heavily used and largely automated in software development projects, the reuse of test practices across similar projects in a given domain is seldom systematized and supported by adequate methods and tools. This paper presents a practical approach that emerged from a concrete industrial case in the smart card domain at STMicroelectronics Belgium in order to better address this kind of challenge. The central concept is a test knowledge repository organized as a collection of specific patterns named QPatterns. A systematic process was followed, first to gather, structure and abstract the test practices, then to produce and validate an initial repository, and finally to make it evolve later on Testers can then rely on this repository to produce high quality test plans identifying all the functional and nonfunctional aspects that have to be addressed, as well as the concrete tests that have to be developed within the context of a new project. A tool support was also developed and integrated in a traceable way into the existing industrial test environment. The approach was validated and is currently under deployment at STMicroelectronics Belgium.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227107","patterns;test;generation;smartcard","Smart cards;Testing;Libraries;Software;Security;Concrete","","2","","16","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Ppt4j: Patch Presence Test for Java Binaries","Z. Pan; X. Hu; X. Xia; X. Zhan; D. Lo; X. Yang","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Software Engineering Application Technology Lab, Huawei, Hangzhou, China; The Hong Kong Polytechnic University, Hong Kong, China; School of Computing and Information Systems, Singapore Management University, Singapore; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2784","2795","The number of vulnerabilities reported in open source software has increased substantially in recent years. Security patches provide the necessary measures to protect software from attacks and vulnerabilities. In practice, it is difficult to identify whether patches have been integrated into software, especially if we only have binary files. Therefore, the ability to test whether a patch is applied to the target binary, a.k.a. patch presence test, is crucial for practitioners. However, it is challenging to obtain accurate semantic information from patches, which could lead to incorrect results. In this paper, we propose a new patch presence test framework named Ppt4j (Patch Presence Test forJava Binaries). Ppt4j is designed for open-source Java libraries. It takes Java binaries (i.e. bytecode files) as input, extracts semantic information from patches, and uses feature-based techniques to identify patch lines in the binaries. To evaluate the effectiveness of our proposed approach Ppt4j, we construct a dataset with binaries that include 110 vulnerabilities. The results show that Ppt4j achieves an F1 score of 98.5% with reasonable efficiency, improving the baseline by 14.2%. Furthermore, we conduct an in-the-wild evaluation of Ppt4j on JetBrains IntelliJ IDEA. The results suggest that a third-party library included in the software is not patched for two CVEs, and we have reported this potential security problem to the vendor.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548944","Patch Presence Test;Binary Analysis;Software Security","Java;Semantics;Feature extraction;Libraries;Security;Software measurement;Data mining","","","","44","","14 Jun 2024","","","IEEE","IEEE Conferences"
"The Quamoco product quality modelling and assessment approach","S. Wagner; K. Lochmann; L. Heinemann; M. Kläs; A. Trendowicz; R. Plösch; A. Seidi; A. Goeb; J. Streit","Inst. of Software Technology, University of Stuttgart, Stuttgart, Germany; Institut für Informatik, Technische Universität München, Garching, Germany; Institut für Informatik, Technische Universität München, Garching, Germany; Fraunhofer IESE, Kaiserslautern, Germany; Fraunhofer IESE, Kaiserslautern, Germany; Department of Business Informatics, Johannes Kepler University Linz, Linz, Austria; CSD Research, Capgemini, Munich, Germany; SAP Research, SAP AG, Darmstadt, Germany; itestra GmbH, Munich, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1133","1142","Published software quality models either provide abstract quality attributes or concrete quality assessments. There are no models that seamlessly integrate both aspects. In the project Quamoco, we built a comprehensive approach with the aim to close this gap. For this, we developed in several iterations a meta quality model specifying general concepts, a quality base model covering the most important quality factors and a quality assessment approach. The meta model introduces the new concept of a product factor, which bridges the gap between concrete measurements and abstract quality aspects. Product factors have measures and instruments to operationalise quality by measurements from manual inspection and tool analysis. The base model uses the ISO 25010 quality attributes, which we refine by 200 factors and 600 measures for Java and C# systems. We found in several empirical validations that the assessment results fit to the expectations of experts for the corresponding systems. The empirical analyses also showed that several of the correlations are statistically significant and that the maintainability part of the base model has the highest correlation, which fits to the fact that this part is the most comprehensive. Although we still see room for extending and improving the base model, it shows a high correspondence with expert opinions and hence is able to form the basis for repeatable and understandable quality assessments in practice.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227106","quality model;quality assessment;meta model;empirical validation","Object oriented modeling;Quality assessment;Biological system modeling;Software quality;Unified modeling language;Concrete","","76","","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Software architecture — What does it mean in industry? (Invited industrial talk)","E. Wolff","Adesso, Berlin, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","999","999","Summary form only given. As communications get embedded in any objects we will see more and more instances of services and information seamlessly coupled to objects. Kindle has been the forerunner and we are going to see many more kind of objects being connected to the Internet. This will create a new slate of opportunities for many companies and Telecom Operators will be able to have a significant and economically relevant role in this space. The talk will address the technologies enabling this transformation and the evolution in value chains that may result emphasizing the role of Telecom Operators in this transformation. A concrete example of a territorial transformation taking place in Trento, Italy, will be given. This example may be discussed to evaluate the extent to which it can be applied in different context.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227250","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Performance debugging in the large via mining millions of stack traces","S. Han; Y. Dang; S. Ge; D. Zhang; T. Xie","Microsoft Research Asia, China; Microsoft Research Asia, China; Microsoft Research Asia, China; Microsoft Research Asia, China; North Carolina State University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","145","155","Given limited resource and time before software release, development-site testing and debugging become more and more insufficient to ensure satisfactory software performance. As a counterpart for debugging in the large pioneered by the Microsoft Windows Error Reporting (WER) system focusing on crashing/hanging bugs, performance debugging in the large has emerged thanks to available infrastructure support to collect execution traces with performance issues from a huge number of users at the deployment sites. However, performance debugging against these numerous and complex traces remains a significant challenge for performance analysts. In this paper, to enable performance debugging in the large in practice, we propose a novel approach, called StackMine, that mines callstack traces to help performance analysts effectively discover highly impactful performance bugs (e.g., bugs impacting many users with long response delay). As a successful technology-transfer effort, since December 2010, StackMine has been applied in performance-debugging activities at a Microsoft team for performance analysis, especially for a large number of execution traces. Based on real-adoption experiences of StackMine in practice, we conducted an evaluation of StackMine on performance debugging in the large for Microsoft Windows 7. We also conducted another evaluation on a third-party application. The results highlight substantial benefits offered by StackMine in performance debugging in the large for large-scale software systems.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227198","","Debugging;Computer bugs;Performance analysis;Data mining;Delay;Software systems","","92","4","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Generating and Visualizing Trace Link Explanations","Y. Liu; J. Lin; O. Anuyah; R. Metoyer; J. Cleland-Huang","University of Notre Dame, Notre Dame, IN; University of Notre Dame, Notre Dame, IN; University of Notre Dame, Notre Dame, IN; University of Notre Dame, Notre Dame, IN; University of Notre Dame, Notre Dame, IN",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1033","1044","Recent breakthroughs in deep-learning (DL) approaches have resulted in the dynamic generation of trace links that are far more accurate than was previously possible. However, DL-generated links lack clear explanations, and therefore non-experts in the domain can find it difficult to understand the underlying semantics of the link, making it hard for them to evaluate the link's correctness or suitability for a specific software engineering task. In this paper we present a novel NLP pipeline for generating and visualizing trace link explanations. Our approach identifies domain-specific concepts, retrieves a corpus of concept-related sentences, mines concept definitions and usage examples, and identifies relations between cross-artifact concepts in order to explain the links. It applies a post-processing step to prioritize the most likely acronyms and definitions and to eliminate non-relevant ones. We evaluate our approach using project artifacts from three different domains of interstellar telescopes, positive train control, and electronic health-care systems, and then report coverage, correctness, and potential utility of the generated definitions. We design and utilize an explanation interface which leverages concept definitions and relations to visualize and explain trace link rationales, and we report results from a user study that was conducted to evaluate the effectiveness of the explanation interface. Results show that the explanations presented in the interface helped non-experts to understand the underlying semantics of a trace link and improved their ability to vet the correctness of the link.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794038","Software traceability;explanation interface;concept mining","Terminology;Statistical analysis;Semantics;Pipelines;Telescopes;Software;Positive train control","","1","","61","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Challenges and Opportunities in Model Checking Large Scale Distributed Systems","R. Majumdar","Max Planck Institute for Software Systems (MPI-SWS), Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1","2","The goal of the Must project is to provide design and verification support for industrial-scale distributed systems. We provide an overview of the project: its design goals, its technical features, as well as some lessons we learnt in the process of transferring academic research to an industrial tool.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3649398","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548469","","Model checking;Software engineering","","","","0","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Enabling Runtime Verification of Causal Discovery Algorithms with Automated Conditional Independence Reasoning","P. Ma; Z. Ji; P. Yao; S. Wang; K. Ren","Hong Kong University of Science and Technology, Hong Kong SAR; Hong Kong University of Science and Technology, Hong Kong SAR; Zhejiang University, China; Hong Kong University of Science and Technology, Hong Kong SAR; Zhejiang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","340","352","Causal discovery is a powerful technique for identifying causal relationships among variables in data. It has been widely used in various applications in software engineering. Causal discovery extensively involves conditional independence (CI) tests. Hence, its output quality highly depends on the performance of CI tests, which can often be unreliable in practice. Moreover, privacy concerns arise when excessive CI tests are performed. Despite the distinct nature between unreliable and excessive CI tests, this paper identifies a unified and principled approach to addressing both of them. Generally, CI statements, the outputs of CI tests, adhere to Pearl's axioms, which are a set of well-established integrity constraints on conditional independence. Hence, we can either detect erroneous CI statements if they violate Pearl's axioms or prune excessive CI statements if they are logically entailed by Pearl's axioms. Holistically, both problems boil down to reasoning about the consistency of CI statements under Pearl's axioms (referred to as CIR problem). We propose a runtime verification tool called CICHECK, designed to harden causal discovery algorithms from reliability and privacy perspectives. CICHECK employs a sound and decidable encoding scheme that translates CIR into SMT problems. To solve the CIR problem efficiently, CICHECK introduces a four-stage decision procedure with three lightweight optimizations that actively prove or refute consistency, and only resort to costly SMT-based reasoning when necessary. Based on the decision procedure to CIR, CICHECK includes two variants: ED-CHECK and P-CHECK, which detect erroneous CI tests (to enhance reliability) and prune excessive CI tests (to enhance privacy), respectively. We evaluate CICHECK on four real-world datasets and 100 CIR instances, showing its effectiveness in detecting erroneous CI tests and reducing excessive CI tests while retaining practical performance.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548460","causal discovery;conditional independence;SMT","Privacy;Runtime;Reliability engineering;Cognition;Encoding;Software reliability;Optimization","","","","57","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Understanding and Detecting On-The-Fly Configuration Bugs","T. Wang; Z. Jia; S. Li; S. Zheng; Y. Yu; E. Xu; S. Peng; X. Liao","National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; Hunan University, Changsha, China; National University of Defense Technology, Changsha, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","628","639","Software systems introduce an increasing number of configuration options to provide flexibility, and support updating the options on the fly to provide persistent services. This mechanism, however, may affect the system reliability, leading to unexpected results like software crashes or functional errors. In this paper, we refer to the bugs caused by on-the-fly configuration updates as on-the-fly configuration bugs, or OCBugs for short. In this paper, we conducted the first in-depth study on 75 real-world OCBugs from 5 widely used systems to understand the symptoms, root causes, and triggering conditions of OCBugs. Based on our study, we designed and implemented Parachute, an automated testing framework to detect OCBugs. Our key insight is that the value of one configuration option, either loaded at the startup phase or updated on the fly, should have the same effects on the target program. Parachute generates tests for on-the-fly configuration updates by mutating the existing tests and conducts differential analysis to identify OCBugs. We evaluated Parachute on 7 real-world software systems. The results show that Parachute detected 75% (42/56) of the known OCBugs, and reported 13 unknown bugs, 11 of which have been confirmed or fixed by developers until the time of writing.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00062","NSFC(grant numbers:61872373,62272473,62202474,U19A2067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172601","on-the-fly configuration updates;bug detection;metamorphic testing","Computer bugs;Writing;Software systems;Reliability;Testing;Software engineering","","4","","61","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Using Deep Learning to Generate Complete Log Statements","A. Mastropaolo; L. Pascarella; G. Bavota","SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2279","2290","Logging is a practice widely adopted in several phases of the software lifecycle. For example, during software development log statements allow engineers to verify and debug the system by exposing fine-grained information of the running software. While the benefits of logging are undisputed, taking proper decisions about where to inject log statements, what information to log, and at which log level (e.g., error, warning) is crucial for the logging effectiveness. In this paper, we present LANCE (Log stAtemeNt reCommEnder), the first approach supporting developers in all these decisions. LANCE features a Text-To-Text-Transfer-Transformer (T5) model that has been trained on 6,894,456 Java methods. LANCE takes as input a Java method and injects in it a full log statement, including a human-comprehensible logging message and properly choosing the needed log level and the statement location. Our results show that LANCE is able to (i) properly identify the location in the code where to inject the statement in 65.9% of Java methods requiring it; (ii) selecting the proper log level in 66.2% of cases; and (iii) generate a completely correct log statement including a meaningful logging message in 15.2% of cases.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3511561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794055","Logging;Empirical Study;Machine Learning on Code","Deep learning;Java;Codes;Software;Software engineering","","15","","53","","20 Jun 2022","","","IEEE","IEEE Conferences"
"The untold story of code refactoring customizations in practice","D. Oliveira; W. K. G. Assunção; A. Garcia; A. C. Bibiano; M. Ribeiro; R. Gheyi; B. Fonseca","Informatics Department, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro (PUC-Rio), Rio de Janeiro, Brazil; Computing Institute - Federal University of Alagoas (UFAL), Maceió, Brazil; Department of Computing and Systems, Federal University of Campina Grande (UFCG), Campina Grande, Brazil; Computing Institute - Federal University of Alagoas (UFAL), Maceió, Brazil",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","108","120","Refactoring is a common software maintenance practice. The literature defines standard code modifications for each refactoring type and popular IDEs provide refactoring tools aiming to support these standard modifications. However, previous studies indicated that developers either frequently avoid using these tools or end up modifying and even reversing the code automatically refactored by IDEs. Thus, developers are forced to manually apply refactorings, which is cumbersome and error-prone. This means that refactoring support may not be entirely aligned with practical needs. The improvement of tooling support for refactoring in practice requires understanding in what ways developers tailor refactoring modifications. To address this issue, we conduct an analysis of 1,162 refactorings composed of more than 100k program modifications from 13 software projects. The results reveal that developers recurrently apply patterns of additional modifications along with the standard ones, from here on called patterns of customized refactorings. For instance, we found customized refactorings in 80.77% of the Move Method instances observed in the software projects. We also investigated the features of refactoring tools in popular IDEs and observed that most of the customization patterns are not fully supported by them. Additionally, to understand the relevance of these customizations, we conducted a survey with 40 developers about the most frequent customization patterns we found. Developers confirm the relevance of customization patterns and agree that improvements in IDE's refactoring support are needed. These observations highlight that refactoring guidelines must be updated to reflect typical refactoring customizations. Also, IDE builders can use our results as a basis to enable a more flexible application of automated refactorings. For example, developers should be able to choose which method must handle exceptions when extracting an exception code into a new method.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00021","CNPq(grant numbers:141276/2020-7,14105412019-0); FAPERJ(grant numbers:225207/2016,010002285/2019,E-26/211.033/2019,202621/2019); FAPEAL(grant numbers:60030.0000000161/2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172813","Refactoring;Custom Refactoring;Refactoring Tooling Support","Surveys;Software maintenance;Java;Codes;Standards;Software engineering;Guidelines","","1","","22","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Repository for Model Driven Development (ReMoDD)","R. B. France; J. M. Bieman; S. P. Mandalaparty; B. H. C. Cheng; A. Jensen","Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science, Colorado State University, Fort Collins, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1471","1472","The Repository for Model-Driven Development (ReMoDD) contains artifacts that support Model-Driven Development (MDD) research and education. ReMoDD is collecting (1) documented MDD case studies, (2) examples of models reflecting good and bad modeling practices, (3) reference models (including metamodels) that can be used as the basis for comparing and evaluating MDD techniques, (4) generic models and transformations reflecting reusable modeling experience, (5) descriptions of modeling techniques, practices and experiences, and (6) modeling exercises and problems that can be used to develop classroom assignments and projects. ReMoDD provides a single point of access to shared artifacts reflecting high-quality MDD experience and knowledge from industry and academia. This access facilitates sharing of relevant knowledge and experience that improve MDD activities in research, education and industry.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227059","ReMoDD;Model-driven development (MDD);model repository","Unified modeling language;Communities;Computational modeling;Programming;Educational institutions;Software systems","","18","","1","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"How much does unused code matter for maintenance?","S. Eder; M. Junker; E. Jürgens; B. Hauptmann; R. Vaas; K. -H. Prommer","Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Institut für Informatik, Technische Universität München, Garching Bei Munchen, Germany; Munich Re, Munchen, Germany; Munich Re, Munchen, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1102","1111","Software systems contain unnecessary code. Its maintenance causes unnecessary costs. We present tool-support that employs dynamic analysis of deployed software to detect unused code as an approximation of unnecessary code, and static analysis to reveal its changes during maintenance. We present a case study on maintenance of unused code in an industrial software system over the course of two years. It quantifies the amount of code that is unused, the amount of maintenance activity that went into it and makes the potential benefit of tool support explicit, which informs maintainers that are about to modify unused code.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227109","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227109","Software maintenance;dynamic analysis;unnecessary code;unused code","Maintenance engineering;Assembly;Software systems;Business;Information systems;Production","","22","1","25","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"FedSlice: Protecting Federated Learning Models from Malicious Participants with Model Slicing","Z. Zhang; Y. Li; B. Liu; Y. Cai; D. Li; Y. Guo; X. Chen","Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University; Institute for AI Industry Research (AIR), Tsinghua University; School of Computer Science, Beijing University of Posts and Telecommunications; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University; Key Laboratory of High-Confidence Software Technologies (MOE), School of Computer Science, Peking University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","460","472","Crowdsourcing Federated learning (CFL) is a new crowdsourcing development paradigm for the Deep Neural Network (DNN) models, also called “software 2.0”. In practice, the privacy of CFL can be compromised by many attacks, such as free-rider attacks, adversarial attacks, gradient leakage attacks, and inference attacks. Conventional defensive techniques have low efficiency because they deploy heavy encryption techniques or rely on Trusted Execution Environments (TEEs). To improve the efficiency of protecting CFL from these attacks, this paper proposes FedSlice to prevent malicious participants from getting the whole server-side model while keeping the performance goal of CFL. FedSlice breaks the server-side model into several slices and delivers one slice to each participant. Thus, a malicious participant can only get a subset of the server-side model, preventing them from effectively conducting effective attacks. We evaluate FedSlice against these attacks, and results show that FedSlice provides effective defense: the server-side model leakage is reduced from 100% to 43.45%, the success rate of adversarial attacks is reduced from 100% to 11.66%, the average accuracy of membership inference is reduced from 71.91% to 51.58%, and the data leakage from shared gradients is reduced to the level of random guesses. Besides, FedSlice only introduces less than 2% accuracy loss and about 14% computation overhead. To the best of our knowledge, this is the first paper to discuss defense methods against these attacks to the CFL framework.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00049","National Natural Science Foundation of China(grant numbers:62172009,62141208); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172662","Deep Neural Networks;Software Engineering;Crowdsourcing;Federated Learning","Crowdsourcing;Privacy;Computational modeling;Artificial neural networks;Software;Data models;Encryption","","4","","88","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Empirical Analysis of Vulnerabilities Life Cycle in Golang Ecosystem","J. Hu; L. Zhang; C. Liu; S. Yang; S. Huang; Y. Liu","College of Command and Control Engineering, Army Engineering University of PLA, Nanjing, China; Continental-NTU Corporate Lab, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; Academy of Military Science, Nanjing, China; College of Command and Control Engineering, Army Engineering University of PLA, Nanjing, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2618","2630","Open-source software (OSS) greatly facilitates program development for developers. However, the high number of vulnerabilities in open-source software is a major concern, including in Golang, a relatively new programming language. In contrast to other commonly used OSS package managers, Golang presents a distinctive feature whereby commits are prevalently used as dependency versions prior to their integration into official releases. This attribute can prove advantageous to users, as patch commits can be implemented in a timely manner before the releases. However, Golang employs a decentralized mechanism for managing dependencies, whereby dependencies are upheld and distributed in separate repositories. This approach can result in delays in the dissemination of patches and unresolved vulnerabilities. To tackle the aforementioned concern, a comprehensive investi-gation was undertaken to examine the life cycle of vulnerability in Golang, commencing from its introduction and culminating with its rectification. To this end, a framework was established by gathering data from diverse sources and systematically amalgamating them with an algorithm to compute the lags in vulnerability patching. It turned out that 66.10% of modules in the Golang ecosystem were affected by vulnerabilities. Within the vulnerability life cycle, we found two kinds of lag impeding the propagation of vulnerability fixing. By analyzing reasons behind non-lagged and lagged vul-nerabilities, timely releasing and indexing patch versions could significantly enhance ecosystem security.","1558-1225","979-8-4007-0217-4","","National Research Foundation, Singapore; DSO National Laboratories; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549334","Vulnerability life cycle;Golang;Open-source software","Computer languages;Ecosystems;Delays;Security;Stakeholders;Open source software;Indexing","","1","","55","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Nufix: Escape From NuGet Dependency Maze","Z. Li; Y. Wang; Z. Lin; S. -C. Cheung; J. -G. Lou","Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Microsoft Research Asia, Beijing, China; The Hong Kong University of Science and Technology and Guangzhou HKUST Fok Ying Tung Research Institute, Hong Kong, China; Microsoft Research Asia, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1545","1557","Developers usually suffer from dependency maze (DM) issues, i.e., package dependency constraints are violated when a project's platform or dependencies are changed. This problem is especially serious in. NET ecosystem due to its fragmented platforms (e.g.,. NET Framework,. NET Core, and. NET Standard). Fixing DM issues is challenging due to the complexity of dependency constraints: multiple DM issues often occur in one project; solving one DM issue usually causes another DM issue cropping up; the exponential search space of possible dependency combinations is also a barrier. In this paper, we aim to help. NET developers tackle the DM issues. First, we empirically studied a set of real DM issues, learning their common fixing strategies and developers' preferences in adopting these strategies. Based on these findings, we propose NuFIX, an automated technique to repair DM issues. NUFIX formulates the repair task as a binary integer linear optimization problem to effectively derive an optimal fix in line with the learnt developers' preferences. The experiment results and expert validation show that NUFIX can generate high-quality fixes for all the DM issues with 262 popular. NET projects. Encouragingly, 20 projects (including affected projects such as Dropbox) have approved and merged our generated fixes, and shown great interests in our technique.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793877",".NET;NuGet;dependencies;empirical study","Ecosystems;Maintenance engineering;Complexity theory;Task analysis;Standards;Optimization;Software engineering","","1","","92","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Toward Automatically Completing GitHub Workflows","A. Mastropaolo; F. Zampettti; G. Bavota; M. D. Penta","SEART @ Software Institute, Università della Svizzera Italiana, Lugano, CH, Switzerland; Dept. of Engineering, University of Sannio, Benevento, IT, Italy; SEART @ Software Institute, Università della Svizzera Italiana, Lugano, CH, Switzerland; Dept. of Engineering, University of Sannio, Benevento, IT, Italy",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","128","139","Continuous integration and delivery (CI/CD) are nowadays at the core of software development. Their benefits come at the cost of setting up and maintaining the CI/CD pipeline, which requires knowledge and skills often orthogonal to those entailed in other software-related tasks. While several recommender systems have been proposed to support developers across a variety of tasks, little automated support is available when it comes to setting up and maintaining CI/CD pipelines. We present GH-WCOM (GitHub Workflow COMpletion), a Transformer-based approach supporting developers in writing a specific type of CI/CD pipelines, namely GitHub workflows. To deal with such a task, we designed an abstraction process to help the learning of the transformer while still making GH-WCOM able to recommend very peculiar workflow elements such as tool options and scripting elements. Our empirical study shows that GH-WCOM provides up to 34.23% correct predictions, and the model's confidence is a reliable proxy for the recommendations' correctness likelihood.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549587","Continuous Integration and Delivery;GitHub Workflows;Pre-Trained Models;Machine Learning on Code","Pipelines;Writing;Predictive models;Transformers;Software;Software reliability;Task analysis","","","","62","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Exploiting Library Vulnerability via Migration Based Automating Test Generation","Z. Chen; X. Hu; X. Xia; Y. Gao; T. Xu; D. Lo; X. Yang","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Huawei, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Huawei, China; Singapore Management University, Singapore; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2820","2831","In software development, developers extensively utilize third-party libraries to avoid implementing existing functionalities. When a new third-party library vulnerability is disclosed, project maintainers need to determine whether their projects are affected by the vulnerability, which requires developers to invest substantial effort in assessment. However, existing tools face a series of issues: static analysis tools produce false alarms, dynamic analysis tools require existing tests and test generation tools have low success rates when facing complex vulnerabilities. Vulnerability exploits, as code snippets provided for reproducing vulnerabilities after disclosure, contain a wealth of vulnerability-related information. This study proposes a new method based on vulnerability exploits, called Vesta (Vulnerability Exploit-based Software Testing Auto-Generator), which provides vulnerability exploit tests as the basis for developers to decide whether to update dependencies. Vesta extends the search-based test generation methods by adding a migration step, ensuring the similarity between the generated test and the vulnerability exploit, which increases the likelihood of detecting potential library vulnerabilities in a project. We perform experiments on 30 vulnerabilities disclosed in the past five years, involving 60 vulnerability-project pairs, and compare the experimental results with the baseline method, Transfer. The success rate of Vesta is 71.7% which is a 53.4% improvement over Transfer in the effectiveness of verifying exploitable vulnerabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639583","National Natural Science Foundation of China(grant numbers:62141222); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548926","Library Vulnerabilities;Search-based Test Generation","Software testing;Codes;Static analysis;Libraries;Test pattern generators;Faces;Software engineering","","","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Compatible Remediation on Vulnerabilities from Third-Party Libraries for Java Projects","L. Zhang; C. Liu; Z. Xu; S. Chen; L. Fan; L. Zhao; J. Wu; Y. Liu","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; College of Intelligence and Computing, Tianjin University, China; College of Cyber Science, Nankai University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2540","2552","With the increasing disclosure of vulnerabilities in open-source software, software composition analysis (SCA) has been widely applied to reveal third-party libraries and the associated vulnerabilities in software projects. Beyond the revelation, SCA tools adopt various remediation strategies to fix vulnerabilities, the quality of which varies substantially. However, ineffective remediation could induce side effects, such as compi-lation failures, which impede acceptance by users. According to our studies, existing SCA tools could not correctly handle the concerns of users regarding the compatibility of remediated projects. To this end, we propose Compatible Remediation of Third-party libraries (CORAL) for Maven projects to fix vulnerabilities without breaking the projects. The evaluation proved that Coralnot only fixed 87.56% of vulnerabilities which outperformed other tools (best 75.32%) and achieved a 98.67% successful compilation rate and a 92.96% successful unit test rate. Furthermore, we found that 78.45% of vulnerabilities in popular Maven projects could be fixed without breaking the compilation, and the rest of the vulnerabilities (21.55%) could either be fixed by upgrades that break the compilations or even be impossible to fix by upgrading.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00212","National Research Foundation Singapore; DSO National Laboratories; National Research Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172542","Remediation;Compatibility;Java;Open-source software","Java;Libraries;Security;Open source software;Software engineering","","7","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"BinaryAI: Binary Software Composition Analysis via Intelligent Binary Source Code Matching","L. Jiang; J. An; H. Huang; Q. Tang; S. Nie; S. Wu; Y. Zhang","Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Tencent Security Keen Lab, Shanghai, China; Tencent Security Keen Lab, Shanghai, China; Tencent Security Keen Lab, Shanghai, China; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2771","2783","While third-party libraries (TPLs) are extensively reused to enhance productivity during software development, they can also introduce potential security risks such as vulnerability propagation. Software composition analysis (SCA), proposed to identify reused TPLs for reducing such risks, has become an essential procedure within modern DevSecOps. As one of the mainstream SCA techniques, binary-to-source SCA identifies the third-party source projects contained in binary files via binary source code matching, which is a major challenge in reverse engineering since binary and source code exhibit substantial disparities after compilation. The existing binary-to-source SCA techniques leverage basic syntactic features that suffer from redundancy and lack robustness in the large-scale TPL dataset, leading to inevitable false positives and compromised recall. To mitigate these limitations, we introduce BinaryAI, a novel binary-to-source SCA technique with two-phase binary source code matching to capture both syntactic and semantic code features. First, BinaryAI trains a transformer-based model to produce function-level embeddings and obtain similar source functions for each binary function accordingly. Then by applying the link-time locality to facilitate function matching, BinaryAI detects the reused TPLs based on the ratio of matched source functions. Our experimental results demonstrate the superior performance of BinaryAI in terms of binary source code matching and the downstream SCA task. Specifically, our embedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving 22.54% recall@l and 0.34 MRR compared with 10.75% and 0.17 respectively. Additionally, BinaryAI outperforms all existing binary-to-source SCA tools in TPL detection, increasing the precision from 73.36% to 85.84% and recall from 59.81% to 64.98% compared with the well-recognized commercial SCA product Black Duck. E-https://www.binaryai.net","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548390","Software Composition Analysis;Static Binary Analysis","Codes;Source coding;Semantics;Redundancy;Syntactics;Transformers;Software","","","","77","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Testing and debugging UML models based on fUML","T. Mayerhofer","Institute of Software Technology and Interactive Systems, University of Technology, Vienna, Austria",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1579","1582","Model-driven development, which has recently gained momentum in academia as well as in industry, changed the software engineering process significantly from being code-centric to being model-centric. Models are considered as the key artifacts and as a result the success of the whole software development process relies on these models and their quality. Consequently, there is an urgent need for adequate methods to ensure high quality of models. Model execution can serve as the crucial basis for such methods by enabling to automatically test and debug models. Therefore, lessons learned from testing and debugging of code may serve as a valuable source of inspiration. However, the peculiarities of models in comparison to code, such as multiple views and different abstraction levels, impede the direct adoption of existing methods for models. Thus, we claim that the currently available tool support for model testing and debugging is still insufficient because these peculiarities are not adequately addressed. In this work, we aim at tackling these shortcomings by proposing a novel model execution environment based on fUML, which enables to efficiently test and debug UML models.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227032","model execution;model debugging;model testing;foundational UML;MDD","Unified modeling language;Testing;Debugging;Semantics;Adaptation models;Standards;Object oriented modeling","","7","","17","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"PS3: Precise Patch Presence Test Based on Semantic Symbolic Signature","Q. Zhan; X. Hu; Z. Li; X. Xia; D. Lo; S. Li","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Software Engineering Application Technology Lab, Huawei, China; Singapore Management University, Singapore; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2061","2072","During software development, vulnerabilities have posed a significant threat to users. Patches are the most effective way to combat vulnerabilities. In a large-scale software system, testing the presence of a security patch in every affected binary is crucial to ensure system security. Identifying whether a binary has been patched for a known vulnerability is challenging, as there may only be small differences between patched and vulnerable versions. Existing approaches mainly focus on detecting patches that are compiled in the same compiler options. However, it is common for developers to compile programs with very different compiler options in different situations, which causes inaccuracy for existing methods. In this paper, we propose a new approach named $PS^{3}$, referring to precise patch presence test based on semantic-level symbolic signature. $PS^{3}$ exploits symbolic emulation to extract signatures that are stable under different compiler options. Then $PS^{3}$ can precisely test the presence of the patch by comparing the signatures between the reference and the target at semantic level. To evaluate the effectiveness of our approach, we constructed a dataset consisting of 3,631 (CVE, binary) pairs of 62 recent CVEs in four C/C++ projects. The experimental results show that $PS^{3}$ achieves scores of 0.82, 0.97, and 0.89 in terms of precision, recall, and F1 score, respectively. $PS^{3}$ outperforms the state-of-the-art baselines by improving 33% in terms of F1 score and remains stable in different compiler options.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639134","Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); National Natural Science Foundation of China(grant numbers:62141222); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549629","Patch presence test;Binary analysis;Software security","Program processors;Semantics;Emulation;Software systems;Security;Testing;Software engineering","","","","38","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Heterogeneous Anomaly Detection for Software Systems via Semi-supervised Cross-modal Attention","C. Lee; T. Yang; Z. Chen; Y. Su; Y. Yang; M. R. Lyu","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Sun Yat-sen University, Guangzhou, China; Sun Yat-sen University, Guangzhou, China; Computing and Networking Innovation Lab, Cloud BU, Huawei; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1724","1736","Prompt and accurate detection of system anomalies is essential to ensure the reliability of software systems. Unlike manual efforts that exploit all available run-time information, existing approaches usually leverage only a single type of monitoring data (often logs or metrics) or fail to make effective use of the joint information among different types of data. Consequently, many false predictions occur. To better understand the manifestations of system anomalies, we conduct a systematical study on a large amount of heterogeneous data, i.e., logs and metrics. Our study demonstrates that logs and metrics can manifest system anomalies collaboratively and complementarily, and neither of them only is sufficient. Thus, integrating heterogeneous data can help recover the complete picture of a system's health status. In this context, we propose Hades, the first end-to-end semi-supervised approach to effectively identify system anomalies based on heterogeneous data. Our approach employs a hierarchical architecture to learn a global representation of the system status by fusing log semantics and metric patterns. It captures discriminative features and meaningful interactions from heterogeneous data via a cross-modal attention module, trained in a semi-supervised manner. We evaluate Hades extensively on large-scale simulated data and datasets from Huawei Cloud. The experimental results present the effectiveness of our model in detecting system anomalies. We also release the code and the annotated dataset for replication and future research.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00148","National Natural Science Foundation of China(grant numbers:62202511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172782","Software System;Anomaly Detection;Cross-modal Learning","Measurement;Codes;Costs;Semantics;Manuals;Semisupervised learning;Software systems","","11","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Bad Snakes: Understanding and Improving Python Package Index Malware Scanning","D. -L. Vu; Z. Newman; J. S. Meyers",Chainguard and FPT University; Chainguard; Chainguard,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","499","511","Open-source, community-driven package repositories see thousands of malware packages each year, but do not currently run automated malware detection systems. In this work, we explore the security goals of the repository administrators and the requirements for deploying such malware scanners via a case study of the Python ecosystem and PyPI repository, including interviews with administrators and maintainers. Further, we evaluate existing malware detection techniques for deployment in this setting by creating a benchmark dataset and comparing several existing tools: the malware checks implemented in PyPI, Bandit4Mal, and OSSGadget's OSS Detect Backdoor. We find that repository administrators have exacting requirements for such malware detection tools. Specifically, they consider a false positive rate of even 0.1% to be unacceptably high, given the large number of package releases that might trigger false alerts. Measured tools have false positive rates between 15% and 97%; increasing thresholds for detection rules to reduce this rate renders the true positive rate useless. While automated tools are far from reaching these demands, we find that a socio-technical malware detection system has emerged to meet these needs: external security researchers perform repository malware scans, filter for useful results, and report the results to repository administrators. These parties face different incentives and constraints on their time and tooling. We conclude with recommendations for improving detection capabilities and strengthening the collaboration between security researchers and software repository administrators.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172836","Open-source software (OSS) Supply Chain;Malware Detection;PyPI;Qualitative Study;Quantitative Study","Ecosystems;Malware;Security;Time factors;Indexes;Interviews;Open source software","","3","","81","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Towards Training Reproducible Deep Learning Models","B. Chen; M. Wen; Y. Shi; D. Lin; G. K. Rajbahadur; Z. M. Jiang","Centre for Software Excellence, Huawei Canada, Kingston, Canada; Huawei Technologies, Shenzhen, China; Huawei Technologies, Shenzhen, China; Centre for Software Excellence, Huawei Canada, Kingston, Canada; Centre for Software Excellence, Huawei Canada, Kingston, Canada; York University, Toronto, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2202","2214","Reproducibility is an increasing concern in Artificial Intelligence (AI), particularly in the area of Deep Learning (DL). Being able to reproduce DL models is crucial for AI-based systems, as it is closely tied to various tasks like training, testing, debugging, and auditing. However, DL models are challenging to be reproduced due to issues like randomness in the software (e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There are various practices to mitigate some of the aforementioned issues. However, many of them are either too intrusive or can only work for a specific usage context. In this paper, we propose a systematic approach to training reproducible DL models. Our approach includes three main parts: (1) a set of general criteria to thoroughly evaluate the reproducibility of DL models for two different domains, (2) a unified framework which leverages a record-and-replay technique to mitigate software-related randomness and a profile-and-patch technique to control hardware-related non-determinism, and (3) a reproducibility guideline which explains the rationales and the mitigation strategies on conducting a reproducible training process for DL models. Case study results show our approach can successfully reproduce six open source and one commercial DL models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794033","Artificial Intelligence;Deep Learning;Software Engineering;Reproducibility","Training;Deep learning;Systematics;Reproducibility of results;Software;Hardware;Artificial intelligence","","4","","69","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Trustworthy by Design","C. J. Smith","Trust Lab, AI Division, Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","8","11","The relatively recent public release of generative artificial intelligence (AI) systems has ignited a significant leap in awareness of the capabilities of AI. In parallel, there has been a recognition of AI system limitations and the bias inherent in systems created by humans. Expectations are rising for more trustworthy, human-centered, and responsible software connecting humans to powerful systems that augment their abilities. There are decades of practice designing systems that work with, and for humans, that we can build upon to face the new challenges and opportunities brought by dynamic AI systems.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3649400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548975","Keynote;ethics;trust;emerging technology;AI","Ethics;Generative AI;Face recognition;Buildings;Software;Planning;Software measurement","","","","25","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated Program Repair in the Era of Large Pre-trained Language Models","C. S. Xia; Y. Wei; L. Zhang","University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1482","1494","Automated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates (traditional) or directly predict potential patches (learning-based). Large Pre-Trained Language Models (LLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged LLMs for APR without relying on any bug-fixing datasets. Meanwhile, such existing work either failed to include state-of-the-art LLMs or was not evaluated on realistic datasets. Thus, the true power of modern LLMs on the important APR problem is yet to be revealed. In this work, we perform the first extensive study on directly applying LLMs for APR. We select 9 recent state-of-the-art LLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use LLMs to generate patches: 1) generate the entire patch function, 2) fill in a chunk of code given the prefix and suffix 3) output a single line fix. We apply the LLMs under these repair settings on 5 datasets across 3 different languages and compare different LLMs in the number of bugs fixed, generation speed and compilation rate. We also compare the LLMs against recent state-of-the-art APR tools. Our study demonstrates that directly applying state-of-the-art LLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied LLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the LLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking. Lastly, we show that LLM-based APR can be further substantially boosted via: 1) increasing the sample size, and 2) incorporating fix template information.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00129","NSF(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172803","Automated Program Repair;Machine Learning","Codes;Computer bugs;Maintenance engineering;Software;Distance measurement;Task analysis;Faces","","63","","89","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Towards Boosting Patch Execution On-the-Fly","S. Benton; Y. Xie; L. Lu; M. Zhang; X. Li; L. Zhang","University of Texas at Dallas; Tsinghua University; Southern University of Science and Technology; Meta Platforms, Inc.; Kennesaw State University; University of Illinois at Urbana-Champaign",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2165","2176","Program repair is an integral part of every software system's life-cycle but can be extremely challenging. To date, various automated program repair (APR) techniques have been proposed to reduce manual debugging efforts. However, given a real-world buggy program, a typical APR technique can generate a large number of patches, each of which needs to be validated against the original test suite, incurring extremely high computation costs. Although existing APR techniques have already leveraged various static and/or dynamic information to find the desired patches faster, they are still rather costly. In this work, we propose SeAPR (Self-Boosted Automated Program Repair), the first general-purpose technique to leverage the earlier patch execution information during APR to directly boost existing APR techniques themselves on-the-fly. Our basic intuition is that patches similar to earlier high-quality/low-quality patches should be promoted/degraded to speed up the detection of the desired patches. The experimental study on 13 state-of-the-art APR tools demonstrates that, overall, SeAPR can sub-stantially reduce the number of patch executions with negligible overhead. Our study also investigates the impact of various configurations on SeAPR. Lastly, our study demonstrates that SeAPR can even leverage the historical patch execution information from other APR tools for the same buggy program to further boost the current APR tool.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510117","National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793548","","Costs;Manuals;Debugging;Maintenance engineering;Benchmark testing;Boosting;Software","","1","","50","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Code Review of Build System Specifications: Prevalence, Purposes, Patterns, and Perceptions","M. Nejati; M. Alfadel; S. McIntosh","Software REBELs, University of Waterloo, Canada; Software REBELs, University of Waterloo, Canada; Software REBELs, University of Waterloo, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1213","1224","Build systems automate the integration of source code into executables. Maintaining build systems is known to be challenging. Lax build maintenance can lead to costly build breakages or unexpected software behaviour. Code review is a broadly adopted practice to improve software quality. Yet, little is known about how code review is applied to build specifications. In this paper, we present the first empirical study of how code review is practiced in the context of build specifications. Through quantitative analysis of 502,931 change sets from the Qt and Eclipse communities, we observe that changes to build specifications are at least two times less frequently discussed during code review when compared to production and test code changes. A qualitative analysis of 500 change sets reveals that (i) comments on changes to build specifications are more likely to point out defects than rates reported in the literature for production and test code, and (ii) evolvability and dependency-related issues are the most frequently raised patterns of issues. Follow-up interviews with nine developers with 1–40 years of experience point out social and technical factors that hinder rigorous review of build specifications, such as a prevailing lack of understanding of and interest in build systems among developers, and the lack of dedicated tooling to support the code review of build specifications.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172582","build systems;build specifications;code review","Codes;Statistical analysis;Source coding;Production;Software quality;Maintenance engineering;Interviews","","3","","45","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Towards the verification of multi-diagram UML models","A. Motta","Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1531","1534","UML is a general-purpose modeling language that offers a heterogeneous set of diagrams to describe the different views of a software system. While there seems to be a general consensus on the semantics of some individual diagrams, the composite semantics of the different views is still an open problem. During my PhD I am considering a significant and consistent set of UML diagrams, where timed-related properties can be modeled carefully, and I am ascribing them with a formal semantics based on metric temporal logic. The use of logic is aimed to help capture the composite semantics of the different views efficiently. The result is then used to feed a bounded model/satisfiability checker to allow users to verify these systems, even from the initial phases of the design. The final goal is to realize an advanced modeling framework where users can exploit both a well-known modeling notation and advanced verification capabilities seamlessly.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227044","UML;formal verification;temporal logic","Unified modeling language;Semantics;Computational modeling;Prototypes;Clocks;Software systems","","","","18","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Towards More Practical Automation of Vulnerability Assessment","S. Pan; L. Bao; J. Zhou; X. Hu; X. Xia; S. Li","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China; Centre for Software Excellence, Huawei, Kingston, Ontario, Canada; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Ningbo, Zhejiang, China; Huawei, Hangzhou, Zhejiang, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, Zhejiang, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1824","1836","It is increasingly suggested to identify emerging software vulner-abilities (SVs) through relevant development activities (e.g., issue reports) to allow early warnings to open source software (OSS) users. However, the support for the following assessment of the de-tected SVs has not yet been explored. SV assessment characterizes the detected SVs to prioritize limited remediation resources on the critical ones. To fill this gap, we aim to enable early vulnerability assessment based on SV-related issue reports (SIR). Besides, we observe the following concerns of the existing assessment techniques: 1) the assessment output lacks rationale and practical value; 2) the associations between Common Vulnerability Scoring System (CVSS) metrics have been ignored; 3) insufficient evaluation sce-narios and metrics. We address these concerns to enhance the prac-ticality of our proposed early vulnerability assessment approach (namely proEVA). Specifically, based on the observation of strong associations between CVSS metrics, we propose a prompt-based model to exploit such relations for CVSS metrics prediction. More-over, we design a curriculum-learning (CL) schedule to guide the model better learn such hidden associations during training. Aside from the standard classification metrics adopted in existing works, we propose two severity-aware metrics to provide a more compre-hensive evaluation regarding the prioritization of the high-severe SVs. Experimental results show that proEVA significantly outper-forms the baselines in both types of metrics. We further discuss the transferability of the prediction model regarding the upgrade of the assessment system, an important yet overlooked evaluation scenario in existing works. The results verify that proEVA is more efficient and flexible in migrating to different assessment systems.","1558-1225","979-8-4007-0217-4","","National Key Research and Development Program of China(grant numbers:2021YFB2701102); National Science Foundation of China(grant numbers:62372398,62141222,U20A20173); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548614","Software Security;Vulnerability Assessment;CVSS","Measurement;Training;Schedules;Automation;Predictive models;Standards;Open source software","","","","73","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Context-Aware Name Recommendation for Field Renaming","C. Dong; Y. Jiang; N. Niu; Y. Zhang; H. Liu","Beijing Institute of Technology, Beijing, China; Peking University, Beijing, China; University of Cincinnati, United States; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2905","2917","Renaming is one of the most popular software refactorings. Although developers may know what the new name should be when they conduct a renaming, it remains valuable for refactoring tools to recommend new names automatically so that developers can simply hit Enter and efficiently accept the recommendation to accomplish the refactoring. Consequently, most IDEs automatically recommend new names for renaming refactorings by default. However, the recommendation made by mainstream IDEs is often incorrect. For example, the precision of IntelliJ IDEA in recommending names for field renamings is as low as 6.3%. To improve the accuracy, in this paper, we propose a context-aware lightweight approach (called CARER) to recommend new names for Java field renamings. Different from mainstream IDEs that rely heavily on initializers and data types of the to-be-renamed fields, CARER exploits both dynamic and static contexts of the renamings as well as naming conventions. We evaluate CARER on 1.1K real-world field renamings discovered from open-source applications. Our evaluation results suggest that CARER can significantly improve the state of the practice in recommending new names for field renamings, improving the precision from 6.30% to 61.15%, and recall from 6.30% to 41.50%. Our evaluation results also suggest that CARER is as efficient as IntelliJ IDEA is, making it suitable to be integrated into IDEs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639195","National Natural Science Foundation of China(grant numbers:62232003,62172037); China Postdoctoral Science Foundation(grant numbers:2023M740078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548109","Refactoring;Rename;Recommendation;Context-Aware","Java;Software;Software engineering","","","","49","","14 Jun 2024","","","IEEE","IEEE Conferences"
"SkCoder: A Sketch-based Approach for Automatic Code Generation","J. Li; Y. Li; G. Li; Z. Jin; Y. Hao; X. Hu","Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; aiXcoder, Beijing, China; Zhejiang University, Ningbo, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2124","2135","Recently, deep learning techniques have shown great success in automatic code generation. Inspired by the code reuse, some researchers propose copy-based approaches that can copy the content from similar code snippets to obtain better performance. Practically, human developers recognize the content in the similar code that is relevant to their needs, which can be viewed as a code sketch. The sketch is further edited to the desired code. However, existing copy-based approaches ignore the code sketches and tend to repeat the similar code without necessary modifications, which leads to generating wrong results. In this paper, we propose a sketch-based code generation approach named Skcoderto mimic developers' code reuse behavior. Given a natural language requirement, Skcoderretrieves a similar code snippet, extracts relevant parts as a code sketch, and edits the sketch into the desired code. Our motivations are that the extracted sketch provides a well-formed pattern for telling models “how to write”. The post-editing further adds requirement-specific details into the sketch and outputs the complete code. We conduct experiments on two public datasets and a new dataset collected by this work. We compare our approach to 20 baselines using 5 widely used metrics. Experimental results show that (1) Skcodercan generate more correct programs, and outperforms the state-of-the-art -CodeT5-base by 30.30%, 35.39%, and 29.62% on three datasets. (2) Our approach is effective to multiple code generation models and improves them by up to 120.1% in Pass@l. (3) We investigate three plausible code sketches and discuss the importance of sketches. (4) We manually evaluate the generated code and prove the superiority of our Skcoderin three aspects.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172719","Code Generation;Deep Learning","Measurement;Deep learning;Codes;Natural languages;Behavioral sciences;Software engineering","","15","","45","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Identifying Key Classes for Initial Software Comprehension: Can We Do It Better?","W. Pan; X. Du; H. Ming; D. -K. Kim; Z. Yang","School of Computer Science and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; School of Computer Science and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; School of Engineering and Computer Science, Oakland University, Rochester, USA; School of Engineering and Computer Science, Oakland University, Rochester, USA; School of Computer Science, Xi'an Jiaotong University, Shaanxi, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1878","1889","Key classes are excellent starting points for developers, especially newcomers, to comprehend an unknown software system. Though many unsupervised key class identification approaches have been proposed in the literature by representing software as class dependency networks (aka software networks) and using some network metrics (e.g., h-index, a-index, and coreness), they are never aware of the field where the nodes exist and the effect of the field on the importance of the nodes in it. According to the classic field theory in physics, every material particle is in a field through which they exert an impact on other particles in the field via non-contact interactions (e.g., electromagnetic force, gravity, and nuclear force). Similarly, every node in a software network might also exist in a field, which might affect the importance of class nodes in it. In this paper, we propose an approach, iFit, to identify key classes in object-oriented software systems. First, we represent software as a CSNWD (Weighted Directed Class-level Software Network) to capture the topological structure of software, including classes, their couplings, and the direction and strength of couplings. Second, we assume that the nodes in the CSNWD exist in a gravitation-like field and propose a new metric, CG (Cumulative Gravitation-like importance), to measure the importance of classes. CG is inspired by Newton's gravitational formula and uses the PageRank value computed by a biased-PageRank algorithm as the masses of classes. Finally, classes in the system are sorted in descending order according to their CG values, and a cutoff is utilized, that is, the top-ranked classes are recommended as key classes. The experiments were performed on a data set composed of six open-source Java systems from the literature. The results show that iFit is superior to the baseline approaches on 93.75% of the total cases, and is scalable to large-scale software systems. Besides, we find that iFit is neutral to the weighting mechanisms used to assign the weights for different coupling types in the CSNWD, that is, when applying iFit to identify key classes, we can use any one of the weighting mechanisms.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00160","National Natural Science Foundation of China(grant numbers:62272412,62032010,61976187); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172749","complex networks;field theory;key classes;PageRank;program comprehension","Couplings;Measurement;Java;Electromagnetic forces;Software systems;Object recognition;Physics","","","","42","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Keyword Extraction From Specification Documents for Planning Security Mechanisms","J. J. Poozhithara; H. U. Asuncion; B. Lagesse","Computer & Software Systems University of Washington, Bothell, USA; Computer & Software Systems University of Washington, Bothell, USA; Computer & Software Systems University of Washington, Bothell, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1661","1673","Software development companies heavily invest both time and money to provide post-production support to fix security vulnerabilities in their products. Current techniques identify vulnerabilities from source code using static and dynamic analyses. However, this does not help integrate security mechanisms early in the architectural design phase. We develop VDocScan, a technique for predicting vulnerabilities based on specification documents, even before the development stage. We evaluate VDocScan using an extensive dataset of CVE vulnerability reports mapped to over 3600 product documentations. An evaluation of 8 CWE vulnerability pillars shows that even interpretable whitebox classifiers predict vulnerabilities with up to 61.1% precision and 78% recall. Further, using strategies to improve the relevance of extracted keywords, addressing class imbalance, segregating products into categories such as Operating Systems, Web applications, and Hardware, and using blackbox ensemble models such as the random forest classifier improves the performance to 96% precision and 91.1% recall. The high precision and recall shows that VDocScan can anticipate vulnerabilities detected in a product's lifetime ahead of time during the Design phase to incorporate necessary security mechanisms. The performance is consistently high for vulnerabilities with the mode of introduction: architecture and design.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00143","CSS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172752","Security;Vulnerability Prediction;CVE;CWE;Keyword Extraction;Documentation","Correlation;Source coding;Operating systems;Companies;Watches;Predictive models;Planning","","","","72","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Fine-Grained, Accurate, and Scalable Source Code Differencing","J. -R. Falleri; M. Martinez","Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, Talence, France; Universitat Politècnica de Catalunya, Barcelona, Spain",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2856","2867","Understanding code changes is of crucial importance in a wide range of software evolution activities. The traditional approach is to use textual differencing, as done with success since the 1970s with the ubiquitous diff tool. However, textual differencing has the important limitation of not aligning the changes to the syntax of the source code. To overcome these issues, structural (i.e. syntactic) differencing has been proposed in the literature, notably GumTree which was one of the pioneering approaches. The main drawback of GumTree's algorithm is the use of an optimal, but expensive tree-edit distance algorithm that makes it difficult to diff large ASTs. In this article, we describe a less expensive heuristic that enables GumTree to scale to large ASTs while yielding results of better quality than the original GumTree. We validate this new heuristic against 4 datasets of changes in two different languages, where we generate edit-scripts with a median size 50% smaller and a total speedup of the matching time between 50x and 281x.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548607","Software evolution;Code differencing","Codes;Accuracy;Source coding;Syntactics;Software;Distance measurement;Software engineering","","","","42","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Trust Enhancement Issues in Program Repair","Y. Noller; R. Shariffdeen; X. Gao; A. Roychoudhury","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2228","2240","Automated program repair is an emerging technology that seeks to automatically rectify bugs and vulnerabilities using learning, search, and semantic analysis. Trust in automatically generated patches is necessary for achieving greater adoption of program repair. Towards this goal, we survey more than 100 software practitioners to understand the artifacts and setups needed to enhance trust in automatically generated patches. Based on the feedback from the survey on developer preferences, we quantitatively evaluate existing test-suite based program repair tools. We find that they cannot produce high-quality patches within a top-10 ranking and an acceptable time period of 1 hour. The developer feedback from our qualitative study and the observations from our quantitative examination of existing repair tools point to actionable insights to drive program repair research. Specifically, we note that producing repairs within an acceptable time-bound is very much dependent on leveraging an abstract search space representation of a rich enough search space. Moreover, while additional developer inputs are valuable for generating or ranking patches, developers do not seem to be interested in a significant human-in-the-loop interaction.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794080","program repair","Semantics;Computer bugs;Maintenance engineering;Software;Human in the loop;Software engineering","","15","","52","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Discovering Repetitive Code Changes in Python ML Systems","M. Dilhara; A. Ketkar; N. Sannidhi; D. Dig","University of Colorado Boulder, USA; Uber Technologies Inc., USA; University of Colorado Boulder, USA; University of Colorado Boulder, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","736","748","Over the years, researchers capitalized on the repetitiveness of software changes to automate many software evolution tasks. Despite the extraordinary rise in popularity of Python-based ML systems, they do not benefit from these advances. Without knowing what are the repetitive changes that ML developers make, researchers, tool, and library designers miss opportunities for automation, and ML developers fail to learn and use best coding practices. To fill the knowledge gap and advance the science and tooling in ML software evolution, we conducted the first and most fine-grained study on code change patterns in a diverse corpus of 1000 top-rated ML systems comprising 58 million SLOC. To conduct this study we reuse, adapt, and improve upon the state-of-the-art repetitive change mining techniques. Our novel tool, R-CPATMINER, mines over 4M commits and constructs 350K fine-grained change graphs and detects 28K change patterns. Using thematic analysis, we identified 22 pattern groups and we reveal 4 major trends of how ML developers change their code. We surveyed 650 ML developers to further shed light on these patterns and their applications, and we received a 15% response rate. We present actionable, empirically-justified implications for four audiences: (i) researchers, (ii) tool builders, (iii) ML library vendors, and (iv) developers and educators.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510225","CSCI(grant numbers:7000-08-Spring 2022); NSF(grant numbers:CCF-1553741,CNS-1941898); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794123","Refactoring;Repetition;Code changes;Machine learning;Python","Java;Codes;Market research;Software systems;Libraries;Data mining;History","","11","","92","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"FlakiMe: Laboratory-Controlled Test Flakiness Impact Assessment","M. Cordy; R. Rwemalika; A. Franci; M. Papadakis; M. Harman","SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; Meta Platforms inc., and University College, London, United Kingdom",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","982","994","Much research on software testing makes an implicit assumption that test failures are deterministic such that they always witness the presence of the same defects. However, this assumption is not always true because some test failures are due to so-called flaky tests, i.e., tests with non-deterministic outcomes. To help testing researchers better investigate flakiness, we introduce a test flakiness assessment and experimentation platform, called FlakiMe. FlakiMe supports the seeding of a (controllable) degree of flakiness into the behaviour of a given test suite. Thereby, FlakiMe equips researchers with ways to investigate the impact of test flakiness on their techniques under laboratory-controlled conditions. To demonstrate the application of FlakiMe, we use it to assess the impact of flakiness on mutation testing and program repair (the PRAPR and ARJA methods). These results indicate that a 10% flakiness is sufficient to affect the mutation score, but the effect size is modest (2% – 5%), while it reduces the number of patches produced for repair by 20% up to 100% of repair problems; a devastating impact on this application of testing. Our experiments with FlakiMe demonstrate that flakiness affects different testing applications in very different ways, thereby motivating the need for a laboratory-controllable flakiness impact assessment platform and approach such as FlakiMe.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510194","CORE(grant numbers:C20/IS/14761415/TestFlakes); European Research Council (ERC)(grant numbers:741278); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794060","","Software testing;Location awareness;Sensitivity;Maintenance engineering;Aerospace electronics;Software engineering;Resilience","","4","","43","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Characterizing logging practices in open-source software","D. Yuan; S. Park; Y. Zhou","University of California, San Diego, USA; University of California, San Diego, USA; University of California, San Diego, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","102","112","Software logging is a conventional programming practice. While its efficacy is often important for users and developers to understand what have happened in the production run, yet software logging is often done in an arbitrary manner. So far, there have been little study for understanding logging practices in real world software. This paper makes the first attempt (to the best of our knowledge) to provide a quantitative characteristic study of the current log messages within four pieces of large open-source software. First, we quantitatively show that software logging is pervasive. By examining developers' own modifications to the logging code in the revision history, we find that they often do not make the log messages right in their first attempts, and thus need to spend a significant amount of efforts to modify the log messages as after-thoughts. Our study further provides several interesting findings on where developers spend most of their efforts in modifying the log messages, which can give insights for programmers, tool developers, and language and compiler designers to improve the current logging practice. To demonstrate the benefit of our study, we built a simple checker based on one of our findings and effectively detected 138 pieces of new problematic logging code from studied software (24 of them are already confirmed and fixed by developers).","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227202","log message;log quality;empirical study;failure diagnosis","Open source software;Servers;History;Production;Programming;Printing","","163","5","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Guidelines for Assessing the Accuracy of Log Message Template Identification Techniques","Z. A. Khan; D. Shin; D. Bianculli; L. Briand","University of Luxembourg Luxembourg, Luxembourg; University of Luxembourg Luxembourg, Luxembourg; University of Luxembourg Luxembourg, Luxembourg; University of Luxembourg Luxembourg, Luxembourg University of Ottawa, Ottawa, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1095","1106","Log message template identification aims to convert raw logs containing free-formed log messages into structured logs to be processed by automated log-based analysis, such as anomaly detection and model inference. While many techniques have been proposed in the literature, only two recent studies provide a comprehensive evaluation and comparison of the techniques using an established benchmark composed of real-world logs. Nevertheless, we argue that both studies have the following issues: (1) they used different accuracy metrics without comparison between them, (2) some ground-truth (oracle) templates are incorrect, and (3) the accuracy evaluation results do not provide any information regarding incorrectly identified templates. In this paper, we address the above issues by providing three guidelines for assessing the accuracy of log template identification techniques: (1) use appropriate accuracy metrics, (2) perform oracle template correction, and (3) perform analysis of incorrect templates. We then assess the application of such guidelines through a comprehensive evaluation of 14 existing template identification techniques on the established benchmark logs. Results show very different insights than existing studies and in particular a much less optimistic outlook on existing techniques.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793976","logs;template identification;metrics","Measurement;Analytical models;Benchmark testing;Anomaly detection;Guidelines;Software engineering","","14","","26","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Improving API Knowledge Discovery with ML: A Case Study of Comparable API Methods","D. Nam; B. Myers; B. Vasilescu; V. Hellendoorn","Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA; Carnegie Mellon University, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1890","1906","Developers constantly learn new APIs, but often lack necessary information from documentation, resorting instead to popular question-and-answer platforms such as Stack Overflow. In this paper, we investigate how to use recent machine-Iearning-based knowledge extraction techniques to automatically identify pairs of comparable API methods and the sentences describing the comparison from Stack Overflow answers. We first built a prototype that can be stocked with a dataset of comparable API methods and provides tool-tips to users in search results and in API documentation. We conducted a user study with this tool based on a dataset of TensorFlow comparable API methods spanning 198 hand-annotated facts from Stack Overflow posts. This study confirmed that providing comparable API methods can be useful for helping developers understand the design space of APIs: developers using our tool were significantly more aware of the comparable API methods and better understood the differences between them. We then created SOREL, an comparable API methods knowledge extraction tool trained on our hand-annotated corpus, which achieves a 71% precision and 55% recall at discovering our manually extracted facts and discovers 433 pairs of comparable API methods from thousands of unseen Stack Overflow posts. This work highlights the merit of jointly studying programming assistance tools and constructing machine learning techniques to power them.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00161","NSF(grant numbers:CCF-2007482); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172706","API;Knowledge Discovery;Pre trained Language Models;Stack Overflow","Prototypes;Documentation;Machine learning;Programming;Knowledge discovery;Software engineering","","2","","82","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Do I Belong? Modeling Sense of Virtual Community Among Linux Kernel Contributors","B. Trinkenreich; K. -J. Stol; A. Sarma; D. M. German; M. A. Gerosa; I. Steinmacher","Northern Arizona University, Flagstaff, AZ, USA; Lero, the SFI Research Centre for Software, University College Cork, Ireland; Oregon State University, Portland, OR, USA; University of Victoria, Victoria, Canada; Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","319","331","The sense of belonging to a community is a basic human need that impacts an individual's behavior, long-term engagement, and job satisfaction, as revealed by research in disciplines such as psychology, healthcare, and education. Despite much research on how to retain developers in Open Source Software (OSS) projects and other virtual, peer-production communities, there is a paucity of research investigating what might contribute to a sense of belonging in these communities. To that end, we develop a theoretical model that seeks to understand the link between OSS developer motives and a Sense of Virtual Community (SVC). We test the model with a dataset collected in the Linux Kernel developer community (N=225), using structural equation modeling techniques. Our results for this case study show that intrinsic motivations (social or hedonic motives) are positively associated with a sense of virtual community, but living in an authoritative country and being paid to contribute can reduce the sense of virtual community. Based on these results, we offer suggestions for open source projects to foster a sense of virtual community, with a view to retaining contributors and Improving projects' sustainability.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00038","National Science Foundation(grant numbers:1900903,1901031,2236198,2235601); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172733","sense of virtual community;belonging;open source;software developers;human factors;survey;PLS-SEM","Surveys;Linux;Static VAr compensators;Psychology;Medical services;Mathematical models;Kernel","","6","","112","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Practical Program Repair via Preference-based Ensemble Strategy","W. Zhong; C. Li; K. Liu; T. Xu; J. Ge; T. F. Bissyandé; B. Luo; V. Ng","National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; Huawei Software Engineering Application Technology Lab, Hangzhou, China; Huawei Software Engineering Application Technology Lab, Hangzhou, China; National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; University of Luxembourg, Luxembourg; National Key Laboratory for Novel Software Technology, Nanjing University, China, Nanjing, China; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","25","37","To date, over 40 Automated Program Repair (APR) tools have been designed with varying bug-fixing strategies, which have been demonstrated to have complementary performance in terms of being effective for different bug classes. Intuitively, it should be feasible to improve the overall bug-fixing performance of APR via assembling existing tools. Unfortunately, simply invoking all available APR tools for a given bug can result in unacceptable costs on APR execution as well as on patch validation (via expensive testing). Therefore, while assembling existing tools is appealing, it requires an efficient strategy to reconcile the need to fix more bugs and the requirements for practicality. In light of this problem, we propose a Preference-based Ensemble Program Repair framework (P-EPR), which seeks to effectively rank APR tools for repairing different bugs. P-EPR is the first non-learning-based APR ensemble method that is novel in its exploitation of repair patterns as a major source of knowledge for ranking APR tools and its reliance on a dynamic update strategy that enables it to immediately exploit and benefit from newly derived repair results. Experimental results show that P-EPR outperforms existing strategies significantly both in flexibility and effectiveness.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623310","National Key Research and Development Program of China(grant numbers:2022YFF0711404); National Natural Science Foundation of China(grant numbers:62172214); NSF(grant numbers:2034508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549166","program repair;ensemble strategy","Measurement;Costs;Computer bugs;Maintenance engineering;Software;Ensemble learning;Testing","","","","54","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Doppelgänger Test Generation for Revealing Bugs in Autonomous Driving Software","Y. Huai; Y. Chen; S. Almanee; T. Ngo; X. Liao; Z. Wan; Q. A. Chen; J. Garcia","University of California, Irvine; University of California, Irvine; University of California, Irvine; VNU University of Engineering and Technology; University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2591","2603","Vehicles controlled by autonomous driving software (ADS) are expected to bring many social and economic benefits, but at the current stage not being broadly used due to concerns with regard to their safety. Virtual tests, where autonomous vehicles are tested in software simulation, are common practices because they are more efficient and safer compared to field operational tests. Specifically, search-based approaches are used to find particularly critical situations. These approaches provide an opportunity to automatically generate tests; however, system-atically producing bug-revealing tests for ADS remains a major challenge. To address this challenge, we introduce DoppelTest, a test generation approach for ADSes that utilizes a genetic algorithm to discover bug-revealing violations by generating scenarios with multiple autonomous vehicles that account for traffic control (e.g., traffic signals and stop signs). Our extensive evaluation shows that DoppelTest can efficiently discover 123 bug-revealing violations for a production-grade ADS (Baidu Apollo) which we then classify into 8 unique bug categories.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00216","NSF(grant numbers:1823262,1929771,1932464,2145493); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172903","cyber-physical systems;autonomous driving systems;search-based software testing","Software testing;Computer bugs;Web and internet services;Traffic control;Software systems;Safety;Test pattern generators","","9","","81","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Learning and Repair of Deep Reinforcement Learning Policies from Fuzz-Testing Data","M. Tappler; A. Pferscher; B. K. Aichernig; B. Könighofer","Graz University of Technology, Institute of Software Technology, Graz, Austria; Graz University of Technology, Institute of Software Technology, Graz, Austria; Graz University of Technology, Institute of Software Technology, Graz, Austria; Graz University of Technology, Institute of Applied Information Processing and Communications, Graz, Austria",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","38","50","Reinforcement learning from demonstrations (RLfD) is a promising approach to improve the exploration efficiency of reinforcement learning (RL) by learning from expert demonstrations in addition to interactions with the environment. In this paper, we propose a framework that combines techniques from search-based testing with RLfD with the goal to raise the level of dependability of RL policies and to reduce human engineering effort. Within our framework, we provide methods for efficiently training, evaluating, and repairing RL policies. Instead of relying on the costly collection of demonstrations from (human) experts, we automatically compute a diverse set of demonstrations via search-based fuzzing methods and use the fuzz demonstrations for RLfD. To evaluate the safety and robustness of the trained RL agent, we search for safety-critical scenarios in the black-box environment. Finally, when unsafe behavior is detected, we compute demonstrations through fuzz testing that represent safe behavior and use them to repair the policy. Our experiments show that our framework is able to efficiently learn high-performing and safe policies without requiring any expert knowledge.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548388","Deep reinforcement learning;Reinforcement learning from demonstrations;Search-based software testing;Policy repair","Training;Video games;Maintenance engineering;Fuzzing;Robustness;Safety;Software reliability","","2","","49","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Learning-based Widget Matching for Migrating GUI Test Cases","Y. Zhang; W. Zhang; D. Ran; Q. Zhu; C. Dou; D. Hao; T. Xie; L. Zhang","Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China; Key Lab of HCST (PKU), MOE; SCS Peking University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","828","840","GUI test case migration is to migrate GUI test cases from a source app to a target app. The key of test case migration is widget matching. Recently, researchers have proposed various approaches by formulating widget matching as a matching task. However, since these matching approaches depend on static word embeddings without using contextual information to represent widgets and manually formulated matching functions, there are main limitations of these matching approaches when handling complex matching relations in apps. To address the limitations, we propose the first learning-based widget matching approach named TEMdroid ( TEst Migration) for test case migration. Unlike the existing approaches, TEMdroid uses BERT to capture contextual information and learns a matching model to match widgets. Additionally, to balance the significant imbalance between positive and negative samples in apps, we design a two-stage training strategy where we first train a hard-negative sample miner to mine hard-negative samples, and further train a matching model using positive samples and mined hard-negative samples. Our evaluation on 34 apps shows that TEM-droid is effective in event matching (i.e., widget matching and target event synthesis) and test case migration. For event matching, TEM-droid's Top1 accuracy is 76%, improving over 17% compared to baselines. For test case migration, TEMdroid's F1 score is 89%, also 7% improvement compared to the baseline approach.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62232003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548171","Software and its engineering → Software testing and debugging;Test migration;GUI testing;Deep learning","Training;Software testing;Software;Data models;Task analysis;Graphical user interfaces;Context modeling","","","","88","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Efficiently Trimming the Fat: Streamlining Software Dependencies with Java Reflection and Dependency Analysis","X. Song; Y. Wang; X. Cheng; G. Liang; Q. Wang; Z. Zhu","Northeastern University, Shenyang, China; Northeastern University, Shenyang, China; Huawei Cloud Computing Technologies Co., Ltd., Beijing, China; Huawei Cloud Computing Technologies Co., Ltd., Beijing, China; Huawei Cloud Computing Technologies Co., Ltd., Beijing, China; National Frontiers Science Center for Industrial Intelligence and Systems Optimization, and Key Laboratory of Data Analytics and Optimization for Smart Industry, Northeastern University, Shenyang, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1261","1272","Numerous third-party libraries introduced into client projects are not actually required, resulting in modern software being gradually bloated. Software developers may spend much unnecessary effort to manage the bloated dependencies: keeping the library versions up-to-date, making sure that heterogeneous licenses are compatible, and resolving dependency conflict or vulnerability issues. However, the prior debloating techniques can easily produce false alarms of bloated dependencies since they are less effective in analyzing Java reflections. Besides, the solutions given by the existing approaches for removing bloated dependencies may induce new issues that are not conducive to dependency management. To address the above limitations, in this paper, we developed a technique, Slimming, to remove bloated dependencies from software projects reliably. Slimming statically analyzes the Java reflections that are commonly leveraged by popular frameworks (e.g., Spring Boot) and resolves the reflective targets via parsing configuration files (*. xml, *. ym1 and *. properties). By modeling string manipulations, Slimming fully resolves the string arguments of our concerned reflection APIs to identify all the required dependencies. More importantly, it helps developers analyze the debloating solutions by weighing the benefits against the costs of dependency management. Our evaluation results show that the static reflection analysis capability of Slimming outperforms all the other existing techniques with 97.0% of Precision and 98.8% of Recall. Compared with the prior debloating techniques, Slimming can reliably remove the bloated dependencies with a 100% test passing ratio and improve the rationality of debloating solutions. In our large-scale study in the Maven ecosystem, Slimming reported 484 bloated dependencies to 66 open-source projects. 38 reports (57.6%) have been confirmed by developers.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62141210); Fundamental Research Funds for the Central Universities(grant numbers:N2217005); Nanjing University(grant numbers:KFKT2021B01); 111 Project(grant numbers:B16009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549332","Bloated Dependencies;Java Reflection;Dependency Management","Java;Ecosystems;XML;Licenses;Reflection;Software;Libraries","","","","47","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Does the Stream API Benefit from Special Debugging Facilities? A Controlled Experiment on Loops and Streams with Specific Debuggers","J. Reichl; S. Hanenberg; V. Gruhn","NA; Institute for Computer Science and Business Information Systems (ICB), University of Duisburg-Essen, Essen, Germany; Institute for Computer Science and Business Information Systems (ICB), University of Duisburg-Essen, Essen, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","576","588","Java's Stream API, that massively makes use of lambda expressions, permits a more declarative way of defining operations on collections in comparison to traditional loops. While experimental results suggest that the use of the Stream API has measurable benefits with respect to code readability (in comparison to loops), a remaining question is whether it has other implications. And one of such implications is, for example, tooling in general and debugging in particular because of the following: While the traditional loop-based approach applies filters one after another to single elements, the Stream API applies filters on whole collections. In the meantime there are dedicated debuggers for the Stream API, but it remains unclear whether such a debugger (on the Stream API) has a measurable benefit in comparison to the traditional stepwise debugger (on loops). The present papers introduces a controlled experiment on the debugging of filter operations using a stepwise debugger versus a stream debugger. The results indicate that under the experiment's settings the stream debugger has a significant ($\mathrm{p} < .001$) and large, positive effect $(\eta_{p}^{2}=.899;\ \frac{M_{stepwise}}{M_{stream}} \sim 204\%)$. However, the experiment reveals that additional factors interact with the debugger treatment such as whether or not the failing object is known upfront. The mentioned factor has a strong and large disordinal interaction effect with the debugger ($\mathrm{p} < .001; \eta_{p}^{2}=.928$): In case an object is known upfront that can be used to identify a failing filter, the stream debugger is even less efficient than the stepwise debugger $(\frac{M_{stepwise}}{M_{stream}}\sim 72\%)$. Hence, while we found overall a positive effect of the stream debugger, the answer whether or not debugging is easier on loops or streams cannot be answered without taking the other variables into account. Consequently, we see a contribution of the present paper not only in the comparison of different debuggers but in the identification of additional factors.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172837","Software Engineering;Programming Techniques;Debugging aids;Usability testing","Java;Codes;Debugging;Software;Object recognition;Testing;Software engineering","","1","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Knowledge-Based Environment Dependency Inference for Python Programs","H. Ye; W. Chen; W. Dou; G. Wu; J. Wei","State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Lab of Computer Sciences, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1245","1256","Besides third-party packages, the Python interpreter and system libraries are also critical dependencies of a Python program. In our empirical study, 34% programs are only compatible with specific Python interpreter versions, and 24% programs require specific system libraries. However, existing techniques mainly focus on inferring third-party package dependencies. Therefore, they can lack other necessary dependencies and violate version constraints, thus resulting in program build failures and runtime errors. This paper proposes a knowledge-based technique named PyEGo, which can automatically infer dependencies of third-party packages, the Python interpreter, and system libraries at compatible versions for Python programs. We first construct the dependency knowl-edge graph PyKG, which can portray the relations and constraints among third-party packages, the Python interpreter, and system libraries. Then, by querying PyKG with extracted program features, PyEGo constructs a program-related sub-graph with dependency candidates of the three types. It finally outputs the latest compatible dependency versions by solving constraints in the sub-graph. We evaluate PyEGo on 2,891 single-file Python gists, 100 open-source Python projects and 4,836 jupyter notebooks. The experimental re-sults show that PyEGo achieves better accuracy, 0.2x to 3.5x higher than the state-of-the-art approaches.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510127","National Key R&D Program of China(grant numbers:2017YFA0700603); National Natural Science Foundation of China(grant numbers:61732019,U20A6003,62072444); Frontier Science Project of Chinese Academy of Sciences(grant numbers:QYZDJ-SSW-JSC036); Youth Innovation Promotion Association at Chinese Academy of Sciences(grant numbers:2018142); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793962","Python;environment dependency inference;version constraint;knowledge graph","Runtime;Knowledge based systems;Feature extraction;Libraries;Data mining;Open source software;Python","","7","","41","","20 Jun 2022","","","IEEE","IEEE Conferences"
"SYMTUNER: Maximizing the Power of Symbolic Execution by Adaptively Tuning External Parameters","S. Cha; M. Lee; S. Lee; H. Oh","Sungkyunkwan University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2068","2079","We present SYMTUNER, a novel technique to automatically tune external parameters of symbolic execution. Practical symbolic execution tools have important external parameters (e.g., symbolic arguments, seed input) that critically affect their performance. Due to the huge parameter space, however, manually customizing those parameters is notoriously difficult even for experts. As a consequence, symbolic execution tools have typically been used in a suboptimal manner that, for example, simply relies on the default parameter settings of the tools and loses the opportunity for better performance. In this paper, we aim to change this situation by automatically configuring symbolic execution parameters. With Symtuner that takes parameter spaces to be tuned, symbolic executors are run without manual parameter configurations; instead, appropriate parameter values are learned and adjusted during symbolic execution. To achieve this, we present a learning algorithm that observes the behavior of symbolic execution and accordingly updates the sampling probability of each parameter space. We evaluated Symtuner with KLEE on 12 open-source C programs. The results show that Symtuner increases branch coverage of KLEE by 56% on average and finds 8 more bugs than KLEE with its default parameters over the latest releases of the programs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510185","Institute of Information & communications Technology Planning & Evaluation (IITP); National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794116","Symbolic Execution;Software Testing","Computer bugs;Manuals;Behavioral sciences;Tuning;Open source software;Software engineering","","2","","66","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Testability Refactoring in Pull Requests: Patterns and Trends","P. Reich; W. Maalei","Applied Software Technology, Universität Hamburg, Hamburg, Germany; Applied Software Technology, Universität Hamburg, Hamburg, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1508","1519","To create unit tests, it may be necessary to refactor the production code, e.g. by widening access to specific methods or by decomposing classes into smaller units that are easier to test independently. We report on an extensive study to understand such composite refactoring procedures for the purpose of improving testability. We collected and studied 346,841 java pull requests from 621 GitHub projects. First, we compared the atomic refactorings in two populations: pull requests with changed test-pairs (i.e. with co-changes in production and test code and thus potentially including testability refactoring) and pull requests without test-pairs. We found significantly more atomic refactorings in test-pairs pull requests, such as Change Variable Type Operation or Change Parameter Type. Second, we manually analyzed the code changes of 200 pull requests, where developers explicitly mention the terms “testability” or “refactor + test”. We identified ten composite refactoring procedures for the purpose of testability, which we call testability refactoring patterns. Third, we manually analyzed additional 524 test-pairs pull requests: both randomly selected and where we assumed to find testability refactorings, e.g. in pull requests about dependency or concurrency issues. About 25% of all analyzed pull requests actually included testability refactoring patterns. The most frequent were extract a method for override or for invocation, widen access to a method for invocation, and extract a class for invocation. We also report on frequent atomic refactorings which co-occur with the patterns and discuss the implications of our findings for research, practice, and education.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172798","Pull request mining;software quality;refactoring patterns;software testability;mining software repositories","Codes;Quality assurance;Sociology;Production;Market research;Software;Statistics","","2","","41","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"An automated approach to generating efficient constraint solvers","D. Balasubramaniam; C. Jefferson; L. Kotthoff; I. Miguel; P. Nightingale","School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK; School of Computer Science, University of Saint Andrews, Saint Andrews, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","661","671","Combinatorial problems appear in numerous settings, from timetabling to industrial design. Constraint solving aims to find solutions to such problems efficiently and automatically. Current constraint solvers are monolithic in design, accepting a broad range of problems. The cost of this convenience is a complex architecture, inhibiting efficiency, extensibility and scalability. Solver components are also tightly coupled with complex restrictions on their configuration, making automated generation of solvers difficult. We describe a novel, automated, model-driven approach to generating efficient solvers tailored to individual problems and present some results from applying the approach. The main contribution of this work is a solver generation framework called Dominion, which analyses a problem and, based on its characteristics, generates a solver using components chosen from a library. The key benefit of this approach is the ability to solve larger and more difficult problems as a result of applying finer-grained optimisations and using specialised techniques as required.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227151","Generative programming;constraint solvers;software architecture;model-driven development","Computer architecture;Software architecture;Libraries;Electronics packaging;Generators;Maintenance engineering;Complexity theory","","6","","39","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Fairness-aware Configuration of Machine Learning Libraries","S. Tizpaz-Niari; A. Kumar; G. Tan; A. Trivedi",University of Texas at El Paso; Pennsylvania State University; Pennsylvania State University; University of Colorado Boulder,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","909","920","This paper investigates the parameter space of machine learning (ML) algorithms in aggravating or mitigating fairness bugs. Data-driven software is increasingly applied in social-critical applications where ensuring fairness is of paramount importance. The existing approaches focus on addressing fairness bugs by either modifying the input dataset or modifying the learning algorithms. On the other hand, the selection of hyperparameters, which provide finer controls of ML algorithms, may enable a less intrusive approach to influence the fairness. Can hyperparameters amplify or suppress discrimination present in the input dataset? How can we help programmers in detecting, understanding, and exploiting the role of hyperparameters to improve the fairness? We design three search-based software testing algorithms to un-cover the precision-fairness frontier of the hyperparameter space. We complement these algorithms with statistical debugging to explain the role of these parameters in improving fairness. We implement the proposed approaches in the tool Parfait-ML (PARameter FAIrness Testing for ML Libraries) and show its effectiveness and utility over five mature ML algorithms as used in six social-critical applications. In these applications, our approach successfully iden-tified hyperparameters that significantly improve (vis-a-vis the state-of-the-art techniques) the fairness without sacrificing precision. Surprisingly, for some algorithms (e.g., random forest), our approach showed that certain configuration of hyperparameters (e.g., restricting the search space of attributes) can amplify biases across applications. Upon further investigation, we found intuitive explanations of these phenomena, and the results corroborate simi-lar observations from the literature.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510202","NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794108","","Software testing;Machine learning algorithms;Software algorithms;Computer bugs;Libraries;Software;Space exploration","","6","","41","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Semi-automatically extracting FAQs to improve accessibility of software development knowledge","S. Henß; M. Monperrus; M. Mezini","Technische Universitat Darmstadt Fachbereich Biologie, Darmstadt, Hessen, DE; University of Lille & INRIA, Lille, France; Technische Universität Darmstadt, Darmstadt, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","793","803","Frequently asked questions (FAQs) are a popular way to document software development knowledge. As creating such documents is expensive, this paper presents an approach for automatically extracting FAQs from sources of software development discussion, such as mailing lists and Internet forums, by combining techniques of text mining and natural language processing. We apply the approach to popular mailing lists and carry out a survey among software developers to show that it is able to extract high-quality FAQs that may be further improved by experts.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227139","","Programming;Software;Data mining;Documentation;Data models;Java;Noise","","16","1","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Evaluating Large Language Models in Class-Level Code Generation","X. Du; M. Liu; K. Wang; H. Wang; J. Liu; Y. Chen; J. Feng; C. Sha; X. Peng; Y. Lou","School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","982","994","Recently, many large language models (LLMs) have been proposed, showing advanced proficiency in code generation. Meanwhile, many efforts have been dedicated to evaluating LLMs on code generation benchmarks such as HumanEval. Although being very helpful for comparing different LLMs, existing evaluation focuses on a sim-ple code generation scenario (i.e., function-level or statement-level code generation), which mainly asks LLMs to generate one single code unit (e.g., a function or a statement) for the given natural language description. Such evaluation focuses on generating independent and often small-scale code units, thus leaving it unclear how LLMs perform in real-world software development scenarios. To fill this knowledge gap, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e., class-level code generation. Compared with existing code generation benchmarks, it better reflects real-world software development scenarios due to it comprising broader contextual dependencies and multiple, interdependent units of code. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on the new benchmark ClassEval, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we find that all LLMs perform much worse on class-level code generation compared to the method-level. While GPT models still dominate other LLMs on class-level code generation, the performance rankings of other models on method-level code generation no longer holds for class-level code generation. Besides, most models (except GPT models) perform better when generating the class method by method; and they have the limited ability of generating dependent code. Based on our findings, we call for software engineering (SE) researchers' expertise to build more LLM benchmarks based on practical and complicated software development scenarios.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639219","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549472","Class-level Code Generation;Large Language Model;Benchmark","Codes;Natural languages;Benchmark testing;Task analysis;Software development management;Software engineering;Python","","","","76","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Detecting and visualizing inter-worksheet smells in spreadsheets","F. Hermans; M. Pinzger; A. van Deursen","Software Engineering Research Group, Delft University of Technology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technology, Delft, Netherlands",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","441","451","Spreadsheets are often used in business, for simple tasks, as well as for mission critical tasks such as finance or forecasting. Similar to software, some spreadsheets are of better quality than others, for instance with respect to usability, maintainability or reliability. In contrast with software however, spreadsheets are rarely checked, tested or certified. In this paper, we aim at developing an approach for detecting smells that indicate weak points in a spreadsheet's design. To that end we first study code smells and transform these code smells to their spreadsheet counterparts. We then present an approach to detect the smells, and to communicate located smells to spreadsheet users with data flow diagrams. To evaluate our apporach, we analyzed occurrences of these smells in the Euses corpus. Furthermore we conducted ten case studies in an industrial setting. The results of the evaluation indicate that smells can indeed reveal weaknesses in a spreadsheet's design, and that data flow diagrams are an appropriate way to show those weaknesses.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227171","spreadsheets;code smells;refactoring;data flow diagrams","Measurement;Data visualization;Surgery;Couplings;Educational institutions;Software engineering;Business","","71","2","25","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Reusing Deep Neural Network Models through Model Re-engineering","B. Qi; H. Sun; X. Gao; H. Zhang; Z. Li; X. Liu","SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; Chongqing University, Chongqing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","983","994","Training deep neural network (DNN) models, which has become an important task in today's software development, is often costly in terms of computational resources and time. With the inspiration of software reuse, building DNN models through reusing existing ones has gained increasing attention recently. Prior approaches to DNN model reuse have two main limitations: 1) reusing the entire model, while only a small part of the model's functionalities (labels) are required, would cause much overhead (e.g., computational and time costs for inference), and 2) model reuse would inherit the defects and weaknesses of the reused model, and hence put the new system under threats of security attack. To solve the above problem, we propose SeaM, a tool that re-engineers a trained DNN model to improve its reusability. Specifically, given a target problem and a trained model, SeaM utilizes a gradient-based search method to search for the model's weights that are relevant to the target problem. The re-engineered model that only retains the relevant weights is then reused to solve the target problem. Evaluation results on widely-used models show that the re-engineered models produced by SeaM only contain 10.11% weights of the original models, resulting 42.41% reduction in terms of inference time. For the target problem, the re-engineered models even outperform the original models in classification accuracy by 5.85%. Moreover, reusing the re-engineered models inherits an average of 57% fewer defects than reusing the entire model. We believe our approach to reducing reuse overhead and defect inheritance is one important step forward for practical model reuse.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00090","National Natural Science Foundation of China(grant numbers:61932007,61972013,62141209,62202026); Australian Research Council (ARC)(grant numbers:DP200102940); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172769","model reuse;deep neural network;re-engineering;DNN modularization","Training;Computational modeling;Source coding;Artificial neural networks;Search problems;Data models;Security","","3","","64","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Symbiotic general-purpose and domain-specific languages","C. Atkinson; R. Gerbig; B. Kennel","Software Engineering Group, University of Mannheim, Mannheim, Germany; Software Engineering Group, University of Mannheim, Mannheim, Germany; Software Engineering Group, University of Mannheim, Mannheim, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1269","1272","Domain-Specific Modeling Languages (DSMLs) have received great attention in recent years and are expected to play a big role in the future of software engineering as processes become more view-centric. However, they are a “two-edged sword”. While they provide strong support for communication within communities, allowing experts to express themselves using concepts tailored to their exact needs, they are a poor vehicle for communication across communities because of their lack of common, transcending concepts. In contrast, General-Purpose Modeling Languages (GPMLs) have the opposite problem - they are poor at the former but good at the latter. The value of models in software engineering would therefore be significantly boosted if the advantages of DSMLs and GPMLs could be combined and models could be viewed in a domain-specific or general-purpose way depending on the needs of the user. In this paper we present an approach for achieving such a synergy based on the orthogonal classification architecture. In this architecture model elements have two classifiers: a linguistic one representing their “general-purpose” and an ontological one representing their “domain-specific” type. By associating visualization symbols with both classifiers it is possible to support two concrete syntaxes at the same time and allow the domain-specific and general-purpose notation to support each other - that is, to form a symbiotic relationship.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227102","symbiotic domain-specific languages;orthogonal classification architecture;ontological classification;linguistic classification","Unified modeling language;Visualization;Syntactics;Concrete;Biological system modeling;Object oriented modeling;Pragmatics","","9","","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Automated Patching for Unreproducible Builds","Z. Ren; S. Sun; J. Xuan; X. Li; Z. Zhou; H. Jiang","Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Computer Science, Wuhan University, Wuhan, China; University of Luxembourg, Luxembourg; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","200","211","Software reproducibility plays an essential role in establishing trust between source code and the built artifacts, by comparing compilation outputs acquired from independent users. Although the testing for unreproducible builds could be automated, fixing unreproducible build issues poses a set of challenges within the reproducible builds practice, among which we consider the localization granularity and the historical knowledge utilization as the most significant ones. To tackle these challenges, we propose a novel approach RepFix that combines tracing-based fine-grained localization with history-based patch generation mechanisms. On the one hand, to tackle the localization granularity challenge, we adopt system-level dynamic tracing to capture both the system call traces and user-space function call information. By integrating the kernel probes and user-space probes, we could determine the location of each executed build command more accurately. On the other hand, to tackle the historical knowledge utilization challenge, we design a similarity based relevant patch retrieving mechanism, and generate patches by applying the edit operations of the existing patches. With the abundant patches accumulated by the reproducible builds practice, we could generate patches to fix the unreproducible builds automatically. To evaluate the usefulness of RepFix, extensive experiments are conducted over a dataset with 116 real-world packages. Based on RepFix, we successfully fix the unreproducible build issues for 64 packages. Moreover, we apply RepFix to the Arch Linux packages, and successfully fix four packages. Two patches have been accepted by the repository, and there is one package for which the patch is pushed and accepted by its upstream repository, so that the fixing could be helpful for other downstream repositories.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510102","Nanjing University of Aeronautics and Astronautics; National Natural Science Foundation of China(grant numbers:62132020,62072068,62032004,61872273,62141221); Fundamental Research Funds for the Central Universities(grant numbers:NJ2020022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793866","reproducible builds;dynamic tracing;automated patch generation","Location awareness;Codes;Linux;Computer bugs;Software;Reproducibility of results;Probes","","4","","44","","20 Jun 2022","","","IEEE","IEEE Conferences"
"V-SZZ: Automatic Identification of Version Ranges Affected by CVE Vulnerabilities","L. Bao; X. Xia; A. E. Hassan; X. Yang","Zhejiang University, China; Huawei, China; Queen's University, Canada; Zhejiang University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2352","2364","Vulnerabilities publicly disclosed in the National Vulnerability Data-base (NVD) are assigned with CVE (Common Vulnerabilities and Exposures) IDs and associated with specific software versions. Many organizations, including IT companies and government, heavily rely on the disclosed vulnerabilities in NVD to mitigate their security risks. Once a software is claimed as vulnerable by NVD, these organizations would examine the presence of the vulnerable versions of the software and assess the impact on themselves. However, the version information about vulnerable software in NVD is not always reliable. Nguyen et al. find that the version information of many CVE vulnerabilities is spurious and propose an approach based on the original SZZ algorithm (i.e., an approach to identify bug-introducing commits) to assess the software versions affected by CVE vulnerabilities. However, SZZ algorithms are designed for common bugs, while vulnerabilities and bugs are different. Many bugs are introduced by a recent bug-fixing commit, but vulnerabilities are usually introduced in their initial versions. Thus, the current SZZ algorithms often fail to identify the inducing commits for vulnerabilities. Therefore, in this study, we propose an approach based on an improved SZZ algorithm to refine software versions affected by CVE vulnerabilities. Our proposed SZZ algorithm leverages the line mapping algorithms to identify the earliest commit that modified the vulnerable lines, and then considers these commits to be the vulnerability-inducing commits, as opposed to the previous SZZ algorithms that assume the commits that last modified the buggy lines as the inducing commits. To evaluate our proposed approach, we manually annotate the true inducing commits and verify the vulnerable versions for 172 CVE vulnerabilities with fixing commits from two publicly available datasets with five C/C++ and 41 Java projects, respectively. We find that 99 out of 172 vulnerabilities whose version information is spurious. The experiment results show that our proposed approach can identify more vulnerabilities with the true inducing commits and correct vulnerable versions than the previous SZZ algorithms. Our approach outperforms the previous SZZ algorithms in terms of F1-score for identifying vulnerability-inducing commits on both C/C++ and Java projects (0.736 and 0.630, respectively). For refining vulnerable versions, our approach also achieves the best performance on the two datasets in terms of F1-score (0.928 and 0.952).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510113","National Science Foundation of China(grant numbers:62141222,U20A20173,6190234); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794006","SZZ;Vulnerability;CVE","Java;Software algorithms;Computer bugs;Refining;Government;Companies;Software","","15","","62","","20 Jun 2022","","","IEEE","IEEE Conferences"
"BRACE: An assertion framework for debugging cyber-physical systems","K. Boos; C. -L. Fok; C. Julien; M. Kim","Center for Advanced Research in Software Engineering, University of Texas, Austin, USA; Center for Advanced Research in Software Engineering, University of Texas, Austin, USA; Center for Advanced Research in Software Engineering, University of Texas, Austin, USA; Center for Advanced Research in Software Engineering, University of Texas, Austin, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1341","1344","Developing cyber-physical systems (CPS) is challenging because correctness depends on both logical and physical states, which are collectively difficult to observe. The developer often need to repeatedly rerun the system while observing its behavior and tweak the hardware and software until it meets minimum requirements. This process is tedious, error-prone, and lacks rigor. To address this, we propose BRACE, A framework that simplifies the process by enabling developers to correlate cyber (i.e., logical) and physical properties of the system via assertions. This paper presents our initial investigation into the requirements and semantics of such assertions, which we call CPS assertions. We discusses our experience implementing and using the framework with a mobile robot, and highlight key future research challenges.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227084","","Robot sensing systems;Monitoring;Temperature sensors;Robot kinematics;Cameras","","3","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"JavaMOP: Efficient parametric runtime monitoring framework","D. Jin; P. O. Meredith; C. Lee; G. Roşu","Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1427","1430","Runtime monitoring is a technique usable in all phases of the software development cycle, from initial testing, to debugging, to actually maintaining proper function in production code. Of particular importance are parametric monitoring systems, which allow the specification of properties that relate objects in a program, rather than only global properties. In the past decade, a number of parametric runtime monitoring systems have been developed. Here we give a demonstration of our system, JavaMOP. It is the only parametric monitoring system that allows multiple differing logical formalisms. It is also the most efficient in terms of runtime overhead, and very competitive with respect to memory usage.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227231","runtime verification;runtime monitoring;testing;debugging;aspect-oriented programming","Monitoring;Runtime;Java;Object oriented programming;Software;Testing","","61","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Log-based testing","A. Elyasov","Department of Information and Computing Sciences, University of Utrecht, Utrecht, Netherlands",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1591","1594","This thesis presents an ongoing research on using logs for software testing. We propose a complex and generic logging and diagnosis framework, that can be efficiently used for continuous testing of future Internet applications. To simplify the diagnosis of logs we suggest to reduce its size by means of rewriting.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227029","log file analysis;instrumentation;rewriting","Instruments;Internet;Libraries;Graphical user interfaces;Automation;Software testing","","3","3","15","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Strengthening Supply Chain Security with Fine-Grained Safe Patch Identification","C. Luo; W. Meng; S. Wang","The Chinese University of Hong Kong, Hong Kong SAR, China; The Chinese University of Hong Kong, Hong Kong SAR, China; HKUST, Hong Kong SAR, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1084","1095","Enhancing supply chain security is crucial, often involving the detection of patches in upstream software. However, current security patch analysis works yield relatively low recall rates (i.e., many security patches are missed). In this work, we offer a new solution to detect safe patches and assist downstream developers in patch propagation. Specifically, we develop SPATCH to detect fine-grained safe patches. SPATCH leverages fine-grained patch analysis and a new differential symbolic execution technique to analyze the functional impacts of code changes. We evaluated SPATCH on various software, including the Linux kernel and OpenSSL, and demonstrated that it outperformed existing methods in detecting safe patches, resulting in observable security benefits. In our case studies, we updated hundreds of functions in modern software using safe patches detected by SPATCH without causing any regression issues. Our detected safe security patches have been merged into the latest version of downstream software like ProtonVpn.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548965","Supply Chain Security;Fine-grained Patch Analysis;Differential Symbolic Execution","Codes;Linux;Supply chains;Focusing;Software;Security;Kernel","","","","42","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning","M. Geng; S. Wang; D. Dong; H. Wang; G. Li; Z. Jin; X. Mao; X. Liao","College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; Key Lab of High Confidence Software Technology, Peking University, Beijing, China; Key Lab of High Confidence Software Technology, Peking University, Beijing, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","453","465","Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548839","Code Summarization;Large Language Model;In-Context Learning","Computer languages;Codes;Supervised learning;Natural languages;Semantics;Task analysis;Software engineering","","7","","78","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Whither software architecture? (Keynote)","J. Kramer","Imperial College London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","963","963","Summary form only given. Social media has revolutionized how humans create and curate knowledge artifacts [1]. It has increased individual engagement, broadened community participation and led to the formation of new social networks. This paradigm shift is particularly evident in software engineering in three distinct ways: firstly, in how software stakeholders co-develop and form communities of practice; secondly, in the complex and distributed software ecosystems that are enabled through insourcing, outsourcing, open sourcing and crowdsourcing of components and related artifacts; and thirdly, by the emergence of socially-enabled software repositories and collaborative development environments [2].","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227253","","","","3","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"On how often code is cloned across repositories","N. Schwarz; M. Lungu; R. Robbes","University of Bern, Switzerland; University of Bern, Switzerland; University of Chile, Chile",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1289","1292","Detecting code duplication in large code bases, or even across project boundaries, is problematic due to the massive amount of data involved. Large-scale clone detection also opens new challenges beyond asking for the provenance of a single clone fragment, such as assessing the prevalence of code clones on the entire code base, and their evolution. We propose a set of lightweight techniques that may scale up to very large amounts of source code in the presence of multiple versions. The common idea behind these techniques is to use bad hashing to get a quick answer. We report on a case study, the Squeaksource ecosystem, which features thousands of software projects, with more than 40 million versions of methods, across more than seven years of evolution. We provide estimates for the prevalence of type-1, type-2, and type-3 clones in Squeaksource.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227097","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227097","Clone detection;Software ecosystems","Cloning;Ecosystems;Software;Indexes;Educational institutions;Layout","","19","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"How to Support ML End-User Programmers through a Conversational Agent","E. A. Garcia; J. F. Pimentel; Z. Feng; M. Gerosa; I. Steinmacher; A. Sarma","Oregon State University, Corvallis, OR, USA; Northern Arizona University, Flagstaff, AZ, USA; Oregon State University, Corvallis, OR, USA; Northern Arizona University, Flagstaff, AZ, USA; Northern Arizona University, Flagstaff, AZ, USA; Oregon State University, Corvallis, OR, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","629","640","Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named “Newton” as an expert to support ML-EUPs. Newton's design was shaped by a comprehensive review of existing literature, from which we identified six primary challenges faced by ML-EUPs and five strategies to assist them. To evaluate the efficacy of Newton's design, we conducted a Wizard of Oz within-subjects study with 12 ML-EUPs. Our findings indicate that Newton effectively assisted ML-EUPs, addressing the challenges highlighted in the literature. We also proposed six design guidelines for future conversational agents, which can help other EUP applications and software engineering activities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608130","National Science Foundation(grant numbers:2236198,2235601,2247929,2303042,2303043); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548214","End-user programming;Conversational Agent;Wizard of Oz","Backtracking;Machine learning algorithms;Codes;Reviews;Design methodology;Machine learning;Task analysis","","1","","53","","14 Jun 2024","","","IEEE","IEEE Conferences"
"ROSInfer: Statically Inferring Behavioral Component Models for ROS-Based Robotics Systems","T. Dürschmid; C. S. Timperley; D. Garlan; C. L. Goues","School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1774","1786","Robotics systems are complex, safety-critical systems that can consist of hundreds of software components that interact with each other dynamically during run time. Software components of robotics systems often exhibit reactive, periodic, and state-dependent behavior. Incorrect component composition can lead to unexpected behavior, such as components passively waiting for initiation messages that never arrive. Model-based software analysis is a common technique to identify incorrect behavioral composition by checking desired properties of given behavioral models that are based on component state machines. However, writing state machine models for hundreds of software components manually is a labor-intensive process. This motivates work on automated model inference. In this paper, we present an approach to infer behavioral models for systems based on the Robot Operating System (ROS) using static analysis by exploiting assumptions about the usage of the ROS API and ecosystem. Our approach is based on searching for common behavioral patterns that ROS developers use for implementing reactive, periodic, and state-dependent behavior using the ROS framework API. We evaluate our approach and our tool ROSInfer on five complex real-world ROS systems with a total of 534 components. For this purpose we manually created 155 models of components from the source code to be used as a ground truth and available data set for other researchers. ROSInfer can infer causal triggers for 87 % of component architectural behaviors in the 534 components.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639206","NSF(grant numbers:CCF-1750116,CNS-2148301); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549638","ROS;Software Architecture;Software Engineering;Robotics;Static Analysis;Bugfinding;Component Models;Behavioral Inference;State Machines;Program Analysis","Analytical models;Biological system modeling;Source coding;Ecosystems;Static analysis;Writing;Software","","2","","83","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"CodaMosa: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models","C. Lemieux; J. P. Inala; S. K. Lahiri; S. Sen","University of British Columbia, Canada; Microsoft Research, USA; Microsoft Research, USA; Microsoft Research, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","919","931","Search-based software testing (SBST) generates high-coverage test cases for programs under test with a combination of test case generation and mutation. SBST's performance relies on there being a reasonable probability of generating test cases that exercise the core logic of the program under test. Given such test cases, SBST can then explore the space around them to exercise various parts of the program. This paper explores whether Large Language Models (LLMs) of code, such as OpenAI's Codex, can be used to help SBST's exploration. Our proposed algorithm, CodaMosa, conducts SBST until its coverage improvements stall, then asks Codex to provide example test cases for under-covered functions. These examples help SBST redirect its search to more useful areas of the search space. On an evaluation over 486 benchmarks, CodaMosa achieves statistically significantly higher coverage on many more benchmarks (173 and 279) than it reduces coverage on (10 and 4), compared to SBST and LLM-only baselines.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172800","search based software testing;codex;test suite generation;python;large language model;automated testing","Software testing;Codes;Benchmark testing;Software;Space exploration;Test pattern generators;Software engineering","","46","","62","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"An Empirical Comparison of Pre-Trained Models of Source Code","C. Niu; C. Li; V. Ng; D. Chen; J. Ge; B. Luo","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2136","2148","While a large number of pre-trained models of source code have been successfully developed and applied to a variety of software engineering (SE) tasks in recent years, our understanding of these pre-trained models is arguably fairly limited. With the goal of advancing our understanding of these models, we perform the first systematic empirical comparison of 19 recently-developed pre-trained models of source code on 13 SE tasks. To gain additional insights into these models, we adopt a recently -developed 4-dimensional categorization of pre-trained models, and subsequently investigate whether there are correlations between different categories of pre-trained models and their performances on different SE tasks.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00180","National Natural Science Foundation of China(grant numbers:61802167); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201250); NSF(grant numbers:2034508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172787","Pre-training of Source Code;AI for SE","Systematics;Codes;Correlation;Source coding;Task analysis;Software engineering","","23","","72","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Causal Relationships and Programming Outcomes: A Transcranial Magnetic Stimulation Experiment","H. Ahmad; M. Endres; K. Newman; P. Santiesteban; E. Shedden; W. Weimer","University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2320","2332","Understanding the relationship between cognition and programming outcomes is important: it can inform interventions that help novices become experts faster. Neuroimaging techniques can measure brain activity, but prior studies of programming report only correlations. We present the first causal neurological investigation of the cognition of programming by using Transcranial Magnetic Stimulation (TMS). TMS permits temporary and noninvasive disruption of specific brain regions. By disrupting brain regions and then measuring programming outcomes, we discover whether a true causal relationship exists. To the best of our knowledge, this is the first use of TMS to study software engineering. Where multiple previous studies reported correlations, we find no direct causal relationships between implicated brain regions and programming. Using a protocol that follows TMS best practices and mitigates for biases, we replicate psychology findings that TMS affects spatial tasks. We then find that neurostimulation can affect programming outcomes. Multi-level regression analysis shows that TMS stimulation of different regions significantly accounts for 2.2% of the variance in task completion time. Our results have implications for interventions in education and training as well as research into causal cognitive relationships.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639096","NSF(grant numbers:2211749); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548459","Neurostimulation;spatial ability;code reading;data structures","Knowledge engineering;Training;Correlation;Transcranial magnetic stimulation;Psychology;Data structures;Cognition","","1","","105","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Test confessions: A study of testing practices for plug-in systems","M. Greiler; A. van Deursen; M. -A. Storey","Delft University of Technology, Netherlands; Delft University of Technology, Netherlands; University of Victoria, BC, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","244","254","Testing plug-in-based systems is challenging due to complex interactions among many different plug-ins, and variations in version and configuration. The objective of this paper is to increase our understanding of what testers and developers think and do when it comes to testing plug-in-based systems. To that end, we conduct a qualitative (grounded theory) study, in which we interview 25 senior practitioners about how they test plug-in applications based on the Eclipse plug-in architecture. The outcome is an overview of the testing practices currently used, a set of identified barriers limiting test adoption, and an explanation of how limited testing is compensated by self-hosting of projects and by involving the community. These results are supported by a structured survey of more than 150 professionals. The study reveals that unit testing plays a key role, whereas plug-in specific integration problems are identified and resolved by the community. Based on our findings, we propose a series of recommendations and areas for future research.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227189","Eclipse;grounded theory;plug-in architectures;open source software development","Testing;Interviews;Communities;Graphical user interfaces;Computer architecture;Manuals;Companies","","34","","28","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Practical and Efficient Model Extraction of Sentiment Analysis APIs","W. Wu; J. Zhang; V. J. Wei; X. Chen; Z. Zheng; I. King; M. R. Lyu","School of Software Engineering, Sun Yat-sen University; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computing, The Hong Kong Polytechnic University; Tencent; School of Software Engineering, Sun Yat-sen University; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","524","536","Despite their stunning performance, developing deep learning models from scratch is a formidable task. Therefore, it popularizes Machine-Learning-as-a-Service (MLaaS), where general users can access the trained models of MLaaS providers via Application Programming Interfaces (APIs) on a pay-per-query basis. Unfortunately, the success of MLaaS is under threat from model extraction attacks, where attackers intend to extract a local model of equivalent functionality to the target MLaaS model. However, existing studies on model extraction of text analytics APIs frequently assume adversaries have strong knowledge about the victim model, like its architecture and parameters, which hardly holds in practice. Besides, since the attacker's and the victim's training data can be considerably discrepant, it is non-trivial to perform efficient model extraction. In this paper, to advance the understanding of such attacks, we propose a framework, PEEP, for practical and efficient model extraction of sentiment analysis APIs with only query access. Specifically, PEEP features a learning-based scheme, which employs out-of-domain public corpora and a novel query strategy to construct proxy training data for model extraction. Besides, PEEP introduces a greedy search algorithm to settle an appropriate architecture for the extracted model. We conducted extensive experiments with two victim models across three datasets and two real-life commercial sentiment analysis APIs. Experimental results corroborate that PEEP can consistently outperform the state-of-the-art baselines in terms of effectiveness and efficiency.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172712","model extraction;sentiment analysis APIs;active learning;architecture search","Training;Analytical models;Sentiment analysis;Training data;Computer architecture;Feature extraction;Data models","","1","","55","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"The Smelly Eight: An Empirical Study on the Prevalence of Code Smells in Quantum Computing","Q. Chen; R. Câmara; J. Campos; A. Souto; I. Ahmed","University of California, Irvine, USA; LASIGE, Faculdade de Ciências, Universidade de Lisboa, Lisboa, Portugal; Faculty of Engineering, University of Porto, Porto, Portugal; LASIGE, Faculdade de Ciências, Universidade de Lisboa, Lisboa, Portugal; University of California, Irvine, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","358","370","Quantum Computing (QC) is a fast-growing field that has enhanced the emergence of new programming languages and frameworks. Furthermore, the increased availability of computational resources has also contributed to an influx in the development of quantum programs. Given that classical and QC are significantly different due to the intrinsic nature of quantum programs, several aspects of QC (e.g., performance, bugs) have been investigated, and novel approaches have been proposed. However, from a purely quantum perspective, maintenance, one of the major steps in a software development life-cycle, has not been considered by researchers yet. In this paper, we fill this gap and investigate the prevalence of code smells in quantum programs as an indicator of maintenance issues. We defined eight quantum-specific smells and validated them through a survey with 35 quantum developers. Since no tool specifically aims to detect quantum smells, we developed a tool called QSmell that supports the proposed quantum-specific smells. Finally, we conducted an empirical investigation to analyze the prevalence of quantum-specific smells in 15 open-source quantum programs. Our results showed that 11 programs (73.33%) contain at least one smell and, on average, a program has three smells. Furthermore, the long circuit is the most prevalent smell present in 53.33% of the programs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172808","Quantum computing;Quantum software engineering;Empirical study;Quantum-specific code smell","Surveys;Computer languages;Quantum computing;Codes;Computer bugs;Maintenance engineering;Software","","4","","90","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"GIFdroid: Automated Replay of Visual Bug Reports for Android Apps","S. Feng; C. Chen","Monash University, Melbourne, Australia; Monash University, Melbourne, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1045","1057","Bug reports are vital for software maintenance that allow users to inform developers of the problems encountered while using software. However, it is difficult for non-technical users to write clear descriptions about the bug occurrence. Therefore, more and more users begin to record the screen for reporting bugs as it is easy to be created and contains detailed procedures triggering the bug. But it is still tedious and time-consuming for developers to reproduce the bug due to the length and unclear actions within the recording. To overcome these issues, we propose GIFdroid, a light-weight approach to automatically replay the execution trace from visual bug reports. GIFdroid adopts image processing techniques to extract the keyframes from the recording, map them to states in GUI Transitions Graph, and generate the execution trace of those states to trigger the bug. Our automated experiments and user study demonstrate its accuracy, efficiency, and usefulness of the approach.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794104","bug replay;visual recording;android testing","Visualization;Software maintenance;Image processing;Computer bugs;Software algorithms;Life estimation;Recording","","12","","84","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)","T. Ahmed; K. S. Pai; P. Devanbu; E. T. Barr","University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA; University of California, Davis, Davis, California, USA; University College London & Google Brain, London, UK",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2720","2732","Large Language Models (LLM) are a new class of computation engines, “programmed” via prompt engineering. Researchers are still learning how to best “program” these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously collect semantics facts, from the code, while working. Mostly these are shallow, simple facts arising from a quick read. For a function, such facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc. One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them implicitly capable of doing this simple level of “code analysis” and extracting such information, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly. actually helps. Prior work shows that LLM performance on code summarization benefits from embedding a few code & summary exemplars in the prompt, before the code to be summarized. While summarization performance has steadily progressed since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization. We find that adding semantic facts to the code in the prompt actually does help! This approach improves performance in several different settings suggested by prior work, including for three different Large Language Models. In most cases, we see improvements, as measured by a range of commonly-used metrics; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU 11Scores of 30–40 BLEU are considered “Good” to “Understandable” for natural language translation; see https://cloud.google.com/translate/automl/docs/evaluate.. In addition, we have also found that including semantic facts yields a substantial enhancement in LLMs' line completion performance.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548617","LLM;Code Summarization;Program Analysis;Prompt Engineering","Measurement;Codes;Semantics;Natural languages;Process control;Writing;Transformers","","1","","70","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Capturing and exploiting fine-grained IDE interactions","Z. Gu","Department of Computer Science, University of California,슠Davis, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1630","1631","Developers interact with IDEs intensively to maximize productivity. A developer's interactions with an IDE reflect his thought process and work habits. In this paper, we propose a general framework to capture and exploit all types of IDE interactions. We have two explicit goals for the framework: its systematic interception of comprehensive user interactions, and the ease of use in writing customized applications. To this end, we developed IDE++ on top of Eclipse IDE. For evaluation, we built applications upon the framework to illustrate 1) the need for capturing comprehensive, finegrained IDE interactions, and 2) IDE++'s ease of use. We believe that IDE++ is a step toward building next generation, customizable and intelligent IDEs.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227220","IDE++;fine-grained interactions","Monitoring;Productivity;Software;Context;Testing;History;Systematics","","3","","1","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"TOGA: A Neural Method for Test Oracle Generation","E. Dinella; G. Ryan; T. Mytkowicz; S. K. Lahiri",University of Pennsylvania; Columbia University; Microsoft Research; Microsoft Research,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2130","2141","Testing is widely recognized as an important stage of the software development lifecycle. Effective software testing can provide benefits such as bug finding, preventing regressions, and documentation. In terms of documentation, unit tests express a unit's intended functionality, as conceived by the developer. A test oracle, typically expressed as an condition, documents the intended behavior of a unit under a given test prefix. Synthesizing a functional test oracle is a challenging problem, as it must capture the intended functionality rather than the implemented functionality. In this paper, we propose TOGA (a neural method for Test Oracle GenerAtion), a unified transformer-based neural approach to infer both exceptional and assertion test oracles based on the context of the focal method. Our approach can handle units with ambiguous or missing documentation, and even units with a missing implementation. We evaluate our approach on both oracle inference accuracy and functional bug-finding. Our technique improves accuracy by 33% over existing oracle inference approaches, achieving 96% over-all accuracy on a held out test dataset. Furthermore, we show that when integrated with a automated test generation tool (EvoSuite), our approach finds 57 real world bugs in large-scale Java programs, including 30 bugs that are not found by any other automated testing method in our evaluation.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510141","ATLAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794043","Testing;transformers;machine learning;language models;test oracles;software testing","Software testing;Java;Computer bugs;Documentation;Computer architecture;Transformers;Software","","16","","37","","20 Jun 2022","","","IEEE","IEEE Conferences"
"DSFM: Enhancing Functional Code Clone Detection with Deep Subtree Interactions","Z. Xu; S. Qiang; D. Song; M. Zhou; H. Wan; X. Zhao; P. Luo; H. Zhang","KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; KLISS, BNRist, School of Software, Tsinghua University, Beijing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2733","2744","Functional code clone detection is important for software maintenance. In recent years, deep learning techniques are introduced to improve the performance of functional code clone detectors. By representing each code snippet as a vector containing its program semantics, syntactically dissimilar functional clones are detected. However, existing deep learning-based approaches attach too much importance to code feature learning, hoping to project all recognizable knowledge of a code snippet into a single vector. We argue that these deep learning-based approaches can be enhanced by considering the characteristics of syntactic code clone detection, where we need to compare the contents of the source code (e.g., intersection of tokens, similar flow graphs, and similar subtrees) to obtain code clones. In this paper, we propose a novel deep learning-based approach named DSFM, which incorporates comparisons between code snippets for detecting functional code clones. Specifically, we improve the typical deep clone detectors with deep subtree interactions that compare every two subtrees extracted abstract syntax trees (ASTs) of two code snippets, thereby introducing more fine-grained semantic similarity. By conducting extensive experiments on three widely-used datasets, GCJ, OJClone, and BigCloneBench, we demonstrate the great potential of deep subtree interactions in code clone detection task. The proposed DSFM outperforms the state-of-the-art approaches, including two traditional approaches, two unsupervised and four supervised deep learning-based baselines.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548996","Code clone detection;semantic clone;code similarity;factorization machine","Software maintenance;Codes;Source coding;Semantics;Cloning;Detectors;Syntactics","","","","58","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Tare: Type-Aware Neural Program Repair","Q. Zhu; Z. Sun; W. Zhang; Y. Xiong; L. Zhang","Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China; Zhongguancun Laboratory, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, (Peking University); School of Computer Science, Peking University, P. R. China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1443","1455","Automated program repair (APR) aims to reduce the effort of software development. With the development of deep learning, lots of DL-based APR approaches have been proposed using an encoder-decoder architecture. Despite the promising performance, these models share the same limitation: generating lots of untypable patches. The main reason for this phenomenon is that the existing models do not consider the constraints of code captured by a set of typing rules. In this paper, we propose, Tare, a type-aware model for neural program repair to learn the typing rules. To encode an individual typing rule, we introduce three novel components: (1) a novel type of grammars, T-Grammar, that integrates the type information into a standard grammar, (2) a novel representation of code, T-Graph, that integrates the key information needed for type checking an AST, and (3) a novel type-aware neural program repair approach, Tare, that encodes the T-Graph and generates the patches guided by T-Grammar. The experiment was conducted on three benchmarks, 393 bugs from Defects4J v1.2, 444 additional bugs from Defects4J v2.0, and 40 bugs from QuixBugs. Our results show that Tare repairs 62, 32, and 27 bugs on these benchmarks respectively, and outperforms the existing APR approaches on all benchmarks. Further analysis also shows that Tare tends to generate more compilable patches than the existing DL-based APR approaches with the typing rule information.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00126","National Natural Science Foundation of China(grant numbers:62161146003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172781","program repair;neural networks","Deep learning;Codes;Computer bugs;Maintenance engineering;Benchmark testing;Software;Generators","","9","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Push-Button Synthesis of Watch Companions for Android Apps","C. Li; Y. Jiang; C. Xu","Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1793","1804","Most Android apps lack their counterparts on convenient smart-watch devices, possibly due to non-trivial engineering efforts required in the new app design and code development. Inspired by the observation that widgets on a smartphone can be mirrored to a smartwatch, this paper presents the Jigsaw framework to greatly alleviate such engineering efforts. Particularly, Jigsaw enables a push-button development of smartphone's companion watch apps by leveraging the programming by example paradigm, version space algebra, and constraint solving. Our experiments on 16 popular open-source apps validated the effectiveness of our synthesis algorithm, as well as their practical usefulness in synthesizing usable watch companions.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510056","National Natural Science Foundation of China(grant numbers:61932021); Jiangsu Natural Science Foundation(grant numbers:BK20202001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794077","Android apps;WearOS apps;program synthesis","Codes;Automation;Annotations;Algebra;Programming;Task analysis;Open source software","","1","","77","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Property-Based Testing in Practice","H. Goldstein; J. W. Cutler; D. Dickstein; B. C. Pierce; A. Head","University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA; Jane Street, New York, NY, USA; University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2307","2319","Property-based testing (PBT) is a testing methodology where users write executable formal specifications of software components and an automated harness checks these specifications against many automatically generated inputs. From its roots in the QuickCheck library in Haskell, PBT has made significant inroads in mainstream languages and industrial practice at companies such as Amazon, Volvo, and Stripe. As PBT extends its reach, it is important to understand how developers are using it in practice, where they see its strengths and weaknesses, and what innovations are needed to make it more effective. We address these questions using data from 30 in-depth interviews with experienced users of PBT at Jane Street, a financial technology company making heavy and sophisticated use of PBT. These interviews provide empirical evidence that PBT's main strengths lie in testing complex code and in increasing confidence beyond what is available through conventional testing methodologies, and, moreover, that most uses fall into a relatively small number of high- leverage idioms. Its main weaknesses, on the other hand, lie in the relative complexity of writing properties and random data generators and in the difficulty of evaluating their effectiveness. From these observations, we identify a number of potentially high-impact areas for future exploration, including performance improvements, differential testing, additional high-leverage testing scenarios, better techniques for generating random input data, test-case reduction, and methods for evaluating the effectiveness of tests.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639581","University of Pennsylvania; NSF(grant numbers:1421243); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549613","property-based testing;random testing;human-centered research","Technological innovation;Companies;Writing;Software;Libraries;Generators;Formal specifications","","","","56","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Towards flexible evolution of Dynamically Adaptive Systems","G. Perrouin; B. Morin; F. Chauvel; F. Fleurey; J. Klein; Y. Le Traon; O. Barais; J. -M. Jézéquel","PRECISE, University of Namur, Belgium; SINTEF IKT, OSLO, Norway; SINTEF IKT, OSLO, Norway; SINTEF IKT, OSLO, Norway; SnT-University of Luxembourg, Luxembourg; SnT-University of Luxembourg, Luxembourg; IRISA, University of Rennes I, France; IRISA, University of Rennes I, France",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1353","1356","Modern software systems need to be continuously available under varying conditions. Their ability to dynamically adapt to their execution context is thus increasingly seen as a key to their success. Recently, many approaches were proposed to design and support the execution of Dynamically Adaptive Systems (DAS). However, the ability of a DAS to evolve is limited to the addition, update or removal of adaptation rules or reconfiguration scripts. These artifacts are very specific to the control loop managing such a DAS and runtime evolution of the DAS requirements may affect other parts of the DAS. In this paper, we argue to evolve all parts of the loop. We suggest leveraging recent advances in model-driven techniques to offer an approach that supports the evolution of both systems and their adaptation capabilities. The basic idea is to consider the control loop itself as an adaptive system.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227081","Dynamically Adaptive Systems;Evolution;Models@Run.Time","Adaptation models;Adaptive systems;Context;Runtime;Cognition;Monitoring;Business","","12","1","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"PExReport: Automatic Creation of Pruned Executable Cross-Project Failure Reports","S. Huang; X. Wang","Department of Computer Science, University of Texas at San Antonio, San Antonio, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","184","195","Modern software development extensively depends on existing libraries written by other developer teams from the same or a different organization. When a developer executes the software, the execution trace may go across the boundaries of multiple software products and create cross-project failures (CPFs). Existing studies show that a stand-alone executable failure report may enable the most effective communication, but creating such a report is often challenging due to the complicated files and dependencies interactions in the software ecosystems. In this paper, to solve the CPF report trilemma, we developed PExReport, which automatically creates stand-alone executable CPF reports. PExReport leverages build tools to prune source code and dependencies, and further analyzes the build process to create a pruned build environment for reproducing the CPF. We performed an evaluation on 74 software project issues with 198 CPFs, and the evaluation results show that PExReport can create executable CPF reports for 184 out of 198 test failures in our dataset, with an average reduction of 72.97% on source classes and the classes in internal JARs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00027","NSF(grant numbers:CCF-1846467,CCF-2007718,CSPECC-1736209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172556","cross-project failure;executable failure report;failure reproduction;build tool;build environment;debloating","Codes;Source coding;Ecosystems;Organizations;Software;Libraries;Hybrid power systems","","","","44","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Locating Framework-specific Crashing Faults with Compact and Explainable Candidate Set","J. Yan; M. Wang; Y. Liu; J. Yan; L. Zhang","Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China; Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","172","183","Nowadays, many applications do not exist independently but rely on various frameworks or libraries. The frequent evolution and the complex implementation of framework APIs induce lots of unexpected post-release crashes. Starting from the crash stack traces, existing approaches either perform application-level call graph (CG) tracing or construct datasets with similar crash-fixing records to locate buggy methods. However, these approaches are limited by the completeness of CG or dependent on historical fixing records, and some of them only focus on specific manually modeled exception types. To achieve effective debugging on complex framework-specific crashes, we propose a code-separation-based locating approach that weakly relies on CG tracing and does not require any prior knowledge. Our key insight is that one crash trace with the description message can be mapped to a definite exception-thrown point in the framework, the semantics analysis of which can help to figure out the root causes of the crash-triggering procedure. Thus, we can pre-construct reusable summaries for all the framework-specific exceptions to support fault localization in application code. Based on that idea, we design the exception-thrown summary (ETS) that describes both the key variables and key APIs related to the exception triggering. Then, we perform static analysis to automatically compute such summaries and make a data-tracking of key variables and APIs in the application code to get the ranked buggy candidates. In the scenario of locating Android framework-specific crashing faults, our tool CrashTracker exhibited an overall MRR value of 0.91 and outperforms the state-of-the-art tool Anchor with higher precision. It only provides a compact candidate set and gives user-friendly reports with explainable reasons for each candidate.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00026","National Natural Science Foundation of China(grant numbers:62102405,62132020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172816","Fault Localization;Framework-specific Exception;Crash Stack Trace;Android Application","Location awareness;Codes;Semantics;Debugging;Static analysis;Computer crashes;Libraries","","","","43","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Big Data = Big Insights? Operationalising Brooks' Law in a Massive GitHub Data Set","C. Gote; P. Mavrodiev; F. Schweitzer; I. Scholtes","Chair of Systems Design, ETH Zurich, Zurich, Switzerland; Chair of Systems Design, ETH Zurich, Zurich, Switzerland; Chair of Systems Design, ETH Zurich, Zurich, Switzerland; Chair of Computer Science XV - Machine Learning for Complex Networks, Julius-Maximilians-Universität Würzburg, Würzburg, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","262","273","Massive data from software repositories and collaboration tools are widely used to study social aspects in software development. One question that several recent works have addressed is how a software project's size and structure influence team productivity, a question famously considered in Brooks' law. Recent studies using massive repository data suggest that developers in larger teams tend to be less productive than smaller teams. Despite using similar methods and data, other studies argue for a positive linear or even super-linear relationship between team size and productivity, thus contesting the view of software economics that software projects are diseconomies of scale. In our work, we study challenges that can explain the disagreement between recent studies of developer productivity in massive repository data. We further provide, to the best of our knowledge, the largest, curated corpus of GitHub projects tailored to investigate the influence of team size and collaboration patterns on individual and collective productivity. Our work contributes to the ongoing discussion on the choice of productivity metrics in the operationalisation of hypotheses about determinants of successful software projects. It further highlights general pitfalls in big data analysis and shows that the use of bigger data sets does not automatically lead to more reliable insights.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510619","Swiss National Science Foundation(grant numbers:176938); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794099","","Productivity;Codes;Social sciences;Collaboration;Estimation;Big Data;Software","","","","63","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Learning and Programming Challenges of Rust: A Mixed-Methods Study","S. Zhu; Z. Zhang; B. Qin; A. Xiong; L. Song","Pennsylvania State University, USA; University of Wisconsin-Madison, USA; China Telecom Cloud Computing, China; Pennsylvania State University, USA; Pennsylvania State University, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1269","1281","Rust is a young systems programming language designed to provide both the safety guarantees of high-level languages and the execution performance of low-level languages. To achieve this design goal, Rust provides a suite of safety rules and checks against those rules at the compile time to eliminate many memory-safety and thread-safety issues. Due to its safety and performance, Rust's popularity has increased significantly in recent years, and it has already been adopted to build many safety-critical software systems. It is critical to understand the learning and programming challenges imposed by Rust's safety rules. For this purpose, we first conducted an empirical study through close, manual inspection of 100 Rust-related Stack Overflow questions. We sought to understand (1) what safety rules are challenging to learn and program with, (2) under which contexts a safety rule becomes more difficult to apply, and (3) whether the Rust compiler is sufficiently helpful in debugging safety-rule violations. We then performed an online survey with 101 Rust programmers to validate the findings of the empirical study. We invited participants to evaluate program variants that differ from each other, either in terms of violated safety rules or the code constructs involved in the violation, and compared the participants' performance on the variants. Our mixed-methods investigation revealed a range of consistent findings that can benefit Rust learners, practitioners, and language designers.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510164","NSF(grant numbers:CNS-1955965,CCF-2145394); IST; Pennsylvania State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794066","Rust;Programming Challenges;Empirical Study;Online Survey","Context;Instruction sets;Manuals;Debugging;Programming;Inspection;Software","","7","","75","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Investigating White-Box Attacks for On-Device Models","M. Zhou; X. Gao; J. Wu; K. Liu; H. Sun; L. Li","Monash University, Melbourne, VIC, Australia; Beihang University, Beijing, China; Monash University, Melbourne, VIC, Australia; Huawei Software Engineering, Application Technology Lab, China; Beihang University, Beijing, China; Beihang University, Beijing",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1876","1887","Numerous mobile apps have leveraged deep learning capabilities. However, on-device models are vulnerable to attacks as they can be easily extracted from their corresponding mobile apps. Although the structure and parameters information of these models can be accessed, existing on-device attacking approaches only generate black-box attacks (i.e., indirect white-box attacks), which are less effective and efficient than white-box strategies. This is because mobile deep learning (DL) frameworks like TensorFlow Lite (TFLite) do not support gradient computing (referred to as non-debuggable models), which is necessary for white-box attacking algorithms. Thus, we argue that existing findings may underestimate the harm-fulness of on-device attacks. To validate this, we systematically analyze the difficulties of transforming the on-device model to its debuggable version and propose a Reverse Engineering framework for On-device Models (REOM), which automatically reverses the compiled on-device TFLite model to its debuggable version, enabling attackers to launch white-box attacks. Our empirical results show that our approach is effective in achieving automated transformation (i.e., 92.6%) among 244 TFLite models. Compared with previous attacks using surrogate models, REOM enables attackers to achieve higher attack success rates (10.23%→89.03%) with a hun-dred times smaller attack perturbations (1.0→0.01). Our findings emphasize the need for developers to carefully consider their model deployment strategies, and use white-box methods to evaluate the vulnerability of on-device models. Our artifacts11https://github.com/zhoumingyi/REOM are available.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62202026,62172214); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548067","SE for AI;Responsible AI;Model Conversion","Deep learning;Analytical models;Computational modeling;Atmospheric modeling;Reverse engineering;Transforms;Mobile applications","","","","42","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"CoLeFunDa: Explainable Silent Vulnerability Fix Identification","J. Zhou; M. Pacheco; J. Chen; X. Hu; X. Xia; D. Lo; A. E. Hassan","Centre for Software Excellence, Huawei, Toronto, Canada; Centre for Software Excellence, Huawei, Toronto, Canada; Centre for Software Excellence, Huawei, Toronto, Canada; School of Software Technology, Zhejiang University, Ningbo, China; Huawei, China; School of Information Systems, Singapore Management University, Singapore; Software Analysis and Intelligence Lab (SAIL), Queen's University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2565","2577","It is common practice for OSS users to leverage and monitor security advisories to discover newly disclosed OSS vulnerabilities and their corresponding patches for vulnerability remediation. It is common for vulnerability fixes to be publicly available one week earlier than their disclosure. This gap in time provides an opportunity for attackers to exploit the vulnerability. Hence, OSS users need to sense the fix as early as possible so that the vulnerability can be remediated before it is exploited. However, it is common for OSS to adopt a vulnerability disclosure policy which causes the majority of vulnerabilities to be fixed silently, meaning the commit with the fix does not indicate any vulnerability information. In this case even if a fix is identified, it is hard for OSS users to understand the vulnerability and evaluate its potential impact. To improve early sensing of vulnerabilities, the identification of silent fixes and their corresponding explanations (e.g., the corresponding common weakness enumeration (CWE) and exploitability rating) are equally important. However, it is challenging to identify silent fixes and provide explanations due to the limited and diverse data. To tackle this challenge, we propose CoLeFunDa: a framework consisting of a Contrastive Learner and FunDa, which is a novel approach for Function change Data augmentation. FunDa first increases the fix data (i.e., code changes) at the function level with unsupervised and supervised strategies. Then the contrastive learner leverages contrastive learning to effectively train a function change encoder, FCBERT, from diverse fix data. Finally, we leverage FCBERT to further fine-tune three downstream tasks, i.e., silent fix identification, CWE category classification, and exploitability rating classification, respectively. Our result shows that CoLeFunDa outperforms all the state-of-art baselines in all downstream tasks. We also conduct a survey to verify the effectiveness of CoLeFunDa in practical usage. The result shows that CoLeFunDa can categorize 62.5% (25 out of 40) CVEs with correct CWE categories within the top 2 recommendations.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00214","National Key Research and Development Program of China(grant numbers:2021 YFB2701102); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172826","OSS Vulnerabilities;Contrastive Learning","Surveys;Codes;Data augmentation;Sensors;Security;Task analysis;Monitoring","","4","","72","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Coverage Guided Fault Injection for Cloud Systems","Y. Gao; W. Dou; D. Wang; W. Feng; J. Wei; H. Zhong; T. Huang","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2211","2223","To support high reliability and availability, modern cloud systems are designed to be resilient to node crashes and reboots. That is, a cloud system should gracefully recover from node crashes/reboots and continue to function. However, node crashes/reboots that occur under special timing can trigger crash recovery bugs that lie in incorrect crash recovery protocols and their implementations. To ensure that a cloud system is free from crash recovery bugs, some fault injection approaches have been proposed to test whether a cloud system can correctly recover from various crash scenarios. These approaches are not effective in exploring the huge crash scenario space without developers' knowledge. In this paper, we propose Crash Fuzz, a fault injection testing approach that can effectively test crash recovery behaviors and reveal crash recovery bugs in cloud systems. CrashFuzz mutates the combinations of possible node crashes and reboots according to runtime feedbacks, and prioritizes the combinations that are prone to increase code coverage and trigger crash recovery bugs for smart exploration. We have implemented CrashFuzz and evaluated it on three popular open-source cloud systems, i.e., ZooKeeper, HDFS and HBase. CrashFuzz has detected 4 unknown bugs and 1 known bug. Compared with other fault injection approaches, CrashFuzz can detect more crash recovery bugs and achieve higher code coverage.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172878","cloud system;crash recovery bug;fault injection;bug detection;fuzzing","Codes;Runtime;Protocols;Computer bugs;Reliability engineering;Timing;Behavioral sciences","","3","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Out of Sight, Out of Mind: Better Automatic Vulnerability Repair by Broadening Input Ranges and Sources","X. Zhou; K. Kim; B. Xu; D. Han; D. Lo","Singapore Management University, Singapore; Singapore Management University, Singapore; North Carolina State University, USA; Royal Holloway University of London, United Kingdom; Singapore Management University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1071","1083","The advances of deep learning (DL) have paved the way for auto-matic software vulnerability repair approaches, which effectively learn the mapping from the vulnerable code to the fixed code. Never-theless, existing DL-based vulnerability repair methods face notable limitations: 1) they struggle to handle lengthy vulnerable code, 2) they treat code as natural language texts, neglecting its inherent structure, and 3) they do not tap into the valuable expert knowledge present in the expert system. To address this, we propose VulMaster, a Transformer-based neural network model that excels at generating vulnerability repairs by comprehensively understanding the entire vulnerable code, irrespective of its length. This model also integrates diverse information, encompassing vulnerable code structures and expert knowledge from the CWE system. We evaluated VulMaster on a real-world C/C++ vulnerability repair dataset comprising 1,754 projects with 5,800 vulnerable functions. The experimental results demonstrated that VulMaster exhibits substan-tial improvements compared to the learning-based state-of-the-art vulnerability repair approach. Specifically, VulMaster improves the EM, BLEU, and CodeBLEU scores from 10.2% to 20.0%, 21.3% to 29.3%, and 32.5% to 40.9%, respectively.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639222","National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548521","","Deep learning;Codes;Neural networks;Natural languages;Maintenance engineering;Transformers;Software","","1","","88","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Flexible and Optimal Dependency Management via Max-SMT","D. Pinckney; F. Cassano; A. Guha; J. Bell; M. Culpo; T. Gamblin","Northeastern University, Boston, USA; Northeastern University, Boston, USA; Northeastern University, Boston, USA; Northeastern University, Boston, USA; np-complete, S.r.l., Mantova, Italy; Lawrence Livermore National Laboratory, Livermore, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1418","1429","Package managers such as NPM have become essential for software development. The NPM repository hosts over 2 million packages and serves over 43 billion downloads every week. Unfortunately, the NPM dependency solver has several shortcomings. 1) NPM is greedy and often fails to install the newest versions of dependencies; 2) NPM's algorithm leads to duplicated dependencies and bloated code, which is particularly bad for web applications that need to minimize code size; 3) NPM's vulnerability fixing algorithm is also greedy, and can even introduce new vulnerabilities; and 4) NPM's ability to duplicate dependencies can break stateful frameworks and requires a lot of care to workaround. Although existing tools try to address these problems they are either brittle, rely on post hoc changes to the dependency tree, do not guarantee optimality, or are not composable. We present Pacsolve, a unifying framework and implementation for dependency solving which allows for customizable constraints and optimization goals. We use Pacsolve to build Maxnpm, a complete, drop-in replacement for NPM, which empowers developers to combine multiple objectives when installing dependencies. We evaluate Maxnpm with a large sample of packages from the NPM ecosystem and show that it can: 1) reduce more vulnerabilities in dependencies than NPM's auditing tool in 33% of cases; 2) chooses newer dependencies than NPM in 14% of cases; and 3) chooses fewer dependencies than NPM in 21% of cases. All our code and data is open and available.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00124","National Science Foundation(grant numbers:CCF-2102288,CCF-2100037,CNS-2100015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172612","package-management;Max-SMT;NPM;Rosette;dependency-management;JavaScript","Codes;Ecosystems;Software algorithms;Semantics;Prototypes;Software;Optimization","","1","","43","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Content classification of development emails","A. Bacchelli; T. Dal Sasso; M. D'Ambros; M. Lanza","REVEAL @ Faculty of Informatics — University of Lugano, Switzerland; REVEAL @ Faculty of Informatics — University of Lugano, Switzerland; REVEAL @ Faculty of Informatics — University of Lugano, Switzerland; REVEAL @ Faculty of Informatics — University of Lugano, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","375","385","Emails related to the development of a software system contain information about design choices and issues encountered during the development process. Exploiting the knowledge embedded in emails with automatic tools is challenging, due to the unstructured, noisy, and mixed language nature of this communication medium. Natural language text is often not well-formed and is interleaved with languages with other syntaxes, such as code or stack traces. We present an approach to classify email content at line level. Our technique classifies email lines in five categories (i.e., text, junk, code, patch, and stack trace) to allow one to subsequently apply ad hoc analysis techniques for each category. We evaluated our approach on a statistically significant set of emails gathered from mailing lists of four unrelated open source systems.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227177","Empirical software engineering;Unstructured Data Mining;Emails","Electronic mail;Data mining;Software;Context;Noise;Java;Text recognition","","63","1","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"What make long term contributors: Willingness and opportunity in OSS community","M. Zhou; A. Mockus","School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Avaya Laboratories Research, Basking Ridge, NJ, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","518","528","To survive and succeed, software projects need to attract and retain contributors. We model the individual's chances to become a valuable contributor through her capacity, willingness, and the opportunity to contribute at the time of joining. Using issue tracking data of Mozilla and Gnome, we find that the probability for a new joiner to become a Long Term Contributor (LTC) is associated with her willingness and environment. Specifically, during their first month, future LTCs tend to be more active and show more community-oriented attitude than other joiners. Joiners who start by commenting on instead of reporting an issue or ones who succeed to get at least one reported issue to be fixed, more than double their odds of becoming an LTC. The micro-climate with a productive and clustered peer group increases the odds. On the contrary, the macro-climate with high project popularity and the micro-climate with low attention from peers reduce the odds. This implies that the interaction between individual's attitude and project's climate are associated with the odds that an individual would become a valuable contributor or disengage from the project. Our findings may provide a basis for empirical approaches to design a better community architecture and to improve the experience of contributors.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227164","Long Term Contributor;open source;willingness;opportunity;interaction of person and environment","Software;Communities;Atmospheric measurements;Particle measurements;Context;History;Meteorology","","113","","21","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Use, disuse, and misuse of automated refactorings","M. Vakilian; N. Chen; S. Negara; B. A. Rajkumar; B. P. Bailey; R. E. Johnson","University of Illinois, Urbana-Champaign, Urbana, IL, USA; University of Illinois, Urbana-Champaign, Urbana, IL, USA; University of Illinois, Urbana-Champaign, Urbana, IL, USA; University of Illinois, Urbana-Champaign, Urbana, IL, USA; University of Illinois, Urbana-Champaign, Urbana, IL, USA; University of Illinois, Urbana-Champaign, Urbana, IL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","233","243","Though refactoring tools have been available for more than a decade, research has shown that programmers underutilize such tools. However, little is known about why programmers do not take advantage of these tools. We have conducted a field study on programmers in their natural settings working on their code. As a result, we collected a set of interaction data from about 1268 hours of programming using our minimally intrusive data collectors. Our quantitative data show that programmers prefer lightweight methods of invoking refactorings, usually perform small changes using the refactoring tool, proceed with an automated refactoring even when it may change the behavior of the program, and rarely preview the automated refactorings. We also interviewed nine of our participants to provide deeper insight about the patterns that we observed in the behavioral data. We found that programmers use predictable automated refactorings even if they have rare bugs or change the behavior of the program. This paper reports some of the factors that affect the use of automated refactorings such as invocation method, awareness, naming, trust, and predictability and the major mismatches between programmers' expectations and automated refactorings. The results of this work contribute to producing more effective tools for refactoring complex software.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227190","Software engineering;Software maintenance;Programming environments;Human factors;User interfaces;Human computer interaction","Interviews;Programming;Context;Educational institutions;Reliability;Software;User interfaces","","89","","41","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Reorder Pointer Flow in Sound Concurrency Bug Prediction","Y. Guo; S. Zhu; Y. Cai; L. He; J. Zhang","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, and University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, and University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, and University of Chinese Academy of Sciences, Beijing, China; TCA, Institute of Software, Chinese Academy of Sciences, and University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, and University of Chinese Academy of Sciences, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","203","215","Due to the non-determinism of thread interleaving, predicting con-currency bugs has long been an extremely difficult task. Recently, several sound bug-detecting approaches were proposed. These approaches are based on local search, i.e., mutating the sequential order of the observed trace and predicting whether the mutated sequential order can trigger a bug. Surprisingly, during this process, they never consider reordering the data flow of the pointers, which can be the key point to detecting many complex bugs. To alleviate this weakness, we propose a new flow-sensitive point-to analysis technique Conpta to help actively reorder the pointer flow during the sequential order mutation process. Based on Conpta, we further propose a new sound predictive bug-detecting approach Eagle to predict four types of concurrency bugs. They are null pointer dereference (NPD), uninitialized pointer use (UPU), use after free (UAF), and double free (DF). By actively reordering the pointer flow, Eagle can explore a larger search space of the thread interleaving during the mutation and thus detect more concurrency bugs. Our evaluation of Eagle on 10 real-world multi-threaded programs shows that Eagle significantly outperforms four state-of-the-art bug-detecting approaches UFO, Convul, Convulpoe and Period in both effectiveness and efficiency.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549700","Concurrency bug prediction;point-to analysis","Concurrent computing;Instruction sets;Computer bugs;Task analysis;Software engineering","","","","79","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction","S. Kang; J. Yoon; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2312","2323","Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose Libro, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of Libro shows that, on the widely studied Defects4J benchmark, Libro can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate Libro against 31 bug reports submitted after the collection of the LLM training data terminated: Libro produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show Libro has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00194","National Research Foundation of Korea (NRF)(grant numbers:NRF-2020R1A2C1013629,NRF-2018R1A5A1059921); Institute for Information & Communications Technology Promotion; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172763","test generation;natural language processing;software engineering","Codes;Computer bugs;Semantics;Training data;Benchmark testing;Writing;Test pattern generators","","40","","42","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"DeepAnalyze: Learning to Localize Crashes at Scale","M. Shetty; C. Bansal; S. Nath; S. Bowles; H. Wang; O. Arman; S. Ahari","Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft, Redmond, USA; Microsoft, Redmond, USA; Microsoft, Redmond, USA; Microsoft, Redmond, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","549","560","Crash localization, an important step in debugging crashes, is challenging when dealing with an extremely large number of diverse applications and platforms and underlying root causes. Large-scale error reporting systems, e.g., Windows Error Reporting (WER), commonly rely on manually developed rules and heuristics to localize blamed frames causing the crashes. As new applications and features are routinely introduced and existing applications are run under new environments, developing new rules and maintaining existing ones become extremely challenging. We propose a data-driven solution to address the problem. We start with the first large-scale empirical study of 362K crashes and their blamed methods reported to WER by tens of thousands of applications running in the field. The analysis provides valuable insights on where and how the crashes happen and what methods to blame for the crashes. These insights enable us to develop Deep-Analyze, a novel multi-task sequence labeling approach for identifying blamed frames in stack traces. We evaluate our model with over a million real-world crashes from four popular Microsoft applications and show that DeepAnalyze, trained with crashes from one set of applications, not only accurately localizes crashes of the same applications, but also bootstrap crash localization for other applications with zero to very little additional training data.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3512759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794075","Software Engineering;Machine Learning;Crash Localization","Location awareness;Operating systems;Training data;Debugging;Multitasking;Computer crashes;Data models","","","","62","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automated Repair of Programs from Large Language Models","Z. Fan; X. Gao; M. Mirchev; A. Roychoudhury; S. H. Tan","National University of Singapore, Singapore; Beihang University, Beijing, China; National University of Singapore, Singapore; National University of Singapore, Singapore; Southern University of Science and Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1469","1481","Large language models such as Codex, have shown the capability to produce code for many programming tasks. However, the success rate of existing models is low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics, resulting in incorrect programs, or even programs which do not compile. In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance reliability in the code produced by large language models. Our study revealed that: (1) automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to fix auto-generated code; (2) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports editing code, is similar to or better than existing Java repair tools TBar and Recoder in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions: (1) enhancing APR tools to surpass limitations in patch space (e.g., introducing more flexible fault localization) is desirable; (2) as large language models can derive more fix patterns by training on more data, future APR tools could shift focus from adding more fix patterns to synthesis/semantics based approaches, (3) combination of language models with APR to curate patch ingredients, is worth studying.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172854","Large Language Model;Program Repair","Location awareness;Training;Analytical models;Codes;Semantics;Maintenance engineering;Programming","","46","","53","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Large Language Models for Test-Free Fault Localization","A. Z. H. Yang; C. L. Goues; R. Martins; V. J. Hellendoorn","Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States; Carnegie Mellon University, Pittsburgh, United States",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","165","176","Fault Localization (FL) aims to automatically localize buggy lines of code, a key first step in many manual and automatic debugging tasks. Previous FL techniques assume the provision of input tests, and often require extensive program analysis, program instrumentation, or data preprocessing. Prior work on deep learning for APR struggles to learn from small datasets and produces limited results on real-world programs. Inspired by the ability of large language models (LLMs) of code to adapt to new tasks based on very few examples, we investigate the applicability of LLMs to line level fault localization. Specifically, we propose to overcome the left-to-right nature of LLMs by fine-tuning a small set of bidirectional adapter layers on top of the representations learned by LLMs to produce LLMAO, the first language model based fault localization approach that locates buggy lines of code without any test coverage information. We fine-tune LLMs with 350 million, 6 billion, and 16 billion parameters on small, manually curated corpora of buggy programs such as the $Defects4\mathcal{J}$ corpus. We observe that our technique achieves substantially more confidence in fault localization when built on the larger models, with bug localization performance scaling consistently with the LLM size. Our empirical evaluation shows that LLMAO improves the Top-1 results over the state-of-the-art machine learning fault localization (MLFL) baselines by 2.3%-54.4%, and Top-5 results by 14.4%-35.6%. LLMAO is also the first FL technique trained using a language model architecture that can detect security vulnerabilities down to the code line level.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623342","ANI(grant numbers:045917); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548193","Software and its engineering → Software functional properties;Computing methodologies → Neural networks","Location awareness;Deep learning;Training;Adaptation models;Codes;Computer bugs;Manuals","","7","","50","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Moving mobile applications between mobile devices seamlessly","V. Schuchardt","Paluno-The Ruhr Institute for Software Technology, University of Duisburg-Essen, Essen, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1595","1598","Users prefer using multiple mobile devices interchangeably by switching between the devices. A solution to this requirement is the migration of applications between mobile devices at runtime. In our vision to move the application from a device A to a device B, instead of synchronizing just the application's data, a simple swiping gesture can be used. Afterwards the user is able to use the same application including its current state on device B. To achieve this, we plan to put the running application on the device A into a paused state, take a snapshot afterwards, move the application to the device B by using a middleware on both devices, extract the snapshot on device B and finally resume it on device B from its paused state. The outcome of the research will be a framework and either a kernel module or an API to migrate mobile applications.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227028","mobile;application;migration;handover","Operating systems;Mobile handsets;Mobile communication;Middleware;Hardware;Browsers;History","","5","5","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Practical Non-Intrusive GUI Exploration Testing with Visual-based Robotic Arms","S. Yu; C. Fang; M. Du; Y. Ling; Z. Chen; Z. Su","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; ETH Zurich, Switzerland",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1597","1609","Graphical User Interface (GUI) testing has been a significant topic in the software engineering community. Most existing GUI testing frameworks are intrusive and can only support some specific platforms, which are quite limited. With the development of dis-tinct scenarios, diverse embedded systems or customized operating systems on different devices do not support existing intrusive GUI testing frameworks. Some approaches adopt robotic arms to re-place the interface invoking of mobile apps under test and use computer vision technologies to identify GUI elements. However, some challenges remain unsolved with such approaches. First, existing approaches assume that GUI screens are fixed so that they cannot be adapted to diverse systems with different screen conditions. Second, existing approaches use XY-plane robotic arm system, which cannot flexibly simulate human testing operations. Third, existing approaches ignore the compatibility bugs of apps and only focus on the crash bugs. To sum up, a more practical approach is required for the non-intrusive scenario. In order to solve the remaining challenges, we propose a practi-cal non-intrusive GUI testing framework with visual-based robotic arms, namely ROBOTEST. ROBOTEST integrates a set of novel GUI screen and widget detection algorithm that is adaptive to detecting screens of different sizes and then to extracting GUI widgets from the detected screens. Then, a complete set of widely-used testing operations are applied with a 4-DOF robotic arm, which can more effectively and flexibly simulate human testing operations. During the app exploration, ROBOTEST integrates the specially designed Principle of Proximity-guided (PoP-guided) exploration strategy, which chooses close widgets of the previous operation targets to reduce the robotic arm movement overhead and improve exploration efficiency. Moreover, ROBOTEST can effectively detect some compat-ibility bugs beyond crash bugs with a GUI comparison on different devices of the same test operations. We evaluate ROBOTEST with 20 real-world mobile apps, together with a case study on a representative industrial embedded system. The results show that ROBOTEST can effectively, efficiently, and generally explore the AUT to find bugs and reduce app exploration time overhead from the robotic arm movement.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639161","National Natural Science Foundation of China(grant numbers:62141215,61932012,62372228); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549424","GUI Testing;Non-Intrusive Testing;GUI Understanding;Robotic Arm","Embedded systems;Service robots;Computer bugs;Fitting;Manipulators;Mobile applications;Robots","","","","66","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Lejacon: A Lightweight and Efficient Approach to Java Confidential Computing on SGX","X. Miao; Z. Lin; S. Wang; L. Yu; S. Li; Z. Wang; P. Nie; Y. Chen; B. Shen; H. Jiang","Shanghai Jiao Tong University, Shanghai, China; Alibaba Group, Shanghai, China; Alibaba Group, Shanghai, China; Alibaba Group, Shanghai, China; Alibaba Group, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Dalian University of Technology, Dalian, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1648","1660","Intel's SGX is a confidential computing technique. It allows key functionalities of C/C++/native applications to be confidentially executed in hardware enclaves. However, numerous cloud applications are written in Java. For supporting their confidential computing, state-of-the-art approaches deploy Java Virtual Machines (JVMs) in enclaves and perform confidential computing on JVMs. Meanwhile, these JVM-in-enclave solutions still suffer from serious limitations, such as heavy overheads of running JVMs in enclaves, large attack surfaces, and deep computation stacks. To mitigate the above limitations, we for-malize a Secure Closed-World (SCW) principle and then propose Lejacon, a lightweight and efficient approach to Java confidential computing. The key idea is, given a Java application, to (1) separately compile its confidential computing tasks into a bundle of Native Confidential Computing (NCC) services; (2) run the NCC services in enclaves on the Trusted Execution Environment (TEE) side, and meanwhile run the non-confidential code on a JVM on the Rich Execution Environment (REE) side. The two sides interact with each other, protecting confidential computing tasks and as well keeping the Trusted Computing Base (TCB) size small. We implement Lejacon and evaluate it against OcclumJ (a state-of-the-art JVM-in-enclave solution) on a set of benchmarks using the BouncyCastle cryptography library. The evaluation results clearly show the strengths of Lejacon: it achieves compet-itive performance in running Java confidential code in enclaves; compared with OcclumJ, Lejacon achieves speedups by up to 16.2x in running confidential code and also reduces the TCB sizes by 90+% on average.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172889","Software Guard Extensions;Separation Compilation;Native Confidential Computing Service;Runtime;Secure Closed-World","Java;Trusted computing;Codes;Runtime;Programming;Virtual machining;Software","","","","66","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Rust-lancet: Automated Ownership-Rule-Violation Fixing with Behavior Preservation","W. Yang; L. Song; Y. Xue","University of Science and Technology of China, Anhui, China; Pennsylvania State University, Pennsylvania, USA; University of Science and Technology of China, Anhui, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1034","1046","As a relatively new programming language, Rust is designed to provide both memory safety and runtime performance. To achieve this goal, Rust conducts rigorous static checks against its safety rules during compilation, effectively eliminating memory safety issues that plague C/C++ programs. Although useful, the safety rules pose programming challenges to Rust programmers, since programmers can easily violate safety rules when coding in Rust, leading their code to be rejected by the Rust compiler, a fact underscored by a recent user study. There exists a desire to automate the process of fixing safety-rule violations to enhance Rust's programmability. In this paper, we concentrate on Rust's ownership rules and develop rust-lancet to automatically fix their violations. We devise three strategies for altering code, each intended to modify a Rust program and make it pass Rust's compiler checks. Additionally, we introduce mental semantics to model the behaviors of Rust programs that cannot be compiled due to ownership-rule violations. We design an approach to verify whether modified programs preserve their original behaviors before patches are applied. We apply rust-lancet to 160 safety-rule violations from two sources, successfully fixing 102 violations under the optimal configuration - more than RUSTC and six LLM-based techniques. Notably, rust-lancet avoids generating any incorrect patches, a distinction from all other baseline techniques. We also verify the effectiveness of each fixing strategy and behavior preservation validation and affirm the rationale behind these components.","1558-1225","979-8-4007-0217-4","","NSF(grant numbers:CNS-1955965,CCF-2145394); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548167","Software and its engineering → General programming languages;Error handling and recovery;Software development techniques;Rust;Program Repair;Compiler Error","Computer languages;Program processors;Codes;Runtime;Semantics;Programming;Software","","","","66","","14 Jun 2024","","","IEEE","IEEE Conferences"
"EGFE: End-to-end Grouping of Fragmented Elements in UI Designs with Multimodal Learning","L. Chen; Y. Chen; S. Xiao; Y. Song; L. Sun; Y. Zhen; T. Zhou; Y. Chang","Zhejiang-Singapore Innovation and AI Joint Research Lab, College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang-Singapore Innovation and AI Joint Research Lab, College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","103","114","When translating UI design prototypes to code in industry, automatically generating code from design prototypes can expedite the development of applications and GUI iterations. However, in design prototypes without strict design specifications, UI components may be composed of fragmented elements. Grouping these fragmented elements can greatly improve the readability and maintainability of the generated code. Current methods employ a two-stage strategy that introduces hand-crafted rules to group fragmented elements. Unfortunately, the performance of these methods is not satisfying due to visually overlapped and tiny UI elements. In this study, we propose EGFE, a novel method for automatically End-to-end Grouping Fragmented Elements via UI sequence prediction. To facilitate the UI understanding, we innovatively construct a Transformer encoder to model the relationship between the UI elements with multi-modal representation learning. The evaluation on a dataset of 4606 UI prototypes collected from professional UI designers shows that our method outperforms the state-of-the-art baselines in the precision (by 29.75%), recall (by 31.07%), and F1-score (by 30.39%) at edit distance threshold of 4. In addition, we conduct an empirical study to assess the improvement of the generated front-end code. The results demonstrate the effectiveness of our method on a real software engineering application. Our end-to-end fragmented elements grouping method creates opportunities for improving UI-related software engineering tasks.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623313","National Key R&D Program of China(grant numbers:No.2022YFB3303300); National Natural Science Foundation of China(grant numbers:62207023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548172","UI elements grouping;Fragmented elements grouping;End-to-end pipeline;Multi-modal Transformer","Representation learning;Industries;Visualization;Codes;Semantics;Prototypes;Transformers","","","","39","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Less is More: Supporting Developers in Vulnerability Detection during Code Review","L. Braz; C. Aeberhard; G. Çalikli; A. Bacchelli",University of Zurich; University of Zurich; University of Glasgow; University of Zurich,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1317","1329","Reviewing source code from a security perspective has proven to be a difficult task. Indeed, previous research has shown that developers often miss even popular and easy-to-detect vulnerabilities during code review. Initial evidence suggests that a significant cause may lie in the reviewers' mental attitude and common practices. In this study, we investigate whether and how explicitly asking developers to focus on security during a code review affects the detection of vulnerabilities. Furthermore, we evaluate the effect of providing a security checklist to guide the security review. To this aim, we conduct an online experiment with 150 participants, of which 71% report to have three or more years of professional development experience. Our results show that simply asking reviewers to focus on security during the code review increases eight times the probability of vulnerability detection. The presence of a security checklist does not significantly improve the outcome further, even when the checklist is tailored to the change under review and the existing vulnerabilities in the change. These results provide evidence supporting the mental attitude hypothesis and call for further work on security checklists' effectiveness and design. Preprint: https://arxiv.org/abs/2202.04586 Data and materials: https://doi.org/10.5281/zenodo.6026291","1558-1225","978-1-4503-9221-1","10.1145/3510003.3511560","Swiss National Science Foundation through the SNF(grant numbers:PP00P2_170529,PZ00P2_186090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794090","code review;security vulnerability;checklist;mental attitude","Codes;Software algorithms;Software;Security;Cryptography;Task analysis;Standards","","5","","92","","20 Jun 2022","","","IEEE","IEEE Conferences"
"BabelRef: Detection and renaming tool for cross-language program entities in dynamic web applications","H. V. Nguyen; H. A. Nguyen; T. T. Nguyen; T. N. Nguyen","Department of Electrical and Computer Engineering, Iowa State University, USA; Department of Electrical and Computer Engineering, Iowa State University, USA; Department of Electrical and Computer Engineering, Iowa State University, USA; Department of Electrical and Computer Engineering, Iowa State University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1391","1394","In a dynamic web application, client-side code is often dynamically generated from server-side code. Client-side program entities such as HTML presentation elements and Javascript functions/variables are embedded within server-side string literals or variables' values. However, existing tools for code maintenance such as automatic renaming support only work for program entities in a single language on either the server side or the client side. In this paper, we introduce BabelRef, a novel tool that is able to automatically identify and rename client-side program entities and their references that are embedded within server-side code.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227240","Refactoring;Web applications;Cross-language","HTML;Servers;Educational institutions;Java;Semantics;Conferences;Browsers","","4","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"ShellFusion: Answer Generation for Shell Programming Tasks via Knowledge Fusion","N. Zhang; C. Liu; X. Xia; C. Treude; Y. Zou; D. Lo; Z. Zheng","School of Software Engineering, Sun Yat-sen University, China; School of Big Data and Software Engineering, Chongqing University, China; Software Engineering Application Technology Lab, Huawei, China; School of Computing and Information Systems, University of Melbourne, Australia; Department of Electrical and Computer Engineering, Queen's University, Canada; School of Information Systems, Singapore Management University, Singapore; School of Software Engineering, Sun Yat-sen University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1970","1981","Shell commands are widely used for accomplishing tasks, such as network management and file manipulation, in Unix and Linux platforms. There are a large number of shell commands available. For example, 50,000+ commands are documented in the Ubuntu Manual Pages (MPs). Quite often, programmers feel frustrated when searching and orchestrating appropriate shell commands to accomplish specific tasks. To address the challenge, the shell programming community calls for easy-to-use tutorials for shell commands. However, existing tutorials (e.g., TLDR) only cover a limited number of frequently used commands for shell beginners and provide limited support for users to search for commands by a task. We propose an approach, i.e., ShellFusion, to automatically generate comprehensive answers (including relevant shell commands, scripts, and explanations) for shell programming tasks. Our approach integrates knowledge mined from Q&A posts in Stack Exchange, Ubuntu MPs, and TLDR tutorials. For a query that describes a shell programming task, ShellFusion recommends a list of relevant shell commands. Specifically, ShellFusion retrieves the top-n Q&A posts with questions similar to the query and detects shell commands with options (e.g., ls -t) from the accepted answers of the retrieved posts. Next, ShellFusion filters out irrelevant commands with descriptions in MP and TLDR that share little semantics with the query, and further ranks the candidate commands based on their similarities with the query and the retrieved posts. To help users understand how to achieve the task using a recommended command, ShellFusion generates a comprehensive answer for each command by synthesizing knowledge from Q&A posts, MPs, and TLDR. Our evaluation of 434 shell programming tasks shows that ShellFusion significantly outperforms Magnum (the state-of-the-art natural language-to-Bash command approach) by at least 179.6% in terms of MRR@K and MAP@K. A user study conducted with 20 shell programmers further shows that ShellFusion can help users address programming tasks more efficiently and accurately, compared with Magnum and DeepAns (a recent answer recommendation baseline).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510131","National Natural Science Foundation of China(grant numbers:62032025); National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794105","Shell Programming;Answer Generation;Knowledge Fusion","Knowledge engineering;Linux;Semantics;Tutorials;Manuals;Programming;Task analysis","","3","","52","","20 Jun 2022","","","IEEE","IEEE Conferences"
"PROPR: Property-Based Automatic Program Repair","M. P. Gissurarson; L. Applis; A. Panichella; A. van Deursen; D. Sands","Chalmers University of Technology, Gothenburg, Sweden; TU Delft, Delft, Netherlands; TU Delft, Delft, Netherlands; TU Delft, Delft, Netherlands; Chalmers University of Technology, Gothenburg, Sweden",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1768","1780","Automatic program repair (APR) regularly faces the challenge of overfitting patches - patches that pass the test suite, but do not actually address the problems when evaluated manually. Currently, overfit detection requires manual inspection or an oracle making quality control of APR an expensive task. With this work, we want to introduce properties in addition to unit tests for APR to address the problem of overfitting. To that end, we design and implement PROPR, a program repair tool for Haskell that leverages both property-based testing (via QuickCheck) and the rich type sys-tem and synthesis offered by the Haskell compiler. We compare the repair-ratio, time-to-first-patch and overfitting-ratio when using unit tests, property-based tests, and their combination. Our results show that properties lead to quicker results and have a lower overfit ratio than unit tests. The created overfit patches provide valuable insight into the underlying problems of the program to repair (e.g., in terms of fault localization or test quality). We consider this step towards fitter, or at least insightful, patches a critical contribution to bring APR into developer workflows.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510620","Knuth and Alice Wallenberg Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794120","automatic program repair;search based software engineering;synthesis;property-based testing;typed holes","Location awareness;Program processors;Redundancy;Manuals;Maintenance engineering;Inspection;Software","","3","","73","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Learning Seed-Adaptive Mutation Strategies for Greybox Fuzzing","M. Lee; S. Cha; H. Oh",Korea University; Sungkyunkwan University; Korea University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","384","396","In this paper, we present a technique for learning seed-adaptive mutation strategies for fuzzers. The performance of mutation-based fuzzers highly depends on the mutation strategy that specifies the probability distribution of selecting mutation methods. As a result, developing an effective mutation strategy has received much attention recently, and program-adaptive techniques, which observe the behavior of the target program to learn the optimized mutation strategy per program, have become a trending approach to achieve better performance. They, however, still have a major limitation; they disregard the impacts of different characteristics of seed inputs which can lead to explore deeper program locations. To address this limitation, we present SEAMFUZZ, a novel fuzzing technique that automatically captures the characteristics of individual seed inputs and applies different mutation strategies for different seed inputs. By capturing the syntactic and semantic similarities between seed inputs, SEAMFUZZ clusters them into proper groups and learns effective mutation strategies tailored for each seed cluster by using the customized Thompson sampling algorithm. Experimental results show that SEAMFUZZ improves both the path-discovering and bug-finding abilities of state-of-the-art fuzzers on real-world programs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00043","Samsung Electronics Co., Ltd(grant numbers:IO201216-08209-01); Institute of Information & communications Technology Planning & Evaluation (IITP)(grant numbers:2020-0-01337); MSIT(Ministry of Science and ICT)(grant numbers:IITP-2023-2020-0-01819); National Research Foundation of Korea(NRF)(grant numbers:2021R1A5A1021944,NRF-2021R1C1C2006410,RS-2023-00208094); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172576","Fuzzing;Software Testing","Semantics;Clustering algorithms;Syntactics;Fuzzing;Probability distribution;Behavioral sciences;Software engineering","","5","","49","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"On the naturalness of software","A. Hindle; E. T. Barr; Z. Su; M. Gabel; P. Devanbu","Department of Computer Science, University of California,슠Davis, Davis, CA, USA; Department of Computer Science, University of California,슠Davis, Davis, CA, USA; Department of Computer Science, University of California,슠Davis, Davis, CA, USA; Department of Computer Science, University of Texas, Dallas, Richardson, TX, USA; Department of Computer Science, University of California,슠Davis, Davis, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","837","847","Natural languages like English are rich, complex, and powerful. The highly creative and graceful use of languages like English and Tamil, by masters like Shakespeare and Avvaiyar, can certainly delight and inspire. But in practice, given cognitive constraints and the exigencies of daily life, most human utterances are far simpler and much more repetitive and predictable. In fact, these utterances can be very usefully modeled using modern statistical methods. This fact has led to the phenomenal success of statistical approaches to speech recognition, natural language translation, question-answering, and text mining and comprehension. We begin with the conjecture that most software is also natural, in the sense that it is created by humans at work, with all the attendant constraints and limitations - and thus, like natural language, it is also likely to be repetitive and predictable. We then proceed to ask whether a) code can be usefully modeled by statistical language models and b) such models can be leveraged to support software engineers. Using the widely adopted n-gram model, we provide empirical evidence supportive of a positive answer to both these questions. We show that code is also very repetitive, and in fact even more so than natural languages. As an example use of the model, we have developed a simple code completion engine for Java that, despite its simplicity, already improves Eclipse's built-in completion capability. We conclude the paper by laying out a vision for future research in this area.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227135","language models;n-gram;natural language processing;code completion;code suggestion","Java;Software;Speech recognition;Entropy;Natural language processing;Computational modeling","","388","1","38","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"BinAug: Enhancing Binary Similarity Analysis with Low-Cost Input Repairing","W. K. Wong; H. Wang; Z. Li; S. Wang","The Hong Kong University of Science and Technology, Hong Kong, SAR; The Hong Kong University of Science and Technology, Hong Kong, SAR; The Hong Kong University of Science and Technology, Hong Kong, SAR; The Hong Kong University of Science and Technology, Hong Kong, SAR",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","51","63","Binary code similarity analysis (BCSA) is a fundamental building block for various software security, reverse engineering, and re-engineering applications. Existing research has applied deep neural networks (DNNs) to measure the similarity between binary code, following the major breakthrough of DNNs in processing media data like images. Despite the encouraging results of DNN-based BCSA, it is however not widely deployed in the industry due to the instability and the black-box nature of DNNs. In this work, we first launch an extensive study over the state-of-the-art (SoTA) BCSA tools, and investigate their erroneous predictions from both quantitative and qualitative perspectives. Then, we accordingly design a low-cost and generic framework, namely Binaug, to improve the accuracy of BCSA tools by repairing their input binary codes. Aligned with the typical workflow of DNN-based BCSA, Binaug obtains the sorted top-K results of code similarity, and then re-ranks the results using a set of carefully-designed transformations. Binaug supports both black- and white-box settings, depending on the accessibility of the DNN model internals. Our experimental results show that Binaug can constantly improve performance of the SoTA BCSA tools by an average of 2.38pt and 6.46pt in the black- and the white-box settings. Moreover, with Binaug, we enhance the F1 score of binary software component analysis, an important downstream application of BCSA, by an average of 5.43pt and 7.45pt in the black- and the white-box settings.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548594","Binary analysis;DNNs;Input repairing","Industries;Reverse engineering;Closed box;Binary codes;Artificial neural networks;Media;Security","","","","110","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Demystifying Exploitable Bugs in Smart Contracts","Z. Zhang; B. Zhang; W. Xu; Z. Lin",Purdue University; Harrison High School; Georgia Institute of Technology; Ohio State University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","615","627","Exploitable bugs in smart contracts have caused significant monetary loss. Despite the substantial advances in smart contract bug finding, exploitable bugs and real-world attacks are still trending. In this paper we systematically investigate 516 unique real-world smart contract vulnerabilities in years 2021–2022, and study how many can be exploited by malicious users and cannot be detected by existing analysis tools. We further categorize the bugs that cannot be detected by existing tools into seven types and study their root causes, distributions, difficulties to audit, consequences, and repair strategies. For each type, we abstract them to a bug model (if possible), facilitating finding similar bugs in other contracts and future automation. We leverage the findings in auditing real world smart contracts, and so far we have been rewarded with $102,660 bug bounties for identifying 15 critical zero-day exploitable bugs, which could have caused up to $22.52 millions monetary loss if exploited.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172700","Blockchain;Smart Contract;Vulnerability;Security;Empirical Study","Automation;Computer bugs;Smart contracts;Maintenance engineering;Security;Software engineering","","21","","109","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Syntax and Domain Aware Model for Unsupervised Program Translation","F. Liu; J. Li; L. Zhang","State Key Laboratory of Software Development Environment, Beihang University, Beijing, China; Key Lab of High Confidence Software Technology, MoE, Peking University, Beijing, China; State Key Laboratory of Software Development Environment, Beihang University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","755","767","There is growing interest in software migration as the development of software and society. Manually migrating projects between languages is error-prone and expensive. In recent years, researchers have begun to explore automatic program translation using supervised deep learning techniques by learning from large-scale parallel code corpus. However, parallel resources are scarce in the programming language domain, and it is costly to collect bilingual data manually. To address this issue, several unsupervised programming translation systems are proposed. However, these systems still rely on huge monolingual source code to train, which is very expensive. Besides, these models cannot perform well for translating the languages that are not seen during the pre-training procedure. In this paper, we propose SDA-Trans, a syntax and domain-aware model for program translation, which leverages the syntax structure and domain knowledge to enhance the cross-lingual transfer ability. SDA-Trans adopts unsupervised training on a smaller-scale corpus, including Python and Java monolingual programs. The experimental results on function translation tasks between Python, Java, and C++ show that SDA-Trans outperforms many large-scale pre-trained models, especially for unseen language translation.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00072","National Science Foundation of China(grant numbers:62177003); State Key Laboratory of Software Development Environment(grant numbers:SKLSDE-2022ZX-13); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172589","program translation;neural networks;syntax structure;unsupervised learning","Training;Deep learning;Java;Source coding;Syntactics;Programming;Software","","6","","44","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"NeuronFair: Interpretable White-Box Fairness Testing through Biased Neuron Identification","H. Zheng; Z. Chen; T. Du; X. Zhang; Y. Cheng; S. Ti; J. Wang; Y. Yu; J. Chen",Zhejiang University of Technology; Zhejiang University; Zhejiang University; Zhejiang University; Huawei International; Zhejiang University; Zhejiang University; National University of Defense Technology; Zhejiang University of Technology,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1519","1531","Deep neural networks (DNNs) have demonstrated their outper-formance in various domains. However, it raises a social concern whether DNNs can produce reliable and fair decisions especially when they are applied to sensitive domains involving valuable re-source allocation, such as education, loan, and employment. It is crucial to conduct fairness testing before DNNs are reliably de-ployed to such sensitive domains, i.e., generating as many instances as possible to uncover fairness violations. However, the existing testing methods are still limited from three aspects: interpretabil-ity, performance, and generalizability. To overcome the challenges, we propose NeuronFair, a new DNN fairness testing framework that differs from previous work in several key aspects: (1) inter-pretable - it quantitatively interprets DNNs' fairness violations for the biased decision; (2) effective - it uses the interpretation results to guide the generation of more diverse instances in less time; (3) generic - it can handle both structured and unstructured data. Extensive evaluations across 7 datasets and the corresponding DNNs demonstrate NeuronFair's superior performance. For instance, on structured datasets, it generates much more instances (~ ×5.84) and saves more time (with an average speedup of 534.56%) compared with the state-of-the-art methods. Besides, the instances of NeuronFair can also be leveraged to improve the fairness of the biased DNNs, which helps build more fair and trustworthy deep learning systems. The code of NeuronFair is open-sourced at https:/github.com/haibinzheng/NeuronFair.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510123","NSFC(grant numbers:62072406,62102359,61772466,62102360); Zhejiang Provincial Natural Science Foundation for Distinguished Young Scholars(grant numbers:LR19F020003); Key R&D Projects in Zhejiang Province(grant numbers:2021C01117,2022C01018); Ten Thousand Talents Program(grant numbers:2020R52011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793943","Interpretability;fairness testing;discriminatory instance;deep learning;biased neuron","Deep learning;Neurons;Neural networks;Employment;Education;Reliability;Resource management","","16","","61","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Diver: Oracle-Guided SMT Solver Testing with Unrestricted Random Mutations","J. Kim; S. So; H. Oh","Korea University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2224","2236","We present Diver, a novel technique for effectively finding critical bugs in SMT solvers. Ensuring the correctness of SMT solvers is becoming increasingly important as many applications use solvers as a foundational basis. In response, several approaches for testing SMT solvers, which are classified into differential testing and oracle-guided approaches, have been proposed until recently. However, they are still unsatisfactory in that (1) differential testing approaches cannot validate unique yet important features of solvers, and (2) oracle-guided approaches cannot generate diverse tests due to their reliance on limited mutation rules. Diver aims to complement these shortcomings, particularly focusing on finding bugs that are missed by existing approaches. To this end, we present a new testing technique that performs oracle-guided yet unrestricted random mutations. We have used Diver to validate the most recent versions of three popular SMT solvers: CVC5, Z3 and dReal. In total, Diver found 25 new bugs, of which 21 are critical and directly affect the reliability of the solvers. We also empirically prove DIVER's own strength by showing that existing tools are unlikely to find the bugs discovered by Diver.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172495","software testing;fuzzing;SMT solver","Computer bugs;Focusing;Software;Reliability;Testing;Software engineering","","1","","51","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"WhoseFault: Automatic developer-to-fault assignment through fault localization","F. Servant; J. A. Jones","Department of Informatics, University of California, Irvine, Irvine, CA, USA; Department of Informatics, University of California, Irvine, Irvine, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","36","46","This paper describes a new technique, which automatically selects the most appropriate developers for fixing the fault represented by a failing test case, and provides a diagnosis of where to look for the fault. This technique works by incorporating three key components: (1) fault localization to inform locations whose execution correlate with failure, (2) history mining to inform which developers edited each line of code and when, and (3) expertise assignment to map locations to developers. To our knowledge, the technique is the first to assign developers to execution failures, without the need for textual bug reports. We implement this technique in our tool, WHOSEFAULT, and describe an experiment where we utilize a large, open-source project to determine the frequency in which our tool suggests an assignment to the actual developer who fixed the fault. Our results show that 81% of the time, WHOSEFAULT produced the same developer that actually fixed the fault within the top three suggestions. We also show that our technique improved by a difference between 4% and 40% the results of a baseline technique. Finally, we explore the influence of each of the three components of our technique over its results, and compare our expertise algorithm against an existing expertise assessment technique and find that our algorithm provides greater accuracy, by up to 37%.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227208","developer assignment;fault localization;mining software repositories;expertise assignment","History;Software;Measurement;Data mining;Software algorithms;Correlation;Informatics","","31","2","35","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Imperative versus Declarative Collection Processing: An RCT on the Understandability of Traditional Loops versus the Stream API in Java","N. Mehlhorn; S. Hanenberg","Independent Consultant, Essen; Paluno - The Ruhr Institute for Software Technology, University of Duisburg- Essen, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1157","1168","Java introduced in version 8 with the Stream API means to operate on collections using lambda expressions. Since then, this API is an alternative way to handle collections in a more declarative manner instead of the traditional, imperative style using loops. However, whether the Stream API is beneficial in comparison to loops in terms of usability is unclear. The present paper introduces a randomized control trial (RCT) on the understandability of collection operations performed on 20 participants with the dependent variables response time and correctness. As tasks, subjects had to determine the results for collection operations (either defined with the Stream API or with loops). The results indicate that the Stream API has a significant $(\mathrm{p} <. 001)$ and large $(\eta_{p}^{2}=.695;\frac{M_{loop}}{M_{stream}}\ \sim 178\%)$ positive effect on the response times. Furthermore, the usage of the Stream API caused significantly less errors. And finally, the participants perceived their speed with the Stream API higher compared to the loop-based code and the participants considered the code based on the Stream API as more readable. Hence, while existing studies found a negative effect of declarative constructs (in terms of lambda expressions) on the usability of a main stream programming language, the present study found the opposite: the present study gives evidence that declarative code on collections using the Stream API based on lambda expressions has a large, positive effect in comparison to traditional loops.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3519016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793929","Programming Languages;Lambda Expressions;Declarative;Imperative;Java;Streams","Java;Computer languages;Codes;Programming;Time factors;Usability;Task analysis","","","","41","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Validating SMT Solvers via Skeleton Enumeration Empowered by Historical Bug-Triggering Inputs","M. Sun; Y. Yang; M. Wen; Y. Wang; Y. Zhou; H. Jin","School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","69","81","SMT solvers check the satisfiability of logic formulas over first-order theories, which have been utilized in a rich number of critical applications, such as software verification, test case generation, and program synthesis. Bugs hidden in SMT solvers would severely mislead those applications and further cause severe consequences. Therefore, ensuring the reliability and robustness of SMT solvers is of critical importance. Although many approaches have been proposed to test SMT solvers, it is still a challenge to discover bugs effectively. To tackle such a challenge, we conduct an empirical study on the historical bug-triggering formulas in SMT solvers' bug tracking systems. We observe that the historical bug-triggering formulas contain valuable skeletons (i.e., core structures of formulas) as well as associated atomic formulas which can cast significant impacts on formulas' ability in triggering bugs. Therefore, we propose a novel approach that utilizes the skeletons extracted from the historical bug-triggering formulas and enumerates atomic formulas under the guidance of association rules derived from historical formulas. In this study, we realized our approach as a practical fuzzing tool HistFuzz and conducted extensive testing on the well-known SMT solvers Z3 and cvc5. To date, HistFuzz has found 111 confirmed new bugs for Z3 and cvc5, of which 108 have been fixed by the developers. More notably, out of the confirmed bugs, 23 are soundness bugs and invalid model bugs found in the solvers' default mode, which are essential for SMT solvers. In addition, our experiments also demonstrate that HistFuzz outperforms the state-of-the-art SMT solver fuzzers in terms of achieved code coverage and effectiveness.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172740","SMT solver;fuzzing;skeleton enumeration;association rules;bug detection","Codes;Computer bugs;Fuzzing;Reliability theory;Skeleton;Software;Robustness","","2","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"On the Reliability of Coverage-Based Fuzzer Benchmarking","M. Böhme; L. Szekeres; J. Metzman","MPI-SP, Germany Monash University, Australia; Google, USA; Google, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1621","1633","Given a program where none of our fuzzers finds any bugs, how do we know which fuzzer is better? In practice, we often look to code coverage as a proxy measure of fuzzer effectiveness and consider the fuzzer which achieves more coverage as the better one. Indeed, evaluating 10 fuzzers for 23 hours on 24 programs, we find that a fuzzer that covers more code also finds more bugs. There is a very strong correlation between the coverage achieved and the number of bugs found by a fuzzer. Hence, it might seem reasonable to compare fuzzers in terms of coverage achieved, and from that derive empirical claims about a fuzzer's superiority at finding bugs. Curiously enough, however, we find no strong agreement on which fuzzer is superior if we compared multiple fuzzers in terms of coverage achieved instead of the number of bugs found. The fuzzer best at achieving coverage, may not be best at finding bugs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793969","fuzzing;benchmarking;test suite effectiveness;code coverage","Codes;Correlation;Computer bugs;Benchmark testing;Reliability engineering;Software reliability;Software engineering","","11","","68","","20 Jun 2022","","","IEEE","IEEE Conferences"
"NPEX: Repairing Java Null Pointer Exceptions without Tests","J. Lee; S. Hong; H. Oh","Korea University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1532","1544","We present NPEX, a new technique for repairing Java null pointer exceptions (NPEs) without tests. State-of-the-art NPE repair techniques rely on test suites written by developers for patch validation. Unfortunately, however, those are typically future test cases that are unavailable at the time bugs are reported or insufficient to identify correct patches. Unlike existing techniques, NPEX does not require test cases; instead, NPEX automatically infers the repair specification of the buggy program and uses the inferred specification to validate patches. The key idea is to learn a statistical model that predicts how developers would handle NPEs by mining null-handling patterns from existing codebases, and to use a variant of symbolic execution that can infer the repair specification from the buggy program using the model. We evaluated NPEX on real-world NPEs collected from diverse open-source projects. The results show that NPEX significantly outperforms the current state-of-the-art.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510186","Institute of Information & communications Technology Planning & Evaluation (IITP)(grant numbers:2020-0-01337,2021-0-00758); MSIT(Ministry of Science and ICT), Korea(grant numbers:IITP-2022-2020-0-01819); National Research Foundation of Korea (NRF)(grant numbers:2021R1A5A1021944); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794030","","Java;Computer bugs;Maintenance engineering;Predictive models;Behavioral sciences;Open source software;Software engineering","","1","","72","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Multilingual training for Software Engineering","T. Ahmed; P. Devanbu","University of California, Davis Davis, California, USA; University of California, Davis Davis, California, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1443","1455","Well-trained machine-learning models, which leverage large amounts of open-source software data, have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach, with performance gradually improving over the past several years with better models and training methods. More, and more diverse, clean, labeled data is better for training; but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean, labeled data generally have wide applicability. For some languages (e.g., Ruby) labeled data is less abundant; in others (e.g., JavaScript) the available data maybe more focused on some application domains, and thus less diverse. As a way around such data bottlenecks, we present evidence suggesting that human-written code in different languages (which performs the same function), is rather similar, and particularly preserving of identifier naming patterns; we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization, code retrieval, and function naming. We note that this data-augmenting approach is broadly compatible with different tasks, languages, and machine-learning models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510049","U.S. National Science Foundation(grant numbers:1414172,2107592); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794126","code summarization;code search;method name prediction;deep learning","Training;Computer languages;Codes;Natural languages;Training data;Machine learning;Syntactics","","14","","76","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Context-aware Bug Reproduction for Mobile Apps","Y. Huang; J. Wang; Z. Liu; S. Wang; C. Chen; M. Li; Q. Wang","Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Electrical Engineering and Computer Science, York University, Canada; Monash University, Melbourne, Australia; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China; Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2336","2348","Bug reports are vital for software maintenance that allow the developers being informed of the problems encountered in the software. Before bug fixing, developers need to reproduce the bugs which is an extremely time-consuming and tedious task, and it is highly expected to automate this process. However, it is challenging to do so considering the imprecise or incomplete natural language described in reproducing steps, and the missing or ambiguous single source of information in GUI components. In this paper, we propose a context-aware bug reproduction approach ScopeDroid which automatically reproduces crashes from textual bug reports for mobile apps. It first constructs a state transition graph (STG) and extracts the contextual information of components. We then design a multi-modal neural matching network to derive the fuzzy matching matrix between all candidate GUI events and reproducing steps. With the STG and matching information, it plans the exploration path for reproducing the bug, and enriches the initial STG iteratively. We evaluate the approach on 102 bug reports from 69 popular Android apps, and it successfully reproduces 63.7% of the crashes, outper-forming the state-of-the-art baselines by 32.6% and 38.3%. We also evaluate the usefulness and robustness of ScopeDroid with promising results. Furthermore, to train the neural matching network, we develop a heuristic-based automated training data generation method, which can potentially motivate and facilitate other activities as user interface operations.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00196","National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172656","","Software maintenance;Computer bugs;Neural networks;Training data;Robustness;Mobile applications;Data mining","","1","","63","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Adaptive Test Selection for Deep Neural Networks","X. Gao; Y. Feng; Y. Yin; Z. Liu; Z. Chen; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","73","85","Deep neural networks (DNN) have achieved tremendous development in the past decade. While many DNN-driven software applications have been deployed to solve various tasks, they could also produce incorrect behaviors and result in massive losses. To reveal the incorrect behaviors and improve the quality of DNN-driven applications, developers often need rich labeled data for the testing and optimization of DNN models. However, in practice, collecting diverse data from application scenarios and labeling them properly is often a highly expensive and time-consuming task. In this paper, we proposed an adaptive test selection method, namely ATS, for deep neural networks to alleviate this problem. ATS leverages the difference between the model outputs to measure the behavior diversity of DNN test data. And it aims at selecting a subset with diverse tests from a massive unlabelled dataset. We experiment ATS with four well-designed DNN models and four widely-used datasets in comparison with various kinds of neuron coverage (NC). The results demonstrate that ATS can significantly outperform all test selection methods in assessing both fault detection and model improvement capability of test suites. It is promising to save the data labeling and model retraining costs for deep neural networks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510232","National Natural Science Foundation of China(grant numbers:62002158,61832009,61932012); Science, Technology and Innovation Commission of Shenzhen Municipality(grant numbers:CJGJZD20200617103001003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793868","deep learning testing;deep neural networks;adaptive random testing;test selection","Deep learning;Adaptation models;Adaptive systems;Computational modeling;Fault detection;Neural networks;Data models","","14","","68","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Fine-grained Commit-level Vulnerability Type Prediction by CWE Tree Structure","S. Pan; L. Bao; X. Xia; D. Lo; S. Li","College of Computer Science and Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China; Huawei, China; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","957","969","Identifying security patches via code commits to allow early warnings and timely fixes for Open Source Software (OSS) has received increasing attention. However, the existing detection methods can only identify the presence of a patch (i.e., a binary classification) but fail to pinpoint the vulnerability type. In this work, we take the first step to categorize the security patches into fine-grained vulnerability types. Specifically, we use the Common Weakness Enumeration (CWE) as the label and perform fine-grained classification using categories at the third level of the CWE tree. We first formulate the task as a Hierarchical Multi-label Classification (HMC) problem, i.e., inferring a path (a sequence of CWE nodes) from the root of the CWE tree to the node at the target depth. We then propose an approach named TreeVul with a hierarchical and chained architecture, which manages to utilize the structure information of the CWE tree as prior knowledge of the classification task. We further propose a tree structure aware and beam search based inference algorithm for retrieving the optimal path with the highest merged probability. We collect a large security patch dataset from NVD, consisting of 6,541 commits from 1,560 GitHub OSS repositories. Experimental results show that Tree-vulsignificantly outperforms the best performing baselines, with improvements of 5.9%, 25.0%, and 7.7% in terms of weighted F1-score, macro F1-score, and MCC, respectively. We further conduct a user study and a case study to verify the practical value of TreeVul in enriching the binary patch detection results and improving the data quality of NVD, respectively.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00088","National Key Research and Development Program of China(grant numbers:2021YFB2701102); National Science Foundation of China(grant numbers:U20A20173,61902344,62141222); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); National Research Foundation, Singapore; National University of Singapore(grant numbers:NSOE-TSS2020-02); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172785","Software Security;Vulnerability Type;CWE","Codes;Data integrity;Computer architecture;Inference algorithms;Classification algorithms;Security;Task analysis","","9","","74","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Compatibility Issue Detection for Android Apps Based on Path-Sensitive Semantic Analysis","S. Yang; S. Chen; L. Fan; S. Xu; Z. Hui; S. Huang","Command and Control Engineering College, Army Engineering, University of PLA, China; College of Intelligence and Computing, Tianjin University, China; College of Cyber Science, Nankai University, China; College of Cyber Science, Nankai University, China; Academy of Military Science, China; Command and Control Engineering College, Army Engineering, University of PLA, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","257","269","Android API-related compatibility issues have be-come a severe problem and significant challenge for app devel-opers due to the well-known Android fragmentation issues. To address this problem, many effective approaches such as app-based and API lifetime-based methods have been proposed to identify incompatible API usages. However, due to the various implementations of API usages and different API invoking paths, there is still a significant weakness of existing approaches, i.e., introducing a massive number of false positives (FP) and false negatives (FN). To this end, in this paper, we propose PSDroid, an automated compatibility detection approach for Android apps, which aims to reduce FPs and FNs by overcoming several technical bottlenecks. Firstly, we make substantial efforts to carry out a preliminary study to summarize a set of novel API usages with diverse checking implementations. Secondly, we construct a refined API lifetime database by leveraging a semantic resolving analysis on all existing Android SDK frameworks. Based on the above two key phases, we design and implement a novel path-sensitive semantic approach to effectively and automatically detect incompatibility issues. To demonstrate the performance, we compared with five existing approaches (i.e., FicFinder, ACRYL, CIDER, IctAPIFinder, and CID) and the results show that PSDroid outperforms existing tools. We also conducted an in-depth root cause analysis to comprehensively explain the ability of PSDroid in reducing FPs and FNs. Finally, 18/30 reported issues have been confirmed and further fixed by app developers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00033","National Natural Science Foundation of China(grant numbers:62102197,62102284,62202245); National Key Research and Development Program of China(grant numbers:2018YFB1403400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172529","Compatibility detection;Android app;Path-sensitive analysis;Semantic analysis","Root cause analysis;Databases;Semantics;Software engineering","","2","","52","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Understanding Transaction Bugs in Database Systems","Z. Cui; W. Dou; Y. Gao; D. Wang; J. Song; Y. Zheng; T. Wang; R. Yang; K. Xu; Y. Hu; J. Wei; T. Huang","State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS; Nanjing Institute of Software Technology; Sun Yat-sen University, Guangzhou, China; State Key Lab of Computer Science at ISCAS; State Key Lab of Computer Science at ISCAS",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2008","2020","Transactions are used to guarantee data consistency and integrity in Database Management Systems (DBMSs), and have become an indispensable component in DBMSs. However, faulty designs and implementations of DBMSs' transaction processing mechanisms can introduce transaction bugs, and lead to severe consequences, e.g., incorrect database states and DBMS crashes. An in-depth understanding of real-world transaction bugs can significantly promote effective techniques in combating transaction bugs in DBMSs. In this paper, we conduct the first comprehensive study on 140 transaction bugs collected from six widely-used DBMSs, i.e., MySQL, PostgreSQL, SQLite, MariaDB, CockroachDB, and TiDB. We investigate these bugs from their bug manifestations, root causes, bug impacts and bug fixing. Our study reveals many in-teresting findings and provides useful guidance for transaction bug detection, testing, and verification.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548080","Database system;transaction bug;empirical study","Computer bugs;Semantics;Database systems;Testing;Software engineering","","1","","78","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Data-Driven Loop Bound Learning for Termination Analysis","R. Xu; J. Chen; F. He","School of Software, Tsinghua University Key Laboratory for Information System Security, MoE Beijing National Research Center for Information Science and Technology, Beijing, China; School of Software, Tsinghua University Key Laboratory for Information System Security, MoE Beijing National Research Center for Information Science and Technology, Beijing, China; School of Software, Tsinghua University Key Laboratory for Information System Security, MoE Beijing National Research Center for Information Science and Technology, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","499","510","Termination is a fundamental liveness property for program verification. A loop bound is an upper bound of the number of loop iterations for a given program. The existence of a loop bound evidences the termination of the program. This paper employs a reinforced black-box learning approach for termination proving, consisting of a loop bound learner and a validation checker. We present efficient data-driven algorithms for inferring various kinds of loop bounds, including simple loop bounds, conjunctive loop bounds, and lexicographic loop bounds. We also devise an efficient validation checker by integrating a quick bound checking algorithm and a two-way data sharing mechanism. We implemented a prototype tool called ddlTerm. Experiments on publicly accessible benchmarks show that ddlTerm outperforms state-of-the-art termination analysis tools by solving 13-48% more benchmarks and saving 40-77% solving time.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510220","National Natural Science Foundation of China(grant numbers:62072267,62021002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793949","Termination analysis;loop bound;data-driven approach","Bridges;Upper bound;Prototypes;Benchmark testing;Software engineering","","1","","43","","20 Jun 2022","","","IEEE","IEEE Conferences"
"What the Fork? Finding Hidden Code Clones in npm","E. Wyss; L. De Carli; D. Davidson","University of Kansas, Lawrence, KS, USA; Worcester Polytechnic Institute, Worcester, MA, USA; University of Kansas, Lawrence, KS, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2415","2426","This work presents findings and mitigations on an under-studied issue, which we term shrinkwrapped clones, that is endemic to the npm software package ecosystem. A shrink-wrapped clone is a package which duplicates, or near-duplicates, the code of another package without any indication or refer-ence to the original package. This phenomenon represents a challenge to the hygiene of package ecosystems, as a clone package may siphon interest from the package being cloned, or create hidden duplicates of vulnerable, insecure code which can fly under the radar of audit processes. Motivated by these considerations, we propose UNWRAP-PER, a mechanism to programmatically detect shrinkwrapped clones and match them to their source package. UNWRAP-PER uses a package difference metric based on directory tree similarity, augmented with a prefilter which quickly weeds out packages unlikely to be clones of a target. Overall, our prototype can compare a given package within the entire npm ecosystem (1,716,061 packages with 20,190,452 differ-ent versions) in 72.85 seconds, and it is thus practical for live deployment. Using our tool, we performed an analysis of a subset of npm packages, which resulted in finding up to 6,292 previously unknown shrinkwrapped clones, of which up to 207 carried vulnerabilities from the original package that had already been fixed in the original package. None of such vulnerabilities were discoverable via the standard npm audit process.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794102","code clone;clone;npm","Codes;Software packages;Ecosystems;Cloning;Prototypes;Real-time systems;Security","","","","46","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"FIRA: Fine-Grained Graph-Based Code Change Representation for Automated Commit Message Generation","J. Dong; Y. Lou; Q. Zhu; Z. Sun; Z. Li; W. Zhang; D. Hao","Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Department of Computer Science, Purdue University West Lafayette, IN, USA; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE School of Computer Science, Peking University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","970","981","Commit messages summarize code changes of each commit in nat-ural language, which help developers understand code changes without digging into detailed implementations and play an essen-tial role in comprehending software evolution. To alleviate human efforts in writing commit messages, researchers have proposed var-ious automated techniques to generate commit messages, including template-based, information retrieval-based, and learning-based techniques. Although promising, previous techniques have limited effectiveness due to their coarse-grained code change representations. This work proposes a novel commit message generation technique, FIRA, which first represents code changes via fine-grained graphs and then learns to generate commit messages automati-cally. Different from previous techniques, FIRA represents the code changes with fine-grained graphs, which explicitly describe the code edit operations between the old version and the new version, and code tokens at different granularities (i.e., sub-tokens and integral tokens). Based on the graph-based representation, FIRA generates commit messages by a generation model, which includes a graph-neural-network-based encoder and a transformer-based decoder. To make both sub-tokens and integral tokens as available ingredients for commit message generation, the decoder is further incorporated with a novel dual copy mechanism. We further per-form an extensive study to evaluate the effectiveness of FIRA. Our quantitative results show that FIRA outperforms state-of-the-art techniques in terms of BLEU, ROUGE-L, and METEOR; and our ablation analysis further shows that major components in our technique both positively contribute to the effectiveness of FIRA. In addition, we further perform a human study to evaluate the quality of generated commit messages from the perspective of developers, and the results consistently show the effectiveness of FIRA over the compared techniques.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793882","Commit Message Generation;Graph Neural Network;Code Change Representation","Vocabulary;Codes;Writing;Benchmark testing;Transformers;Software;Graph neural networks","","22","","46","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Where is it? Tracing the Vulnerability-Relevant Files from Vulnerability Reports","J. Sun; J. Chen; Z. Xing; Q. Lu; X. Xu; L. Zhu","CSIRO, Sydney, NSW, Australia; CSIRO, Sydney, NSW, Australia; CSIRO & Australian National University, Canberra, ACT, Australia; CSIRO, Sydney, NSW, Australia; CSIRO, Sydney, NSW, Australia; CSIRO & Australian National University, Canberra, ACT, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2469","2481","With the widely usage of open-source software, supply-chain-based vulnerability attacks, including SolarWind and Log4Shell, have posed significant risks to software security. Currently, people rely on vulnerability advisory databases or commercial software bill of materials (SBOM) to defend against potential risks. Unfortunately, these datasets do not provide finer-grained file-level vulnerability information, compromising their effectiveness. Previous works have not adequately addressed this issue, and mainstream vulnerability detection methods have their drawbacks that hinder resolving this gap. Driven by the real needs, we propose a framework that can trace the vulnerability-relevant file for each disclosed vulnera-bility. Our approach uses NVD descriptions with metadata as the inputs, and employs a series of strategies with a LLM model, search engine, heuristic-based text matching method and a deep learning classifier to recommend the most likely vulnerability-relevant file, effectively enhancing the completeness of existing NVD data. Our experiments confirm that the efficiency of the proposed framework, with CodeBERT achieving 0.92 AUC and 0.85 MAP, and our user study proves our approach can help with vulnerability-relevant file detection effectively. To the best of our knowledge, our work is the first one focusing on tracing vulnerability-relevant files, laying the groundwork of building finer-grained vulnerability-aware software bill of materials.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548095","vulnerability-relevant file;security;software supply chain","Deep learning;Databases;Bills of materials;Supply chains;Focusing;Search engines;Metadata","","","","77","","14 Jun 2024","","","IEEE","IEEE Conferences"
"DeepState: Selecting Test Suites to Enhance the Robustness of Recurrent Neural Networks","Z. Liu; Y. Feng; Y. Yin; Z. Chen","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","598","609","Deep Neural Networks (DNN) have achieved tremendous success in various software applications. However, accompanied by outstanding effectiveness, DNN-driven software systems could also exhibit incorrect behaviors and result in some critical accidents and losses. The testing and optimization of DNN-driven software systems rely on a large number of labeled data that often require many human efforts, resulting in high test costs and low efficiency. Although plenty of coverage-based criteria have been proposed to assist in the data selection of convolutional neural networks, it is difficult to apply them on Recurrent Neural Network (RNN) models due to the difference between the working nature. In this paper, we propose a test suite selection tool DeepState towards the particular neural network structures of RNN models for reducing the data labeling and computation cost. DeepState selects data based on a stateful perspective of RNN, which identifies the possibly misclassified test by capturing the state changes of neurons in RNN models. We further design a test selection method to enable testers to obtain a test suite with strong fault detection and model improvement capability from a large dataset. To evaluate DeepState, we conduct an extensive empirical study on popular datasets and prevalent RNN models containing image and text processing tasks. The experimental results demonstrate that DeepState outperforms existing coverage-based techniques in selecting tests regarding effectiveness and the inclusiveness of bug cases. Meanwhile, we observe that the selected data can improve the robustness of RNN models effectively.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510231","National Natural Science Foundation of China(grant numbers:62002158,61832009,61932012); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794081","deep learning testing;deep neural networks;recurrent neural networks;test selection","Recurrent neural networks;Costs;Computational modeling;Computer bugs;Software systems;Data models;Robustness","","6","","66","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Measuring Secure Coding Practice and Culture: A Finger Pointing at the Moon is not the Moon","I. Ryan; U. Roedig; K. -J. Stol","ADVANCE Centre for Research Training, School of Computer Science and IT, University College Cork, Cork, Ireland; Connect Research Centre, School of Computer Science and IT, University College Cork, Cork, Ireland; Lero, the SFI Research Centre for Software, School of Computer Science and IT, University College Cork, Cork, Ireland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1622","1634","Software security research has a core problem: it is impossible to prove the security of complex software. A low number of known defects may simply indicate that the software has not been attacked yet, or that successful attacks have not been detected. A high defect count may be the result of white-hat hacker targeting, or of a successful bug bounty program which prevented insecurities from persisting in the wild. This makes it difficult to measure the security of non-trivial software. Researchers instead usually measure effort directed towards ensuring software security. However, different researchers use their own tailored measures, usually devised from industry secure coding guidelines. Not only is there no agreed way to measure effort, there is also no agreement on what effort entails. Qualitative studies emphasise the importance of security culture in an organisation. Where software security practices are introduced solely to ensure compliance with legislative or industry standards, a box-ticking attitude to security may result. The security culture may be weak or non-existent, making it likely that precautions not explicitly mentioned in the standards will be missed. Thus, researchers need both a way to assess software security practice and a way to measure software security culture. To assess security practice, we converted the empirically-established 12 most common software security activities into questions. To assess security culture, we devised a number of questions grounded in prior literature. We ran a secure development survey with both sets of questions, obtaining organic responses from 1,100 software coders in 59 countries. We used proven common activities to assess security practice, and made a first attempt to quantitatively assess aspects of security culture in the broad developer population. Our results show that some coders still work in environments where there is little to no attempt to ensure code security. Security practice and culture do not always correlate, and some organisations with strong secure coding practice have weak secure coding culture. This may lead to problems in defect prevention and sustained software security effort.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172883","Security;secure coding;security compliance","Industries;Surveys;Moon;Fingers;Software;Encoding;Time measurement","","7","","64","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Linear-time Temporal Logic guided Greybox Fuzzing","R. Meng; Z. Dong; J. Li; I. Beschastnikh; A. Roychoudhury","National University of Singapore, Singapore; Fudan University China; National University of Singapore, Singapore; University of British Columbia, Canada; National University of Singapore, Singapore",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1343","1355","Software model checking as well as runtime verification are verification techniques which are widely used for checking temporal properties of software systems. Even though they are property verification techniques, their common usage in practice is in “bug finding”, that is, finding violations of temporal properties. Motivated by this observation and leveraging the recent progress in fuzzing, we build a greybox fuzzing framework to find violations of Linear-time Temporal Logic (LTL) properties. Our framework takes as input a sequential program written in C/C++, and an LTL property. It finds violations, or counterexample traces, of the LTL property in stateful software systems; however, it does not achieve verification. Our work substantially extends directed greybox fuzzing to witness arbitrarily complex event or-derings. We note that existing directed greybox fuzzing approaches are limited to witnessing reaching a location or witnessing simple event orderings like use-after-free. At the same time, compared to model checkers, our approach finds the counterexamples faster, thereby finding more counterexamples within a given time budget. Our LTL-FUZZER tool, built on top of the AFL fuzzer, is shown to be effective in detecting bugs in well-known protocol implementations, such as OpenSSL and Telnet. We use LTL-FUZZER to reproduce known vulnerabilities (CVEs), to find 15 zero-day bugs by checking properties extracted from RFCs (for which 12 CVEs have been assigned), and to find violations of both safety as well as liveness properties in real-world protocol implementations. Our work represents a practical advance over software model checkers - while simultaneously representing a conceptual advance over existing greybox fuzzers. Our work thus provides a starting point for understanding the unexplored synergies among software model checking, runtime verification and greybox fuzzing.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794100","","Runtime;Protocols;Computer bugs;Fuzzing;Model checking;Software systems;Safety","","6","","71","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Where is Your App Frustrating Users?","Y. Wang; J. Wang; H. Zhang; X. Ming; L. Shi; Q. Wang","Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; The University of Newcastle, Callaghan, Australia; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technologies, Institute of Software Chinese Academy of Sciences, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2427","2439","User reviews of mobile apps provide a communication channel for developers to perceive user satisfaction. Many app features that users have problems with are usually expressed by key phrases such as “upload pictures”, which could be buried in the review texts. The lack of fine-grained view about problematic features could obscure the developers' understanding of where the app is frustrating users, and postpone the improvement of the apps. Existing pattern-based approaches to extract target phrases suffer from low accuracy due to insufficient semantic understanding of the reviews, thus can only summarize the high-level topics/aspects of the reviews. This paper proposes a semantic-aware, fine-grained app review analysis approach (SIRA) to extract, cluster, and visualize the problematic features of apps. The main component of SIRA is a novel BERT+Attr-CRF model for fine-grained problematic feature extraction, which combines textual descriptions and review attributes to better model the semantics of reviews and boost the performance of the traditional BERT-CRF model. SIRA also clusters the extracted phrases based on their semantic relations and presents a visualization of the summaries. Our evaluation on 3,426 reviews from six apps confirms the effectiveness of SIRA in problematic feature extraction and clustering. We further conduct an empirical study with SIRA on 318,534 reviews of 18 popular apps to explore its potential application and examine its usefulness in real-world practice.","1558-1225","978-1-4503-9221-1","","National Key Research and Development Program of China(grant numbers:2018YFB1403400); National Natural Science Foundation of China(grant numbers:62072442); Youth Innovation Promotion Association Chinese Academy of Sciences; Australian Research Council(grant numbers:DP220103044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793551","App Review;Information Extraction;Deep Learning","Codes;Clustering methods;Semantics;Communication channels;Feature extraction;Mobile applications;Data mining","","1","","67","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Efficient Online Testing for DNN-Enabled Systems using Surrogate-Assisted and Many-Objective Optimization","F. U. Haq; D. Shin; L. Briand","University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","811","822","With the recent advances of Deep Neural Networks (DNNs) in real-world applications, such as Automated Driving Systems (ADS) for self-driving cars, ensuring the reliability and safety of such DNN-enabled Systems emerges as a fundamental topic in software testing. One of the essential testing phases of such DNN-enabled systems is online testing, where the system under test is embedded into a specific and often simulated application environment (e.g., a driving environment) and tested in a closed-loop mode in interaction with the environment. However, despite the importance of online testing for detecting safety violations, automatically generating new and diverse test data that lead to safety violations presents the following challenges: (1) there can be many safety requirements to be considered at the same time, (2) running a high-fidelity simulator is often very computationally-intensive, and (3) the space of all possible test data that may trigger safety violations is too large to be exhaustively explored. In this paper, we address the challenges by proposing a novel approach, called SAMOTA (Surrogate-Assisted Many-Objective Testing Approach), extending existing many-objective search algorithms for test suite generation to efficiently utilize surrogate models that mimic the simulator, but are much less expensive to run. Empirical evaluation results on Pylot, an advanced ADS composed of multiple DNNs, using CARLA, a high-fidelity driving simulator, show that SAMOTA is significantly more effective and efficient at detecting unknown safety requirement violations than state-of-the-art many-objective test suite generation algorithms and random search. In other words, SAMOTA appears to be a key enabler technology for online testing in practice.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510188","National Research Fund(grant numbers:BRIDGES2020/IS/14711346/FUNTASY); European Research Council(grant numbers:694277); National Research Foundation of Korea(grant numbers:2019R1A6A3A03033444); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794023","DNN testing;online testing;many-objective search;surrogate-assisted optimization;self-driving cars","Software testing;Deep learning;Software algorithms;Neural networks;Safety;Software reliability;Optimization","","20","","45","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Towards Understanding Fairness and its Composition in Ensemble Machine Learning","U. Gohar; S. Biswas; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1533","1545","Machine Learning (ML) software has been widely adopted in modern society, with reported fairness implications for minority groups based on race, sex, age, etc. Many recent works have proposed methods to measure and mitigate algorithmic bias in ML models. The existing approaches focus on single classifier-based ML models. However, real-world ML models are often composed of multiple independent or dependent learners in an ensemble (e.g., Random Forest), where the fairness composes in a non-trivial way. How does fairness compose in ensembles? What are the fairness impacts of the learners on the ultimate fairness of the ensemble? Can fair learners result in an unfair ensemble? Furthermore, studies have shown that hyperparameters influence the fairness of ML models. Ensemble hyperparameters are more complex since they affect how learners are combined in different categories of ensembles. Understanding the impact of ensemble hyperparameters on fairness will help programmers design fair ensembles. Today, we do not understand these fully for different ensemble algorithms. In this paper, we comprehensively study popular real-world ensembles: Bagging, Boosting, Stacking, and Voting. We have developed a benchmark of 168 ensemble models collected from Kaggle on four popular fairness datasets. We use existing fairness metrics to understand the composition of fairness. Our results show that ensembles can be designed to be fairer without using mitigation techniques. We also identify the interplay between fairness composition and data characteristics to guide fair ensemble design. Finally, our benchmark can be leveraged for further research on fair ensembles. To the best of our knowledge, this is one of the first and largest studies on fairness composition in ensembles yet presented in the literature.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00133","US NSF(grant numbers:CCF-19-34884,CCF-22-23812,CNS-21-20448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172501","fairness;ensemble;machine learning;models","Training;Machine learning algorithms;Stacking;Software algorithms;Benchmark testing;Software;Software measurement","","11","","65","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Detecting Automatic Software Plagiarism via Token Sequence Normalization","T. Sağlam; M. Brödel; L. Schmid; S. Hahner","Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1384","1396","While software plagiarism detectors have been used for decades, the assumption that evading detection requires programming proficiency is challenged by the emergence of automated pla-giarism generators. These generators enable effortless obfus-cation attacks, exploiting vulnerabilities in existing detectors by inserting statements to disrupt the matching of related programs. Thus, we present a novel, language-independent de-fense mechanism that leverages program dependence graphs, rendering such attacks infeasible. We evaluate our approach with multiple real-world datasets and show that it defeats plagiarism generators by offering resilience against automated obfuscation while maintaining a low rate of false positives.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549395","Software Plagiarism Detection;Plagiarism Obfuscation;Ob-fuscation Attacks;Code Normalization;PDG;Tokenization","Uncertainty;Plagiarism;Scalability;Semantics;Detectors;Rendering (computer graphics);Generators","","","","55","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Large-scale Security Measurements on the Android Firmware Ecosystem","Q. Hou; W. Diao; Y. Wang; X. Liu; S. Liu; L. Ying; S. Guo; Y. Li; M. Nie; H. Duan","School of Cyber Science and Technology, Shandong University; School of Cyber Science and Technology, Shandong University; QI-ANXIN Technology Research Institute; School of Cyber Science and Technology, Shandong University; QI-ANXIN Technology Research Institute; QI-ANXIN Technology Research Institute; School of Cyber Science and Technology, Shandong University; QI-ANXIN Technology Research Institute; QI-ANXIN Technology Research Institute; Institute for Network Science and Cyberspace, Tsinghua University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1257","1268","Android is the most popular smartphone platform with over 85% market share. Its success is built on openness, and phone vendors can utilize the Android source code to make products with unique software/hardware features. On the other hand, the fragmentation and customization of Android also bring many security risks that have attracted the attention of researchers. Many efforts were put in to investigate the security of customized Android firmware. However, most of the previous work focuses on designing efficient analysis tools or analyzing particular aspects of the firmware. There still lacks a panoramic view of Android firmware ecosystem secu-rity and the corresponding understandings based on large-scale firmware datasets. In this work, we made a large-scale compre-hensive measurement of the Android firmware ecosystem security. Our study is based on 6,261 firmware images from 153 vendors and 602 Android-related CVEs, which is the largest Android firmware dataset ever used for security measurements. In particular, our study followed a series of research questions, covering vulnerabili-ties, patches, security updates, and pre-installed apps. To automate the analysis process, we designed a framework, ANDSCANNER, to complete ROM crawling, ROM parsing, patch analysis, and app analysis. Through massive data analysis and case explorations, sev-eral interesting findings are obtained. For example, the patch delay and missing issues are widespread in Android images, say 24.2% and 6.1 % of all images, respectively. The latest images of several phones still contain vulnerable pre-installed apps, and even the corresponding vulnerabilities have been publicly disclosed. In ad-dition to data measurements, we also explore the causes behind these security threats through case studies and demonstrate that the discovered security threats can be converted into exploitable vulnerabilities via 38 newfound vulnerabilities by our framework, 32 of which have been assigned CVE/CNVD numbers. This study provides much new knowledge of the Android firmware ecosystem with deep understanding of software engineering security practices.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510072","Joint Funds of the National Natural Science Foundation of China(grant numbers:U1836113); National Natural Science Foundation of China(grant numbers:62002203,92064008,61902148); Shandong Provincial Natural Science Foundation(grant numbers:ZR2020MF055,ZR2021LZH007,ZR2020LZH002,ZR2020QF045); Beijing Nova Program of Science and Technology(grant numbers:Z191100001119131); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793923","Android Firmware Ecosystem;Security Measurements;Security Patches;Pre-installed Apps","Knowledge engineering;Atmospheric measurements;Ecosystems;Particle measurements;Security;Software measurement;Smart phones","","4","","61","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Detecting Exception Handling Bugs in C++ Programs","H. Zhang; J. Luo; M. Hu; J. Yan; J. Zhang; Z. Qiu","State Key Lab. of Computer Science, Institute of Software, CAS, China, Univ. of Chinese Academy of Sciences, Beijing, China; Tech. Center of Softw. Eng., Institute of Software, CAS, China, Univ. of Chinese Academy of Sciences, Beijing, China; State Key Lab. of Computer Science, Institute of Software, CAS, China, Hangzhou Institute for Advanced Study, Univ. of Chinese Academy of Sciences, Beijing, China; State Key Lab. of Computer Science, Institute of Software, CAS, China, Univ. of Chinese Academy of Sciences, Beijing, China; State Key Lab. of Computer Science, Institute of Software, CAS, China, Univ. of Chinese Academy of Sciences, Beijing, China; School of Mathematical Sciences, Peking University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1084","1095","Exception handling is a mechanism in modern programming languages. Studies have shown that the exception handling code is error-prone. However, there is still limited research on detecting exception handling bugs, especially for C++ programs. To tackle the issue, we try to precisely represent the exception control flow in C++ programs and propose an analysis method that makes use of the control flow to detect such bugs. More specifically, we first extend control flow graph by introducing the concepts of five different kinds of basic blocks, and then modify the classic symbolic execution framework by extending the program state to a quadruple and properly processing try, throw and catch statements. Based on the above techniques, we develop a static analysis tool on the top of Clang Static Analyzer to detect exception handling bugs. We run our tool on projects with high stars from GitHub and find 36 exception handling bugs in 8 projects, with a precision of 84%. We compare our tool with four state-of-the-art static analysis tools (Cppcheck, Clang Static Analyzer, Facebook Infer and IKOS) on projects from GitHub and handmade benchmarks. On the GitHub projects, other tools are not able to detect any exception handling bugs found by our tool. On the handmade benchmarks, our tool has a significant higher recall.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00098","National Natural Science Foundation of China(grant numbers:62132020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172633","static analysis;exception handling;bug finding","Computer languages;Computer bugs;Process control;Stars;C++ languages;Static analysis;Benchmark testing","","","","43","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Supporting extract class refactoring in Eclipse: The ARIES project","G. Bavota; A. De Lucia; A. Marcus; R. Oliveto; F. Palomba","School of Science, University of Salerno, Fisciano, Salerno, Italy; School of Science, University of Salerno, Fisciano, Salerno, Italy; Computer Science Department, Wayne State University, Detroit, MI, USA; STAT Department, University of Molise, Pesche, Italy; STAT Department, University of Molise, Pesche, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1419","1422","During software evolution changes are inevitable. These changes may lead to design erosion and the introduction of inadequate design solutions, such as design antipatterns. Several empirical studies provide evidence that the presence of antipatterns is generally associated with lower productivity, greater rework, and more significant design efforts for developers. In order to improve the quality and remove antipatterns, refactoring operations are needed. In this demo, we present the Extract class features of ARIES (Automated Refactoring In EclipSe), an Eclipse plug-in that supports the software engineer in removing the “Blob” antipattern.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227233","Refactoring;Design;Quality","Software;Measurement;Couplings;Feature extraction;Clustering algorithms;Databases;Education","","18","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"An Empirical Study on Noisy Label Learning for Program Understanding","W. Wang; Y. Li; A. Li; J. Zhang; W. Ma; Y. Liu","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1159","1170","Recently, deep learning models have been widely applied in program understanding tasks, and these models achieve state-of-the-art results on many benchmark datasets. A major challenge of deep learning for program understanding is that the effectiveness of these approaches depends on the quality of their datasets, and these datasets often contain noisy data samples. A typical kind of noise in program understanding datasets is label noise, which means that the target outputs for some inputs are incorrect. Researchers have proposed various approaches to alleviate the negative impact of noisy labels, and formed a new research topic: noisy label learning (NLL). In this paper, we conduct an empirical study on the effectiveness of noisy label learning on deep learning for program understanding datasets. We evaluate various NLL approaches and deep learning models on three tasks: program classification, vulnerability detection, and code summarization. From the evaluation results, we come to the following findings: 1) small trained-from-scratch models are prone to label noises in program understanding, while large pretrained models are highly robust against them. 2) NLL approaches significantly improve the program classification accuracies for small models on noisy training sets, but they only slightly benefit large pretrained models in classification accuracies. 3) NLL can effectively detect synthetic noises in program understanding, but struggle in detecting real-world noises. We believe our findings can provide insights on the abilities of NLL in program understanding, and shed light on future works in tackling noises in software engineering datasets. We have released our code at https://github.com/jacobwwh/noise_SE.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548728","program understanding;deep learning;noisy label learning","Deep learning;Training;Codes;Accuracy;Noise;Supervised learning;Robustness","","","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Diversity-Driven Automated Formal Verification","E. First; Y. Brun","University of Massachusetts Amherst, Amherst, MA, USA; University of Massachusetts Amherst, Amherst, MA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","01","13","Formally verified correctness is one of the most desirable properties of software systems. But despite great progress made via interactive theorem provers, such as Coq, writing proof scripts for verification remains one of the most effort-intensive (and often prohibitively difficult) software development activities. Recent work has created tools that automatically synthesize proofs or proof scripts. For example, CoqHammer can prove 26.6% of theorems completely automatically by reasoning using precomputed facts, while TacTok and ASTactic, which use machine learning to model proof scripts and then perform biased search through the proof-script space, can prove 12.9% and 12.3% of the theorems, respectively. Further, these three tools are highly complementary; together, they can prove 30.4% of the theorems fully automatically. Our key insight is that control over the learning process can produce a diverse set of models, and that, due to the unique nature of proof synthesis (the existence of the theorem prover, an oracle that infallibly judges a proof's correctness), this diversity can significantly improve these tools' proving power. Accordingly, we develop Diva, which uses a diverse set of models with TacTok's and ASTactic's search mech-anism to prove 21.7% of the theorems. That is, Diva proves 68% more theorems than TacTok and 77% more than ASTactic. Complementary to CoqHammer, Diva proves 781 theorems (27% added value) that CoqHammer does not, and 364 theorems no existing tool has proved automatically. Together with CoqHammer, Diva proves 33.8% of the theorems, the largest fraction to date. We explore nine dimensions for learning diverse models, and identify which dimensions lead to the most useful diversity. Further, we develop an optimization to speed up Diva's execution by 40×. Our study introduces a completely new idea for using diversity in machine learning to improve the power of state-of-the-art proof-script synthesis techniques, and empirically demonstrates that the improvement is significant on a dataset of 68K theorems from 122 open-source software projects.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510138","National Science Foundation(grant numbers:CCF-1763423); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793984","Automated formal verification;language models;Coq;interactive proof assistants;proof synthesis","Process control;Machine learning;Writing;Aerospace electronics;Software systems;Cognition;Optimization","","5","","91","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automated Handling of Anaphoric Ambiguity in Requirements: A Multi-solution Study","S. Ezzini; S. Abualhaija; C. Arora; M. Sabetzadeh","University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; Deakin University, Australia; University of Ottawa, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","187","199","Ambiguity is a pervasive issue in natural-language requirements. A common source of ambiguity in requirements is when a pronoun is anaphoric. In requirements engineering, anaphoric ambiguity occurs when a pronoun can plausibly refer to different entities and thus be interpreted differently by different readers. In this paper, we develop an accurate and practical automated approach for handling anaphoric ambiguity in requirements, addressing both ambiguity detection and anaphora interpretation. In view of the multiple competing natural language processing (NLP) and machine learning (ML) technologies that one can utilize, we simultaneously pursue six alternative solutions, empirically assessing each using a col-lection of ≈1,350 industrial requirements. The alternative solution strategies that we consider are natural choices induced by the existing technologies; these choices frequently arise in other automation tasks involving natural-language requirements. A side-by-side em-pirical examination of these choices helps develop insights about the usefulness of different state-of-the-art NLP and ML technologies for addressing requirements engineering problems. For the ambigu-ity detection task, we observe that supervised ML outperforms both a large-scale language model, SpanBERT (a variant of BERT), as well as a solution assembled from off-the-shelf NLP coreference re-solvers. In contrast, for anaphora interpretation, SpanBERT yields the most accurate solution. In our evaluation, (1) the best solution for anaphoric ambiguity detection has an average precision of ≈60% and a recall of 100%, and (2) the best solution for anaphora interpretation (resolution) has an average success rate of ≈98%.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793957","Requirements Engineering;Natural-language Requirements;Ambiguity;Natural Language Processing (NLP);Machine Learning (ML);Language Models;BERT","Solution design;Automation;Bit error rate;Semantics;Machine learning;Natural language processing;Requirements engineering","","10","","95","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Does data sampling improve deep learning-based vulnerability detection? Yeas! and Nays!","X. Yang; S. Wang; Y. Li; S. Wang","University of Manitoba, Canada; University of Manitoba, Canada; New Jersey Institute of Technology, USA; New Jersey Institute of Technology, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2287","2298","Recent progress in Deep Learning (DL) has sparked interest in using DL to detect software vulnerabilities automatically and it has been demonstrated promising results at detecting vulnerabilities. However, one prominent and practical issue for vulnerability detection is data imbalance. Prior study observed that the performance of state-of-the-art (SOTA) DL-based vulnerability detection (DLVD) approaches drops precipitously in real world imbalanced data and a 73% drop of F1-score on average across studied approaches. Such a significant performance drop can disable the practical usage of any DLVD approaches. Data sampling is effective in alleviating data imbalance for machine learning models and has been demonstrated in various software engineering tasks. Therefore, in this study, we conducted a systematical and extensive study to assess the impact of data sampling for data imbalance problem in DLVD from two aspects: i) the effectiveness of DLVD, and ii) the ability of DLVD to reason correctly (making a decision based on real vulnerable statements). We found that in general, oversampling outperforms undersampling, and sampling on raw data outperforms sampling on latent space, typically random oversampling on raw data performs the best among all studied ones (including advanced one SMOTE and OSS). Surprisingly, OSS does not help alleviate the data imbalance issue in DLVD. If the recall is pursued, random undersampling is the best choice. Random oversampling on raw data also improves the ability of DLVD approaches for learning real vulnerable patterns. However, for a significant portion of cases (at least 33% in our datasets), DVLD approach cannot reason their prediction based on real vulnerable statements. We provide actionable suggestions and a roadmap to practitioners and researchers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172668","Vulnerability detection;deep learning;data sampling;interpretable AI","Deep learning;Systematics;Software;Data models;Task analysis;Software engineering","","1","","57","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"VGX: Large-Scale Sample Generation for Boosting Learning-Based Software Vulnerability Analyses","Y. Nong; R. Fang; G. Yi; K. Zhao; X. Luo; F. Chen; H. Cai",Washington State University; Washington State University; Washington State University; Hong Kong Polytechnic University; Hong Kong Polytechnic University; The University of Texas at Dallas; Washington State University,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1837","1849","Accompanying the successes of learning-based defensive software vulnerability analyses is the lack of large and quality sets of labeled vulnerable program samples, which impedes further advancement of those defenses. Existing automated sample generation approaches have shown potentials yet still fall short of practical expectations due to the high noise in the generated samples. This paper proposes VGX, a new technique aimed for large-scale generation of high-quality vulnerability datasets. Given a normal program, VGX identifies the code contexts in which vulnerabilities can be injected, using a customized Transformer featured with a new value-flow-based position encoding and pretrained against new objectives particularly for learning code structure and context. Then, VGX materializes vulnerability-injection code editing in the identified contexts using patterns of such edits obtained from both historical fixes and human knowledge about real-world vulnerabilities. Compared to four state-of-the-art (SOTA) (i.e., pattern-, Transformer-, GNN-, and pattern+Transformer-based) baselines, VGX achieved 99.09-890.06% higher F1 and 22.45%-328.47% higher label accuracy. For in-the-wild sample production, VGX generated 150,392 vulnerable samples, from which we randomly chose 10% to assess how much these samples help vulnerability detection, localization, and repair. Our results show SOTA techniques for these three application tasks achieved 19.15-330.80% higher F1, 12.86-19.31% higher top-10 accuracy, and 85.02-99.30% higher top-50 accuracy, respectively, by adding those samples to their original training data. These samples also helped a SOTA vulnerability detector discover 13 more real-world vulnerabilities (CVEs) in critical systems (e.g., Linux kernel) that would be missed by the original model.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548471","vulnerability dataset;vulnerability injection;data quality;vulnerability analysis;deep learning;program generation","Location awareness;Codes;Training data;Production;Maintenance engineering;Transformers;Software","","","","72","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Fuzz4ALL: Universal Fuzzing with Large Language Models","C. S. Xia; M. Paltenghi; J. L. Tian; M. Pradel; L. Zhang","University of Illinois, Urbana-Champaign, USA; University of Stuttgart, Germany; University of Illinois, Urbana-Champaign, USA; University of Stuttgart, Germany; University of Illinois, Urbana-Champaign, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1547","1559","Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4ALL, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4ALL is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are well- suited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4ALL on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java, and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4ALL has identified 98 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 64 bugs already confirmed by developers as previously unknown.","1558-1225","979-8-4007-0217-4","","National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); European Research Council(grant numbers:851895); German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548154","fuzzing;large language models;software engineering","Software libraries;Runtime;Quantum computing;Program processors;Computer bugs;Fuzzing;Programming","","1","","88","","14 Jun 2024","","","IEEE","IEEE Conferences"
"CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pretrained Models","H. Yu; B. Shen; D. Ran; J. Zhang; Q. Zhang; Y. Ma; G. Liang; Y. Li; Q. Wang; T. Xie","School of Software and Microelectronics, Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Key Lab of HCST (PKU) MOE, SCS Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Huawei Cloud Computing Technologies Co., Ltd., China; Huawei Cloud Computing Technologies Co., Ltd., China; Huawei Cloud Computing Technologies Co., Ltd., China; School of Software and Microelectronics, Peking University, China; Huawei Cloud Computing Technologies Co., Ltd., China; Key Lab of HCST (PKU) MOE, SCS Peking University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","428","439","Code generation models based on the pretraining and fine-tuning paradigm have been increasingly attempted by both academia and industry, resulting in well-known industrial models such as Codex, CodeGen, and PanGu-Coder. To evaluate the effectiveness of these models, multiple existing benchmarks (e.g., HumanEval and AiXBench) are proposed, including only cases of generating a standalone function, i.e., a function that may invoke or access only built-in functions and standard libraries. However, non-standalone functions, which typically are not included in the existing benchmarks, constitute more than 70% of the functions in popular open-source projects, and evaluating models' effectiveness on standalone functions cannot reflect these models' effectiveness on pragmatic code generation scenarios (i.e., code generation for real settings of open source or proprietary code). To help bridge the preceding gap, in this paper, we propose a benchmark named CoderEval, consisting of 230 Python and 230 Java code generation problems carefully curated from popular real-world open-source projects and a self-contained execution platform to automatically assess the functional correctness of generated code. CoderEval supports code generation problems from six levels of context dependency, where context refers to code elements such as types, APIs, variables, and consts defined outside the target function but within the dependent third-party libraries, current class, file, or project. CoderEval can be used to evaluate the effectiveness of models in generating code beyond only standalone functions. By evaluating three state-of-the-art code generation models (Code-Gen, PanGu-Coder, and ChatGPT) on CoderEval and HumanEval, we find that the effectiveness of these models in generating stan-dalone functions is substantially higher than that in generating non-standalone functions. Our analysis highlights the current progress and pinpoints future directions to further improve a model's effectiveness by leveraging contextual information for pragmatic code generation.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623322","National Key Research and Development Program(grant numbers:2021YFF0704202); National Natural Science Foundation of China(grant numbers:62161146003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548523","Code Generation;Large Language Models;Benchmark","Industries;Codes;Benchmark testing;Chatbots;Libraries;Standards;Pragmatics","","","","30","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automatically finding performance problems with feedback-directed learning software testing","M. Grechanik; C. Fu; Q. Xie","Accenture Technology Lab, University of Illinois, Chicago, Chicago, IL, USA; Accenture Technology Laboratory, Chicago, IL, USA; Accenture Technology Laboratory, Chicago, IL, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","156","166","A goal of performance testing is to find situations when applications unexpectedly exhibit worsened characteristics for certain combinations of input values. A fundamental question of performance testing is how to select a manageable subset of the input data faster to find performance problems in applications automatically. We offer a novel solution for finding performance problems in applications automatically using black-box software testing. Our solution is an adaptive, feedback-directed learning testing system that learns rules from execution traces of applications and then uses these rules to select test input data automatically for these applications to find more performance problems when compared with exploratory random testing. We have implemented our solution and applied it to a medium-size application at a major insurance company and to an open-source application. Performance problems were found automatically and confirmed by experienced testers and developers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227197","","Insurance;Matrix decomposition;Databases;Software testing;Graphical user interfaces;Companies","","56","","35","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Supporting sustainability with software — An industrial perspective (Keynote)","F. -D. Clesle","SAP AG, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","962","962","Summary form only given. TechnoAware research and develops technologies and solutions for ambient intelligence. Established in 2003 TechnoAware was born from the experiences and competencies of the ISIP40 research group of the University of Genova. This research group is studying and implementing video analytics algorithms since 1985 and is considered nowadays one of the major actors in this filed worldwide. Entirely made up by researchers and experts in the video analytics field, TechnoAware main principles are: proprietary technologies (highly customizable and modular solutions), scientific competencies (high quality level and performances), continuous research and technological innovation (cutting edge products).","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227254","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CCTEST: Testing and Repairing Code Completion Systems","Z. Li; C. Wang; Z. Liu; H. Wang; D. Chen; S. Wang; C. Gao","The Hong Kong University of Science and Technology, Hong Kong SAR; Harbin Institute of Technology, Shenzhen, China; The Hong Kong University of Science and Technology, Hong Kong SAR; Swiss Federal Institute of Technology Lausanne, Switzerland; The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; Harbin Institute of Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1238","1250","Code completion, a highly valuable topic in the software development domain, has been increasingly promoted for use by recent advances in large language models (LLMs). To date, visible LLM-based code completion frameworks such as GitHub Copilot and GPT are trained using deep learning over vast quantities of unstructured text and open source code. As the paramount component and the cornerstone in daily programming tasks, code completion has largely boosted professionals' efficiency in building real-world software systems. In contrast to this flourishing market, we find that code completion systems often output suspicious results, and to date, an automated testing and enhancement framework for code completion systems is not available. This research proposes CCTEST, a framework to test and repair code completion systems in black-box settings. CCTEST features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs. Then, it detects inconsistent outputs, representing possibly erroneous cases, from all the completed code cases. Moreover, CCTEST repairs the code completion outputs by selecting the output that mostly reflects the “average” appearance of all output cases, as the final output of the code completion systems. With around 18K test inputs, we detected 33,540 inputs that can trigger erroneous cases (with a true positive rate of 86%) from eight popular LLM-based code completion systems. With repairing, we show that the accuracy of code completion systems is notably increased by 40% and 67% with respect to BLEU score and Levenshtein edit similarity.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172845","","Deep learning;Codes;Source coding;Closed box;Maintenance engineering;Task analysis;Programming profession","","12","","94","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Retrieving Data Constraint Implementations Using Fine-Grained Code Patterns","J. M. Florez; J. Perry; S. Wei; A. Marcus","The University of Texas at Dallas, Richardson, Texas, USA; The University of Texas at Dallas, Richardson, Texas, USA; The University of Texas at Dallas, Richardson, Texas, USA; The University of Texas at Dallas, Richardson, Texas, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1893","1905","Business rules are an important part of the requirements of software systems that are meant to support an organization. These rules describe the operations, definitions, and constraints that apply to the organization. Within the software system, business rules are often translated into constraints on the values that are required or allowed for data, called data constraints. Business rules are subject to frequent changes, which in turn require changes to the corre-sponding data constraints in the software. The ability to efficiently and precisely identify where data constraints are implemented in the source code is essential for performing such necessary changes. In this paper, we introduce Lasso, the first technique that automatically retrieves the method and line of code where a given data constraint is enforced. Lasso is based on traceability link recovery approaches and leverages results from recent research that identified line-of-code level implementation patterns for data constraints. We implement three versions of Lasso that can retrieve data constraint implementations when they are implemented with any one of 13 frequently occurring patterns. We evaluate the three versions on a set of 299 data constraints from 15 real-world Java systems, and find that they improve method-level link recovery by 30%,70%, and 163%, in terms of true positives within the first 10 results, compared to their text-retrieval-based baseline. More importantly, the Lasso variants correctly identify the line of code implementing the constraint inside the methods for 68% of the 299 constraints.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510167","US National Science Foundation(grant numbers:CCF-1955837,CCF-1910976); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793956","business rule;data constraint;traceability link recovery;empirical study;fine-grained traceability;code pattern","Java;Codes;Organizations;Software systems;Pattern matching;Software engineering","","2","","70","","20 Jun 2022","","","IEEE","IEEE Conferences"
"A Scalable t-wise Coverage Estimator","E. Baranov; S. Chakraborty; A. Legay; K. S. Meel; V. N. Variyam","Universite catholique de Louvain, Belgium; Indian Statistical Institute, India; Universite catholique de Louvain, Belgium; National University of Singapore, Singapore; University of Nebraska-Lincoln, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","36","47","Owing to the pervasiveness of software in our modern lives, software systems have evolved to be highly configurable. Combinatorial testing has emerged as a dominant paradigm for testing highly configurable systems. Often constraints are employed to define the environments where a given system under test (SUT) is expected to work. Therefore, there has been a sustained interest in designing constraint-based test suite generation techniques. A significant goal of test suite generation techniques is to achieve $t$-wise coverage for higher values of $t$. Therefore, designing scalable techniques that can estimate $t$-wise coverage for a given set of tests and/or the estimation of maximum achievable $t$-wise coverage under a given set of constraints is of crucial importance. The existing estimation techniques face significant scalability hurdles. The primary scientific contribution of this work is the design of scalable algorithms with mathematical guarantees to estimate (i) $t$-wise coverage for a given set of tests, and (ii) maximum $t$-wise coverage for a given set of constraints. In particular, we design a scalable framework ApproxCov that takes in a test set $\mathcal{U}$, a coverage parameter $t$, a tolerance parameter $\varepsilon$, and a confidence parameter $\delta$, and returns an estimate of the t-wise coverage of $\mathcal{U}$ that is guaranteed to be within ($1\pm \varepsilon$) -factor of the ground truth with probability at least $1-\delta$. We design a scalable framework ApproxMaxCov that, for a given formula $\mathsf{F}$, a coverage parameter $t$, a tolerance parameter $\varepsilon$, and a confidence parameter $\delta$, outputs an approximation which is guaranteed to be within ($1\pm\varepsilon$) factor of the maximum achievable $t$-wise coverage under $\mathsf{F}$, with probability $\geq 1-\delta$. Our comprehensive evaluation demonstrates that ApproxCov and ApproxMaxCov can handle benchmarks that are beyond the reach of current state-of-the-art approaches. We believe that the availability of ApproxCov and ApproxMaxCov will enable test suite designers to evaluate the effectiveness of their generators and thereby significantly impact the development of combinatorial testing techniques.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510218","H2020(grant numbers:826278-SERUMS-H2020-SCI-FA-DTS-2018-2020); National Science Foundation(grant numbers:TRIPODS-1934884); National Research Foundation Singapore(grant numbers:NRF-NRFFAI1-2019-0004); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794022","Configurable software;$t$-wise coverage;Approximation","Monte Carlo methods;Combinatorial testing;Scalability;Estimation;Benchmark testing;Software systems;Generators","","1","","68","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Data-driven Recurrent Set Learning For Non-termination Analysis","Z. Han; F. He","Key Laboratory for Information System Security, MoE Beijing National Research Center for Information Science and Technology, School of Software, Tsinghua University, Beijing, China; Key Laboratory for Information System Security, MoE Beijing National Research Center for Information Science and Technology, School of Software, Tsinghua University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1303","1315","Termination is a fundamental liveness property for program verification. In this paper, we revisit the problem of non-termination analysis and propose the first data-driven learning algorithm for synthesizing recurrent sets, where the non-terminating samples are effectively speculated by a novel method. To ensure convergence of learning, we develop a learning algorithm which is guaranteed to converge to a valid recurrent set if one exists, and thus establish its relative completeness. The methods are implemented in a prototype tool, and experimental results on public benchmarks show its efficacy in proving non-termination as it outperforms state-of-the-art tools, both in terms of cases solved and performance. Evaluation on non-linear programs also demonstrates its ability to handle complex programs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172827","program termination;recurrent set;data-driven approach;black-box learning","Closed box;Prototypes;Benchmark testing;Decision trees;Convergence;Software engineering","","","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Rogueone: Detecting Rogue Updates via Differential Data-Flow Analysis Using Trust Domains","R. J. Sofaer; Y. David; M. Kang; J. Yu; Y. Cao; J. Yang; J. Nieh","Columbia University New York, NY, USA; Columbia University New York, NY, USA; Johns Hopkins University Baltimore, MD, USA; Johns Hopkins University Baltimore, MD, USA; Johns Hopkins University Baltimore, MD, USA; Columbia University New York, NY, USA; Columbia University New York, NY, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1235","1247","Rogue updates, an important type of software supply-chain attack in which attackers conceal malicious code inside updates to benign software, are a growing problem due to their stealth and effective-ness. We design and implement Rogueone, a system for detecting rogue updates to JavaScript packages. Rogueone uses a novel dif-ferential data-flow analysis to capture how an update changes a package's interactions with external APIs. Using an efficient form of abstract interpretation that can exclude unchanged code in a pack-age, it constructs an object data-flow relationship graph (ODRG) that tracks data-flows among objects. Rogueone then maps objects to trust domains, a novel abstraction which summarizes trust relationships in a package. Objects are assigned a trust domain based on whether they originate in the target package, a dependency, or in a system API. Rogueone uses the ODRG to build a set of data-flows across trust domains. It compares data-flow sets across package versions to detect untrustworthy new interactions with external APIs. We evaluated Rogueone on hundreds of npm pack-ages, demonstrating its effectiveness at detecting rogue updates and distinguishing them from benign ones. Rogueone achieves high accuracy and can be more than seven times as effective in detecting rogue updates and avoiding false positives compared to other systems built to detect malicious packages.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639199","NSF(grant numbers:CNS-2046361,CNS-2052947,CNS-2154404,CNS-2247370,CCF-2124080); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548976","JavaScript;Malicious updates;Malware detection;Node.js;Supply-chain security","Target tracking;Codes;Accuracy;Malware;Security;Software engineering","","","","77","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Explanation-Guided Fairness Testing through Genetic Algorithm","M. Fan; W. Wei; W. Jin; Z. Yang; T. Liu","Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","871","882","The fairness characteristic is a critical attribute of trusted AI systems. A plethora of research has proposed diverse methods for individual fairness testing. However, they are suffering from three major limitations, i.e., low efficiency, low effectiveness, and model-specificity. This work proposes ExpGA, an explanation-guided fairness testing approach through a genetic algorithm (GA). ExpGA employs the explanation results generated by interpretable methods to collect high-quality initial seeds, which are prone to derive discriminatory samples by slightly modifying feature values. ExpGA then adopts GA to search discriminatory sample candidates by optimizing a fitness value. Benefiting from this combination of explanation results and GA, ExpGA is both efficient and effective to detect discriminatory individuals. Moreover, ExpGA only requires prediction probabilities of the tested model, resulting in a better generalization capability to various models. Experiments on multiple real-world benchmarks, including tabular and text datasets, show that ExpGA presents higher efficiency and effectiveness than four state-of-the-art approaches.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510137","National Key R&D Program of China(grant numbers:2018YFB1004500); National Natural Science Foundation of China(grant numbers:61902306,62002280,61632015,61602369,U1766215,61772408,61702414,61833015); China Postdoctoral Science Foundation(grant numbers:2019TQ0251,2020M673439,2020M683507); Innovative Re-search Group of the National Natural Science Foundation of China(grant numbers:61721002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793975","Explanation result;fairness testing;genetic algorithm","Software algorithms;Predictive models;Benchmark testing;Software;Artificial intelligence;Genetic algorithms;Software engineering","","6","","43","","20 Jun 2022","","","IEEE","IEEE Conferences"
"UniLog: Automatic Logging via LLM and In-Context Learning","J. Xu; Z. Cui; Y. Zhao; X. Zhang; S. He; P. He; L. Li; Y. Kang; Q. Lin; Y. Dang; S. Rajmohan; D. Zhang","School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Southeast University, Nanjing, China; Peking University, Beijing, China; Microsoft, Beijing, China; Microsoft, Beijing, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Microsoft, Beijing, China; Microsoft, Beijing, China; Microsoft, Beijing, China; Microsoft, Redmond, USA; Microsoft, Redmond, USA; Microsoft, Redmond, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1","12","Logging, which aims to determine the position of logging statements, the verbosity levels, and the log messages, is a crucial process for software reliability enhancement. In recent years, numerous automatic logging tools have been designed to assist developers in one of the logging tasks (e.g., providing suggestions on whether to log in try-catch blocks). These tools are useful in certain situations yet cannot provide a comprehensive logging solution in general. Moreover, although recent research has started to explore end-to-end logging, it is still largely constrained by the high cost of fine-tuning, hindering its practical usefulness in software development. To address these problems, this paper proposes UniLog, an automatic logging framework based on the in-context learning (ICL) paradigm of large language models (LLMs). Specifically, UniLog can generate an appropriate logging statement with only a prompt containing five demonstration examples without any model tuning. In addition, UniLog can further enhance its logging ability after warmup with only a few hundred random samples. We evaluated UniLog on a large dataset containing 12,012 code snippets extracted from 1,465 GitHub repositories. The results show that UniLog achieved the state-of-the-art performance in automatic logging: (1) 76.9% accuracy in selecting logging positions, (2) 72.3% accuracy in predicting verbosity levels, and (3) 27.1 BLEU-4 score in generating log messages. Meanwhile, UniLog requires less than 4% of the parameter tuning time needed by fine-tuning the same LLM.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623326","National Natural Science Foundation of China(grant numbers:62102340); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549201","Logging;Large Language Model;In-Context Learning","Analytical models;Codes;Costs;Software reliability;Task analysis;Tuning;Software development management","","2","","56","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Bug prediction based on fine-grained module histories","H. Hata; O. Mizuno; T. Kikuno","Osaka University, Osaka, Japan; Kyoto Institute of Technology, Kyoto, Japan; Osaka University, Osaka, Japan",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","200","210","There have been many bug prediction models built with historical metrics, which are mined from version histories of software modules. Many studies have reported the effectiveness of these historical metrics. For prediction levels, most studies have targeted package and file levels. Prediction on a fine-grained level, which represents the method level, is required because there may be interesting results compared to coarse-grained (package and file levels) prediction. These results include good performance when considering quality assurance efforts, and new findings about the correlations between bugs and histories. However, fine-grained prediction has been a challenge because obtaining method histories from existing version control systems is a difficult problem. To tackle this problem, we have developed a fine-grained version control system for Java, Historage. With this system, we target Java software and conduct fine-grained prediction with well-known historical metrics. The results indicate that fine-grained (method-level) prediction outperforms coarse-grained (package and file levels) prediction when taking the efforts necessary to find bugs into account. Using a correlation analysis, we show that past bug information does not contribute to method-level bug prediction.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227193","bug prediction;fine-grained prediction;finegrained histories;historical metrics;effort-based evaluation","Measurement;History;Predictive models;Computer bugs;Software;Java;Complexity theory","","92","","47","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Log Parsing with Prompt-based Few-shot Learning","V. -H. Le; H. Zhang","School of Information and Physical Sciences, The University of Newcastle, Australia; School of Big Data and Software Engineering, Chongqing University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2438","2449","Logs generated by large-scale software systems provide crucial information for engineers to understand the system status and diagnose problems of the systems. Log parsing, which converts raw log messages into structured data, is the first step to enabling automated log analytics. Existing log parsers extract the common part as log templates using statistical features. However, these log parsers often fail to identify the correct templates and parameters because: 1) they often overlook the semantic meaning of log messages, and 2) they require domain-specific knowledge for different log datasets. To address the limitations of existing methods, in this paper, we propose LogPPT to capture the patterns of templates using prompt-based few-shot learning. LogPPT utilises a novel prompt tuning method to recognise keywords and parameters based on a few labelled log data. In addition, an adaptive random sampling algorithm is designed to select a small yet diverse training set. We have conducted extensive experiments on 16 public log datasets. The experimental results show that LogPPT is effective and efficient for log parsing.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00204","Australian Research Council(grant numbers:DP200102940,DP220103044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172786","log parsing;few-shot learning;prompt-tuning;deep learning","Training;Scalability;Software algorithms;Semantics;Production;Feature extraction;Software systems","","24","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Code Search based on Context-aware Code Translation","W. Sun; C. Fang; Y. Chen; G. Tao; T. Han; Q. Zhang","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; Purdue University, West Lafayette, Indiana, USA; School of Information Management, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","388","400","Code search is a widely used technique by developers during software development. It provides semantically similar implementations from a large code corpus to developers based on their queries. Existing techniques leverage deep learning models to construct embedding representations for code snippets and queries, respectively. Features such as abstract syntactic trees, control flow graphs, etc., are commonly employed for representing the semantics of code snippets. However, the same structure of these features does not necessarily denote the same semantics of code snippets, and vice versa. In addition, these techniques utilize multiple different word mapping functions that map query words/code tokens to embedding representations. This causes diverged embeddings of the same word/token in queries and code snippets. We propose a novel context-aware code translation technique that translates code snippets into natural language descriptions (called translations). The code translation is conducted on machine instructions, where the context information is collected by simulating the execution of instructions. We further design a shared word mapping function using one single vocabulary for generating embeddings for both translations and queries. We evaluate the effectiveness of our technique, called TranCS, on the CodeSearchNet corpus with 1,000 queries. Experimental results show that TranCS significantly outperforms state-of-the-art techniques by 49.31% to 66.50% in terms of MRR (mean reciprocal rank).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510140","National Natural Science Foundation of China(grant numbers:61690201,62141215); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794095","code search;deep learning;code translation","Deep learning;Vocabulary;Codes;Semantics;Natural languages;Syntactics;Software","","8","","68","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Adaptive Performance Anomaly Detection for Online Service Systems via Pattern Sketching","Z. Chen; J. Liu; Y. Su; H. Zhang; X. Ling; M. R. Lyu","The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; The University of Newcastle, NSW, Australia; Yongqiang Yang Huawei Cloud BU, Beijing, China; The Chinese University of Hong Kong, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","61","72","To ensure the performance of online service systems, their status is closely monitored with various software and system metrics. Performance anomalies represent the performance degradation issues (e.g., slow response) of the service systems. When performing anomaly detection over the metrics, existing methods often lack the merit of interpretability, which is vital for engineers and analysts to take remediation actions. Moreover, they are unable to effectively accommodate the ever-changing services in an online fashion. To address these limitations, in this paper, we propose ADSketch, an interpretable and adaptive performance anomaly detection approach based on pattern sketching. ADSketch achieves interpretability by identifying groups of anomalous metric patterns, which represent particular types of performance issues. The underlying issues can then be immediately recognized if similar patterns emerge again. In addition, an adaptive learning algorithm is designed to embrace unprecedented patterns induced by service updates or user behavior changes. The proposed approach is evaluated with public data as well as industrial data collected from a representative online service system in Huawei Cloud. The experimental results show that ADSketch outperforms state-of-the-art approaches by a significant margin, and demonstrate the effectiveness of the online algorithm in new pattern discovery. Furthermore, our approach has been successfully deployed in industrial practice.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510085","Australian Research Council (ARC)(grant numbers:DP200102940,DP220103044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794065","Cloud computing;performance anomaly detection;online learning","Measurement;Adaptive learning;Adaptation models;Time series analysis;Software algorithms;Production;Software","","7","","39","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Using Reinforcement Learning for Load Testing of Video Games","R. Tufano; S. Scalabrino; L. Pascarella; E. Aghajani; R. Oliveto; G. Bavota","SEART @ Software Institute, Università della Svizzera italiana, Switzerland; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2303","2314","Different from what happens for most types of software systems, testing video games has largely remained a manual activity per-formed by human testers. This is mostly due to the continuous and intelligent user interaction video games require. Recently, rein-forcement learning (RL) has been exploited to partially automate functional testing. RL enables training smart agents that can even achieve super-human performance in playing games, thus being suitable to explore them looking for bugs. We investigate the pos-sibility of using RL for load testing video games. Indeed, the goal of game testing is not only to identify functional bugs, but also to examine the game's performance, such as its ability to avoid lags and keep a minimum number of frames per second (FPS) when high-demanding 3D scenes are shown on screen. We define a method-ology employing RL to train an agent able to play the game as a human while also trying to identify areas of the game resulting in a drop of FPS. We demonstrate the feasibility of our approach on three games. Two of them are used as proof-of-concept, by injecting artificial performance bugs. The third one is an open-source 3D game that we load test using the trained agent showing its potential to identify areas of the game resulting in lower FPS.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510625","European Research Council (ERC)(grant numbers:851720); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793989","Reinforcement Learning;Load Testing","Training;Three-dimensional displays;Computer bugs;Games;Reinforcement learning;Manuals;Software systems","","7","","51","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Stack layout transformation: Towards diversity for securing binary programs","B. Rodes","Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1543","1546","Despite protracted efforts by both researchers and practitioners, security vulnerabilities remain in modern software. Artificial diversity is an effective defense against many types of attack, and one form, address-space randomization, has been widely applied. Present artificial diversity implementations are either coarse-grained or require source code. Because of the widespread use of software of unknown provenance, e.g., libraries, where no source code is provided or available, building diversity into the source code is not always possible. I investigate an approach to stack layout transformation that operates on x86 binary programs, which would allow users to obfuscate vulnerabilities and increase their confidence in the software's dependability. The proposed approach is speculative: the stack frame layout for a function is inferred from the binary and assessed by executing the transformed program. Upon assessment failure, the inferred layout is refined in hopes to better reflect the actual function layout.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227041","security;artificial diversity;stack frame layout;address randomization;binary programs","Layout;Software;Security;Transforms;Measurement;Benchmark testing","","4","","15","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Static Stack-Preserving Intra-Procedural Slicing of WebAssembly Binaries","Q. Stiévenart; D. W. Binkley; C. De Roover","Vrije Universiteit Brussel, Brussels, Belgium; Loyola University Maryland, Baltimore, MD, USA; Vrije Universiteit Brussel, Brussels, Belgium",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2031","2042","The recently introduced WebAssembly standard aims to be a portable compilation target, enabling the cross-platform distribution of pro-grams written in a variety of languages. We propose an approach to slice WebAssembly programs in order to enable applications in reverse engineering, code comprehension, and security among others. Given a program and a location in that program, program slicing produces a minimal version of the program that preserves the behavior at the given location. Specifically, our approach is a static, intra-procedural, backward slicing approach that takes into account WebAssembly-specific dependences to identify the instructions of the slice. To do so it must correctly overcome the considerable challenges of performing dependence analysis at the bi-nary level. Furthermore, for the slice to be executable, the approach needs to ensure that the stack behavior of its output complies with WebAssembly's validation requirements. We implemented and eval-uated our approach on a suite of 8 386 real-world WebAssembly binaries, finding that the average size of the 495 204 868 slices computed is 53% of the original code, an improvement over the 60% attained by related work slicing ARM binaries. To gain a more qual-itative understanding of the slices produced by our approach, we compared them to 1 956 source-level slices of benchmark C pro-grams. This inspection helps to illustrate the slicer's strengths and to uncover potential future improvements.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793936","Static program slicing;WebAssembly;Binary analysis","Codes;Reverse engineering;Inspection;Benchmark testing;Behavioral sciences;Security;Standards","","7","","69","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Detecting similar software applications","C. McMillan; M. Grechanik; D. Poshyvanyk","College of William and Mary, Williamsburg, VA, USA; Accenture Technology Laboratories, University of Illinois, Chicago, IL, USA; College of William and Mary, Williamsburg, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","364","374","Although popular text search engines allow users to retrieve similar web pages, source code search engines do not have this feature. Detecting similar applications is a notoriously difficult problem, since it implies that similar highlevel requirements and their low-level implementations can be detected and matched automatically for different applications. We created a novel approach for automatically detecting Closely reLated ApplicatioNs (CLAN) that helps users detect similar applications for a given Java application. Our main contributions are an extension to a framework of relevance and a novel algorithm that computes a similarity index between Java applications using the notion of semantic layers that correspond to packages and class hierarchies. We have built CLAN and we conducted an experiment with 33 participants to evaluate CLAN and compare it with the closest competitive approach, MUDABlue. The results show with strong statistical significance that CLAN automatically detects similar applications from a large repository of 8,310 Java applications with a higher precision than MUDABlue.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227178","","Semantics;Java;Software;Search engines;Large scale integration;Time division multiplexing;Vectors","","81","","50","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Practical Automated Detection of Malicious npm Packages","A. Sejfia; M. Schäfer","University of Southern California, Los Angeles, USA; GitHub, Oxford, UK",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1681","1692","The npm registry is one of the pillars of the JavaScript and Type-Script ecosystems, hosting over 1.7 million packages ranging from simple utility libraries to complex frameworks and entire applications. Each day, developers publish tens of thousands of updates as well as hundreds of new packages. Due to the overwhelming popularity of npm, it has become a prime target for malicious actors, who publish new packages or compromise existing packages to introduce malware that tampers with or exfiltrates sensitive data from users who install either these packages or any package that (transitively) depends on them. Defending against such attacks is essential to maintaining the integrity of the software supply chain, but the sheer volume of package updates makes comprehensive manual review infeasible. We present Amalfi, a machine-learning based approach for automatically detecting potentially malicious packages comprised of three complementary techniques. We start with classifiers trained on known examples of malicious and benign packages. If a package is flagged as malicious by a classifier, we then check whether it includes metadata about its source repository, and if so whether the package can be reproduced from its source code. Packages that are reproducible from source are not usually malicious, so this step allows us to weed out false positives. Finally, we also employ a simple textual clone-detection technique to identify copies of malicious packages that may have been missed by the classifiers, reducing the number of false negatives. Amalfi improves on the state of the art in that it is lightweight, requiring only a few seconds per package to extract features and run the classifiers, and gives good results in practice: running it on 96287 package versions published over the course of one week, we were able to identify 95 previously unknown malware samples, with a manageable number of false positives.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793552","supply chain security;malware detection","Training;Supply chains;Ecosystems;Manuals;Static analysis;Syntactics;Feature extraction","","14","","34","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Augmenting test suites automatically","K. Rubinov; J. Wuttke","Faculty of Informatics, University of Lugano, Switzerland; Computer Science & Engineering, University of Washington, Seattle, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1433","1434","We present an approach to augment test suites with automatically generated integration test cases. Our approach utilizes existing test cases to direct generation towards producing complex object interactions and execution sequences that have not been observed before.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227078","software testing;unit and integration testing;automatic test generation","Testing;Data mining;Educational institutions;Prototypes;Java;Libraries;Manuals","","6","","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Using machine learning to enhance automated requirements model transformation","E. -V. Chioaşcă","School of Computer Science, University of Manchester, Institute of Science and Technology, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1487","1490","Textual specification documents do not represent a suitable starting point for software development. This issue is due to the inherent problems of natural language such as ambiguity, impreciseness and incompleteness. In order to overcome these shortcomings, experts derive analysis models such as requirements models. However, these models are difficult and costly to create manually. Furthermore, the level of abstraction of the models is too low, thus hindering the automated transformation process. We propose a novel approach which uses high abstraction requirements models in the form of Object System Models (OSMs) as targets for the transformation of natural language specifications in conjunction with appropriate text mining and machine learning techniques. OSMs allow the interpretation of the textual specification based on a small set of facts and provide structural and behavioral information. This approach will allow both (1) the enhancement of minimal specifications, and in the case of comprehensive specifications (2) the determination of the most suitable structure of reusable requirements.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227055","Natural language specification;text mining;machine learning;Object System Models","Unified modeling language;Natural languages;Analytical models;Object recognition;Object oriented modeling;Containers","","5","1","13","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"SDiC: Context-based retrieval in Eclipse","B. Antunes; J. Cordeiro; P. Gomes","Centre for Informatics and Systems, University of Coimbra, Coimbra, Portugal; Centre for Informatics and Systems, University of Coimbra, Coimbra, Portugal; Centre for Informatics and Systems, University of Coimbra, Coimbra, Portugal",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1467","1468","While working in an IDE, developers typically deal with a large number of different artifacts at the same time. The software development process requires that they repeatedly switch between different artifacts, which often depends on searching for these artifacts in the source code structure. We propose a tool that integrates context-based search and recommendation of source code artifacts in Eclipse. The artifacts are collected from the workspace of the developer and represented using ontologies. A context model of the developer is used to improve search and give recommendations of these artifacts, which are ranked according to their relevance to the developer. The tool was tested by a group of developers and the results show that contextual information has an important role in retrieving relevant information for developers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227061","","Context;Context modeling;Ontologies;Knowledge based systems;Computational modeling;Programming;Switches","","","","4","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Vulnerability Detection with Graph Simplification and Enhanced Graph Representation Learning","X. -C. Wen; Y. Chen; C. Gao; H. Zhang; J. M. Zhang; Q. Liao","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Big Data and Software Engineering, Chongqing University, China; Department of Informatics, King's College, London, UK; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2275","2286","Prior studies have demonstrated the effectiveness of Deep Learning (DL) in automated software vulnerability detection. Graph Neural Networks (GNNs) have proven effective in learning the graph representations of source code and are commonly adopted by existing DL-based vulnerability detection methods. However, the existing methods are still limited by the fact that GNNs are essentially difficult to handle the connections between long-distance nodes in a code structure graph. Besides, they do not well exploit the multiple types of edges in a code structure graph (such as edges representing data flow and control flow). Consequently, despite achieving state-of-the-art performance, the existing GNN-based methods tend to fail to capture global information (i.e., long-range dependencies among nodes) of code graphs. To mitigate these issues, in this paper, we propose a novel vulnerability detection framework with grAph siMplification and enhanced graph rePresentation LEarning, named AMPLE. AMPLE mainly contains two parts: 1) graph simplification, which aims at reducing the distances between nodes by shrinking the node sizes of code structure graphs; 2) enhanced graph representation learning, which involves one edge-aware graph convolutional network module for fusing heterogeneous edge information into node representations and one kernel-scaled representation module for well capturing the relations between distant graph nodes. Experiments on three public benchmark datasets show that AMPLE outperforms the state-of-the-art methods by 0.39%-35.32% and 7.64%-199.81% with respect to the accuracy and F1 score metrics, respectively. The results demonstrate the effectiveness of AMPLE in learning global information of code graphs for vulnerability detection.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00191","National Key R&D Program of China(grant numbers:2022YFB3103900); National Natural Science Foundation of China(grant numbers:62002084,62276075,62272132); Natural Science Foundation of Guang-dong Province(grant numbers:2023A1515011959); Shenzhen Basic Research(grant numbers:JCYJ20220531095214031); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172762","Software vulnerability;graph simplification;graph representation learning","Representation learning;Measurement;Learning systems;Deep learning;Codes;Image edge detection;Source coding","","15","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Runtime monitoring of component changes with Spy@Runtime","C. Ghezzi; A. Mocci; M. Sangiorgio","Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1403","1406","We present Spy@Runtime, a tool to infer and work with behavior models. Spy@Runtime generates models through a dynamic black box approach and is able to keep them updated with observations coming from actual system execution. We also show how to use models describing the protocol of interaction of a software component to detect and report functional changes as soon as they are discovered. Monitoring functional properties is particularly useful in an open environment in which there is a distributed ownership of a software system. Parts of the system may be changed independently and therefore it becomes necessary to monitor the component's behavior at run time.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227237","Model Inference;Runtime Monitoring","Monitoring;Runtime;Protocols;Software;Analytical models;Java;Integrated circuit modeling","","11","","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Metamorphic Shader Fusion for Testing Graphics Shader Compilers","D. Xiao; Z. Liu; S. Wang","The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2400","2412","Computer graphics are powered by graphics APIs (e.g., OpenGL, Direct3D) and their associated shader compilers, which render high-quality images by compiling and optimizing user-written high-level shader programs into GPU machine code. Graphics rendering is extensively used in production scenarios like virtual reality (VR), gaming, autonomous driving, and robotics. Despite the development by industrial manufacturers such as Intel, Nvidia, and AMD, shader compilers - like traditional software - may produce ill-rendered outputs. In turn, these errors may result in negative results, from poor user experience in entertainment to accidents in driving assistance systems. This paper introduces FSHADER, a metamorphic testing (MT) framework designed specifically for shader compilers to uncover erroneous compilations and optimizations. FSHADER tests shader compilers by mutating input shader programs via four carefully-designed metamorphic relations (MRs). In particular, FSHADER fuses two shader programs via an MR and checks the visual consistency between the image rendered from the fused shader program with the output of fusing individually rendered images. Our study of 12 shader compilers covers five mainstream GPU vendors, including Intel, AMD, Nvidia, ARM, and Apple. We successfully uncover over 16K error-triggering inputs that generate incorrect rendering outputs. We manually locate and characterize buggy optimization places, and developers have confirmed representative bugs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172737","Compiler testing;Metamorphic testing;Shader compilers;Graphics compilers;GPU driver;Virtual reality","Visualization;Computer bugs;Graphics processing units;Virtual reality;Rendering (computer graphics);User experience;Software","","2","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"ModuleGuard: Understanding and Detecting Module Conflicts in Python Ecosystem","R. Zhu; X. Wang; C. Liu; Z. Xu; W. Shen; R. Chang; L. Yang","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2606","2617","Python has become one of the most popular programming languages for software development due to its simplicity, readability, and versatility. As the Python ecosystem grows, developers face increasing challenges in avoiding module conflicts, which occur when different packages have the same namespace modules. Un-fortunately, existing work has neither investigated the module conflict comprehensively nor provided tools to detect the conflict. Therefore, this paper systematically investigates the module con-flict problem and its impact on the Python ecosystem. We propose a novel technique called InstSimulator, which leverages semantics and installation simulation to achieve accurate and efficient module extraction. Based on this, we implement a tool called ModuleGuard to detect module conflicts for the Python ecosystem. For the study, we first collect 97 MC issues, classify the characteristics and causes of these MC issues, summarize three different conflict patterns, and analyze their potential threats. Then, we conducted a large-scale analysis of the whole PyPI ecosystem (4.2 million packages) and GitHub popular projects (3,711 projects) to detect each MC pattern and analyze their potential impact. We discovered that module conflicts still impact numerous TPLs and GitHub projects. This is primarily due to developers' lack of understanding of the modules within their direct dependencies, not to mention the modules of the transitive dependencies. Our work reveals Python's shortcomings in handling naming conflicts and provides a tool and guidelines for developers to detect conflicts.","1558-1225","979-8-4007-0217-4","","National Key R&D Program of China(grant numbers:2022YFB3103900); National Research Foundation, Singapore; DSO National Laboratories; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549349","Module Conflict;PyPI Ecosystem;Dependency Graphs;Namespace Conflict;Dependency Resolution","Systematics;Accuracy;Ecosystems;Semantics;Faces;Python;Software development management","","","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Fonte: Finding Bug Inducing Commits from Failures","G. An; J. Hong; N. Kim; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; SAP Labs Korea, Seoul, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea; School of Computing, KAIST, Daejeon, Republic of Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","589","601","A Bug Inducing Commit (BIC) is a commit that introduces a software bug into the codebase. Knowing the relevant BIC for a given bug can provide valuable information for debugging as well as bug triaging. However, existing BIC identification techniques are either too expensive (because they require the failing tests to be executed against previous versions for bisection) or inapplicable at the debugging time (because they require post hoc artefacts such as bug reports or bug fixes). We propose Fonte, an efficient and accurate BIC identification technique that only requires test coverage. Fonte combines Fault Localisation (FL) with BIC identification and ranks commits based on the suspiciousness of the code elements that they modified. Fonte reduces the search space of BICs using failure coverage as well as a filter that detects commits that are merely style changes. Our empirical evaluation using 130 real-world BICs shows that Fonte significantly outperforms state-of-the-art BIC identification techniques based on Information Retrieval as well as neural code embedding models, achieving at least 39% higher MRR. We also report that the ranking scores produced by Fonte can be used to perform weighted bisection, further reducing the cost of BIC identification. Finally, we apply Fonte to a large-scale industry project with over 10M lines of code, and show that it can rank the actual BIC within the top five commits for 87% of the studied real batch-testing failures, and save the BIC inspection cost by 32% on average.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00059","National Research Foundation of Korea (NRF)(grant numbers:NRF-2020R1A2C1013629); Institute for Information & communications Technology Promotion; Samsung Electronics(grant numbers:10201210-07969-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172540","Bug Inducing Commit;Fault Localisation;Git;Weighted Bisection;Batch Testing","Industries;Costs;Codes;Computer bugs;Debugging;Syntactics;Software","","","","42","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Understanding the Threats of Upstream Vulnerabilities to Downstream Projects in the Maven Ecosystem","Y. Wu; Z. Yu; M. Wen; Q. Li; D. Zou; H. Jin","School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1046","1058","Modern software systems are increasingly relying on dependencies from the ecosystem. A recent estimation shows that around 35% of an open-source project's code come from its depended libraries. Unfortunately, open-source libraries are often threatened by various vulnerability issues, and the number of disclosed vulnerabilities is increasing steadily over the years. Such vulnerabilities can pose significant security threats to the whole ecosystem, not only to the vulnerable libraries themselves, but also to the corresponding downstream projects. Many Software Composition Analysis (SCA) tools have been proposed, aiming to detect vulnerable libraries or components referring to existing vulnerability databases. However, recent studies report that such tools often generate a large number of false alerts. Particularly, up to 73.3% of the projects depending on vulnerable libraries are actually safe. Aiming to devise more precise tools, understanding the threats of vulnerabilities holistically in the ecosystem is significant, as already performed by a number of existing studies. However, previous researches either analyze at a very coarse granularity (e.g., without analyzing the source code) or are limited by the study scales. This study aims to bridge such gaps. In particular, we collect 44,450 instances of (CVE, upstream, downstream) relations and analyze around 50 million invocations made from downstream to upstream projects to understand the potential threats of upstream vulnerabilities to downstream projects in the Maven ecosystem. Our investigation makes interesting yet significant findings with respect to multiple aspects, including the reach-ability of vulnerabilities, the complexities of the reachable paths as well as how downstream projects and developers perceive upstream vulnerabilities. We believe such findings can not only provide a holistic understanding towards the threats of upstream vulnerabilities in the Maven ecosystem, but also can guide future researches in this field.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172868","Maven;Ecosystem Security;Vulnerability","Codes;Databases;Source coding;Ecosystems;Estimation;Software systems;Libraries","","7","","61","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Lessons from Eight Years of Operational Data from a Continuous Integration Service: An Exploratory Case Study of CircleCI","K. Gallaba; M. Lamothe; S. McIntosh","Centre for Software Excellence, Huawei Canada, Kingston, Canada; Polytechnique Montréal, Montréal, Canada; University of Waterloo, Waterloo, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1330","1342","Continuous Integration (CI) is a popular practice that enables the rapid pace of modern software development. Cloud-based CI services have made CI ubiquitous by relieving software teams of the hassle of maintaining a CI infrastructure. To improve these CI services, prior research has focused on analyzing historical CI data to help service consumers. However, finding areas of improvement for CI service providers could also improve the experience for service consumers. To search for these opportunities, we conduct an empirical study of 22.2 million builds spanning 7,795 open-source projects that used CircleCI from 2012 to 2020. First, we quantitatively analyze the builds (i.e., invocations of the CI service) with passing or failing outcomes. We observe that the heavy and typical service consumer groups spend significantly different proportions of time on seven of the nine build actions (e.g., dependency retrieval). On the other hand, the compilation and testing actions consistently consume a large proportion of build time across consumer groups (median 33%). Second, we study builds that terminate prior to generating a pass or fail signal. Through a systematic manual analysis, we find that availability issues, configuration errors, user cancellation, and exceeding time limits are key reasons that lead to premature build termination. Our observations suggest that (1) heavy service consumers would benefit most from build acceleration approaches that tackle long build durations (e.g., skipping build steps) or high throughput rates (e.g., optimizing CI service job queues), (2) efficiency in CI pipelines can be improved for most CI consumers by focusing on the compilation and testing stages, and (3) avoiding misconfigurations and tackling service availability issues present the largest opportunities for improving the robustness of CI services.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794021","Automated Builds;Build Systems;Continuous Integration","Systematics;Pipelines;Manuals;Life estimation;Throughput;Robustness;Queueing analysis","","6","","52","","20 Jun 2022","","","IEEE","IEEE Conferences"
"SPEcBCFuzz: Fuzzing LTL Solvers with Boundary Conditions","L. Carvalho; R. Degiovanni; M. Cordy; N. Aguirre; Y. L. Traon; M. Papadakis","SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; Universidad Nacional de Rio Cuarto and CONICET, Argentina; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1508","1520","LTL solvers check the satisfiability of Linear-time Temporal Logic (LTL) formulas and are widely used for verifying and testing critical software systems. Thus, potential bugs in the solvers' implemen-tations can have a significant impact. We present SPECBCFUZZ, a fuzzing method for finding bugs in LTL solvers, that is guided by boundary conditions (BCs), corner cases whose (un)satisfiability depends on rare traces. SPECBCFUZZ implements a search-based algorithm that fuzzes LTL formulas giving relevance to BCs. It inte-grates syntactic and semantic similarity metrics to explore the vicinity of the seeded formulas with BCs. We evaluate SPECBCFUZZ on 21 different configurations (including the latest and past releases) of four mature and state-of-the-art LTL solvers (NuSMV, Black, Aalta, and PLTL) that implement a diverse set of satisfiability algorithms. SPECBCFUZZ produces 368,716 bug-triggering formulas, detecting bugs in 18 out of the 21 solvers' configurations we study. Over-all, SPECBCFUZZ reveals: soundness issues (wrong answers given by a solver) in Aalta and PLTL; crashes, e.g., segmentation faults, in NuSMV, Black and Aalta; flaky behaviors (different responses across re-runs of the solver on the same formula) in NuSMV and Aalta; performance bugs (large time performance degradation between successive versions of the solver on the same formula) in Black, Aalta and PLTL; and no bug in NuSMV BDD (all versions), suggesting that the latter is currently the most robust solver.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548218","Fuzzing;Search-Based Software Engineering;Linear-time Temporal Logic","Measurement;Computer bugs;Software algorithms;Semantics;Fuzzing;Syntactics;Boundary conditions","","","","80","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models","S. Gao; H. Zhang; C. Gao; C. Wang","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Big Data and Software Engineering, Chongqing University, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","30","42","Previous research on code intelligence usually trains a deep learning model on a fixed dataset in an offline manner. However, in real-world scenarios, new code repositories emerge incessantly, and the carried new knowledge is beneficial for providing up-to-date code intelligence services to developers. In this paper, we aim at the following problem: How to enable code intelligence models to continually learn from ever-increasing data? One major challenge here is catastrophic forgetting, meaning that the model can easily forget knowledge learned from previous datasets when learning from the new dataset. To tackle this challenge, we propose REPEAT, a novel method for continual learning of code intelligence models. Specifically, REPEAT addresses the catastrophic forgetting problem with representative exemplars replay and adaptive parameter regularization. The representative exemplars replay component selects informative and diverse exemplars in each dataset and uses them to re-train model periodically. The adaptive parameter regularization component recognizes important parameters in the model and adaptively penalizes their changes to preserve the knowledge learned before. We evaluate the proposed approach on three code intelligence tasks including code summarization, software vulnerability detection, and code clone detection. Extensive experiments demonstrate that REPEAT consistently outperforms baseline methods on all tasks. For example, REPEAT improves the conventional fine-tuning method by 1.22, 5.61, and 1.72 on code summarization, vulnerability detection and clone detection, respectively.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172346","","Deep learning;Adaptation models;Codes;Cloning;Data models;Software;Task analysis","","6","","63","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Large-scale formal verification in practice: A process perspective","J. Andronick; R. Jeffery; G. Klein; R. Kolanski; M. Staples; H. Zhang; L. Zhu","NICTA, Eveleigh, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Eveleigh, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Eveleigh, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Eveleigh, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Eveleigh, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Eveleigh, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Eveleigh, NSW, Australia",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1002","1011","The L4.verified project was a rare success in large-scale, formal verification: it provided a formal, machine-checked, code-level proof of the full functional correctness of the seL4 microkernel. In this paper we report on the development process and management issues of this project, highlighting key success factors. We formulate a detailed descriptive model of its middle-out development process, and analyze the evolution and dependencies of code and proof artifacts. We compare our key findings on verification and re-verification with insights from other verification efforts in the literature. Our analysis of the project is based on complete access to project logs, meeting notes, and version control data over its entire history, including its long-term, ongoing maintenance phase. The aim of this work is to aid understanding of how to successfully run large-scale formal software verification projects.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227120","program verification;microkernel;L4;software process;formal methods","Kernel;Prototypes;Maintenance engineering;Abstracts;Analytical models;Computer bugs","","13","1","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"DeepArc: Modularizing Neural Networks for the Model Maintenance","X. Ren; Y. Lin; Y. Xue; R. Liu; J. Sun; Z. Feng; J. S. Dong","University of Science and Technology of China, China; Shanghai Jiao Tong University, China; University of Science and Technology of China, China; National University of Singapore, Singapore; Singapore Management University, Singapore; Tianjin University, China; National University of Singapore, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1008","1019","Neural networks are an emerging data-driven programming paradigm widely used in many areas. Unlike traditional software systems consisting of decomposable modules, a neural network is usually delivered as a monolithic package, raising challenges for some maintenance tasks such as model restructure and re-adaption. In this work, we propose DeepArc, a novel modularization method for neural networks, to reduce the cost of model maintenance tasks. Specifically, DeepArc decomposes a neural network into several consecutive modules, each of which encapsulates consecutive layers with similar semantics. The network modularization facilitates practical tasks such as refactoring the model to preserve existing features (e.g., model compression) and enhancing the model with new features (e.g., fitting new samples). The modularization and encapsulation allow us to restructure or retrain the model by only pruning and tuning a few localized neurons and layers. Our experiments show that (1) DeepArc can boost the runtime efficiency of the state-of-the-art model compression techniques by 14.8%; (2) compared to the traditional model retraining, DeepArc only needs to train less than 20% of the neurons on average to fit adversarial samples and repair under-performing models, leading to 32.85% faster training performance while achieving similar model prediction performance.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172675","architecture;modularization;neural networks","Training;Runtime;Neurons;Semantics;Predictive models;Maintenance engineering;Software systems","","3","","46","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Analyzing and Debugging Normative Requirements via Satisfiability Checking","N. Feng; L. Marsso; S. G. Yaman; B. Townsend; Y. Baatartogtokh; R. Ayad; V. O. de Mello; I. Standen; I. Stefanakos; C. Imrie; G. Rodrigues; A. Cavalcanti; R. Calinescu; M. Chechik","University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; University of York, York, UK; University of York, York, UK; Smith College, Northampton, USA; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; University of York, York, UK; University of York, York, UK; University of York, York, UK; University of Brasilia, Brasilia, Brazil; University of York, York, UK; University of York, York, UK; University of Toronto, Toronto, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2643","2654","As software systems increasingly interact with humans in application domains such as transportation and healthcare, they raise concerns related to the social, legal, ethical, empathetic, and cultural (SLEEC) norms and values of their stakeholders. Normative non-functional requirements (N-NFRs) are used to capture these concerns by setting SLEEC-relevant boundaries for system behavior. Since N-NFRs need to be specified by multiple stakeholders with widely different, non-technical expertise (ethicists, lawyers, regulators, end users, etc.), N-NFR elicitation is very challenging. To address this difficult task, we introduce N-Check, a novel tool-supported formal approach to N-NFR analysis and debugging. N-Check employs satisfiability checking to identify a broad spectrum of N-NFR well-formedness issues, such as conflicts, redundancy, restrictiveness, and insufficiency, yielding diagnostics that pinpoint their causes in a user-friendly way that enables non-technical stake-holders to understand and fix them. We show the effectiveness and usability of our approach through nine case studies in which teams of ethicists, lawyers, philosophers, psychologists, safety analysts, and engineers used N-Check to analyse and debug 233 N-NFRs, comprising 62 issues for the software underpinning the operation of systems, such as, assistive-care robots and tree-disease detection drones to manufacturing collaborative robots.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639093","Royal Academy of Engineering(grant numbers:CiET1718/45); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548060","Satisfiability;Requirement Engineering","Ethics;Systematics;Transportation;Termination of employment;Debugging;Software systems;Stakeholders","","1","","41","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Mining Java class identifier naming conventions","S. Butler","Centre for Research in Computing and Department of Computing, Open University, Milton Keynes, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1641","1643","Classes represent key elements of knowledge in object-orientated source code. Class identifier names describe the knowledge recorded in the class and, much of the time, record some detail of the lineage of the class. We investigate the structure of Java class names identifying common patterns of naming and the way components of class identifier names are repeated in inheritance hierarchies. Detailed knowledge of class identifier name structures can be used to improve the accuracy of concept location tools, to support reverse engineering of domain models and requirements traceability, and to support development teams through class identifier naming recommendation systems.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227216","identifier names;inheritance;source code","Java;Software maintenance;Accuracy;Educational institutions;Programming;Speech","","7","","21","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Towards Reliable AI: Adequacy Metrics for Ensuring the Quality of System-Level Testing of Autonomous Vehicles","N. Neelofar; A. Aleti","Monash University, Australia; Monash University, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","816","827","AI-powered systems have gained widespread popularity in various domains, including Autonomous Vehicles (AVs). However, ensuring their reliability and safety is challenging due to their complex nature. Conventional test adequacy metrics, designed to evaluate the effectiveness of traditional software testing, are often insufficient or impractical for these systems. White-box metrics, which are specifically designed for these systems, leverage neuron coverage information. These coverage metrics necessitate access to the underlying AI model and training data, which may not always be available. Furthermore, the existing adequacy metrics exhibit weak correlations with the ability to detect faults in the generated test suite, creating a gap that we aim to bridge in this study. In this paper, we introduce a set of black-box test adequacy metrics called “Test suite Instance Space Adequacy” (TISA) metrics, which can be used to gauge the effectiveness of a test suite. The TISA metrics offer a way to assess both the diversity and coverage of the test suite and the range of bugs detected during testing. Additionally, we introduce a framework that permits testers to visualise the diversity and coverage of the test suite in a two-dimensional space, facilitating the identification of areas that require improvement. We evaluate the efficacy of the TISA metrics by examining their correlation with the number of bugs detected in system-level simulation testing of AVs. A strong correlation, coupled with the short computation time, indicates their effectiveness and efficiency in estimating the adequacy of testing AVs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548794","","Measurement;Software testing;Correlation;Computer bugs;Training data;Software reliability;Safety","","","","87","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Repairing Brain-Computer Interfaces with Fault-Based Data Acquisition","C. Winston; C. Winston; C. N. Winston; C. Winston; C. Winston; R. P. N. Rao; R. Just","University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1869","1880","Brain-computer interfaces (BCls) decode recorded neural signals from the brain and/or stimulate the brain with encoded neural sig-nals. BCls span both hardware and software and have a wide range of applications in restorative medicine, from restoring movement through prostheses and robotic limbs to restoring sensation and communication through spellers. BCls also have applications in di-agnostic medicine, e.g., providing clinicians with data for detecting seizures, sleep patterns, or emotions. Despite their promise, BCls have not yet been adopted for long-term, day-to-day use because of challenges related to reliability and robustness, which are needed for safe operation in all scenarios. Ensuring safe operation currently requires hours of manual data collection and recalibration, involving both patients and clinicians. However, data collection is not targeted at eliminating specific faults in a BCI. This paper presents a new methodology for char-acterizing, detecting, and localizing faults in BCls. Specifically, it proposes partial test oracles as a method for detecting faults and slice functions as a method for localizing faults to characteristic patterns in the input data or relevant tasks performed by the user. Through targeted data acquisition and retraining, the proposed methodology improves the correctness of BCls. We evaluated the proposed methodology on five BCl applications. The results show that the proposed methodology (1) precisely localizes faults and (2) can significantly reduce the frequency of faults through retraining based on targeted, fault-based data acquisition. These results sug-gest that the proposed methodology is a promising step towards repairing faulty BCls.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3512764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793968","Brain-computer interface;neural decoding;partial test oracles;fault localization","Software testing;Location awareness;Data acquisition;Data collection;Robot sensing systems;Brain-computer interfaces;Software","","","","37","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Comprehensive Semantic Repair of Obsolete GUI Test Scripts for Mobile Applications","S. Cao; M. Pan; Y. Pei; W. Yang; T. Zhang; L. Wang; X. Li","State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1096","1108","Graphical User Interface (GUI) testing is one of the primary approaches for testing mobile apps. Test scripts serve as the main carrier of GUI testing, yet they are prone to obsolescence when the GUIs change with the apps' evolution. Existing repair approaches based on GUI layouts or images prove effective when the GUI changes between the base and updated versions are minor, however, they may struggle with substantial changes. In this paper, a novel approach named COSER is introduced as a solution to re-pairing broken scripts, which is capable of addressing larger GUI changes compared to existing methods. COSER incorporates both external semantic information from the GUI elements and internal semantic information from the source code to provide a unique and comprehensive solution. The efficacy of COSER was demonstrated through experiments conducted on 20 Android apps, resulting in superior performance when compared to the state-of-the-art tools METER and GUIDER. In addition, a tool that implements the COSER approach is available for practical use and future research.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639108","National Natural Science Foundation of China(grant numbers:62372227,62232014,62032010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549582","GUI test script repair;Android testing;regression testing","Meters;Source coding;Semantics;Layout;Maintenance engineering;Aging;Mobile applications","","","","39","","14 Jun 2024","","","IEEE","IEEE Conferences"
"DStream: A Streaming-Based Highly Parallel IFDS Framework","X. Wang; Z. Zuo; L. Bu; J. Zhao","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2488","2500","The IFDS framework supports interprocedural dataflow analysis with distributive flow functions over finite domains. A large class of interprocedural dataflow analysis problems can be formulated as IFDS problems and thus can be solved with the IFDS framework precisely. Unfortunately, scaling IFDS analysis to large-scale programs is challenging in terms of both massive memory consumption and low analysis efficiency. This paper presents DStream, a scalable system dedicated to precise and highly parallel IFDS analysis for large-scale programs. DStream leverages a streaming-based out-of-core computation model to reduce memory footprint significantly and adopts fine-grained data parallelism to achieve efficiency. We implemented a taint analysis as a DStream instance analysis and compared DStream with three state-of-the-art tools. Our exper-iments validate that DStream outperforms all other tools with average speedups from 4.37x to 14.46x on a commodity PC with limited available memory. Meanwhile, the experiments confirm that DStream successfully scales to large-scale programs which the state-of-the-art tools (e.g., FlowDroid and/or DiskDroid) fail to analyze.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172864","interprocedural static analysis;IFDS analysis;streaming;data-parallel computation","Costs;Scalability;Computational modeling;Memory management;Software algorithms;Parallel processing;Data models","","2","","39","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Crosscutting revision control system","S. Ifrah; D. H. Lorenz","Department of Mathematics and Computer Science, Open University of Israel, Raanana, Israel; Department of Mathematics and Computer Science, Open University of Israel, Raanana, Israel",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","321","330","Large and medium scale software projects often require a source code revision control (RC) system. Unfortunately, RC systems do not perform well with obliviousness and quantification found in aspect-oriented code. When classes are oblivious to aspects, so is the RC system, and the crosscutting effect of aspects is not tracked. In this work, we study this problem in the context of using AspectJ (a standard AOP language) with Subversion (a standard RC system). We describe scenarios where the crosscutting effect of aspects combined with the concurrent changes that RC supports can lead to inconsistent states of the code. The work contributes a mechanism that checks-in with the source code versions of crosscutting metadata for tracking the effect of aspects. Another contribution of this work is the implementation of a supporting Eclipse plug-in (named XRC) that extends the JDT, AJDT, and SVN plug-ins for Eclipse to provide crosscutting revision control (XRC) for aspect-oriented programming.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227182","revision control;version control;aspects","Visualization;Control systems;Programming;Engines;History;Weaving;Software","","1","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A self-healing technique for Java applications","A. Carzaniga; A. Gorla; A. Mattavelli; N. Perino","Faculty of Informatics, University of Lugano, Lugano, Switzerland; Faculty of Informatics, University of Lugano, Lugano, Switzerland; Faculty of Informatics, University of Lugano, Lugano, Switzerland; Faculty of Informatics, University of Lugano, Lugano, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1445","1446","Despite the best design practices and testing techniques, many faults exist and manifest themselves in deployed software. In this paper we propose a self-healing framework that aims to mask fault manifestations at runtime in Java applications by automatically applying workarounds. The framework integrates a checkpoint-recovery mechanism to restore a consistent state after the failure, and a mechanism to replace the Java code at runtime to apply the workaround.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227072","Self-healing;Checkpoint-recovery;Failure avoidance;Equivalent sequences","Runtime;Java;Containers;Testing;Software systems;Redundancy","","3","","3","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Using invariant relations in the termination analysis of while loops","W. Ghardallou","Computer Sciences Department, University of Tunis, Tunis, Tunisia",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1519","1522","Proving program termination plays an important role in ensuring reliability of software systems. Many researchers have lent much attention to this open long-standing problem, most of them were interested in proving that iterative programs terminate under a given input. In this paper, we present a method to solve a more interesting and challenging problem, namely, the generation of the termination condition of while loops i.e. condition over initial states under which a loop terminates normally. To this effect, we use a concept introduced by Mili et al., viz. invariant relation.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227047","invariant relation;while loop;termination condition;program verification","Arrays;Prototypes;Approximation methods;Semantics;Software;Computers","","1","","17","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CONFETTI: Amplifying Concolic Guidance for Fuzzers","J. Kukucka; L. Pina; P. Ammann; J. Bell","George Mason University, Fairfax, VA, USA; University of Illinois Chicago, Chicago, Illinois, USA; George Mason University, Fairfax, VA, USA; Northeastern University, Boston, MA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","438","450","Fuzz testing (fuzzing) allows developers to detect bugs and vul-nerabilities in code by automatically generating defect-revealing inputs. Most fuzzers operate by generating inputs for applications and mutating the bytes of those inputs, guiding the fuzzing pro-cess with branch coverage feedback via instrumentation. Whitebox guidance (e.g., taint tracking or concolic execution) is sometimes in-tegrated with coverage-guided fuzzing to help cover tricky-to-reach branches that are guarded by complex conditions (so-called “magic values”). This integration typically takes the form of a targeted in-put mutation, e.g., placing particular byte values at a specific offset of some input in order to cover a branch. However, these dynamic analysis techniques are not perfect in practice, which can result in the loss of important relationships between input bytes and branch predicates, thus reducing the effective power of the technique. We introduce a new, surprisingly simple, but effective technique, global hinting, which allows the fuzzer to insert these interesting bytes not only at a targeted position, but in any position of any input. We implemented this idea in Java, creating Confetti, which uses both targeted and global hints for fuzzing. In an empirical com-parison with two baseline approaches, a state-of-the-art greybox Java fuzzer and a version of Confetti without global hinting, we found that Confetti covers more branches and finds 15 previously unreported bugs, including 9 that neither baseline could find. By conducting a post-mortem analysis of Confetti's execution, we determined that global hinting was at least as effective at revealing new coverage as traditional, targeted hinting.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510628","NSF(grant numbers:CCF-2100037,CNS-2100015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794114","fuzz testing;concolic execution;taint tracking","Java;Target tracking;Codes;Instruments;Computer bugs;Fuzzing;Programming","","6","","82","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Tensor-Aware Energy Accounting","T. Babakol; Y. D. Liu","SUNY Binghamton, Binghamton, NY, USA; SUNY Binghamton, Binghamton, NY, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1134","1145","With the rapid growth of Artificial Intelligence (AI) applications supported by deep learning (DL), the energy efficiency of these applications has an increasingly large impact on sustainability. We introduce Smaragdine, a new energy accounting system for tensor-based DL programs implemented with TENSORFLOW. At the heart of Smaragdine is a novel white-box methodology of energy accounting: Smaragdine is aware of the internal structure of the DL program, which we call tensor-aware energy accounting. With Smaragdine, the energy consumption of a DL program can be broken down into units aligned with its logical hierarchical de-composition structure. We apply Smaragdine for understanding the energy behavior of BERT, one of the most widely used language models. Layer-by-layer and tensor-by-tensor, Smaragdine is capable of identifying the highest energy/power-consuming components of BERT. Furthermore, we conduct two case studies on how Smaragdine supports downstream toolchain building, one on the comparative energy impact of hyperparameter tuning of BERT, the other on the energy behavior evolution when BERT evolves to its next generation, ALBERT.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549335","","Deep learning;Heart;Energy consumption;Tensors;Natural languages;Sustainable development;Tuning","","","","68","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Improving Fault Localization and Program Repair with Deep Semantic Features and Transferred Knowledge","X. Meng; X. Wang; H. Zhang; H. Sun; X. Liu","SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; The University of Newcastle, NSW, Australia; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1169","1180","Automatic software debugging mainly includes two tasks of fault lo-calization and automated program repair. Compared with the traditional spectrum-based and mutation-based methods, deep learning-based methods are proposed to achieve better performance for fault localization. However, the existing methods ignore the deep seman-tic features or only consider simple code representations. They do not leverage the existing bug-related knowledge from large-scale open-source projects either. In addition, existing template-based program repair techniques can incorporate project specific information better than deep-learning approaches. However, they are weak in selecting the fix templates for efficient program repair. In this work, we propose a novel approach called TRANSFER, which lever-ages the deep semantic features and transferred knowledge from open-source data to improve fault localization and program repair. First, we build two large-scale open-source bug datasets and design 11 BiLSTM-based binary classifiers and a BiLSTM-based multi-classifier to learn deep semantic features of statements for fault localization and program repair, respectively. Second, we combine semantic-based, spectrum-based and mutation-based features and use an MLP-based model for fault localization. Third, the semantic-based features are leveraged to rank the fix templates for program repair. Our extensive experiments on widely-used benchmark De-fects4J show that TRANSFER outperforms all baselines in fault localization, and is better than existing deep-learning methods in automated program repair. Compared with the typical template-based work TBar, TRANSFER can correctly repair 6 more bugs (47 in total) on Defects4J.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510147","National Key Research and Development Program of China(grant numbers:2018YFB1306000); National Natural Science Foundation of China(grant numbers:62072017,62141209); Australian Research Council Discovery Projects(grant numbers:DP200102940,DP220103044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794014","Fault localization;program repair;transfer learning;neural networks;software debugging","Location awareness;Codes;Semantics;Computer bugs;Maintenance engineering;Feature extraction;Software debugging","","14","","67","","20 Jun 2022","","","IEEE","IEEE Conferences"
"APER: Evolution-Aware Runtime Permission Misuse Detection for Android Apps","S. Wang; Y. Wang; X. Zhan; Y. Wang; Y. Liu; X. Luo; S. -C. Cheung","Southern University of Science and Technology, Shenzhen, China; Northeastern University, Shenyang, China; The Hong Kong Polytechnic University, Hong Kong, China; Northeastern University, Shenyang, China; Southern University of Science and Technology, Shenzhen, China; The Hong Kong Polytechnic University, Hong Kong, China; The Hong Kong University of Science and Technology and Guangzhou HKUST Fok Ying Tung Research Institute, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","125","137","The Android platform introduces the runtime permission model in version 6.0. The new model greatly improves data privacy and user experience, but brings new challenges for app developers. First, it allows users to freely revoke granted permissions. Hence, developers cannot assume that the permissions granted to an app would keep being granted. Instead, they should make their apps carefully check the permission status before invoking dangerous APIs. Second, the permission specification keeps evolving, bringing new types of compatibility issues into the ecosystem. To understand the impact of the challenges, we conducted an empirical study on 13,352 popular Google Play apps. We found that 86.0% apps used dangerous APIs asynchronously after permission management and 61.2% apps used evolving dangerous APIs. If an app does not properly handle permission revocations or platform differences, unexpected runtime issues may happen and even cause app crashes. We call such Android Runtime Permission issues as ARP bugs. Unfortunately, existing runtime permission issue detection tools cannot effectively deal with the ARP bugs induced by asynchronous permission management and permission specification evolution. To fill the gap, we designed a static analyzer, Aper, that performs reaching definition and dominator analysis on Android apps to detect the two types of ARP bugs. To compare Aper with existing tools, we built a benchmark, ARPFIX, from 60 real ARP bugs. Our experiment results show that Aper significantly outperforms two academic tools, ARPDROID and Revdroid, and an industrial tool, Lint, on ARPFIX, with an average improvement of 46.3% on F1-score. In addition, Aper successfully found 34 ARP bugs in 214 open-source Android apps, most of which can result in abnormal app behaviors (such as app crashes) according to our manual validation. We reported these bugs to the app developers. So far, 17 bugs have been confirmed and seven have been fixed.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510074","National Natural Science Foundation of China(grant numbers:61932021,61802164,61902056); Guangdong Provincial Key Laboratory(grant numbers:2020BI21201001); Innovation and Technology Commission of Hong Kong (Innovation and Technology)(grant numbers:MHP/055/19,PiH/255/21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793542","Android Runtime Permission;Compatibility Issues;Static Analysis","Data privacy;Runtime;Computer bugs;Ecosystems;Benchmark testing;User experience;Data models","","4","","71","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Generating Realistic and Diverse Tests for LiDAR-Based Perception Systems","G. Christian; T. Woodlief; S. Elbaum","University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2604","2616","Autonomous systems rely on a perception component to interpret their surroundings, and when misinterpretations occur, they can and have led to serious and fatal system-level failures. Yet, existing methods for testing perception software remain limited in both their capacity to efficiently generate test data that translates to real-world performance and in their diversity to capture the long tail of rare but safety-critical scenarios. These limitations are particularly evident for perception systems based on LiDAR sensors, which have emerged as a crucial component in modern autonomous systems due to their ability to provide a 3D scan of the world and operate in all lighting conditions. To address these limitations, we introduce a novel approach for testing LiDAR-based perception systems by leveraging existing real-world data as a basis to generate realistic and diverse test cases through mutations that preserve realism invariants while generating inputs rarely found in existing data sets, and automatically crafting oracles that identify potentially safety-critical issues in perception performance. We implemented our approach to assess its ability to identify perception failures, generating over 50,000 test inputs for five state-of-the-art LiDAR-based perception systems. We found that it efficiently generated test cases that yield errors in perception that could result in real consequences if these systems were deployed and does so at a low rate of false positives.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00217","NSF(grant numbers:AFOSR#FA9550-21-1-0164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172508","Software Testing and Validation;Machine Learning","Software testing;Three-dimensional displays;Laser radar;Autonomous systems;Lighting;Tail;Software","","4","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Enhancing Exploratory Testing by Large Language Model and Knowledge Graph","Y. Su; D. Liao; Z. Xing; Q. Huang; M. Xie; Q. Lu; X. Xu","Australian National University, Australia; Jiangxi Normal University, China; Data61, CSIRO, Australia; Jiangxi Normal University, China; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1197","1208","Exploratory testing leverages the tester's knowledge and creativity to design test cases for effectively uncovering system-level bugs from the end user's perspective. Researchers have worked on test scenario generation to support exploratory testing based on a system knowledge graph, enriched with scenario and oracle knowledge from bug reports. Nevertheless, the adoption of this approach is hindered by difficulties in handling bug reports of inconsistent quality and varied expression styles, along with the infeasibility of the generated test scenarios. To overcome these limitations, we utilize the superior natural language understanding (NLU) capabilities of Large Language Models (LLMs) to construct a System KG of User Tasks and Failures (SysKG-UTF). Leveraging the system and bug knowledge from the KG, along with the logical reasoning capabilities of LLMs, we generate test scenarios with high feasibility and coherence. Particularly, we design chain-of-thought (CoT) reasoning to extract human-like knowledge and logical reasoning from LLMs, simulating a developer's process of validating test scenario feasibility. Our evaluation shows that our approach significantly enhances the KG construction, particularly for bug reports with low quality. Furthermore, our approach generates test scenarios with high feasibility and coherence. The user study further proves the effectiveness of our generated test scenarios in supporting exploratory testing. Specifically, 8 participants find 36 bugs from 8 seed bugs in two hours using our test scenarios, a significant improvement over the 21 bugs found by the state-of-the-art baseline.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548271","Exploratory testing;Knowledge graph;AI chain;Prompt engineering","Computer bugs;Knowledge graphs;Coherence;Cognition;Natural language processing;Scenario generation;Task analysis","","","","38","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Striking a Balance: Pruning False-Positives from Static Call Graphs","A. Utture; S. Liu; C. G. Kalhauge; J. Palsberg","University of California, Los Angeles, U.S.A.; University of California, Los Angeles, U.S.A.; DTU, Denmark; University of California, Los Angeles, U.S.A.",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2043","2055","Researchers have reported that static analysis tools rarely achieve a false-positive rate that would make them attractive to developers. We overcome this problem by a technique that leads to reporting fewer bugs but also much fewer false positives. Our technique prunes the static call graph that sits at the core of many static analyses. Specifically, static call-graph construction proceeds as usual, after which a call-graph pruner removes many false-positive edges but few true edges. The challenge is to strike a balance between being aggressive in removing false-positive edges but not so aggressive that no true edges remain. We achieve this goal by automatically producing a call-graph pruner through an automatic, ahead-of-time learning process. We added such a call-graph pruner to a software tool for null-pointer analysis and found that the false-positive rate decreased from 73% to 23%. This improvement makes the tool more useful to developers.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510166","ONR(grant numbers:N00014-18-1-2037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794059","Static Analysis;Machine learning classification;Call graphs","Computer bugs;Static analysis;Software tools;Software engineering","","6","","50","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Robustification of Behavioral Designs against Environmental Deviations","C. Zhang; T. Saluja; R. Meira-Góes; M. Bolton; D. Garlan; E. Kang","Carnegie Mellon University, Pittsburgh, PA, USA; Swarthmore College, Swarthmore, PA, USA; The Pennsylvania State University, State College, PA, USA; University of Virginia, Charlottesville, VA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","423","434","Modern software systems are deployed in a highly dynamic, uncertain environment. Ideally, a system that is robust should be capable of establishing its most critical requirements even in the presence of possible deviations in the environment. We propose a technique called behavioral robustification, which involves systematically and rigorously improving the robustness of a design against potential deviations. Given behavioral models of a system and its environment, along with a set of user-specified deviations, our robustification method produces a redesign that is capable of satisfying a desired property even when the environment exhibits those deviations. In particular, we describe how the robustification problem can be formulated as a multi-objective optimization problem, where the goal is to restrict the deviating environment from causing a violation of a desired property, while maximizing the amount of existing functionality and minimizing the cost of changes to the original design. We demonstrate the effectiveness of our approach on case studies involving the robustness of an electronic voting machine and safety-critical interfaces.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00046","National Science Foundation(grant numbers:CCF-2144860); NSA(grant numbers:H9823018D0008); Office of Naval Research(grant numbers:N00014172899); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172695","robustness;robustification;labeled transition systems","Costs;Software systems;Robustness;Behavioral sciences;Electronic voting;Optimization;Software engineering","","6","","48","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"PYEVOLVE: Automating Frequent Code Changes in Python ML Systems","M. Dilhara; D. Dig; A. Ketkar","University of Colorado Boulder, USA; JetBrains Research, University of Colorado Boulder, USA; Uber Technologies Inc., USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","995","1007","Because of the naturalness of software and the rapid evolution of Machine Learning (ML) techniques, frequently repeated code change patterns (CPATs) occur often. They range from simple API migrations to changes involving several complex control structures such as for loops. While manually performing CPATs is tedious, the current state-of-the-art techniques for inferring transformation rules are not advanced enough to handle unseen variants of complex CPATs, resulting in a low recall rate. In this paper we present a novel, automated workflow that mines CPATs, infers the transformation rules, and then transplants them automatically to new target sites. We designed, implemented, evaluated and released this in a tool, PYEVOLVE. At its core is a novel data-flow, control-flow aware transformation rule inference engine. Our technique allows us to advance the state-of-the-art for transformation-by-example tools; without it, 70% of the code changes that PYEVOLVE transforms would not be possible to automate. Our thorough empirical evaluation of over 40,000 transformations shows 97% precision and 94% recall. By accepting 90% of CPATs generated by PYEVOLVE in famous open-source projects, developers confirmed its changes are useful.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00091","NSF(grant numbers:CNS-1941898,CNS-2213763); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172702","Python;Machine Learning;Repetitive code changes;Transformation by Example;Program synthesis;Programming by example;Program transformation","Codes;Transforms;Machine learning;Software;Organ transplantation;Engines;Software engineering","","3","","89","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"JuCify: A Step Towards Android Code Unification for Enhanced Static Analysis","J. Samhi; J. Gao; N. Daoudi; P. Graux; H. Hoyez; X. Sun; K. Allix; T. F. Bissyandé; J. Klein","SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; Tcchnische Universitat Kaiserslautern, Germany; Monash University, Australia; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1232","1244","Native code is now commonplace within Android app packages where it co-exists and interacts with Dex bytecode through the Java Native Interface to deliver rich app functionalities. Yet, state-of-the-art static analysis approaches have mostly overlooked the presence of such native code, which, however, may implement some key sensitive, or even malicious, parts of the app behavior. This limitation of the state of the art is a severe threat to validity in a large range of static analyses that do not have a complete view of the executable code in apps. To address this issue, we propose a new advance in the ambitious research direction of building a unified model of all code in Android apps. The JUCIFY approach presented in this paper is a significant step towards such a model, where we extract and merge call graphs of native code and bytecode to make the final model readily-usable by a common Android analysis framework: in our implementation, JUCIFY builds on the Soot internal intermediate representation. We performed empirical investigations to highlight how, without the unified model, a significant amount of Java methods called from the native code are “unreachable” in apps' callgraphs, both in goodware and malware. Using JUCIFY, we were able to enable static analyzers to reveal cases where malware relied on native code to hide invocation of payment library code or of other sensitive code in the Android framework. Additionally, JUCIFY'S model enables state-of-the-art tools to achieve better precision and recall in detecting data leaks through native code. Finally, we show that by using JUCIFY we can find sensitive data leaks that pass through native code.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3512766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794131","Android;Native code;Security;static analysis;Software Engineering","Java;Analytical models;Codes;Buildings;Static analysis;Malware;Libraries","","18","","79","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"A User-Centered Security Evaluation of Copilot","O. Asare; N. Asokan; M. Nagappan","University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1947","1957","Code generation tools driven by artificial intelligence have recently become more popular due to advancements in deep learning and natural language processing that have increased their capabilities. The proliferation of these tools may be a double-edged sword because while they can increase developer productivity by making it easier to write code, research has shown that they can also generate insecure code. In this paper, we perform a user-centered evaluation GitHub's Copilot to better understand its strengths and weaknesses with respect to code security. We conduct a user study where participants solve programming problems (with and without Copilot assistance) that have potentially vulnerable solutions. The main goal of the user study is to determine how the use of Copilot affects participants' security performance. In our set of participants (n=25), we find that access to Copilot accompanies a more secure solution when tackling harder problems. For the easier problem, we observe no effect of Copilot access on the security of solutions. We also observe no disproportionate impact of Copilot use on particular kinds of vulnerabilities. Our results indicate that there are potential security benefits to using Copilot, but more research is warranted on the effects of the use of code generation tools on technically complex problems with security requirements.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548424","user study;code generation;copilot;security;software engineering","Productivity;Deep learning;Codes;Writing;Programming;Natural language processing;Security","","","","24","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Improving Machine Translation Systems via Isotopic Replacement","Z. Sun; J. M. Zhang; Y. Xiong; M. Harman; M. Papadakis; L. Zhang","Key Laboratory of High Confidence Software Technologies, MoE, School of Computer Science, Peking University; University College London; Key Laboratory of High Confidence Software Technologies, MoE, School of Computer Science, Peking University; Meta platforms, University College London; University of Luxembourg; Key Laboratory of High Confidence Software Technologies, MoE, School of Computer Science, Peking University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1181","1192","Machine translation plays an essential role in people's daily international communication. However, machine translation systems are far from perfect. To tackle this problem, researchers have proposed several approaches to testing machine translation. A promising trend among these approaches is to use word replacement, where only one word in the original sentence is replaced with another word to form a sentence pair. However, precise control of the impact of word replacement remains an outstanding issue in these approaches. To address this issue, we propose CAT, a novel word-replacement-based approach, whose basic idea is to identify word replacement with controlled impact (referred to as isotopic replacement). To achieve this purpose, we use a neural-based language model to encode the sentence context, and design a neural-network-based algorithm to evaluate context-aware semantic similarity between two words. Furthermore, similar to TransRepair, a state-of-the-art word-replacement-based approach, CAT also provides automatic fixing of revealed bugs without model retraining. Our evaluation on Google Translate and Transformer indicates that CAT achieves significant improvements over TransRepair. In particular, 1) CAT detects seven more types of bugs than TransRe-pair; 2) CAT detects 129% more translation bugs than TransRepair; 3) CAT repairs twice more bugs than TransRepair, many of which may bring serious consequences if left unfixed; and 4) CAT has better efficiency than TransRepair in input generation (0.01s v.s. 0.41s) and comparable efficiency with TransRepair in bug repair (1.92s v.s. 1.34s).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510206","National Key Research and Development Program of China(grant numbers:2019YFE0198100); Innovation and Technology Commission of HKSAR(grant numbers:MHP/055/19); National Natural Science Foundation of China(grant numbers:61922003); ERC(grant numbers:741278); Luxembourg National Research Fund (FNR)(grant numbers:C17/IS/11686509/CODEMATES); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793859","machine translation;testing and repair;machine learning testing;neural networks","Computer bugs;Semantics;Maintenance engineering;Transformers;Market research;Internet;Machine translation","","10","","40","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively Tuning Pre-Trained Code Models","S. Gao; W. Mao; C. Gao; L. Li; X. Hu; X. Xia; M. R. Lyu","The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Beihang university, Beijing, China; Zhejiang university, Zhejiang, China; Zhejiang university, Zhejiang, China; The Chinese University of Hong Kong, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","969","981","Pre-trained code models have recently achieved substantial improvements in many code intelligence tasks. These models are first pre-trained on large-scale unlabeled datasets in a task-agnostic manner using self-supervised learning, and then fine-tuned on labeled datasets in downstream tasks. However, the labeled datasets are usually limited in size (i.e., human intensive efforts), which may hinder the performance of pre-trained code models in specific tasks. To mitigate this, one possible solution is to leverage the large-scale unlabeled data in the tuning stage by pseudo-labeling, i.e., generating pseudo labels for unlabeled data and further training the pre-trained code models with the pseudo-labeled data. However, directly employing the pseudo-labeled data can bring a large amount of noise, i.e., incorrect labels, leading to suboptimal performance. How to effectively leverage the noisy pseudo-labeled data is a challenging yet under-explored problem. In this paper, we propose a novel approach named HINT to improve pre-trained code models with large-scale unlabeled datasets by better utilizing the pseudo-labeled data. HINT includes two main modules: HybrId pseudo-labeled data selection and Noise-tolerant Training. In the hybrid pseudo-data selection module, considering the robustness issue, apart from directly measuring the quality of pseudo labels through training loss, we propose to further employ a retrieval-based method to filter low-quality pseudo-labeled data. The noise-tolerant training module aims to further mitigate the influence of errors in pseudo labels by training the model with a noise-tolerant loss function and by regularizing the consistency of model predictions. We evaluate the effectiveness of HINT on three popular code intelligence tasks, including code summarization, defect detection, and assertion generation. We build our method on top of three popular open-source pre-trained code models. The experimental results show that HINT can better leverage those unlabeled data in a task-specific way and provide complementary benefits for pre-trained models, e.g., improving the best baseline model by 15.33%, 16.50%, and 8.98% on code summarization, defect detection, and assertion generation, respectively.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549593","Software and its engineering → Software development techniques","Training;Codes;Source coding;Predictive models;Data models;Task analysis;Tuning","","","","74","","14 Jun 2024","","","IEEE","IEEE Conferences"
"ViolationTracker: Building Precise Histories for Static Analysis Violations","P. Yu; Y. Wu; X. Peng; J. Peng; J. Zhang; P. Xie; W. Zhao","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2022","2034","Automatic static analysis tools (ASATs) detect source code violations to static analysis rules and are usually used as a guard for source code quality. The adoption of ASATs, however, is often challenged because of several problems such as a large number of false alarms, invalid rule priorities, and inappropriate rule configurations. Research has shown that tracking the history of the violations is a promising way to solve the above problems because the facts of violation fixing may reflect the developers' subjective expectations on the violation detection results. Precisely identifying the revisions that induce or fix a violation is however challenging because of the imprecise matching of violations between code revisions and ignorance of merge commits in the maintenance history. In this paper, we propose ViolationTracker, an approach to precisely matching the violation instances between adjacent revisions and building the life cycle of violations with the identification of inducing, fixing, deleting, and reopening of each violation case. The approach employs code entity anchoring heuristics for violation matching and considers merge commits that used to be ignored in existing research. We evaluate ViolationTracker with a manually-validated dataset that consists of 500 violation instances and 158 threads of 30 violation cases with detailed evolution history from open-source projects. Violation Tracker achieves over 93 % precision and 98 % recall on violation matching, outperforming the state-of-the-art approach, and 99.4 % precision on rebuilding the histories of violation cases. We also show that ViolationTracker is useful to identify actionable violations. A preliminary empirical study reveals the possibility to prioritize static analysis rules according to further analysis on the actionable rates of the rules.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00171","National Natural Science Foundation of China(grant numbers:62172099); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172698","","Codes;Source coding;Buildings;Static analysis;Manuals;Maintenance engineering;History","","","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Leveraging test generation and specification mining for automated bug detection without false positives","M. Pradel; T. R. Gross","Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","288","298","Mining specifications and using them for bug detection is a promising way to reveal bugs in programs. Existing approaches suffer from two problems. First, dynamic specification miners require input that drives a program to generate common usage patterns. Second, existing approaches report false positives, that is, spurious warnings that mislead developers and reduce the practicability of the approach. We present a novel technique for dynamically mining and checking specifications without relying on existing input to drive a program and without reporting false positives. Our technique leverages automatically generated tests in two ways: Passing tests drive the program during specification mining, and failing test executions are checked against the mined specifications. The output are warnings that show with concrete test cases how the program violates commonly accepted specifications. Our implementation reports no false positives and 54 true positives in ten well-tested Java programs.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227185","Bug detection;Specification mining;False positives","Protocols;Generators;Computer bugs;Receivers;Concrete;Runtime","","37","1","44","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"A Universal Data Augmentation Approach for Fault Localization","H. Xie; Y. Lei; M. Yan; Y. Yu; X. Xia; X. Mao","School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; National University of Defense Technology, Changsha, China; Software Engineering Application Technology Lab, Huawei, China; National University of Defense Technology, Changsha, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","48","60","Data is the fuel to models, and it is still applicable in fault localization (FL). Many existing elaborate FL techniques take the code coverage matrix and failure vector as inputs, expecting the techniques could find the correlation between program entities and failures. However, the input data is high-dimensional and extremely imbalanced since the real-world programs are large in size and the number of failing test cases is much less than that of passing test cases, which are posing severe threats to the effectiveness of FL techniques. To overcome the limitations, we propose Aeneas, a universal data augmentation approach that generAtes synthesized failing test cases from reduced feature sace for more precise fault localization. Specifically, to improve the effectiveness of data augmentation, Aeneas applies a revised principal component analysis (PCA) first to generate reduced feature space for more concise representation of the original coverage matrix, which could also gain efficiency for data synthesis. Then, Aeneas handles the imbalanced data issue through generating synthesized failing test cases from the reduced feature space through conditional variational autoencoder (CVAE). To evaluate the effectiveness of Aeneas, we conduct large-scale experiments on 458 versions of 10 programs (from ManyBugs, SIR, and Defects4J) by six state-of-the-art FL techniques. The experimental results clearly show that Aeneas is statistically more effective than baselines, e.g., our approach can improve the six original methods by 89% on average under the Top-1 accuracy.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510136","National Key Research and Development Project of China(grant numbers:2020YFB1711900); National Defense Basic Scientific Research Project(grant numbers:WDZC20 205500308); Fundamental Research Funds for the Central Universities(grant numbers:2021CDJQY-018); National Natural Science Foundation of China(grant numbers:62002034); Natural Science Foundation of Chongqing(grant numbers:cstc2021jcyj-msxmX0538); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793942","Fault Localization;Imbalanced Data;Data Augmentation","Location awareness;Correlation;Codes;Pipelines;Feature extraction;Data models;Fuels","","15","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Out of Context: How Important is Local Context in Neural Program Repair?","J. A. Prenner; R. Robbes","Free University of Bozen/Bolzano, Bozen/Bolzano, Italy; CNRS, Univ. Bordeaux, Bordeaux INP, LaBRI, Talence, France",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1008","1020","Deep learning source code models have been applied very successfully to the problem of automated program repair. One of the standing issues is the small input window of current models which often cannot fully fit the context code required for a bug fix (e.g., method or class declarations of a project). Instead, input is often restricted to the local context, that is, the lines below and above the bug location. In this work we study the importance of this local context on repair success: how much local context is needed?; is context before or after the bug location more important? how is local context tied to the bug type? To answer these questions we train and evaluate Transformer models in many different local context configurations on three datasets and two programming languages. Our results indicate that overall repair success increases with the size of the local context (albeit not for all bug types) and confirm the common practice that roughly 50-60% of the input window should be used for context leading the bug. Our results are not only relevant for researchers working on Transformer-based APR tools but also for benchmark and dataset creators who must decide what and how much context to include in their datasets.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549171","automated program repair;data-driven software engineering","Training;Deep learning;Computer languages;Source coding;Computer bugs;Maintenance engineering;Transformers","","","","49","","14 Jun 2024","","","IEEE","IEEE Conferences"
"PyAnalyzer: An Effective and Practical Approach for Dependency Extraction from Python Code","W. Jin; S. Xu; D. Chen; J. He; D. Zhong; M. Fan; H. Chen; H. Zhang; T. Liu","Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Huawei Technologies Co., Ltd, Shenzhen, China; Huawei Technologies Co., Ltd, Shenzhen, China; Xi'an Jiaotong University, Xi'an, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1372","1383","Dependency extraction based on static analysis lays the ground-work for a wide range of applications. However, dynamic language features in Python make code behaviors obscure and nondeter-ministic; consequently, it poses huge challenges for static analyses to resolve symbol-level dependencies. Although prosperous techniques and tools are adequately available, they still lack sufficient capabilities to handle object changes, first-class citizens, varying call sites, and library dependencies. To address the fundamental difficulty for dynamic languages, this work proposes an effective and practical method namely PyAnalyzer for dependency extraction. PyAnalyzer uniformly models functions, classes, and modules into first-class heap objects, propagating the dynamic changes of these objects and class inheritance. This manner better simulates dynamic features like duck typing, object changes, and first-class citizens, resulting in high recall results without compromising pre-cision. Moreover, PyAnalyzer leverages optional type annotations as a shortcut to express varying call sites and resolve library depen-dencies on demand. We collected two micro-benchmarks (278 small programs), two macro-benchmarks (59 real-world applications), and 191 real-world projects (10MSLOC) for comprehensive comparisons with 7 advanced techniques (i.e., Understand, Sourcetrail, Depends, ENRE19, PySonar2, PyCG, and Type4Py). The results demonstrated that PyAnalyzer achieves a high recall and hence improves the F1 by 24.7% on average, at least 1.4x faster without an obvious compromise of memory efficiency. Our work will benefit diverse client applications.","1558-1225","979-8-4007-0217-4","","National Key R&D Program of China(grant numbers:2022YFB2703500); National Natural Science Foundation of China(grant numbers:62232014,62272377,62293501,62293502,62032010,62372368,62372367,62272387); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549350","Dependency Extraction;Python;Dynamic Features","Codes;Annotations;Memory management;Static analysis;Feature extraction;Libraries;Task analysis","","","","65","","14 Jun 2024","","","IEEE","IEEE Conferences"
"An empirical study about the effectiveness of debugging when random test cases are used","M. Ceccato; A. Marchetto; L. Mariani; C. D. Nguyen; P. Tonella","Fondazione Bruno Kessler (FBK), Trento, Italy; Fondazione Bruno Kessler (FBK), Trento, Italy; University of Milano-Bicocca, Milano, Italy; Fondazione Bruno Kessler (FBK), Trento, Italy; Fondazione Bruno Kessler (FBK), Trento, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","452","462","Automatically generated test cases are usually evaluated in terms of their fault revealing or coverage capability. Beside these two aspects, test cases are also the major source of information for fault localization and fixing. The impact of automatically generated test cases on the debugging activity, compared to the use of manually written test cases, has never been studied before. In this paper we report the results obtained from two controlled experiments with human subjects performing debugging tasks using automatically generated or manually written test cases. We investigate whether the features of the former type of test cases, which make them less readable and understandable (e.g., unclear test scenarios, meaningless identifiers), have an impact on accuracy and efficiency of debugging. The empirical study is aimed at investigating whether, despite the lack of readability in automatically generated test cases, subjects can still take advantage of them during debugging.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227170","Empirical Software Engineering;Debugging;Automatic Test Case Generation","Debugging;Accuracy;Manuals;Complexity theory;Measurement;Training;Testing","","13","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Automated Black-Box Testing of Mass Assignment Vulnerabilities in RESTful APIs","D. Corradini; M. Pasqua; M. Ceccato","Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2553","2564","Mass assignment is one of the most prominent vulnerabilities in RESTful APIs that originates from a misconfiguration in common web frameworks. This allows attackers to exploit naming convention and automatic binding to craft malicious requests that (massively) override data supposed to be read-only. In this paper, we adopt a black-box testing perspective to automatically detect mass assignment vulnerabilities in RESTful APIs. Indeed, execution scenarios are generated purely based on the OpenAPI specification, that lists the available operations and their message format. Clustering is used to group similar operations and reveal read-only fields, the latter are candidates for mass assignment. Then, test interaction sequences are automatically generated by instantiating abstract testing templates, with the aim of trying to use the found read-only fields to carry out a mass assignment attack. Test interactions are run, and their execution is assessed by a specific oracle, in order to reveal whether the vulnerability could be successfully exploited. The proposed novel approach has been implemented and evaluated on a set of case studies written in different programming languages. The evaluation highlights that the approach is quite effective in detecting seeded vulnerabilities, with a remarkably high accuracy.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00213","Italian Ministry of University and Research(grant numbers:40-G-14702-3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172607","REST API;Security testing;Black-box testing;Automated software testing;Mass assignment","Knowledge engineering;Authorization;Computer languages;Databases;Closed box;Restful API;Programming","","2","","29","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Fault Localization via Efficient Probabilistic Modeling of Program Semantics","M. Zeng; Y. Wu; Z. Ye; Y. Xiong; X. Zhang; L. Zhang","Key Laboratory of High Confidence Software Technologies, School of Computer Science, Ministry of Education (Peking University), Peking University, Beijing, PR, China; Key Laboratory of High Confidence Software Technologies, School of Computer Science, Ministry of Education (Peking University), Peking University, Beijing, PR, China; Key Laboratory of High Confidence Software Technologies, School of Computer Science, Ministry of Education (Peking University), Peking University, Beijing, PR, China; Key Laboratory of High Confidence Software Technologies, School of Computer Science, Ministry of Education (Peking University), Peking University, Beijing, PR, China; Key Laboratory of High Confidence Software Technologies, School of Computer Science, Ministry of Education (Peking University), Peking University, Beijing, PR, China; Key Laboratory of High Confidence Software Technologies, School of Computer Science, Ministry of Education (Peking University), Peking University, Beijing, PR, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","958","969","Testing-based fault localization has been a significant topic in software engineering in the past decades. It localizes a faulty program element based on a set of passing and failing test executions. Since whether a fault could be triggered and detected by a test is related to program semantics, it is crucial to model program semantics in fault localization approaches. Existing approaches either consider the full semantics of the program (e.g., mutation-based fault localization and angelic debugging), leading to scalability issues, or ignore the semantics of the program (e.g., spectrum-based fault localization), leading to imprecise localization results. Our key idea is: by modeling only the correctness of program values but not their full semantics, a balance could be reached between effectiveness and scalability. To realize this idea, we introduce a probabilistic approach to model program semantics and utilize information from static analysis and dynamic execution traces in our modeling. Our approach, SmartFL (SeMantics bAsed pRobabilisTic Fault Localization), is evaluated on a real-world dataset, Defects4J. The top-1 statement-level accuracy of our approach is 21 %, which is the best among state-of-the-art methods. The average time cost is 210 seconds per fault while existing methods that capture full semantics are often 10x or more slower.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793888","fault localization;semantics;probabilistic modeling","Location awareness;Analytical models;Scalability;Semantics;Static analysis;Debugging;Probabilistic logic","","6","","38","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Default: Mutual Information-based Crash Triage for Massive Crashes","X. Zhang; J. Chen; C. Feng; R. Li; W. Diao; K. Zhang; J. Lei; C. Tang","National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; School of Cyber Science and Technology, Shandong University; Chinese University of Hong Kong; National University of Defense Technology; National University of Defense Technology",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","635","646","With the considerable success achieved by modern fuzzing in-frastructures, more crashes are produced than ever before. To dig out the root cause, rapid and faithful crash triage for large numbers of crashes has always been attractive. However, hindered by the practical difficulty of reducing analysis imprecision without compromising efficiency, this goal has not been accomplished. In this paper, we present an end-to-end crash triage solution Default, for accurately and quickly pinpointing unique root cause from large numbers of crashes. In particular, we quantify the “crash relevance” of program entities based on mutual information, which serves as the criterion of unique crash bucketing and allows us to bucket massive crashes without pre-analyzing their root cause. The quantification of “crash relevance” is also used in the shortening of long crashing traces. On this basis, we use the interpretability of neural networks to precisely pinpoint the root cause in the shortened traces by evaluating each basic block's impact on the crash label. Evaluated with 20 programs with 22216 crashes in total, Default demonstrates remarkable accuracy and performance, which is way beyond what the state-of-the-art techniques can achieve: crash de-duplication was achieved at a super-fast processing speed - 0.017 seconds per crashing trace, without missing any unique bugs. After that, it identifies the root cause of 43 unique crashes with no false negatives and an average false positive rate of 9.2%.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3512760","National Natural Science Foundation of China(grant numbers:61902148); Qilu Young Scholar Program of Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793954","Crash Triage;Software Security","Location awareness;Software algorithms;Neural networks;Computer bugs;Fuzzing;Computer crashes;Security","","","","53","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Where does this code come from and where does it go? — Integrated code history tracker for open source systems","K. Inoue; Y. Sasaki; P. Xia; Y. Manabe","Osaka University, Osaka, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan; Osaka University, Osaka, Japan",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","331","341","When we reuse a code fragment in an open source system, it is very important to know the history of the code, such as the code origin and evolution. In this paper, we propose an integrated approach to code history tracking for open source repositories. This approach takes a query code fragment as its input, and returns the code fragments containing the code clones with the query code. It utilizes publicly available code search engines as external resources. Based on this model, we have designed and implemented a prototype system named Ichi Tracker. Using Ichi Tracker, we have conducted three case studies. These case studies show the ancestors and descendents of the code, and we can recognize their evolution history.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227181","Code Search;Software Evolution;Open Source System","Search engines;Cloning;History;Google;Licenses;Strontium;Engines","","22","","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Using an LLM to Help with Code Understanding","D. Nam; A. Macvean; V. Hellendoorn; B. Vasilescu; B. Myers","Carnegie Mellon University, U.S.A.; Google, Inc., U.S.A.; Carnegie Mellon University, U.S.A.; Carnegie Mellon University, U.S.A.; Carnegie Mellon University, U.S.A.",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1184","1196","Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domainspecific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548827","User study;LLM;Program comprehension;Information support;Developer tool","Codes;Navigation;Prototypes;Documentation;Task analysis;Web search;Software engineering","","3","","79","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Demystifying Compiler Unstable Feature Usage and Impacts in the Rust Ecosystem","C. Li; Y. Wu; W. Shen; Z. Zhao; R. Chang; C. Liu; Y. Liu; K. Ren","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Nanyang Technological University Singapore, Singapore; Nanyang Technological University Singapore, Singapore; Zhejiang University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","266","278","Rust programming language is gaining popularity rapidly in building reliable and secure systems due to its security guarantees and outstanding performance. To provide extra functionalities, the Rust compiler introduces Rust unstable features (RUF) to extend compiler functionality, syntax, and standard library support. However, these features are unstable and may get removed, introducing compilation failures to dependent packages. Even worse, their impacts propagate through transitive dependencies, causing large-scale failures in the whole ecosystem. Although RUF is widely used in Rust, previous research has primarily concentrated on Rust code safety, with the usage and impacts of RUF from the Rust compiler remaining unexplored. Therefore, we aim to bridge this gap by systematically analyzing the RUF usage and impacts in the Rust ecosystem. We propose novel techniques for extracting RUF precisely, and to assess its impact on the entire ecosystem quantitatively, we accurately resolve package dependencies. We have analyzed the whole Rust ecosystem with 590K package versions and 140M transitive dependencies. Our study shows that the Rust ecosystem uses 1000 different RUF, and at most 44% of package versions are affected by RUF, causing compiling failures for at most 12% of package versions. To mitigate wide RUF impacts, we further design and implement a RUF-compilation-failure recovery tool that can recover up to 90% of the failure. We believe our techniques, findings, and tools can help stabilize the Rust compiler, ultimately enhancing the security and reliability of the Rust ecosystem.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623352","National Key R&D Program of China(grant numbers:2022YFB3103900); National Natural Science Foundation of China(grant numbers:62002317); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549570","Rust ecosystem;Rust unstable feature;Dependency graph","Ecosystems;Semantics;Syntactics;Reliability engineering;Libraries;Software reliability;Safety","","1","","66","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Testing Time Limits in Screener Questions for Online Surveys with Programmers","A. Danilova; S. Horstmann; M. Smith; A. Naiakshina","University of Bonn; University of Bonn; Fraunhofer FKIE, University of Bonn; University of Bonn",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2080","2090","Recruiting study participants with programming skill is essential for researchers. As programming is not a common skill, recruiting programmers as participants in large numbers is challenging. Plat-forms like Amazon MTurk or Qualtrics offer to recruit participants with programming knowledge. As this is self-reported, participants without programming experience could still take part, either due to a misunderstanding or to obtain the study compensation. If these participants are not detected, the data quality will suffer. To tackle this, Danilova et al. [11] developed and tested screening tasks to detect non-programmers. Unfortunately, the most reliable screen-ers were also those that took the most time. Since screeners should take as little time as possible, we examine whether the introduction of time limits allows us to create more efficient (i.e., quicker but still reliable) screeners. Our results show that this is possible and we extend the pool of screeners and make recommendations on how to improve the process.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794125","Developer Study;Methodology Developer Studies","Data integrity;Programming;Reliability engineering;Software reliability;Time factors;Task analysis;Testing","","1","","33","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Extrapolating Coverage Rate in Greybox Fuzzing","D. Liyanage; S. Lee; C. Tantithamthavorn; M. Böhme","Monash University, Australia; MPI-SP, Germany; Monash University, Australia; MPI-SP, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1623","1634","A fuzzer can literally run forever. However, as more resources are spent, the coverage rate continuously drops, and the utility of the fuzzer declines. To tackle this coverage-resource tradeoff, we could introduce a policy to stop a campaign whenever the coverage rate drops below a certain threshold value, say 10 new branches covered per 15 minutes. During the campaign, can we predict the coverage rate at some point in the future? If so, how well can we predict the future coverage rate as the prediction horizon or the current campaign length increases? How can we tackle the statistical challenge of adaptive bias, which is inherent in greybox fuzzing (i.e., samples are not independent and identically distributed)? In this paper, we i) evaluate existing statistical techniques to predict the coverage rate $U(t_{0}+k)$ at any time $t_{0}$ in the campaign after a period of $k$ units of time in the future and ii) develop a new extrapolation methodology that tackles the adaptive bias. We propose to efficiently simulate a large number of blackbox campaigns from the collected coverage data, estimate the coverage rate for each of these blackbox campaigns and conduct a simple regression to extrapolate the coverage rate for the greybox campaign. Our empirical evaluation using the Fuzztastic fuzzer benchmark demonstrates that our extrapolation methodology exhibits at least one order of magnitude lower error compared to the existing benchmark for 4 out of 5 experimental subjects we investigated. Notably, compared to the existing extrapolation methodology, our extrapola-tor excels in making long-term predictions, such as those extending up to three times the length of the current campaign.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548757","greybox fuzzing;extrapolation;coverage rate;adaptive bias;statistical method","Extrapolation;Closed box;Fuzzing;Benchmark testing;Software engineering","","","","30","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Application of Self-Adaptive techniques to federated authorization models","C. Bailey","School of Computing, University of Kent, Canterbury, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1495","1498","Authorization infrastructures are an integral part of any network where resources need to be protected. As organisations start to federate access to their resources, authorization infrastructures become increasingly difficult to manage, to a point where relying only on human resources becomes unfeasible. In our work, we propose a Self-Adaptive Authorization Framework (SAAF) that is capable of monitoring the usage of resources, and controlling access to resources through the manipulation of authorization assets (e.g., authorization policies, access rights and sessions), due to the identification of abnormal usage. As part of this work, we explore the use of models for facilitating the autonomic management of federated authorization infrastructures by 1) classifying access behaviour exhibited by users, 2) modelling authorization assets, including usage, for identifying abnormal behaviour, and 3) managing authorization through the adaptation and reflection of modelled authorization assets. SAAF will be evaluated by integrating it into an existing authorization infrastructure that would allow the simulation of abnormal usage scenarios.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227053","self-adaptation;model driven engineering;model transformation;authorization;computing security","Authorization;Adaptation models;Unified modeling language;Permission;Computational modeling;Monitoring","","3","","14","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"“Did You Miss My Comment or What?” Understanding Toxicity in Open Source Discussions","C. Miller; S. Cohen; D. Klug; B. Vasilescu; C. Kästner",Carnegie Mellon University; Wesleyan University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","710","722","Online toxicity is ubiquitous across the internet and its negative impact on the people and that online communities that it effects has been well documented. However, toxicity manifests differently on various platforms and toxicity in open source communities, while frequently discussed, is not well understood. We take a first stride at understanding the characteristics of open source toxicity to better inform future work on designing effective intervention and detection methods. To this end, we curate a sample of 100 toxic GitHub issue discussions combining multiple search and sampling strategies. We then qualitatively analyze the sample to gain an understanding of the characteristics of open-source toxicity. We find that the pervasive forms of toxicity in open source differ from those observed on other platforms like Reddit or Wikipedia. In our sample, some of the most prevalent forms of toxicity are entitled, demanding, and arrogant comments from project users as well as insults arising from technical disagreements. In addition, not all toxicity was written by people external to the projects; project members were also common authors of toxicity. We also discuss the implications of our findings. Among others we hope that our findings will be useful for future detection work.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510111","National Science Foundation(grant numbers:DGE1745016,DGE2140739,1901311,2107298); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794094","open source software;online toxicity;software development","Toxicology;Social networking (online);Hate speech;Encyclopedias;Internet;Online services;Open source software","","12","","112","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"BugRedux: Reproducing field failures for in-house debugging","W. Jin; A. Orso","Georgia Institute of Technology, USA; Georgia Institute of Technology, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","474","484","A recent survey conducted among developers of the Apache, Eclipse, and Mozilla projects showed that the ability to recreate field failures is considered of fundamental importance when investigating bug reports. Unfortunately, the information typically contained in a bug report, such as memory dumps or call stacks, is usually insufficient for recreating the problem. Even more advanced approaches for gathering field data and help in-house debugging tend to collect either too little information, and be ineffective, or too much information, and be inefficient. To address these issues, we present BugRedux, a novel general approach for in-house debugging of field failures. BugRedux aims to synthesize, using execution data collected in the field, executions that mimic the observed field failures. We define several instances of BugRedux that collect different types of execution data and perform, through an empirical study, a cost-benefit analysis of the approach and its variations. In the study, we apply BugRedux to 16 failures of 14 real-world programs. Our results are promising in that they show that it is possible to synthesize in-house executions that reproduce failures observed in the field using a suitable set of execution data.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227168","","Computer crashes;Software;Instruments;Debugging;Optical fibers;MIMICs;Generators","","116","","42","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Assisting end-user development in browser-based mashup tools","S. R. Chowdhury","DISI, University of Trento, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1625","1627","Despite the recent progresses in end-user development and particularly in mashup application development, developing even simple mashups is still non-trivial and requires intimate knowledge about the functionality of web APIs and services, their interfaces, parameter settings, data mappings, and so on. We aim to assist less skilled developers in composing own mashups by interactively recommending composition knowledge in the form of modeling patterns and fostering knowledge reuse. Our prototype system demonstrates our idea of interactive recommendation and automated pattern weaving, which involves recommending relevant composition patterns to the users during development, and once selected, applying automatically the changes as suggested in the selected pattern to the mashup model under development. The experimental evaluation of our prototype implementation demonstrates that even complex composition patterns can be efficiently stored, queried and weaved into the model under development in browser-based mashup tools.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227222","assisted development;end-user development;composition pattern;pattern recommendation;weaving","Mashups;Weaving;Context modeling;Load modeling;Engines;Programming;Prototypes","","5","1","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"PerfSig: Extracting Performance Bug Signatures via Multi-modality Causal Analysis","J. He; Y. Lin; X. Gu; C. -C. M. Yeh; Z. Zhuang","ShanghaiTech University, Shanghai, China; North Carolina State University, Raleigh, NC, USA; North Carolina State University, Raleigh, NC, USA; Visa Research, Palo Alto, CA, USA; Visa Research, Palo Alto, CA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1669","1680","Diagnosing a performance bug triggered in production cloud environments is notoriously challenging. Extracting performance bug signatures can help cloud operators quickly pinpoint the problem and avoid repeating manual efforts for diagnosing similar performance bugs. In this paper, we present PerfSig, a multi-modality performance bug signature extraction tool which can identify principal anomaly patterns and root cause functions for performance bugs. PerfSig performs fine-grained anomaly detection over various machine data such as system metrics, system logs, and function call traces. We then conduct causal analysis across different machine data using information theory method to pinpoint the root cause function of a performance bug. PerfSig generates bug signatures as the combination of the identified anomaly patterns and root cause functions. We have implemented a prototype of PerfSig and conducted evaluation using 20 real world performance bugs in six commonly used cloud systems. Our experimental results show that PerfSig captures various kinds of fine-grained anomaly patterns from different machine data and successfully identifies the root cause functions through multi-modality causal analysis for 19 out of 20 tested performance bugs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510110","NSF(grant numbers:CNS1513942,CNS1149445); NSA(grant numbers:H98230-17-D-0080); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793858","Debugging;Bug signatures;Software reliability;Performance","Measurement;Computer bugs;Prototypes;Production;Reliability engineering;Software reliability;System analysis and design","","1","","59","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Detecting Dialog-Related Keyboard Navigation Failures in Web Applications","P. T. Chiou; A. S. Alotaibi; W. G. J. Halfond","University of Southern California, USA; University of Southern California, USA; University of Southern California, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1368","1380","The ability to navigate the Web via the keyboard interface is critical to people with various types of disabilities. However, modern websites often violate web accessibility guidelines for keyboard navigability with respect to web dialogs. In this paper, we present a novel approach for automatically detecting web accessibility bugs that prevent or hinder keyboard users' ability to navigate dialogs in web pages. An extensive evaluation of our technique on real-world subjects showed that our technique is effective in detecting these dialog-related keyboard navigation failures.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00120","National Science Foundation(grant numbers:2009045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172835","Web Accessibility;WCAG;Software Testing;Keyboard Navigation;Dialog;Keyboard Accessibility;Web Dialog;Accessible Dialog;Dialog Accessibility","Navigation;Computer bugs;Keyboards;Web pages;Debugging;Software engineering;Guidelines","","1","","74","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"MiniMon: Minimizing Android Applications with Intelligent Monitoring-based Debloating","J. Liu; Z. Zhang; X. Hu; F. Thung; S. Maoz; D. Gao; E. Toch; Z. Zhao; D. Lo","Singapore Management University, Singapore; Singapore Management University, Singapore; Zhejiang University Hangzhou, Zhejiang, China; Singapore Management University, Singapore; Tel Aviv University, Israel; Singapore Management University, Singapore; Tel Aviv University, Israel; Singapore Management University, Singapore; Singapore Management University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2542","2554","The size of Android applications is getting larger to fulfill the requirements of various users. However, not all the features of the applications are needed and desired by a specific user. The unnecessary and non-desired features can increase the attack surface and consume system resources such as storage and memory. To address this issue, we propose a framework, MiniMon, to debloat unnecessary features from an Android app based on the logs of specific users' interactions with the app. However, rarely used features may not be recorded during the data collection, and users' preferences may change slightly over time. To address these challenges, we embed several solutions in our framework that can uncover user-desired features by learning and generalizing from the logs of how users interact with an application. MiniMon first collects the application methods that are executed when users interact with it. Then, given the collected executed methods and the call graph of the application, MiniMon applies 10 techniques to generalize from logs. These include three program analysis-based techniques, two graph clustering-based techniques, and five graph embedding-based techniques to identify the additional methods in an app that are similar to the logged executed methods. Finally, MiniMon generates a debloated application by removing methods that are not similar to the executed methods. To evaluate the performance of variants of MiniMon that use different generalization techniques, we create a benchmark for a controlled experiment. The results show that the graph embedding-based generalization technique that considers the information of all nodes in the call graph is the best, and can correctly uncover 75.5% of the unobserved but desired behaviors and still debloat more than half of the app. We also conducted a user study that uncovers that the use of the intelligent (generalization) method of MiniMon boosts the overall user satisfaction rate by 37.6%.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639113","National Research Foundation(grant numbers:NCRP25-P03-NCR-TAU); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549273","Android;Software Debloating;Log Analysis","Operating systems;Data collection;Benchmark testing;Monitoring;Software engineering","","","","71","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Toward Improved Deep Learning-Based Vulnerability Detection","A. Sejfia; S. Das; S. Shafiq; N. Medvidović","University of Southern California, California, USA; University of Southern California, California, USA; Johannes Kepler University, Austria; University of Southern California, California, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","741","752","Deep learning (DL) has been a common thread across several recent techniques for vulnerability detection. The rise of large, publicly available datasets of vulnerabilities has fueled the learning process underpinning these techniques. While these datasets help the DL-based vulnerability detectors, they also constrain these detectors' predictive abilities. Vulnerabilities in these datasets have to be represented in a certain way, e.g., code lines, functions, or pro-gram slices within which the vulnerabilities exist. We refer to this representation as a base unit. The detectors learn how base units can be vulnerable and then predict whether other base units are vulnerable. We have hypothesized that this focus on individual base units harms the ability of the detectors to properly detect those vul-nerabilities that span multiple base units (or MBU vulnerabilities). For vulnerabilities such as these, a correct detection occurs when all comprising base units are detected as vulnerable. Verifying how existing techniques perform in detecting all parts of a vulnerability is important to establish their effectiveness for other downstream tasks. To evaluate our hypothesis, we conducted a study focusing on three prominent DL-based detectors: ReVeal, DeepWukong, and LineVul. Our study shows that all three detectors contain MBU vulnerabilities in their respective datasets. Further, we observed significant accuracy drops when detecting these types of vulner-abilities. We present our study and a framework that can be used to help DL-based detectors toward the proper inclusion of MBU vulnerabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608141","National Science Foundation(grant numbers:182335); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549730","vulnerability detection;deep learning;software vulnerabilities;vulnerability dataets","Deep learning;Codes;Accuracy;Focusing;Detectors;Task analysis;Software engineering","","","","43","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automatically Detecting Reflow Accessibility Issues in Responsive Web Pages","P. T. Chiou; R. Winn; A. S. Alotaibi; W. G. J. Halfond","University of Southern California, USA; University of Southern California, USA; University of Southern California, USA; University of Southern California, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1811","1823","Many web applications today use responsive design to adjust the view of web pages to match the screen size of end users. People with disabilities often use an alternative view either due to zooming on a desktop device to enlarge text or viewing within a smaller view-port when using assistive technologies. When web pages are not implemented to correctly adjust the page's content across different screen sizes, it can lead to both a loss of content and functionalities between the different versions. Recent studies show that these re-flow accessibility issues are among the most prevalent modern web accessibility issues. In this paper, we present a novel automated technique to automatically detect reflow accessibility issues in web pages for keyboard users. The evaluation of our approach on real-world web pages demonstrated its effectiveness in detecting reflow accessibility issues, outperforming state-of-the-art techniques.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639229","National Science Foundation(grant numbers:2009045); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548318","Web Accessibility;WCAG;Software Testing;Response Web Design;Reflow;Keyboard Accessibility;Inclusive Design","Layout;Web pages;Keyboards;Assistive technologies;User experience;Software engineering","","","","93","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated analysis of CSS rules to support style maintenance","A. Mesbah; S. Mirshokraie","University of British Columbia, Canada; University of British Columbia, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","408","418","CSS is a widely used language for describing the presentation semantics of HTML elements on the web. The language has a number of characteristics, such as inheritance and cascading order, which makes maintaining CSS code a challenging task for web developers. As a result, it is common for unused rules to be accumulated over time. Despite these challenges, CSS analysis has not received much attention from the research community. We propose an automated technique to support styling code maintenance, which (1) analyzes the runtime relationship between the CSS rules and DOM elements of a given web application (2) detects unmatched and ineffective selectors, overridden declaration properties, and undefined class values. Our technique, implemented in an open source tool called Cilla, has a high precision and recall rate. The results of our case study, conducted on fifteen open source and industrial web-based systems, show an average of 60% unused CSS selectors in deployed applications, which points to the ubiquity of the problem.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227174","Cascading style sheets;CSS;dynamic analysis;software maintenance;web applications","Cascading style sheets;Color;HTML;Maintenance engineering;Runtime;Layout;Browsers","","23","5","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Repairing Order-Dependent Flaky Tests via Test Generation","C. Li; C. Zhu; W. Wang; A. Shi","The University of Texas at Austin, Austin, TX, USA; The University of Texas at Austin, Austin, TX, USA; The University of Texas at Austin, Austin, TX, USA; The University of Texas at Austin, Austin, TX, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1881","1892","Flaky tests are tests that pass or fail nondeterministically on the same version of code. These tests can mislead developers concerning the quality of their code changes during regression testing. A common kind of flaky tests are order-dependent tests, whose pass/ fail outcomes depend on the test order in which they are run. Such tests have different outcomes because other tests running before them pollute shared state. Prior work has proposed repairing order-dependent tests by searching for existing tests, known as “cleaners”, that reset the shared state, allowing the order-dependent test to pass when run after a polluted shared state. The code within a cleaner represents a patch to repair the order-dependent test. However, this technique requires cleaners to already exist in the test suite. We propose ODRepair, an automated technique to repair order-dependent tests even without existing cleaners. The idea is to first determine the exact polluted shared state that results in the order-dependent test to fail and then generate code that can modify and reset the shared state so that the order-dependent test can pass. We focus on shared state through internal heap memory, in particular shared state reachable from static fields. Once we know which static field leads to the pollution, we search for reset-methods in the code-base that can potentially access and modify state reachable from that static field. We then apply an automatic test-generation tool to generate method-call sequences, targeting these reset-methods. Our evaluation on 327 order-dependent tests from a publicly available dataset shows that ODRepair automatically identifies the polluted static field for 181 tests, and it can generate patches for 141 of these tests. Compared against state-of-the-art iFixFlakies, ODRepair can generate patches for 24 tests that iFixFlakies cannot.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510173","NSF(grant numbers:CCF-1718903); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793979","flaky test;order-dependent test;test generation;automated repair","Codes;Pollution;Maintenance engineering;Test pattern generators;Testing;Software engineering","","9","","49","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automated Program Repair, What Is It Good For? Not Absolutely Nothing!","H. Eladawy; C. L. Goues; Y. Brun","University of Massachusetts, Amherst, MA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; University of Massachusetts, Amherst, MA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1021","1033","Industrial deployments of automated program repair (APR), e.g., at Facebook and Bloomberg, signal a new milestone for this exciting and potentially impactful technology. In these deployments, developers use APR-generated patch suggestions as part of a human-driven debugging process. Unfortunately, little is known about how using patch suggestions affects developers during debugging. This paper conducts a controlled user study with 40 developers with a median of 6 years of experience. The developers engage in debugging tasks on nine naturally-occurring defects in real-world, open-source, Java projects, using Recoder, SimFix, and TBar, three state-of-the-art APR tools. For each debugging task, the developers either have access to the project's tests, or, also, to code suggestions that make all the tests pass. These suggestions are either developer-written or APR-generated, which can be correct or deceptive. De-ceptive suggestions, which are a common APR occurrence, make all the available tests pass but fail to generalize to the intended specification. Through a total of 160 debugging sessions, we find that access to a code suggestion significantly increases the odds of submitting a patch. Access to correct APR suggestions increase the odds of debugging success by 14,000% as compared to having access only to tests, but access to deceptive suggestions decrease the odds of success by 65%. Correct suggestions also speed up de-bugging. Surprisingly, we observe no significant difference in how novice and experienced developers are affected by APR, suggesting that APR may find uses across the experience spectrum. Overall, developers come away with a strong positive impression of APR, suggesting promise for APR-mediated, human-driven debugging, despite existing challenges in APR-generated repair quality.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639095","National Science Foundation(grant numbers:CCF-1750116,CCF-2210243); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548723","automated program repair;debugging;human factors;user study","Java;Codes;Social networking (online);Debugging;Maintenance engineering;Task analysis;Software engineering","","","","98","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Empirical Study of the Docker Smells Impact on the Image Size","T. Durieux","TU Delft, The Netherlands",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2568","2579","Docker, a widely adopted tool for packaging and deploying applications leverages Dockerfiles to build images. However, creating an optimal Dockerfile can be challenging, often leading to “Docker smells” or deviations from best practices. This paper presents a study of the impact of 14 Docker smells on the size of Docker images. To assess the size impact of Docker smells, we identified and repaired 16 145 Docker smells from 11313 open-source Docker-files. We observe that the smells result in an average increase of 48.06 MB (4.6 %) per smelly image. Depending on the smell type, the size increase can be up to 10 %, and for some specific cases, the smells can represent 89 % of the image size. Interestingly, the most impactful smells are related to package managers which are commonly encountered and are relatively easy to fix. To collect the perspective of the developers regarding the size impact of the Docker smells, we submitted 34 pull requests that repair the smells and we reported their impact on the Docker image to the developers. 26/34 (76.5 %) of the pull requests have been merged and they contribute to a saving of 3.46 GB (16.4 %). The developer's comments demonstrate a positive interest in addressing those Docker smells even when the pull requests have been rejected.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549489","","Merging;Ecosystems;Maintenance engineering;Packaging;Best practices;Software engineering","","","","0","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Measuring and Mitigating Gaps in Structural Testing","S. B. Hossain; M. B. Dwyer; S. Elbaum; A. Nguyen-Tuong","Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia; Department of Computer Science, University of Virginia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1712","1723","Structural code coverage is a popular test adequacy metric that measures the percentage of program structure (e.g., statement, branch, decision) executed by a test suite. While structural coverage has several benefits, previous studies suggested that code coverage is not a good indicator of a test suite's fault-detection effectiveness as coverage computation does not consider test oracle quality. In this research, we formally define the coverage gap in structural testing as the percentage of program structure that is executed but not observed by any test oracles. Our large-scale empirical study of 13 Java applications, 16K test cases and 51.6K test assertions shows that even for mature test suites, the gap can be as high as 51 percentage points (pp) and 34pp on average. Our study reveals that the coverage gap strongly and negatively correlates with a test suite's fault-detection effectiveness. To mitigate gaps, we propose a lightweight static analysis of program dependencies to produce a ranked recommendation of test focus methods that can reduce the gap and improve test suite quality. When considering 34.8K assertions in the test suite as ground truth, the recommender suggests two-thirds of the focus methods written by developers within the top five recommendations.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00147","Air Force Office of Scientific Research(grant numbers:FA9550-21-0164); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172745","code coverage;checked coverage;test oracles;mutation testing;fault-detection effectiveness","Java;Codes;Static analysis;Software measurement;Testing;Software engineering","","3","","53","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"BFTDETECTOR: Automatic Detection of Business Flow Tampering for Digital Content Service","I. L. Kim; W. Wang; Y. Kwon; X. Zhang","Department of Computer Science, Purdue University, West Lafayette, USA; University of Southern California, Los Angeles, USA; Department of Computer Science, Purdue University, West Lafayette, USA; Department of Computer Science, Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","448","459","Digital content services provide users with a wide range of content, such as news, articles, or movies, while monetizing their content through various business models and promotional methods. Unfortunately, poorly designed or unpro-tected business logic can be circumvented by malicious users, which is known as business flow tampering. Such flaws can severely harm the businesses of digital content service providers. In this paper, we propose an automated approach that discov-ers business flow tampering flaws. Our technique automatically runs a web service to cover different business flows (e.g., a news website with vs. without a subscription paywall) to collect execution traces. We perform differential analysis on the execution traces to identify divergence points that determine how the business flow begins to differ, and then we test to see if the divergence points can be tampered with. We assess our approach against 352 real-world digital content service providers and discover 315 flaws from 204 websites, including TIME, Fortune, and Forbes. Our evaluation result shows that our technique successfully identifies these flaws with low false-positive and false-negative rates of 0.49% and 1.44%, respectively.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00048","NSF(grant numbers:1908021,1916499,2047980,2145616); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172893","JavaScript;business flow tampering;dynamic analysis;vulnerability detection","Fault diagnosis;Analytical models;Web services;Software algorithms;Motion pictures;Business;Software engineering","","","","49","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A systematic study of automated program repair: Fixing 55 out of 105 bugs for $8 each","C. Le Goues; M. Dewey-Vogt; S. Forrest; W. Weimer","Computer Science Department, University of Virginia, Charlottesville, VA, USA; Computer Science Department, University of Virginia, Charlottesville, VA, USA; Computer Science Department, University of New Mexico, Albuquerque, NM, USA; Computer Science Department, University of Virginia, Charlottesville, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","3","13","There are more bugs in real-world programs than human programmers can realistically address. This paper evaluates two research questions: “What fraction of bugs can be repaired automatically?” and “How much does it cost to repair a bug automatically?” In previous work, we presented GenProg, which uses genetic programming to repair defects in off-the-shelf C programs. To answer these questions, we: (1) propose novel algorithmic improvements to GenProg that allow it to scale to large programs and find repairs 68% more often, (2) exploit GenProg's inherent parallelism using cloud computing resources to provide grounded, human-competitive cost measurements, and (3) generate a large, indicative benchmark set to use for systematic evaluations. We evaluate GenProg on 105 defects from 8 open-source programs totaling 5.1 million lines of code and involving 10,193 test cases. GenProg automatically repairs 55 of those 105 defects. To our knowledge, this evaluation is the largest available of its kind, and is often two orders of magnitude larger than previous work in terms of code or test suite size or defect count. Public cloud computing prices allow our 105 runs to be reproduced for $403; a successful repair completes in 96 minutes and costs $7.32, on average.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227211","genetic programming;automated program repair;cloud computing","Maintenance engineering;Computer bugs;Cloud computing;Benchmark testing;Systematics;Open source software;Genetic programming","","311","5","38","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Reconciling manual and automatic refactoring","X. Ge; Q. L. DuBose; E. Murphy-Hill","Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","211","221","Although useful and widely available, refactoring tools are underused. One cause of this underuse is that a developer sometimes fails to recognize that she is going to refactor before she begins manually refactoring. To address this issue, we conducted a formative study of developers' manual refactoring process, suggesting that developers' reliance on “chasing error messages” when manually refactoring is an error-prone manual refactoring strategy. Additionally, our study distilled a set of manual refactoring workflow patterns. Using these patterns, we designed a novel refactoring tool called BeneFactor. BeneFactor detects a developer's manual refactoring, reminds her that automatic refactoring is available, and can complete her refactoring automatically. By alleviating the burden of recognizing manual refactoring, BeneFactor is designed to help solve the refactoring tool underuse problem.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227192","","Manuals;Software;Java;Videos;Software reliability","","59","","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Privacy and utility for defect prediction: Experiments with MORPH","F. Peters; T. Menzies","Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","189","199","Ideally, we can learn lessons from software projects across multiple organizations. However, a major impediment to such knowledge sharing are the privacy concerns of software development organizations. This paper aims to provide defect data-set owners with an effective means of privatizing their data prior to release. We explore MORPH which understands how to maintain class boundaries in a data-set. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. The value of training on this MORPHed data is tested via a 10-way within learning study and a cross learning study using Random Forests, Naive Bayes, and Logistic Regression for ten object-oriented defect datasets from the PROMISE data repository. Measured in terms of exposure of sensitive attributes, the MORPHed data was four times more private than the unMORPHed data. Also, in terms of the f-measures, there was little difference between the MORPHed and unMORPHed data (original data and data privatized by data-swapping) for both the cross and within study. We conclude that at least for the kinds of OO defect data studied in this project, data can be privatized without concerns for inference efficacy.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227194","privacy;defect prediction;data mining","Privacy;Data privacy;Companies;Software;Predictive models;Privatization","","51","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Partial evaluation of model transformations","A. Razavi; K. Kontogiannis","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; Department of Electrical and Computer Engineering, National and Technical University of Athens, Athens, Greece",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","562","572","Model Transformation is considered an important enabling factor for Model Driven Development. Transformations can be applied not only for the generation of new models from existing ones, but also for the consistent co-evolution of software artifacts that pertain to various phases of software lifecycle such as requirement models, design documents and source code. Furthermore, it is often common in practical scenarios to apply such transformations repeatedly and frequently; an activity that can take a significant amount of time and resources, especially when the affected models are complex and highly interdependent. In this paper, we discuss a novel approach for deriving incremental model transformations by the partial evaluation of original model transformation programs. Partial evaluation involves pre-computing parts of the transformation program based on known model dependencies and the type of the applied model change. Such pre-evaluation allows for significant reduction of transformation time in large and complex model repositories. To evaluate the approach, we have implemented QvtMix, a prototype partial evaluator for the Query, View and Transformation Operational Mappings (QVT-OM) language. The experiments indicate that the proposed technique can be used for significantly improving the performance of repetitive applications of model transformations.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227160","","Unified modeling language;Computational modeling;Syntactics;Abstracts;Synchronization;Context modeling;Software","","5","","18","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Towards a federated cloud ecosystem (Invited industrial talk)","C. Chapman","Cloud Research and Development centre, Dell, Dublin, Ireland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","967","967","Summary form only given. Collects the abstracts for the constituents of the 2012 IEEE International Power Engineering and Optimization Conference (PEOCO2012) proceedings.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227252","","","","1","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Certification-based development of critical systems","P. Steele","Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1575","1578","Safety-critical systems certification is a complex endeavor. Regulating agencies are moving to goal-based standards in an effort to remedy significant problems of prescriptive standards. However, goal-based standards introduce new difficulties into the development and certification processes. In this work I introduce Certification-Based Development, or CBD. CBD is a process framework designed to mitigate these difficulties by meeting the needs of a specific certifying agency with regard to a specific system.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227033","certification;safety case;safety-critical systems;standards","Safety;Standards;Electronics packaging;Systematics;Software;Measurement;Educational institutions","","2","","17","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"An approach to variability management in service-oriented product lines","S. Khoshnevis","Department of Computer Engineering, Faculty of Electrical and Computer Engineering, Shahid Beheshti University, Tehran, Iran",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1483","1486","Service-Oriented product lines (SOPLs) are dynamic software product lines, in which, the products are developed based on services and service-oriented architecture. Although there are similarities between components and services, there are important differences so that we cannot use component-based product line engineering methods and techniques for SOPL engineering. These differences emerge from the fact that, services can be discovered as black box elements from external repositories. Moreover, services can be dynamically bound and are business-aligned. Therefore, analyzing the conformance of discovered external services with the variability of services in the SOPL - which must be aligned to the variable business needs-is necessary. Variability must be managed, that is, it must be represented (modeled), used (instantiated and capable of conformance checking) and maintained (evolved) over time. Feature Models are insufficient for modeling variability in SOPL, because, services cannot be simply mapped to one or more features, and identification of the mapping depends on knowing the detailed implementation of the services. This research aims at providing an approach to managing the variability in SOPLs so that external services can be involved in the SOPL engineering. This paper presents an overview of the proposal.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227056","Service-Oriented Product Line;Variability Management;Variability Modeling;Conformance Checking","Business;Support vector machines;Modeling;Service oriented architecture;Biological system modeling;Computers","","1","","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code Models","C. Niu; C. Li; V. Ng; B. Luo","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing; Human Language Technology Research Institute, University of Texas at Dallas, Richardson, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","537","549","Despite the recent advances showing that a model pre-trained on large-scale source code data is able to gain appreciable generalization capability, it still requires a sizeable amount of data on the target task for fine-tuning. And the effectiveness of the model generalization is largely affected by the size and quality of the fine-tuning data, which is detrimental for target tasks with limited or unavailable resources. Therefore, cross-task generalization, with the goal of improving the generalization of the model to unseen tasks that have not been seen before, is of strong research and application value. In this paper, we propose a large-scale benchmark that includes 216 existing code-related tasks. Then, we annotate each task with the corresponding meta information such as task description and instruction, which contains detailed information about the task and a solution guide. This also helps us to easily create a wide variety of “training/evaluation” task splits to evaluate the various cross-task generalization capabilities of the model. Then we perform some preliminary experiments to demonstrate that the cross-task generalization of models can be largely improved by in-context learning methods such as few-shot learning and learning from task instructions, which shows the promising prospects of conducting cross-task learning research on our benchmark. We hope that the collection of the datasets and our benchmark will facilitate future work that is not limited to cross-task generalization.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00055","National Natural Science Foundation of China(grant numbers:61802167,2034508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172565","Pre-training of source code;cross-task transfer learning;few-shot learning;AI for SE","Learning systems;Deep learning;Source coding;Benchmark testing;Software;Data models;Task analysis","","3","","76","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"AI-based Question Answering Assistance for Analyzing Natural-language Requirements","S. Ezzini; S. Abualhaija; C. Arora; M. Sabetzadeh","SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Deakin University, Geelong, Australia; School of Electrical Engineering and Computer Science, University of Ottawa, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1277","1289","By virtue of being prevalently written in natural language (NL), requirements are prone to various defects, e.g., inconsistency and incompleteness. As such, requirements are frequently subject to quality assurance processes. These processes, when carried out entirely manually, are tedious and may further overlook important quality issues due to time and budget pressures. In this paper, we propose QAssist - a question-answering (QA) approach that provides automated assistance to stakeholders, including requirements engineers, during the analysis of NL requirements. Posing a question and getting an instant answer is beneficial in various quality-assurance scenarios, e.g., incompleteness detection. Answering requirements-related questions automatically is challenging since the scope of the search for answers can go beyond the given requirements specification. To that end, QAssist provides support for mining external domain-knowledge resources. Our work is one of the first initiatives to bring together QA and external domain knowledge for addressing requirements engineering challenges. We evaluate QAssist on a dataset covering three application domains and containing a total of 387 question-answer pairs. We experiment with state-of-the-art QA methods, based primarily on recent large-scale language models. In our empirical study, QAssist localizes the answer to a question to three passages within the requirements specification and within the external domain-knowledge resource with an average recall of 90.1% and 96.5%, respectively. QAssist extracts the actual answer to the posed question with an average accuracy of 84.2%.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00113","NSERC of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172663","Natural-language Requirements;Question Answering (QA);Language Models;Natural Language Processing (NLP);Natural Language Generation (NLG);BERT;T5","Knowledge engineering;Quality assurance;Terminology;Natural languages;Question answering (information retrieval);Internet;Stakeholders","","8","","87","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Object-centric debugging","J. Ressia; A. Bergel; O. Nierstrasz","Software Composition Group, University of Bern, Switzerland; PLEIAD Lab, Department of Computer Science (DCC), University of Chile, Chile; Software Composition Group, University of Bern, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","485","495","During the process of developing and maintaining a complex software system, developers pose detailed questions about the runtime behavior of the system. Source code views offer strictly limited insights, so developers often turn to tools like debuggers to inspect and interact with the running system. Unfortunately, traditional debuggers focus on the runtime stack as the key abstraction to support debugging operations, though the questions developers pose often have more to do with objects and their interactions. We propose object-centric debugging as an alternative approach to interacting with a running software system. We show how, by focusing on objects as the key abstraction, natural debugging operations can be defined to answer developer questions related to runtime behavior. We present a running prototype of an object-centric debugger, and demonstrate, with the help of a series of examples, how object-centric debugging offers more effective support for many typical developer tasks than a traditional stack-oriented debugger.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227167","debugging;object-oriented programming;reflection;program comprehension","Debugging;Runtime;Data structures;Indexes;Software systems;Monitoring","","24","","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Automatic parameter recommendation for practical API usage","C. Zhang; J. Yang; Y. Zhang; J. Fan; X. Zhang; J. Zhao; P. Ou","Department of Computer Science and Engineering, Shanghai Jiaotong University, China; School of Software, Shanghai Jiaotong University, China; School of Software, Shanghai Jiaotong University, China; School of Software, Shanghai Jiaotong University, China; School of Software, Shanghai Jiaotong University, China; School of Software, Shanghai Jiaotong University, China; School of Software, Shanghai Jiaotong University, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","826","836","Programmers extensively use application programming interfaces (APIs) to leverage existing libraries and frameworks. However, correctly and efficiently choosing and using APIs from unfamiliar libraries and frameworks is still a non-trivial task. Programmers often need to ruminate on API documentations (that are often incomplete) or inspect code examples (that are often absent) to learn API usage patterns. Recently, various techniques have been proposed to alleviate this problem by creating API summarizations, mining code examples, or showing common API call sequences. However, few techniques focus on recommending API parameters. In this paper, we propose an automated technique, called Precise, to address this problem. Differing from common code completion systems, Precise mines existing code bases, uses an abstract usage instance representation for each API usage example, and then builds a parameter usage database. Upon a request, Precise queries the database for abstract usage instances in similar contexts and generates parameter candidates by concretizing the instances adaptively. The experimental results show that our technique is more general and applicable than existing code completion systems, specially, 64% of the parameter recommendations are useful and 53% of the recommendations are exactly the same as the actual parameters needed. We have also performed a user study to show our technique is useful in practice.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227136","recommendation;API;argument;parameter;code completion","Context;Abstracts;Arrays;Indexes;Complexity theory;Documentation","","59","4","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model","Z. Liu; C. Chen; J. Wang; M. Chen; B. Wu; Z. Tian; Y. Huang; J. Hu; Q. Wang","State Key Laboratory of Intelligent Game, Beijing, China; Technical University of Munich, Munich, Germany; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Work done during the internship at ISCAS, The Pennsylvania State University; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1685","1696","Mobile applications have become a ubiquitous part of our daily life, providing users with access to various services and utilities. Text input, as an important interaction channel between users and applications, plays an important role in core functionality such as search queries, authentication, messaging, etc. However, certain special text (e.g., -18 for Font Size) can cause the app to crash, and generating diversified unusual inputs for fully testing the app is highly demanded. Nevertheless, this is also challenging due to the combination of explosion dilemma, high context sensitivity, and complex constraint relations. This paper proposes InputBlaster which leverages the LLM to automatically generate unusual text inputs for mobile app crash detection. It formulates the unusual inputs generation problem as a task of producing a set of test generators, each of which can yield a batch of unusual text inputs under the same mutation rule. In detail, InputBlaster leverages LLM to produce the test generators together with the mutation rules serving as the reasoning chain, and utilizes the in-context learning schema to demonstrate the LLM with examples for boosting the performance. InputBlaster is evaluated on 36 text input widgets with cash bugs involving 31 popular Android apps, and results show that it achieves 78% bug detection rate, with 136% higher than the best baseline. Besides, we integrate it with the automated GUI testing tool and detect 37 unseen crashes in real-world apps.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548767","Android GUI testing;Large language model;In-context learning","Sensitivity;Computer bugs;Maintenance engineering;Generators;Cognition;Mobile applications;Task analysis","","1","","73","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Detecting JVM JIT Compiler Bugs via Exploring Two-Dimensional Input Spaces","H. Jia; M. Wen; Z. Xie; X. Guo; R. Wu; M. Sun; K. Chen; H. Jin","School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Informatics, Xiamen University, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","43","55","Java Virtual Machine (JVM) is the fundamental software system that supports the interpretation and execution of Java bytecode. To support the surging performance demands for the increasingly complex and large-scale Java programs, Just-In-Time (JIT) compiler was proposed to perform sophisticated runtime optimization. However, this inevitably induces various bugs, which are becoming more pervasive over the decades and can often cause significant consequences. To facilitate the design of effective and efficient testing techniques to detect JIT compiler bugs. This study first performs a preliminary study aiming to understand the characteristics of JIT compiler bugs and the corresponding triggering test cases. Inspired by the empirical findings, we propose JOpFuzzer, a new JVM testing approach with a specific focus on JIT compiler bugs. The main novelty of JOpFuzzer is embodied in three aspects. First, besides generating new seeds, JOpFuzzer also searches for diverse configurations along the new dimension of optimization options. Second, JOpFuzzer learns the correlations between various code features and different optimization options to guide the process of seed mutation and option exploration. Third, it leverages the profile data, which can reveal the program execution information, to guide the fuzzing process. Such nov-elties enable JOpFuzzer to effectively and efficiently explore the two-dimensional input spaces. Extensive evaluation shows that JOpFuzzer outperforms the state-of-the-art approaches in terms of the achieved code coverages. More importantly, it has detected 41 bugs in OpenJDK, and 25 of them have already been confirmed or fixed by the corresponding developers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172514","JVM;JIT Compiler;JVM Testing","Java;Codes;Runtime;Computer bugs;Fuzzing;Software systems;Virtual machining","","3","","43","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Code Search Is All You Need? Improving Code Suggestions with Code Search","J. Chen; X. Hu; Z. Li; C. Gao; X. Xia; D. Lo","School of Software Technology, Zhejiang University, Ningbo, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Concordia University, Montreal, Canada; Harbin Institute of Technology, Shenzhen, China; Zhejiang University, Hangzhou, China; Singapore Management University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","880","892","Modern integrated development environments (IDEs) provide various automated code suggestion techniques (e.g., code completion and code generation) to help developers improve their efficiency. Such techniques may retrieve similar code snippets from the code base or leverage deep learning models to provide code suggestions. However, how to effectively enhance the code suggestions using code retrieval has not been systematically investigated. In this paper, we study and explore a retrieval-augmented framework for code suggestions. Specifically, our framework leverages different retrieval approaches and search strategies to search similar code snippets. Then the retrieved code is used to further enhance the performance of language models on code suggestions. We conduct experiments by integrating different language models into our framework and compare the results with their original models. We find that our framework noticeably improves the performance of both code completion and code generation by up to 53.8% and 130.8% in terms of BLEU-4, respectively. Our study highlights that integrating the retrieval process into code suggestions can improve the performance of code suggestions by a large margin.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639085","Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); National Natural Science Foundation of China(grant numbers:62141222); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548560","Code Suggestion;Code Search;Language Model","Deep learning;Codes;Search problems;Software engineering","","1","","63","","14 Jun 2024","","","IEEE","IEEE Conferences"
"LIBALCHEMY: A Two-Layer Persistent Summary Design for Taming Third-Party Libraries in Static Bug-Finding Systems","R. Wu; Y. He; J. Huang; C. Wang; W. Tang; Q. Shi; X. Xiao; C. Zhang","Xiamen Key Laboratory of Intelligent Storage and Computing, School of Informatics, Xiamen University, Xiamen, China; Xiamen Key Laboratory of Intelligent Storage and Computing, School of Informatics, Xiamen University, Xiamen, China; Xiamen Key Laboratory of Intelligent Storage and Computing, School of Informatics, Xiamen University, Xiamen, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Person, Hang Zhou, China; The Hong Kong University of Science and Technology, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1285","1297","Despite the benefits of using third-party libraries (TPLs), the misuse of TPL functions raises quality and security concerns. Using traditional static analysis to detect bugs caused by TPL function is nontrivial. One promising solution would be to automatically generate and persist the summaries of TPL functions offline and then reuse these summaries in compositional static analysis online. However, when dealing with millions of lines of TPL code, the summaries designed by existing studies suffer from an unresolved paradox. That is, a highly precise form of summary leads to an unaffordable space and time overhead, while an imprecise one seriously hurts its precision or recall. To address the paradox, we propose a novel two-layer summary design. The first layer utilizes a line-sized program representation known as the program dependence graph to compactly encode path conditions, while the second layer encodes bug-type-specific properties. We implemented our idea as a tool called Libalchemy and evaluated it on fifteen mature and extensively checked open-source projects. Experimental results show that Libalchemy can check over ten million lines of code within ten hours. Libalchemy has detected 55 true bugs with a high precision of 90.16%, eleven of which have been assigned CVE IDs. Compared to whole-program analysis and the conventional design of path-sensitively precise summaries, Libalchemy achieves an 18.56× and 12.77× speedup and saves 91.49% and 90.51% of memory usage, respectively.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639132","Natural Science Foundation of China(grant numbers:62272400); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548278","static bug-finding;function summary;third-party library","Codes;Computer bugs;Static analysis;Libraries;Security;Software engineering","","","","79","","14 Jun 2024","","","IEEE","IEEE Conferences"
"On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot","A. Mastropaolo; L. Pascarella; E. Guglielmi; M. Ciniselli; S. Scalabrino; R. Oliveto; G. Bavota","SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland; SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland; STAKE Lab, University of Molise, Italy; STAKE Lab, University of Molise, Italy; SEART @ Software Institute, Università della Svizzera italiana (USI), Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2149","2160","Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in ∼46% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code (±28%).","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00181","European Research Council (ERC)(grant numbers:851720); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172792","Empirical Study;Recommender Systems","Deep learning;Java;Codes;Natural languages;Robustness;Generators;Encoding","","28","","67","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Where should the bugs be fixed? More accurate information retrieval-based bug localization based on bug reports","J. Zhou; H. Zhang; D. Lo","School of Software, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China; School of Software, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China; School of Information Systems, Singapore Management University, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","14","24","For a large and evolving software system, the project team could receive a large number of bug reports. Locating the source code files that need to be changed in order to fix the bugs is a challenging task. Once a bug report is received, it is desirable to automatically point out to the files that developers should change in order to fix the bug. In this paper, we propose BugLocator, an information retrieval based method for locating the relevant files for fixing a bug. BugLocator ranks all files based on the textual similarity between the initial bug report and the source code using a revised Vector Space Model (rVSM), taking into consideration information about similar bugs that have been fixed before. We perform large-scale experiments on four open source projects to localize more than 3,000 bugs. The results show that BugLocator can effectively locate the files where the bugs should be fixed. For example, relevant buggy files for 62.60% Eclipse 3.1 bugs are ranked in the top ten among 12,863 files. Our experiments also show that BugLocator outperforms existing state-of-the-art bug localization methods.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227210","bug localization;information retrieval;feature location;bug reports","Computer bugs;Vectors;Mathematical model;Equations;Information retrieval;Indexing;Computational modeling","","378","2","39","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Free Lunch for Testing: Fuzzing Deep-Learning Libraries from Open Source","A. Wei; Y. Deng; C. Yang; L. Zhang",Stanford University; University of Illinois at Urbana-Champaign; Nanjing University; University of Illinois at Urbana-Champaign,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","995","1007","Deep learning (DL) systems can make our life much easier, and thus are gaining more and more attention from both academia and industry. Meanwhile, bugs in DL systems can be disastrous, and can even threaten human lives in safety-critical applications. To date, a huge body of research efforts have been dedicated to testing DL models. However, interestingly, there is still limited work for testing the underlying DL libraries, which are the foundation for building, optimizing, and running DL models. One potential reason is that test generation for the underlying DL libraries can be rather challenging since their public APIs are mainly exposed in Python, making it even hard to automatically determine the API input parameter types due to dynamic typing. In this paper, we propose FreeFuzz, the first approach to fuzzing DL libraries via mining from open source. More specifically, FreeFuzz obtains code/models from three different sources: 1) code snippets from the library documentation, 2) library developer tests, and 3) DL models in the wild. Then, FreeFuzz automatically runs all the collected code/models with instrumentation to trace the dynamic information for each covered API, including the types and values of each parameter during invocation, and shapes of input/output tensors. Lastly, FreeFuzz will leverage the traced dynamic information to perform fuzz testing for each covered API. The extensive study of FreeFuzz on PyTorch and TensorFlow, two of the most popular DL libraries, shows that FreeFuzz is able to automatically trace valid dynamic information for fuzzing 1158 popular APIs, 9X more than state-of-the-art LEMON with 3.5X lower overhead than LEMON. To date, FreeFuzz has detected 49 bugs for PyTorch and TensorFlow (with 38 already confirmed by developers as previously unknown).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510041","National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793919","","Tensors;Shape;Instruments;Computer bugs;Documentation;Fuzzing;Libraries","","21","","84","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Revisiting Neuron Coverage for DNN Testing: A Layer-Wise and Distribution-Aware Criterion","Y. Yuan; Q. Pang; S. Wang","The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1200","1212","Various deep neural network (DNN) coverage criteria have been proposed to assess DNN test inputs and steer input mutations. The coverage is characterized via neurons having certain outputs, or the discrepancy between neuron outputs. Nevertheless, recent research indicates that neuron coverage criteria show little correlation with test suite quality. In general, DNNs approximate distributions, by incorporating hierarchical layers, to make predictions for inputs. Thus, we champion to deduce DNN behaviors based on its approximated distributions from a layer perspective. A test suite should be assessed using its induced layer output distributions. Accordingly, to fully examine DNN behaviors, input mutation should be directed toward diversifying the approximated distributions. This paper summarizes eight design requirements for DNN coverage criteria, taking into account distribution properties and practical concerns. We then propose a new criterion, Neural Coverage (nlc),that satisfies all design requirements. NLC treats a single DNN layer as the basic computational unit (rather than a single neuron) and captures four critical properties of neuron output distributions. Thus, NL C accurately describes how DNNs comprehend inputs via approximated distributions. We demonstrate that NLC is significantly correlated with the diversity of a test suite across a number of tasks (classification and generation) and data formats (image and text). Its capacity to discover DNN prediction errors is promising. Test input mutation guided by NLC results in a greater quality and diversity of exposed erroneous behaviors.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172683","machine learning testing;coverage","Correlation;Neurons;Artificial neural networks;Fuzzing;Behavioral sciences;Task analysis;Optimization","","9","","50","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"ECFuzz: Effective Configuration Fuzzing for Large-Scale Systems","J. Li; S. Li; K. Li; F. Luo; H. Yu; S. Li; X. Li","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; National University of Defense Technology, Hunan, China; National Key Laboratory of Science and Technology on Information System Security, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","566","577","A large-scale system contains a huge configuration space because of its large number of configuration parameters. This leads to a combination explosion among configuration parameters when exploring the configuration space. Existing configuration testing techniques first use fuzzing to generate different configuration parameters, and then directly inject them into the program under test to find configuration-induced bugs. However, they do not fully consider the complexity of large-scale systems, resulting in low testing effectiveness. In this paper, we propose ECFuzz, an effective configuration fuzzer for large-scale systems. Our core approach consists of (i) Multi-dimensional configuration generation strategy. ECFuzz first designs different mutation strategies according to different dependencies and selects multiple configuration parameters from the candidate configuration parameters to effectively generate con-figuration parameters; (ii) Unit-testing-oriented configuration validation strategy. ECFuzz introduces unit testing into configuration testing techniques to filter out configuration parameters that are unlikely to yield errors before executing system testing, and effectively validate generated configuration parameters. We have conducted extensive experiments in real-world large-scale systems including HCommon, HDFS, HBase, ZooKeeper and Alluxio. Our evaluation shows that ECFuzz is effective in finding configuration-induced crash bugs. Compared with the state-of-the-art configuration testing tools including ConfTest, ConfErr and ConfDiagDe-tector, ECFuzz finds 60.3-67 more unexpected failures when the same 1000 testcases are injected into the system with an increase of 1.87x-2.63x. Moreover, ECFuzz has exposed 14 previously unknown bugs, and 5 of them have been confirmed.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549558","Configuration;Large-Scale Systems;Testing;Fuzzing","System testing;Computer bugs;Fuzzing;Explosions;Large-scale systems;Space exploration;Complexity theory","","1","","40","","14 Jun 2024","","","IEEE","IEEE Conferences"
"When Contracts Meets Crypto: Exploring Developers' Struggles with Ethereum Cryptographic APIs","J. Zhang; J. Chen; Z. Wan; T. Chen; J. Gao; Z. Chen","School of Computer Science, Peking University, Beijing, China; Sun Yat-sen University, Zhuhai, China; Zhejiang University, Hangzhou, China; University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science, Peking University, Beijing, China; School of Computer Science, Peking University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2021","2033","To empower smart contracts with the promising capabilities of cryptography, Ethereum officially introduced a set of cryptographic APIs that facilitate basic cryptographic operations within smart contracts, such as elliptic curve operations. However, since developers are not necessarily cryptography experts, requiring them to directly interact with these basic APIs has caused real-world security issues and potential usability challenges. To guide future research and solutions to these challenges, we conduct the first empirical study on Ethereum cryptographic practices. Through the analysis of 91,484,856 Ethereum transactions, 500 crypto-related contracts, and 483 StackExchange posts, we provide the first in-depth look at cryptographic tasks developers need to accomplish and identify five categories of obstacles they encounter. Furthermore, we conduct an online survey with 78 smart contract practitioners to explore their perspectives on these obstacles and elicit the underlying reasons. We find that more than half of practitioners face more challenges in cryptographic tasks compared to general business logic in smart contracts. Their feedback highlights the gap between low-level cryptographic APIs and high-level tasks they need to accomplish, emphasizing the need for improved cryptographic APIs, task-based templates, and effective assistance tools. Based on these findings, we provide practical implications for further improvements and outline future research directions.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639131","National Natural Science Foundation of China(grant numbers:62302534,62332004,62202011); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548685","Ethereum;Smart Contracts;Empirical Study;Cryptography;API Usability","Surveys;Elliptic curves;Smart contracts;Cryptography;Logic;Task analysis;Usability","","","","107","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Using Pre-Trained Models to Boost Code Review Automation","R. Tufano; S. Masiero; A. Mastropaolo; L. Pascarella; D. Poshyvanyk; G. Bavota","SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEART @ Software Institute, Università della Svizzera italiana, Switzerland; SEMERU @ Computer Science Department, William and Mary, USA; SEART @ Software Institute, Università della Svizzera italiana, Switzerland",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2291","2302","Code review is a practice widely adopted in open source and industrial projects. Given the non-negligible cost of such a process, researchers started investigating the possibility of automating specific code review tasks. We recently proposed Deep Learning (DL) models targeting the automation of two tasks: the first model takes as input a code submitted for review and implements in it changes likely to be recommended by a reviewer; the second takes as input the submitted code and a reviewer comment posted in natural language and automatically implements the change required by the reviewer. While the preliminary results we achieved are encouraging, both models had been tested in rather simple code review scenarios, substantially simplifying the targeted problem. This was also due to the choices we made when designing both the technique and the experiments. In this paper, we build on top of that work by demonstrating that a pre-trained Text-To-Text Transfer Transformer (T5) model can outperform previous DL models for automating code review tasks. Also, we conducted our experiments on a larger and more realistic (and challenging) dataset of code review activities.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510621","European Research Council(grant numbers:851720); NSF(grant numbers:CCF-1955853,CCF-2007246); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794027","Code Review;Empirical Study;Machine Learning on Code","Deep learning;Codes;Automation;Costs;Natural languages;Transformers;Task analysis","","36","","51","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Fill in the Blank: Context-aware Automated Text Input Generation for Mobile GUI Testing","Z. Liu; C. Chen; J. Wang; X. Che; Y. Huang; J. Hu; Q. Wang","State Key Laboratory of Intelligent Game, Beijing, China; Monash University, Melbourne, Australia; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1355","1367","Automated GUI testing is widely used to help ensure the quality of mobile apps. However, many GUIs require appropriate text inputs to proceed to the next page, which remains a prominent obstacle for testing coverage. Considering the diversity and semantic requirement of valid inputs (e.g., flight departure, movie name), it is challenging to automate the text input generation. Inspired by the fact that the pre-trained Large Language Model (LLM) has made outstanding progress in text generation, we propose an approach named QTypist based on LLM for intelligently generating semantic input text according to the GUI context. To boost the performance of LLM in the mobile testing scenario, we develop a prompt-based data construction and tuning method which automatically extracts the prompts and answers for model tuning. We evaluate QTypist on 106 apps from Google Play, and the result shows that the passing rate of QTypist is 87%, which is 93% higher than the best baseline. We also integrate QTypist with the automated GUI testing tools and it can cover 42% more app activities, 52% more pages, and subsequently help reveal 122% more bugs compared with the raw tool.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00119","National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172490","Text input generation;GUI testing;Android app;Large language model;Prompt-tuning","Semantics;Computer bugs;Motion pictures;Data models;Internet;Data mining;Tuning","","25","","94","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Learning to Recommend Method Names with Global Context","F. Liu; G. Li; Z. Fu; S. Lu; Y. Hao; Z. Jin","Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China; Silicon Heart Tech Co., Ltd, Beijing, China; Key Lab of High Confidence Software Technology, MoE (Peking University), Beijing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1294","1306","In programming, the names for the program entities, especially for the methods, are the intuitive characteristic for understanding the functionality of the code. To ensure the readability and maintainability of the programs, method names should be named properly. Specifically, the names should be meaningful and consistent with other names used in related contexts in their codebase. In recent years, many automated approaches are proposed to suggest consistent names for methods, among which neural machine translation (NMT) based models are widely used and have achieved state-of-the-art results. However, these NMT-based models mainly focus on extracting the code-specific features from the method body or the surrounding methods, the project-specific context and documentation of the target method are ignored. We conduct a statistical analysis to explore the relationship between the method names and their contexts. Based on the statistical results, we propose GTNM, a Global Transformer-based Neural Model for method name suggestion, which considers the local context, the project-specific context, and the documentation of the method simultaneously. Experimental results on java methods show that our model can outperform the state-of-the-art results by a large margin on method name suggestion, demonstrating the effectiveness of our proposed model.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510154","National Key R&D Program of China(grant numbers:2020AAA0109400); National Natural Science Foundation of China(grant numbers:62072007,62192733); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794069","method name recommendation;global context;deep learning","Java;Codes;Statistical analysis;Documentation;Programming;Transformers;Feature extraction","","9","","48","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Ex pede Herculem: Augmenting Activity Transition Graph for Apps via Graph Convolution Network","Z. Liu; C. Chen; J. Wang; Y. Su; Y. Huang; J. Hu; Q. Wang","State Key Laboratory of Intelligent Game, Beijing, China; Monash University, Melbourne, Australia; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1983","1995","Mobile apps are indispensable for people's daily life. With the increase of GUI functions, apps have become more complex and diverse. As the Android app is event-driven, Activity Transition Graph (ATG) becomes an important way of app abstract and graphical user interface (GUI) modeling. Although existing works provide static and dynamic analysis to build ATG for applications, the completeness of ATG obtained is poor due to the low coverage of these techniques. To tackle this challenge, we propose a novel approach, ArchiDroid, to automatically augment the ATG via graph convolution network. It models both the semantics of activities and the graph structure of activity transitions to predict the transition between activities based on the seed ATG extracted by static analysis. The evaluation demonstrates that ArchiDroid can achieve 86% precision and 94% recall in predicting the transition between activities for augmenting ATG. We further apply the augmented ATG in two downstream tasks, i.e., guidance in automated GUI testing and assistance in app function design. Results show that the automated GUI testing tool integrated with ArchiDroid achieves 43% more activity coverage and detects 208% more bugs. Besides, ArchiDroid can predict the missing transition with 85% accuracy in real-world apps for assisting the app function design, and an interview case study further demonstrates its usefulness.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00168","National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172707","GUI testing;deep learning;program analysis;empirical study","Convolution;Buildings;Semantics;Static analysis;Predictive models;Mobile applications;Task analysis","","2","","107","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Deeply Reinforcing Android GUI Testing with Deep Reinforcement Learning","Y. Lan; Y. Lu; Z. Li; M. Pan; W. Yang; T. Zhang; X. Li","State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aero-nautics and Astronautics, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","854","866","As the scale and complexity of Android applications continue to grow in response to increasing market and user demands, quality assurance challenges become more significant. While previous studies have demonstrated the superiority of Reinforcement Learning (RL) in Android GUI testing, its effectiveness remains limited, particularly in large, complex apps. This limitation arises from the ineffectiveness of Tabular RL in learning the knowledge within the large state-action space of the App Under Test (AUT) and from the suboptimal utilization of the acquired knowledge when em-ploying more advanced RL techniques. To address such limitations, this paper presents DQT, a novel automated Android GUI testing approach based on deep reinforcement learning. DQT preserves widgets' structural and semantic information with graph embedding techniques, building a robust foundation for identifying similar states or actions and distinguishing different ones. Moreover, a specially designed Deep Q-Network (DQN) effectively guides curiosity-driven exploration by learning testing knowledge from runtime interactions with the AUT and sharing it across states or actions. Experiments conducted on 30 diverse open-source apps demonstrate that DQT outperforms existing state-of-the-art testing approaches in both code coverage and fault detection, particularly for large, complex apps. The faults detected by DQT have been reproduced and reported to developers; so far, 21 of the reported issues have been explicitly confirmed, and 14 have been fixed.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623344","National Natural Science Foundation of China(grant numbers:62032010,62232014,61972193); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549457","Android testing;deep reinforcement learning;graph embedding","Runtime;Quality assurance;Codes;Fault detection;Semantics;Buildings;Deep reinforcement learning","","","","77","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Path Transitions Tell More: Optimizing Fuzzing Schedules via Runtime Program States","K. Zhang; X. Xiao; X. Zhu; R. Sun; M. Xue; S. Wen","Tsinghua Shenzhen International Graduate School, Tsinghua University; Tsinghua Shenzhen International Graduate School, Tsinghua University; Swinburne University of Technology; The University of Adelaide; The University of Adelaide; Swinburne University of Technology",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1658","1668","Coverage-guided Greybox Fuzzing (CGF) is one of the most successful and widely-used techniques for bug hunting. Two major approaches are adopted to optimize CGF: (i) to reduce search space of inputs by inferring relationships between input bytes and path constraints; (ii) to formulate fuzzing processes (e.g., path transitions) and build up probability distributions to optimize power schedules, i.e., the number of inputs generated per seed. However, the former is subjective to the inference results which may include extra bytes for a path constraint, thereby limiting the efficiency of path constraints resolution, code coverage discovery, and bugs exposure; the latter formalization, concentrating on power schedules for seeds alone, is inattentive to the schedule for bytes in a seed. In this paper, we propose a lightweight fuzzing approach, Truzz, to optimize existing Coverage-guided Greybox Fuzzers (CGFs). To address two aforementioned challenges, Truzz identifies the bytes related to the validation checks (i.e., the checks guarding error-handling code), and protects those bytes from being frequently mutated, making most generated inputs examine the functionalities of programs, in lieu of being rejected by validation checks. The byte-wise relationship determination mitigates the problem of loading extra bytes when fuzzers infer the byte-constraint relation. Furthermore, the proposed path transition within Truzz can efficiently prioritize the seed as the new path, harvesting many new edges, and the new path likely belongs to a code region with many undiscovered code lines. To evaluate our approach, we implemented 6 state-of-the-art fuzzers, AFL, AFLFast, NEUZZ, MOPT, FuzzFactory and GreyOne, in Truzz. The experimental results show that on average, Truzz can generate 16.14% more inputs flowing into functional code, in addition to 24.75% more new edges than the vanilla fuzzers. Finally, our approach exposes 13 bugs in 8 target programs, and 6 of them have not been identified by the vanilla fuzzers.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510063","National Natural Science Foundation of China(grant numbers:61972219); National Key Research and Development Program of China(grant numbers:2018YFB1800601); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794074","Fuzzing;Software Security;Path Transition;Mutation","Schedules;Codes;Runtime;Limiting;Computer bugs;Loading;Fuzzing","","5","","43","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Eflect: Porting Energy-Aware Applications to Shared Environments","T. Babakol; A. Canino; Y. D. Liu","SUNY Binghamton, Binghamton, NY, USA; SUNY Binghamton, Binghamton, NY, USA; SUNY Binghamton, Binghamton, NY, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","823","834","Developing energy-aware applications is a well known approach to software-based energy optimization. This promising approach is however faced with a significant hurdle when deployed to the environments shared among multiple applications, where the energy consumption effected by one application may erroneously be observed by another application. We introduce EFLECT, a novel software framework for disentangling the energy consumption of co-running applications. Our key idea, called energy virtualization, enables each energy-aware application to be only aware of the energy consumption effected by its execution. EFLECT is unique in its lightweight design: it is a purely application-level solution that requires no modification to the underlying hardware or system software. Experiments show Eflect incurs low overhead with high precision. Furthermore, it can seamlessly port existing application-level energy frameworks - one for energy-adaptive approximation and the other for energy profiling - to shared environments while retaining their intended effectiveness.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793873","Energy Accounting;Energy Profiling;Power Disturbance;Concur-rency","Ports (computers);Energy consumption;Hardware;System software;Virtualization;Optimization;Monitoring","","1","","41","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Semi-Automatic, Inline and Collaborative Web Page Code Curations","R. Rutishauser; A. A. Meyer; R. Holmes; T. Fritz","Department of Informatics, University of Zurich, Zurich, Switzerland; Department of Informatics, University of Zurich, Zurich, Switzerland; Department of Computer Science, University of British Columbia, Vancouver, Canada; Department of Informatics, University of Zurich, Zurich, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1866","1877","Software developers spend about a quarter of their workday using the web to fulfill various information needs. Searching for relevant information online can be time-consuming, yet acquired information is rarely systematically persisted for later reference. In this work, we introduce SALI, an approach for semi-automated inline linking of web pages to source code locations. SALI helps developers naturally capture high-quality, explicit links between web pages and specific source code lo-cations by recommending links for curation within the IDE. Through two laboratory studies, we examined the developer's ability to both curate and consume links between web pages and specific source code locations while performing software development tasks. The studies were performed with 20 subjects working on realistic software change tasks from widely-used open-source projects. Results show that developers continuously and concisely curate web pages at meaningful locations in the code with little effort. Additionally, we found that other developers could use these curations while performing new and different change tasks to speed up relevant information gathering within unfamiliar codebases by a factor of 2.4.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172862","Semi-automated link curation;knowledge management;web browsing;collaboration","Costs;Codes;Source coding;Web pages;Rendering (computer graphics);Software;Recording","","","","45","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Scalable Relational Analysis via Relational Bound Propagation","C. Stevens; H. Bagheri","Department of Computer Science, Iowa State University, Ames, Iowa, USA; University of Nebraska-Lincoln School of Computing, Lincoln, Nebraska, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2183","2194","Bounded formal analysis techniques (such as bounded model checking) are incredibly powerful tools for today's software engineers. However, such techniques often suffer from scalability challenges when applied to large-scale, real-world systems. It can be very diffi-cult to ensure the bounds are set properly, which can have a pro-found impact on the performance and scalability of any bounded for-mal analysis. In this paper, we propose a novel approach-relational bound propagation-which leverages the semantics of the underlying relational logic formula encoded by the specification to auto-matically tighten the bounds for any relational specification. Our approach applies two sets of semantic rules to propagate the bounds on the relations via the abstract syntax tree of the formula, first upward to higher-level expressions on those relations then down-ward from those higher-level expressions to the relations. Thus, relational bound propagation can reduce the number of variables examined by the analysis and decrease the cost of performing the analysis. This paper presents formal definitions of these rules, all of which have been rigorously proven. We realize our approach in an accompanying tool, Propter, and present experimental results using Propter that test the efficacy of relational bound propagation to decrease the cost of relational bounded model checking. Our results demonstrate that relational bound propagation reduces the number of primary variables in 63.58% of tested specifications by an average of 30.68% (N=519) and decreases the analysis time for the subject specifications by an average of 49.30%. For large-scale, real-world specifications, Propter was able to reduce total analysis time by an average of 68.14% (N=25) while introducing comparatively little overhead (6.14% baseline analysis time).","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549757","formal methods;bounded model checking;bound tightening","Fuzzy logic;Costs;Scalability;Semantics;Metals;Model checking;Syntactics","","","","42","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Silent Vulnerable Dependency Alert Prediction with Vulnerability Key Aspect Explanation","J. Sun; Z. Xing; Q. Lu; X. Xu; L. Zhu; T. Hoang; D. Zhao","Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Research School of Computer Science, CECS, Australian National University, Canberra, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","970","982","Due to convenience, open-source software is widely used. For beneficial reasons, open-source maintainers often fix the vulnerabilities silently, exposing their users unaware of the updates to threats. Previous works all focus on black-box binary detection of the silent dependency alerts that suffer from high false-positive rates. Open-source software users need to analyze and explain AI prediction themselves. Explainable AI becomes remarkable as a complementary of black-box AI models, providing details in various forms to explain AI decisions. Noticing there is still no technique that can discover silent dependency alert on time, in this work, we propose a framework using an encoder-decoder model with a binary detector to provide explainable silent dependency alert prediction. Our model generates 4 types of vulnerability key aspects including vulnerability type, root cause, attack vector, and impact to enhance the trustworthiness and users' acceptance to alert prediction. By experiments with several models and inputs, we confirm CodeBERT with both commit messages and code changes achieves the best results. Our user study shows that explainable alert predictions can help users find silent dependency alert more easily than black-box predictions. To the best of our knowledge, this is the first research work on the application of Explainable AI in silent dependency alert prediction, which opens the door of the related domains.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172824","","Codes;Soft sensors;Closed box;Detectors;Predictive models;Generators;Data models","","3","","82","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Developer-Intent Driven Code Comment Generation","F. Mu; X. Chen; L. Shi; S. Wang; Q. Wang","State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; Lassonde School of Engineering, York University, Toronto, Canada; State Key Laboratory of Intelligent Game, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","768","780","Existing automatic code comment generators mainly focus on producing a general description of functionality for a given code snippet without considering developer intentions. However, in real-world practice, comments are complicated, which often contain information reflecting various intentions of developers, e.g., functionality summarization, design rationale, implementation details, code properties, etc. To bridge the gap between automatic code comment generation and real-world comment practice, we define Developer-Intent Driven Code Comment Generation, which can generate intent-aware comments for the same source code with different intents. To tackle this challenging task, we propose DOME, an approach that utilizes Intent-guided Selective Attention to explicitly select intent-relevant information from the source code, and produces various comments reflecting different intents. Our approach is evaluated on two real-world Java datasets, and the experimental results show that our approach outperforms the state-of-the-art baselines. A human evaluation also confirms the significant potential of applying DOME in practical usage, enabling developers to comment code effectively according to their own needs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172531","Code Comment Generation;Intent-Controllable Comment Generation;Automated Comment-Intent Labeling","Training;Java;Codes;Source coding;Semantics;Generators;Labeling","","6","","66","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Use of Test Doubles in Android Testing: An In-Depth Investigation","M. Fazzini; C. Choi; J. M. Copia; G. Lee; Y. Kakehi; A. Gorla; A. Orso","University of Minnesota, Minneapolis, MN, USA; University of Minnesota, Minneapolis, MN, USA; IMDEA Software Institute, Madrid, Spain; University of Minnesota, Minneapolis, MN, USA; Georgia Institute of Technology, Atlanta, GA, USA; IMDEA Software Institute, Madrid, Spain; Georgia Institute of Technology, Atlanta, GA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2266","2278","Android apps interact with their environment extensively, which can result in flaky, slow, or hard-to-debug tests. Developers often address these problems using test doubles—developer-defined objects that replace app or library classes during test execution. Although test doubles are widely used, there is limited understanding of how they are used in practice. To bridge this gap, we present an in-depth empirical study that aims to shed light on how developers create and use test doubles in Android apps. In our study, we first analyze a dataset of 1,006 apps with publicly available test suites to identify which frameworks and approaches developers most commonly use to create test doubles. We then investigate several research questions by studying how test doubles defined using these popular frameworks are created and used in the ten apps in the dataset that define the highest number of test doubles using these frameworks. Our results, based on the analysis of 2,365 test doubles that replace a total of 784 classes, provide insight into the types of test doubles used within Android apps and how they are utilized. Our results also show that test doubles used in Android apps and traditional Java test doubles differ in at least some respect. Finally, our results show that test doubles can introduce test smells and even mistakes in the test code. In the paper, we also discuss some implications of our findings that can help researchers and practitioners working in this area and guide future research.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510175","NSF(grant numbers:CCF-1563991,CCF-0725202); DARPA(grant numbers:N66001-21-C-4024); ONR(grant numbers:N00014-18-1-2662); DOE(grant numbers:DE-FOA-0002460); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794020","Test mocking;mobile apps;software environment","Couplings;Bridges;Waste materials;Java;Codes;Libraries;Testing","","5","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"How do Developers Talk About GitHub Actions? Evidence from Online Software Development Community","Y. Zhang; Y. Wu; T. Chen; T. Wang; H. Liu; H. Wang","National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","492","504","Continuous integration, deployment and delivery (CI/CD) have become cornerstones of DevOps practices. In recent years, GitHub Action (GHA) has rapidly replaced the traditional CI/CD tools on GitHub, providing efficiently automated workflows for developers. With the widespread use and influence of GHA, it is critical to understand the existing problems that GHA developers face in their practices as well as the potential solutions to these problems. Unfortunately, we currently have relatively little knowledge in this area. To fill this gap, we conduct a large-scale empirical study of 6,590 Stack Overflow (SO) questions and 315 GitHub issues. Our study leads to the first comprehensive taxonomy of problems related to GHA, covering 4 categories and 16 sub-categories. Then, we analyze the popularity and difficulty of problem categories and their correlations. Further, we summarize 56 solution strategies for different GHA problems. We also distill practical implications of our findings from the perspective of different audiences. We believe that our study contributes to the research of emerging GHA practices and guides the future support of tools and technologies.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549737","GitHub Actions;Empirical Study;Stack Overflow","DevOps;Correlation;Accuracy;Taxonomy;Manuals;Labeling;Faces","","1","","58","","14 Jun 2024","","","IEEE","IEEE Conferences"
"DocFlow: Extracting Taint Specifications from Software Documentation","M. Tileria; J. Blasco; S. K. Dash","Royal Holloway, University of London, United Kingdom; Universidad Politécnica de Madrid, Spain; Royal Holloway, University of London, United Kingdom",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","729","740","Security practitioners routinely use static analysis to detect security problems and privacy violations in Android apps. The soundness of these analyses depends on how the platform is modelled and the list of sensitive methods. Collecting these methods often becomes impractical given the number of methods available, the pace at which the Android platform is updated, and the proprietary libraries Google releases on each new version. Despite the constant evolution of the Android platform, app developers cope with all these new features thanks to the documentation that comes with each new Android release. In this work, we take advantage of the rich documentation provided by platforms like Android and propose DocFlow, a framework to generate taint specifications for a platform, directly from its documentation. DocFlow models the semantics of API methods using their documentation to detect sensitive methods (sources and sinks) and assigns them semantic labels. Our approach does not require access to source code, enabling the analysis of proprietary libraries for which the code is unavailable. We evaluate DocFlow using Android platform packages and closed-source Google Play Services libraries. Our results show that our framework detects sensitive methods with high precision, adapts to new API versions, and can be easily extended to detect other method types. Our approach provides evidence that Android documentation encodes rich semantic information to categorise sensitive methods, removing the need to analyse source code or perform feature extraction.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549190","Taint analysis;Documentation;Android;Natural Language Processing","Privacy;Codes;Operating systems;Source coding;Semantics;Documentation;Static analysis","","","","63","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Vere: Verification Guided Synthesis for Repairing Deep Neural Networks","J. Ma; P. Yang; J. Wang; Y. Sun; C. -C. Huang; Z. Wang","Hangzhou Dianzi University, Zhejiang University, Hangzhou, China; SKLCS, Institute of Software, CAS, Beijing, China; ZJU-Hangzhou Global Scientific and Technological Innovation Center, Zhejiang University, Hangzhou, China; University of Manchester, Manchester, United Kingdom; Nanjing Institute of Software Technology, ISCAS, Nanjing, China; Hangzhou Dianzi University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","64","76","Neural network repair aims to fix the ‘bugs'11We use 'bugs' to denote different kinds of inputs that could trigger an error in the model's output. of neural networks by modifying the model's architecture or parameters. However, due to the data-driven nature of neural networks, it is difficult to explain the relationship between the internal neurons and erro-neous behaviors, making further repair challenging. While several work exists to identify responsible neurons based on gradient or causality analysis, their effectiveness heavily rely on the quality of available ‘bugged’ data and multiple heuristics in layer or neuron selection. In this work, we address the issue utilizing the power of formal verification (in particular for neural networks). Specifically, we propose Vere, a verification-guided neural network repair framework that performs fault localization based on linear relax-ation to symbolically calculate the repair significance of neurons and furthermore optimize the parameters of problematic neurons to repair erroneous behaviors. We evaluated Vere on various repair tasks, and our experimental results show that Vere can efficiently and effectively repair all neural networks without degrading the model's performance. For the task of removing backdoors, Vere successfully reduces attack success rate from 98.47% to 0.38% on average, while causing an average performance drop of 0.9%. For the task of repairing safety properties, Vere successfully repairs all the 36 tasks and achieves 99.87% generalization on average.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62102359,62176080); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548054","DNN Repair;Verification Guided Synthesis;Fault Localization","Location awareness;Neurons;Artificial neural networks;Maintenance engineering;Safety;Task analysis;Biological neural networks","","","","89","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Temporal analysis of API usage concepts","G. Uddin; B. Dagenais; M. P. Robillard","School of Computer Science, McGill University, Montreal, QUE, Canada; School of Computer Science, McGill University, Montreal, QUE, Canada; School of Computer Science, McGill University, Montreal, QUE, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","804","814","Software reuse through Application Programming Interfaces (APIs) is an integral part of software development. The functionality offered by an API is not always accessed uniformly throughout the lifetime of a client program. We propose Temporal API Usage Pattern Mining to detect API usage patterns in terms of their time of introduction into client programs. We detect concepts as distinct groups of API functionality from the change history of a client program. We locate those concepts in the client change history and detect temporal usage patterns, where a pattern contains a set of concepts that were added into the client program in a specific temporal order. We investigated the properties of temporal API usage patterns through a multiple-case study of three APIs and their use in up to 19 client software projects. Our technique was able to detect a number of valuable patterns in two out of three of the APIs investigated. Further investigation showed some patterns to be relatively consistent between clients, produced by multiple developers, and not trivially derivable from program structure or API documentation.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227138","API Usage;API Usability;Usage Pattern;Software Reuse;Mining Software Repositories","History;Data mining;Joining processes;Principal component analysis;Availability;Application programming interfaces;Documentation","","22","1","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Reachable Coverage: Estimating Saturation in Fuzzing","D. Liyanage; M. Böhme; C. Tantithamthavorn; S. Lipp","Monash University, Australia; MPI-SP, Germany; Monash University, Australia; TU Munich, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","371","383","Reachable coverage is the number of code elements in the search space of a fuzzer (i.e., an automatic software testing tool). A fuzzer cannot find bugs in code that is unreachable. Hence, reachable coverage quantifies fuzzer effectiveness. Using static program analysis, we can compute an upper bound on the number of reachable coverage elements, e.g., by extracting the call graph. However, we cannot decide whether a coverage element is reachable in general. If we could precisely determine reachable coverage efficiently, we would have solved the software verification problem. Unfortunately, we cannot approach a given degree of accuracy for the static approximation, either. In this paper, we advocate a statistical perspective on the approximation of the number of elements in the fuzzer's search space, where accuracy does improve as a function of the analysis runtime. In applied statistics, corresponding estimators have been developed and well established for more than a quarter century. These estimators hold an exciting promise to finally tackle the long-standing challenge of counting reachability. In this paper, we explore the utility of these estimators in the context of fuzzing. Estimates of reachable coverage can be used to measure (a) the amount of untested code, (b) the effectiveness of the testing technique, and (c) the completeness of the ongoing fuzzing campaign (w.r.t. the asymptotic max. achievable coverage). We make all data and our analysis publicly available.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00042","Australian Research Council(grant numbers:DE190100046,DE200100941); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172496","","Codes;Upper bound;Runtime;Computer bugs;Fuzzing;Software","","3","","55","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Raisin: Identifying Rare Sensitive Functions for Bug Detection","J. Huang; J. Nie; Y. Gong; W. You; B. Liang; P. Bian","School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; Huawei Technologies CO., LTD., Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2159","2170","Mastering the knowledge about the bug-prone functions (i.e., sensitive functions) is important to detect bugs. Some automated techniques have been proposed to identify the sensitive functions in large software systems, based on machine learning or natural Ian- guage processing. However, the existing statistics-based techniques are not directly applicable to a special kind of sensitive functions, i.e., the rare sensitive functions, which have very few invocations even in large systems. Unfortunately, the rare ones can also introduce bugs. Therefore, how to effectively identify such functions is a problem deserving attention. This study is the first to explore the identification of rare sensitive functions. We propose a context-based analogical reasoning technique to automatically infer rare sensitive functions. A 1+context scheme is devised, where a function and its context are embedded into a pair of vectors, enabling pairwise analogical reasoning. Con-sidering that the rarity of the functions may lead to low-quality embedding vectors, we propose a weighted subword embedding method that can highlight the semantics of the key subwords to facilitate effective embedding. In addition, frequent sensitive functions are utilized to filter out reasoning candidates. We implement a prototype called Raisin and apply it to identify the rare sensitive functions and detect bugs in large open-source code bases. We successfully discover thousands of previously unknown rare sensitive functions and detect 21 bugs confirmed by the developers. Some of the rare sensitive functions cause bugs even with a solitary in-vocation in the kernel. It is demonstrated that identifying them is necessary to enhance software reliability.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639165","National Natural Science Foundation of China (NSFC)(grant numbers:62272465,62002361,U1836209); Fundamental Research Funds for the Central Universities(grant numbers:22XNKJ29); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548513","Rare sensitive function;Bug detection;Analogical reasoning;Em-bedding","Codes;Computer bugs;Semantics;Prototypes;Machine learning;Software systems;Cognition","","","","47","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Statically checking API protocol conformance with mined multi-object specifications","M. Pradel; C. Jaspan; J. Aldrich; T. R. Gross","Department of Computer Science, ETH Zurich, Switzerland; Institute for Software Research, Carnegie Mellon University, USA; Institute for Software Research, Carnegie Mellon University, USA; Department of Computer Science, ETH Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","925","935","Programmers using an API often must follow protocols that specify when it is legal to call particular methods. Several techniques have been proposed to find violations of such protocols based on mined specifications. However, existing techniques either focus on single-object protocols or on particular kinds of bugs, such as missing method calls. There is no practical technique to find multi-object protocol bugs without a priori known specifications. In this paper, we combine a dynamic analysis that infers multi-object protocols and a static checker of API usage constraints into a fully automatic protocol conformance checker. The combined system statically detects illegal uses of an API without human-written specifications. Our approach finds 41 bugs and code smells in mature, real-world Java programs with a true positive rate of 51%. Furthermore, we show that the analysis reveals bugs not found by state of the art approaches.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227127","Typestate;Static analysis;Specification mining","Protocols;Computer bugs;Law;Error analysis;Training;Java","","43","","43","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Tolerate Control-Flow Changes for Sound Data Race Prediction","S. Zhu; Y. Guo; L. Zhang; Y. Cai","State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1342","1354","Data races seriously threaten the correctness of concurrent programs. Earlier works can report false positives. Recently, trace-based predictive analysis has achieved sound results by inferring feasible traces based on sound partial orders or constraint solvers. However, they hold the same assumption: any read event may affect the control-flow of a predicted trace. Thus, being control-flow sensitive, they have to enforce any read event (in an inferred trace) to either read the same value or a value from the same event as that in the original trace, albeit some slightly relax this. This (even with relaxation) severely limits their predictive ability and many true data races can be missed. We introduce the concept of Fix-Point Event and propose a new partial order model. This allows us to not only predict races with witness traces (like existing works with no control-flow changes) but also soundly infer existences of witness traces with potential control-flow changes. Thus, we can achieve a higher concurrency coverage and detect more data races soundly. We have implemented above as a tool ToccRACE and conducted a set of experiments on a benchmark of seven real-world programs and a large-scale software MySQL, where MySQL produced 427 traces with a total size of 3.4TB. Compared with the state-of-the-art sound data race detector SeqCheck,ToccRACE is significantly more effective by detecting 84.4%/200% more unique/dynamic races on the benchmark programs and 52.22%/49.8% more unique/dynamic races on MySQL, incurring reasonable time and memory costs (about 1.1x×43.5x on the benchmark programs and 10x/1.03x on MySQL). Furthermore, ToccRACE is sound and is comnlcte on two threads.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00118","National Natural Science Foundation of China(grant numbers:61932012,62232016); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172730","Concurrency bugs;data races;control flow;static information","Concurrent computing;Costs;Instruction sets;Detectors;Benchmark testing;Programming;Predictive models","","1","","50","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Multitest:Physical-Aware Object Insertion for Testing Multi-Sensor Fusion Perception Systems","X. Gao; Z. Wang; Y. Feng; L. Ma; Z. Chen; B. Xu","State Key Laboratory for Novel, Software Technology Nanjing University, China; University of Alberta, Edmonton, Canada; State Key Laboratory for Novel, Software Technology Nanjing University, China; The University of Tokyo, Japan; State Key Laboratory for Novel, Software Technology Nanjing University, China; State Key Laboratory for Novel, Software Technology Nanjing University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1710","1722","Multi-sensor fusion stands as a pivotal technique in addressing numerous safety-critical tasks and applications, e.g., self-driving cars and automated robotic arms. With the continuous advancement in data-driven artificial intelligence (AI), MSF's potential for sensing and understanding intricate external environments has been further amplified, bringing a profound impact on intelligent systems and specifically on their perception systems. Similar to tra-ditional software, adequate testing is also required for AI-enabled MSF systems. Yet, existing testing methods primarily concentrate on single-sensor perception systems (e.g., image-based and point cloud-based object detection systems). There remains a lack of emphasis on generating multimodal test cases for MSF systems. To address these limitations, we design and implement MULTI-TEST, a fitness-guided metamorphic testing method for complex MSF perception systems. Multitest employs a physical-aware approach to synthesize realistic multimodal object instances and insert them into critical positions of background images and point clouds. A fitness metric is designed to guide and boost the test generation process. We conduct extensive experiments with five SOTA perception systems to evaluate Multitest from the perspectives of: (1) generated test cases' realism, (2) fault detection capabilities, and (3) performance improvement. The results show that Multitest can generate realistic and modality-consistent test data and effectively detect hundreds of diverse faults of an MSF system under test. Moreover, retraining an MSF system on the test cases generated by Multitest can improve the system's robustness. Our replication package and synthesized testing dataset are publicly available at https://sites.google.com/view/msftest.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639191","National Natural Science Foundation of China(grant numbers:61932012,61832009,62002158); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548713","Testing;Multi-Sensor Fusion;Perception Systems","Point cloud compression;Measurement;System testing;Detectors;Robot sensing systems;Robustness;Test pattern generators","","1","","63","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Natural Attack for Pre-trained Models of Code","Z. Yang; J. Shi; J. He; D. Lo","School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University; School of Computing and Information Systems, Singapore Management University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1482","1493","Pre-trained models of code have achieved success in many important software engineering tasks. However, these powerful models are vulnerable to adversarial attacks that slightly perturb model inputs to make a victim model produce wrong outputs. Current works mainly attack models of code with examples that preserve operational program semantics but ignore a fundamental requirement for adversarial example generation: perturbations should be natural to human judges, which we refer to as naturalness requirement. In this paper, we propose ALERT (Naturalness Aware Attack), a black-box attack that adversarially transforms inputs to make victim models produce wrong outputs. Different from prior works, this paper considers the natural semantic of generated examples at the same time as preserving the operational semantic of original inputs. Our user study demonstrates that human developers consistently consider that adversarial examples generated by ALERT are more natural than those generated by the state-of-the-art work by Zhang et al. that ignores the naturalness requirement. On attacking CodeBERT, our approach can achieve attack success rates of 53.62%, 27.79%, and 35.78% across three downstream tasks: vulnerability prediction, clone detection and code authorship attribution. On GraphCodeBERT, our approach can achieve average success rates of 76.95%, 7.96% and 61.47% on the three tasks. The above outperforms the baseline by 14.07% and 18.56% on the two pretrained models on average. Finally, we investigated the value of the generated adversarial examples to harden victim models through an adversarial fine-tuning procedure and demonstrated the accuracy of CodeBERT and GraphCodeBERT against ALERT-generated adversarial examples increased by 87.59% and 92.32%, respectively.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510146","Singapore Ministry of Education (MOE); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794089","Genetic Algorithm;Adversarial Attack;Pre-Trained Models","Codes;Perturbation methods;Semantics;Cloning;Transforms;Task analysis;Software engineering","","31","","55","","20 Jun 2022","","","IEEE","IEEE Conferences"
"CCRep: Learning Code Change Representations via Pre-Trained Code Model and Query Back","Z. Liu; Z. Tang; X. Xia; X. Yang","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","17","29","Representing code changes as numeric feature vectors, i.e., code change representations, is usually an essential step to automate many software engineering tasks related to code changes, e.g., commit message generation and just-in-time defect prediction. Intuitively, the quality of code change representations is crucial for the effectiveness of automated approaches. Prior work on code changes usually designs and evaluates code change representation approaches for a specific task, and little work has investigated code change encoders that can be used and jointly trained on various tasks. To fill this gap, this work proposes a novel Code Change Representation learning approach named CCRep, which can learn to encode code changes as feature vectors for diverse downstream tasks. Specifically, CCRep regards a code change as the combination of its before-change and after-change code, leverages a pre-trained code model to obtain high-quality contextual embeddings of code, and uses a novel mechanism named query back to extract and encode the changed code fragments and make them explicitly interact with the whole code change. To evaluate CCRep and demonstrate its applicability to diverse code-change-related tasks, we apply it to three tasks: commit message generation, patch correctness assessment, and just-in-time defect prediction. Experimental results show that CCRep outperforms the state-of-the-art techniques on each task.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00014","National Natural Science Foundation of China(grant numbers:62202420); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172503","code change;representation learning;commit message generation;patch correctness assessment;just-in-time defect prediction","Representation learning;Adaptation models;Codes;Feature extraction;Task analysis;Software engineering;Context modeling","","8","","70","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Constructing parser for industrial software specifications containing formal and natural language description","F. Iwama; T. Nakamura; H. Takeuchi","IBM Research-Tokyo, IBM Japan Limited, Yamato, Kanagawa, Japan; IBM Research-Tokyo, IBM Japan Limited, Yamato, Kanagawa, Japan; IBM Research-Tokyo, IBM Japan Limited, Yamato, Kanagawa, Japan",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1012","1021","This paper describes a novel framework for creating a parser to process and analyze texts written in a “partially structured” natural language. In many projects, the contents of document artifacts tend to be described as a mixture of formal parts (i.e. the text constructs follow specific conventions) and parts written in arbitrary free text. Formal parsers, typically defined and used to process a description with rigidly defined syntax such as program source code are very precise and efficient in processing the formal part, while parsers developed for natural language processing (NLP) are good at robustly interpreting the free-text part. Therefore, combining these parsers with different characteristics can allow for more flexible and practical processing of various project documents. Unfortunately, conventional approaches to constructing a parser from multiple small parsers were studied extensively only for formal language parsers and are not directly applicable to NLP parsers due to the differences in the way the input text is extracted and evaluated. We propose a method to configure and generate a combined parser by extending an approach based on parser combinator, the operators for composing multiple formal parsers, to support both NLP and formal parsers. The resulting text parser is based on Parsing Expression Grammars, and it benefits from the strength of both parser types. We demonstrate an application of such combined parser in practical situations and show that the proposed approach can efficiently construct a parser for analyzing project-specific industrial specification documents.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227119","Document Analysis;Parser Combinator;Parsing Expression Grammars;Requirement Engineering","Syntactics;Natural language processing;Formal languages;Grammar;Abstracts;Semantics","","5","","13","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Impact of Code Language Models on Automated Program Repair","N. Jiang; K. Liu; T. Lutellier; L. Tan","Purdue University, West Lafayette, USA; Lynbrook High School, San Jose, USA; University of Alberta, Alberta, Canada; Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1430","1442","Automated program repair (APR) aims to help developers improve software reliability by generating patches for buggy programs. Although many code language models (CLM) are developed and effective in many software tasks such as code completion, there has been little comprehensive, in-depth work to evaluate CLMs' fixing capabilities and to fine-tune CLMs for the APR task. Firstly, this work is the first to evaluate ten CLMs on four APR benchmarks, which shows that surprisingly, the best CLM, as is, fixes 72% more bugs than the state-of-the-art deep-learning (DL)-based APR techniques. Secondly, one of the four APR benchmarks was created by us in this paper to avoid data leaking for a fair evaluation. Thirdly, it is the first work to fine-tune CLMs with APR training data, which shows that fine-tuning brings 31%-1,267% improvement to CLMs and enables them to fix 46%-164 % more bugs than existing DL-based APR techniques. Fourthly, this work studies the impact of buggy lines, showing that CLMs, as is, cannot make good use of the buggy lines to fix bugs, yet fine-tuned CLMs could potentially over-rely on buggy lines. Lastly, this work analyzes the size, time, and memory efficiency of different CLMs. This work shows promising directions for the APR domain, such as fine-tuning CLMs with APR-specific designs, and also raises awareness of fair and comprehensive evaluations of CLMs and calls for more transparent reporting of open-source repositories used in the pre-training data to address the data leaking problem.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172517","Automated Program Repair;Code Language Model;Fine-Tuning;Deep Learning","Codes;Computer bugs;Memory management;Training data;Benchmark testing;Maintenance engineering;Software","","43","","62","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Generating obstacle conditions for requirements completeness","D. Alrajeh; J. Kramer; A. van Lamsweerde; A. Russo; S. Uchitel","Department of Computing, Imperial College London, UK; Department of Computing, Imperial College London, UK; ICTEAM, Université catholique de Louvain, Belgium; Department of Computing, Imperial College London, UK; Department of Computing, Imperial College London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","705","715","Missing requirements are known to be among the major causes of software failure. They often result from a natural inclination to conceive over-ideal systems where the software-to-be and its environment always behave as expected. Obstacle analysis is a goal-anchored form of risk analysis whereby exceptional conditions that may obstruct system goals are identified, assessed and resolved to produce complete requirements. Various techniques have been proposed for identifying obstacle conditions systematically. Among these, the formal ones have limited applicability or are costly to automate. This paper describes a tool-supported technique for generating a set of obstacle conditions guaranteed to be complete and consistent with respect to the known domain properties. The approach relies on a novel combination of model checking and learning technologies. Obstacles are iteratively learned from counterexample and witness traces produced by model checking against a goal and converted into positive and negative examples, respectively. A comparative evaluation is provided with respect to published results on the manual derivation of obstacles in a real safety-critical system for which failures have been reported.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227147","Requirements completeness;risk identification;obstacle;model synthesis;model checking;inductive learning;goal-oriented requirements engineering","Software;Analytical models;Computational modeling;Encoding;Semantics;Knowledge based systems;Learning systems","","27","","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"OSSFP: Precise and Scalable C/C++ Third-Party Library Detection using Fingerprinting Functions","J. Wu; Z. Xu; W. Tang; L. Zhang; Y. Wu; C. Liu; K. Sun; L. Zhao; Y. Liu","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Software, Tsinghua University, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","270","282","Third-party libraries (TPLs) are frequently used in software to boost efficiency by avoiding repeated developments. However, the massive using TPLs also brings security threats since TPLs may introduce bugs and vulnerabilities. Therefore, software composition analysis (SCA) tools have been proposed to detect and manage TPL usage. Unfortunately, due to the presence of common and trivial functions in the bloated feature dataset, existing tools fail to precisely and rapidly identify TPLs in C/C++ real-world projects. To this end, we propose OSSFP, a novel SCA framework for effective and efficient TPL detection in large-scale real-world projects via generating unique fingerprints for open source software. By removing common and trivial functions and keeping only the core functions to build the fingerprint index for each TPL project, OSSFP significantly reduces the database size and accelerates the detection process. It also improves TPL detection accuracy since noises are excluded from the fingerprints. We applied OSSFP on a large data set containing 23,427 C/C++ repositories, which included 585,683 versions and 90 billion lines of code. The result showed that it could achieve 90.84% of recall and 90.34% of precision, which outperformed the state-of-the-art tool by 35.31% and 3.71%, respectively. OSSFP took only 0.12 seconds on average to identify all TPLs per project, which was 22 times faster than the other tool. OSSFP has proven to be highly scalable on large-scale datasets.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00034","National Research Foundation; National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172788","","Codes;Databases;Computer bugs;Fingerprint recognition;Libraries;Security;Indexes","","7","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"GraPacc: A graph-based pattern-oriented, context-sensitive code completion tool","A. T. Nguyen; H. A. Nguyen; T. T. Nguyen; T. N. Nguyen","Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1407","1410","Code completion tool plays an important role in daily development activities. It helps developers by auto-completing tedious and detailed code during an editing session. However, existing code completion tools are limited to recommending only context-free code templates and a single method call of the variable under editing. We introduce GraPacc, an advanced, context-sensitive code completion tool that is based on frequent API usage patterns. It extracts the context-sensitive features from the code under editing, for example, the API elements on focus and the current editing point, and their relations to other code elements. It then ranks the relevant API usage patterns and auto-completes the current code with the proper elements according to the chosen pattern.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227236","Pattern-oriented Code Completion;Usage Pattern","Feature extraction;Context;Switches;Indexes;Vectors;Programming","","20","2","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Optimistic Prediction of Synchronization-Reversal Data Races","Z. Shi; U. Mathur; A. Pavlogiannis","National University of Singapore, Singapore, Singapore; National University of Singapore, Singapore, Singapore; Aarhus University, Aarhus, Denmark",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1648","1660","Dynamic data race detection has emerged as a key technique for ensuring reliability of concurrent software in practice. However, dynamic approaches can often miss data races owing to non-determinism in the thread scheduler. Predictive race detection techniques cater to this shortcoming by inferring alternate executions that may expose data races without re-executing the underlying program. More formally, the dynamic data race prediction problem asks, given a trace $\sigma$ of an execution of a concurrent program, can $\sigma$ be correctly reordered to expose a data race? Existing state-of-the art techniques for data race prediction either do not scale to executions arising from real world concurrent software, or only expose a limited class of data races, such as those that can be exposed without reversing the order of synchronization operations. In general, exposing data races by reasoning about synchronization reversals is an intractable problem. In this work, we identify a class of data races, called Optimistic Sync(hronization)- Reversal races that can be detected in a tractable manner and often include nontrivial data races that cannot be exposed by prior tractable techniques. We also propose a sound algorithm OSR for detecting all optimistic sync-reversal data races in overall quadratic time, and show that the algorithm is optimal by establishing a matching lower bound. Our experiments demonstrate the effectiveness of OSR- on our extensive suite of benchmarks, OSR reports the largest number of data races, and scales well to large execution traces.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548308","concurrency;dynamic analysis;data race detection","Concurrent computing;Software algorithms;Programming;Prediction algorithms;Dynamic scheduling;Software;Cognition","","","","75","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"ReBucket: A method for clustering duplicate crash reports based on call stack similarity","Y. Dang; R. Wu; H. Zhang; D. Zhang; P. Nobel","Microsoft Research Asia, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Corporation, Redmond, WA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1084","1093","Software often crashes. Once a crash happens, a crash report could be sent to software developers for investigation upon user permission. To facilitate efficient handling of crashes, crash reports received by Microsoft's Windows Error Reporting (WER) system are organized into a set of “buckets”. Each bucket contains duplicate crash reports that are deemed as manifestations of the same bug. The bucket information is important for prioritizing efforts to resolve crashing bugs. To improve the accuracy of bucketing, we propose ReBucket, a method for clustering crash reports based on call stack matching. ReBucket measures the similarities of call stacks in crash reports and then assigns the reports to appropriate buckets based on the similarity values. We evaluate ReBucket using crash data collected from five widely-used Microsoft products. The results show that ReBucket achieves better overall performance than the existing methods. On average, the F-measure obtained by ReBucket is about 0.88.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227111","crash reports;clustering;duplicate crash report detection;call stack trace;WER","Training;Computer bugs;Equations;Mathematical model;Software;Measurement","","93","5","21","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Characterizing and predicting which bugs get reopened","T. Zimmermann; N. Nagappan; P. J. Guo; B. Murphy","Microsoft Research, USA; Microsoft Research, USA; University of Stanford, USA; Microsoft Research, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1074","1083","Fixing bugs is an important part of the software development process. An underlying aspect is the effectiveness of fixes: if a fair number of fixed bugs are reopened, it could indicate instability in the software system. To the best of our knowledge there has been on little prior work on understanding the dynamics of bug reopens. Towards that end, in this paper, we characterize when bug reports are reopened by using the Microsoft Windows operating system project as an empirical case study. Our analysis is based on a mixed-methods approach. First, we categorize the primary reasons for reopens based on a survey of 358 Microsoft employees. We then reinforce these results with a large-scale quantitative study of Windows bug reports, focusing on factors related to bug report edits and relationships between people involved in handling the bug. Finally, we build statistical models to describe the impact of various metrics on reopening bugs ranging from the reputation of the opener to how the bug was found.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227112","bug triage;bug reopen;bug report","Computer bugs;Humans;Databases;Testing;Software;Programming;Personnel","","85","","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Difuzer: Uncovering Suspicious Hidden Sensitive Operations in Android Apps","J. Samhi; L. Li; T. F. Bissyandé; J. Klein","SnT, University of Luxembourg, Luxembourg,; Monash University, Australia; SnT, University of Luxembourg, Luxembourg,; SnT, University of Luxembourg, Luxembourg,",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","723","735","One prominent tactic used to keep malicious behavior from being detected during dynamic test campaigns is logic bombs, where malicious operations are triggered only when specific conditions are satisfied. Defusing logic bombs remains an unsolved problem in the literature. In this work, we propose to investigate Suspicious Hidden Sensitive Operations (SHSOs) as a step towards triaging logic bombs. To that end, we develop a novel hybrid approach that combines static analysis and anomaly detection techniques to un-cover SHSOs, which we predict as likely implementations of logic bombs. Concretely, Difuzer identifies SHSO entry-points using an instrumentation engine and an inter-procedural data-flow analysis. Then, it extracts trigger-specific features to characterize SHSOs and leverages One-Class SVM to implement an unsupervised learning model for detecting abnormal triggers. We evaluate our prototype and show that it yields a precision of 99.02% to detect SHSOs among which 29.7% are logic bombs. Difuzer outperforms the state-of-the-art in revealing more logic bombs while yielding less false positives in about one order of magnitude less time. All our artifacts are released to the community.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793902","Android Security;Logic bomb;Software Security;Malware","Support vector machines;Weapons;Instruments;Prototypes;Static analysis;Feature extraction;Internet","","7","","89","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing","Z. Ma; A. R. Chen; D. J. Kim; T. -H. P. Chen; S. Wang","Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Electrical and Computer Engineering Department, University of Alberta, Edmonton, Alberta, Canada; Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Quebec, Canada; Department of Computer Science, University of Manitoba, Winnipeg, Manitoba, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1209","1221","Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639150","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548600","Log parsing;log analysis;large language model","Training;Analytical models;Runtime;Computer architecture;Inference algorithms;Data mining;Task analysis","","1","","76","","14 Jun 2024","","","IEEE","IEEE Conferences"
"VulCNN: An Image-inspired Scalable Vulnerability Detection System","Y. Wu; D. Zou; S. Dou; W. Yang; D. Xu; H. Jin","Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Fudan University, China; University of Texas at Dallas, United States; Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2365","2376","Since deep learning (DL) can automatically learn features from source code, it has been widely used to detect source code vulnerability. To achieve scalable vulnerability scanning, some prior studies intend to process the source code directly by treating them as text. To achieve accurate vulnerability detection, other approaches consider distilling the program semantics into graph representations and using them to detect vulnerability. In practice, text-based techniques are scalable but not accurate due to the lack of program semantics. Graph-based methods are accurate but not scalable since graph analysis is typically time-consuming. In this paper, we aim to achieve both scalability and accuracy on scanning large-scale source code vulnerabilities. Inspired by existing DL-based image classification which has the ability to analyze millions of images accurately, we prefer to use these techniques to accomplish our purpose. Specifically, we propose a novel idea that can efficiently convert the source code of a function into an image while preserving the program details. We implement Vul-CNN and evaluate it on a dataset of 13,687 vulnerable functions and 26,970 non-vulnerable functions. Experimental results report that VulCNN can achieve better accuracy than eight state-of-the-art vul-nerability detectors (i.e., Checkmarx, FlawFinder, RATS, TokenCNN, VulDeePecker, SySeVR, VulDeeLocator, and Devign). As for scalability, VulCNN is about four times faster than VulDeePecker and SySeVR, about 15 times faster than VulDeeLocator, and about six times faster than Devign. Furthermore, we conduct a case study on more than 25 million lines of code and the result indicates that VulCNN can detect large-scale vulnerability. Through the scanning reports, we finally discover 73 vulnerabilities that are not reported in NVD.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793871","Vulnerability Detection;CNN;Large Scale;Image","Deep learning;Codes;Scalability;Semantics;Detectors;Transforms;Rats","","31","","57","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automating Code-Related Tasks Through Transformers: The Impact of Pre-training","R. Tufano; L. Pascarella; G. Bavota","Software Institute - USI Universita della Svizzera italiana, Switzerland; Software Institute - USI Universita della Svizzera italiana, Switzerland; Software Institute - USI Universita della Svizzera italiana, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2425","2437","Transformers have gained popularity in the software engineering (SE) literature. These deep learning models are usually pre-trained through a self-supervised objective, meant to provide the model with basic knowledge about a language of interest (e.g., Java). A classic pre-training objective is the masked language model (MLM), in which a percentage of tokens from the input (e.g., a Java method) is masked, with the model in charge of predicting them. Once pre-trained, the model is then fine-tuned to support the specific downstream task of interest (e.g., code summarization). While there is evidence suggesting the boost in performance provided by pre-training, little is known about the impact of the specific pre-training objective(s) used. Indeed, MLM is just one of the possible pre-training objectives and recent work from the natural language processing field suggest that pre-training objectives tailored for the specific downstream task of interest may substantially boost the model's performance. For example, in the case of code summarization, a tailored pre-training objective could be the identification of an appropriate name for a given method, considering the method name to generate as an extreme summary. In this study, we focus on the impact of pre-training objectives on the performance of trans-formers when automating code-related tasks. We start with a systematic literature review aimed at identifying the pre-training objectives used in SE. Then, we pre-train 32 transformers using both (i) generic pre-training objectives usually adopted in SE; and (ii) pre-training objectives tailored to specific code-related tasks subject of our experimentation, namely bug-fixing, code summarization, and code completion. We also compare the pre-trained models with non pre-trained ones and show the advantage brought by pre-training in different scenarios, in which more or less fine-tuning data are available. Our results show that: (i) pre-training helps in boosting performance only if the amount of fine-tuning data available is small; (ii) the MLM objective is usually sufficient to maximize the prediction performance of the model, even when comparing it with pre-training objectives specialized for the downstream task at hand.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172872","Pre-training;Code Recommenders","Java;Codes;Systematics;Training data;Predictive models;Transformers;Data models","","3","","87","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Constraint Based Program Repair for Persistent Memory Bugs","Z. Huang; C. Wang","University of Southern California, Los Angeles, USA; University of Southern California, Los Angeles, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1109","1120","We propose a constraint based method for repairing bugs associated with the use of persistent memory (PM) in application software. Our method takes a program execution trace and the violated property as input and returns a suggested repair, which is a combination of inserting new PM instructions and reordering these instructions to eliminate the property violation. Compared with the state-of-the-art approach, our method has three advantages. First, it can repair both durability and crash consistency bugs whereas the state-of-the-art approach can only repair the relatively-simple durability bugs. Second, our method can discover new repair strategies instead of relying on repair strategies hard-coded into the repair tool. Third, our method uses a novel symbolic encoding to model PM semantics, which allows our symbolic analysis to be more efficient than the explicit enumeration of possible scenarios and thus explore a large number of repairs quickly. We have evaluated our method on benchmark programs from the well-known Intel PMDK library as well as real applications such as Memcached, Recipe, and Redis. The results show that our method can repair all of the 41 known bugs in these benchmarks, while the state-of-the-art approach cannot repair any of the crash consistency bugs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548530","Persistent memory;program repair;verification;debugging;testing","Analytical models;Computer bugs;Semantics;Maintenance engineering;Benchmark testing;Libraries;Encoding","","","","47","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"DeepVD: Toward Class-Separation Features for Neural Network Vulnerability Detection","W. Wang; T. N. Nguyen; S. Wang; Y. Li; J. Zhang; A. Yadavally","Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Computer Science Department, University of Illinois Urbana-Champaign, Illinois, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2249","2261","The advances of machine learning (ML) including deep learning (DL) have enabled several approaches to implicitly learn vulnerable code patterns to automatically detect software vulnerabilities. A recent study showed that despite successes, the existing ML/DL-based vulnerability detection (VD) models are limited in the ability to distinguish between the two classes of vulnerability and benign code. We propose DeepVD, a graph-based neural network VD model that emphasizes on class-separation features between vulnerability and benign code. DeepVDleverages three types of class-separation features at different levels of abstraction: statement types (similar to Part-of-Speech tagging), Post-Dominator Tree (covering regular flows of execution), and Exception Flow Graph (covering the exception and error-handling flows). We conducted several experiments to evaluate DeepVD in a real-world vulnerability dataset of 303 projects with 13,130 vulnerable methods. Our results show that DeepVD relatively improves over the state-of-the-art ML/DL-based VD approaches 13%–29.6% in precision, 15.6%–28.9% in recall, and 16.4%–25.8% in F-score. Our ablation study confirms that our designed features and components help DeepVDachieve high class-separability for vulnerability and benign code.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172789","neural vulnerability detection;graph neural network;class separation","Deep learning;Codes;Neural networks;Tagging;Feature extraction;Software;Flow graphs","","6","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SecBench.js: An Executable Security Benchmark Suite for Server-Side JavaScript","M. H. M. Bhuiyan; A. S. Parthasarathy; N. Vasilakis; M. Pradel; C. -A. Staicu",CISPA Helmholtz Center for Information Security; IIITDM Kancheepuram; Brown University & MIT; University of Stuttgart; CISPA Helmholtz Center for Information Security,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1059","1070","NPM is the largest software ecosystem in the world, offering millions of free, reusable packages. In recent years, various security threats to packages published on npm have been reported, including vulnerabilities that affect millions of users. To continuously improve techniques for detecting vulnerabilities and mitigating attacks that exploit them, a reusable benchmark of vulnerabilities would be highly desirable. Ideally, such a benchmark should be realistic, come with executable exploits, and include fixes of vulnerabilities. Unfortunately, there currently is no such benchmark, forcing researchers to repeatedly develop their own evaluation datasets and making it difficult to compare techniques with each other. This paper presents SecBench.js,, the first comprehensive benchmark suite of vulnerabilities and executable exploits for npm. The benchmark comprises 600 vulnerabilities, which cover the five most common vulnerability classes for server-side JavaScript. Each vulnerability comes with a payload that exploits the vulnerability and an oracle that validates successful exploitation. SecBench.js, enables various applications, of which we explore three in this paper: (i) cross-checking SecBench.js, against public security advisories reveals 168 vulnerable versions in 19 packages that are mislabeled in the advisories; (ii) applying simple code transformations to the exploits in our suite helps identify flawed fixes of vulnerabilities; (iii) dynamically analyzing calls to common sink APIs, e.g., exec(), yields a ground truth of code locations for evaluating vulnerability detectors. Beyond providing a reusable benchmark to the community, our work identified 20 zero-day vulnerabilities, most of which are already acknowledged by practitioners.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00096","European Research Council(grant numbers:851895); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172577","","Fault diagnosis;Codes;Benchmark testing;Software;Safety;Security;Public policy","","4","","61","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"RepresentThemAll: A Universal Learning Representation of Bug Reports","S. Fang; T. Zhang; Y. Tan; H. Jiang; X. Xia; X. Sun","Macau University of Science and Technology, Macau, China; Macau University of Science and Technology, Macau, China; Macau University of Science and Technology, Macau, China; Dalian University of Technology, Dalian, China; Huawei, Hangzhou, China; Yangzhou University, Yangzhou, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","602","614","Deep learning techniques have shown promising performance in automated software maintenance tasks associated with bug reports. Currently, all existing studies learn the customized representation of bug reports for a specific downstream task. Despite early success, training multiple models for multiple downstream tasks faces three issues: complexity, cost, and compatibility, due to the customization, disparity, and uniqueness of these automated approaches. To resolve the above challenges, we propose RepresentThemAll, a pre-trained approach that can learn the universal representation of bug reports and handle multiple downstream tasks. Specifically, RepresentThemAll is a universal bug report framework that is pre-trained with two carefully designed learning objectives: one is the dynamic masked language model and another one is a contrastive learning objective, “find yourself”. We evaluate the performance of RepresentThemAll on four downstream tasks, including duplicate bug report detection, bug report summarization, bug priority prediction, and bug severity prediction. Our experimental results show that RepresentThemAll outperforms all baseline approaches on all considered downstream tasks after well-designed fine-tuning.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00060","Macao Science and Technology Development Fund(grant numbers:0047/2020/A1,0014/2022/A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172597","","Training;Deep learning;Software maintenance;Costs;Computer bugs;Stacking;Transformers","","2","","69","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"DivLog: Log Parsing with Prompt Enhanced In-Context Learning","J. Xu; R. Yang; Y. Huo; C. Zhang; P. He","School of Data Science, The Chinese University of Hong Kong, Shenzhen, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen, China; Dept. of Computer Science & Engineering, The Chinese University of Hong Kong, China; ETH Zurich, Switzerland; School of Data Science, The Chinese University of Hong Kong, Shenzhen, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2457","2468","Log parsing, which involves log template extraction from semi-structured logs to produce structured logs, is the first and the most critical step in automated log analysis. However, current log parsers suffer from limited effectiveness for two reasons. First, traditional data-driven log parsers solely rely on heuristics or handcrafted features designed by domain experts, which may not consistently perform well on logs from diverse systems. Second, existing super-vised log parsers require model tuning, which is often limited to fixed training samples and causes sub-optimal performance across the entire log source. To address this limitation, we propose Di-vLog, an effective log parsing framework based on the in-context learning (ICL) ability of large language models (LLMs). Specifically, before log parsing, DivLog samples a small amount of offline logs as candidates by maximizing their diversity. Then, during log parsing, DivLog selects five appropriate labeled candidates as examples for each target log and constructs them into a prompt. By mining the semantics of examples in the prompt, DivLog generates a target log template in a training-free manner. In addition, we design a straightforward yet effective prompt format to extract the output and enhance the quality of the generated log templates. We conducted experiments on 16 widely-used public datasets. The results show that DivLog achieves (1) 98.1% Parsing Accuracy, (2) 92.1% Precision Template Accuracy, and (3) 92.9% Recall Template Accuracy on average, exhibiting state-of-the-art performance.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62102340); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548166","Log Parsing;Large Language Model;In-Context Learning","Training;Measurement;Analytical models;Semantics;Feature extraction;Tuning;Software engineering","","1","","56","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Improving IDE recommendations by considering global implications of existing recommendations","K. Muşlu; Y. Brun; R. Holmes; M. D. Ernst; D. Notkin","Computer Science & Engineering, University of Washington, Seattle, WA, USA; Computer Science & Engineering, University of Washington, Seattle, WA, USA; University of Waterloo, Waterloo, ON, CA; Computer Science & Engineering, University of Washington, Seattle, WA, USA; Computer Science & Engineering, University of Washington, Seattle, WA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1349","1352","Modern integrated development environments (IDEs) offer recommendations to aid development, such as auto-completions, refactorings, and fixes for compilation errors. Recommendations for each code location are typically computed independently of the other locations. We propose that an IDE should consider the whole codebase, not just the local context, before offering recommendations for a particular location. We demonstrate the potential benefits of our technique by presenting four concrete scenarios in which the Eclipse IDE fails to provide proper Quick Fixes at relevant locations, even though it offers those fixes at other locations. We describe a technique that can augment an existing IDE's recommendations to account for non-local information. For example, when some compilation errors depend on others, our technique helps the developer decide which errors to resolve first.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227082","","Engines;Concrete;Educational institutions;USA Councils;Java;Abstracts;Whales","","1","5","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"DeepLSH: Deep Locality-Sensitive Hash Learning for Fast and Efficient Near-Duplicate Crash Report Detection","Y. Remil; A. Bendimerad; R. Mathonat; C. Raissi; M. Kaytoue","INSA Lyon, Infologic R&D, Bourg-Lès-Valence, France; Infologic R&D, Bourg-Lès-Valence, France; Infologic R&D, Bourg-Lès-Valence, France; Riot Games, Singapore; INSA Lyon, Infologic R&D, Bourg-Lès-Valence, France",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2445","2456","Automatic crash bucketing is a crucial phase in the software de-velopment process for efficiently triaging bug reports. It generally consists in grouping similar reports through clustering techniques. However, with real-time streaming bug collection, systems are needed to quickly answer the question: What are the most similar bugs to a new one?, that is, efficiently find near-duplicates. It is thus natural to consider nearest neighbors search to tackle this problem and especially the well-known locality-sensitive hashing (LSH) to deal with large datasets due to its sublinear performance and theoretical guarantees on the similarity search accuracy. Surprisingly, LSH has not been considered in the crash bucketing literature. It is indeed not trivial to derive hash functions that satisfy the so-called locality-sensitive property for the most advanced crash bucketing metrics. Consequently, we study in this paper how to leverage LSH for this task. To be able to consider the most relevant metrics used in the literature, we introduce DeepLsh, a Siamese DNN architecture with an original loss function, that perfectly approximates the locality-sensitivity property even for Jaccard and Cosine metrics for which exact LSH solutions exist. We support this claim with a series of experiments on an original dataset, which we make available.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548326","Crash deduplication;Stack trace similarity;Approximate nearest neighbors;Locality-sensitive hashing;Siamese neural networks","Measurement;Hash functions;Computer bugs;Neural networks;Nearest neighbor methods;Search problems;Software","","","","41","","14 Jun 2024","","","IEEE","IEEE Conferences"
"On the Helpfulness of Answering Developer Questions on Discord with Similar Conversations and Posts from the Past","A. Lill; A. N. Meyer; T. Fritz","University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","691","703","A big part of software developers' time is spent finding answers to their coding-task-related questions. To answer their questions, developers usually perform web searches, ask questions on Q&A websites, or, more recently, in chat communities. Yet, many of these questions have frequently already been answered in previous chat conversations or other online communities. Automatically identifying and then suggesting these previous answers to the askers could, thus, save time and effort. In an empirical analysis, we first explored the frequency of repeating questions on the Discord chat platform and assessed our approach to identify them automatically. The approach was then evaluated with real-world developers in a field experiment, through which we received 142 ratings on the helpful-ness of the suggestions we provided to help answer 277 questions that developers posted in four Discord communities. We further collected qualitative feedback through 53 surveys and 10 follow-up interviews. We found that the suggestions were considered helpful in 40% of the cases, that suggesting Stack Overflow posts is more often considered helpful than past Discord conversations, and that developers have difficulties describing their problems as search queries and, thus, prefer describing them as natural language questions in online communities.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549304","Developer Questions;Chat Community;Semantic Similarity","Surveys;Natural languages;Oral communication;Documentation;Search problems;Software;Encoding","","","","69","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code Representations","C. Niu; C. Li; V. Ng; J. Ge; L. Huang; B. Luo","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute University of Texas at Dallas, Richardson, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Dept. of Computer Science, Southern Methodist University, Dallas, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","01","13","Recent years have seen the successful application of large pretrained models to code representation learning, resulting in substantial improvements on many code-related downstream tasks. But there are issues surrounding their application to SE tasks. First, the majority of the pre-trained models focus on pre-training only the encoder of the Transformer. For generation tasks that are addressed using models with the encoder-decoder architecture, however, there is no reason why the decoder should be left out during pre-training. Second, many existing pre-trained models, including state-of-the-art models such as T5-learning, simply reuse the pretraining tasks designed for natural languages. Moreover, to learn the natural language description of source code needed eventually for code-related tasks such as code summarization, existing pretraining tasks require a bilingual corpus composed of source code and the associated natural language description, which severely limits the amount of data for pre-training. To this end, we propose SPT-Code, a sequence-to-sequence pre-trained model for source code. In order to pre-train SPT-Code in a sequence-to-sequence manner and address the aforementioned weaknesses associated with existing pre-training tasks, we introduce three pre-training tasks that are specifically designed to enable SPT-Code to learn knowledge of source code, the corresponding code structure, as well as a natural language description of the code without relying on any bilingual corpus, and eventually exploit these three sources of information when it is applied to downstream tasks. Experimental results demonstrate that SPT-Code achieves state-of-the-art performance on five code-related downstream tasks after fine-tuning.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510096","National Natural Science Foundation of China(grant numbers:61802167,61802095); Natural Science Foundation of Jiangsu Province, China(grant numbers:BK20201250); NSF(grant numbers:2034508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793930","pre-training;code representation learning;sequence-to-sequence","Representation learning;Codes;Natural languages;Computer architecture;Transformers;Decoding;Task analysis","","25","","63","","20 Jun 2022","","","IEEE","IEEE Conferences"
"AST-Trans: Code Summarization with Efficient Tree-Structured Attention","Z. Tang; X. Shen; C. Li; J. Ge; L. Huang; Z. Zhu; B. Luo","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Alexa AI, Amazon, Berlin, Germany; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science, Southern Methodist University, Dallas, Texas, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","150","162","Code summarization aims to generate brief natural language descriptions for source codes. The state-of-the-art approaches follow a transformer-based encoder-decoder architecture. As the source code is highly structured and follows strict grammars, its Abstract Syntax Tree (AST) is widely used for encoding structural information. However, ASTs are much longer than the corresponding source code. Existing approaches ignore the size constraint and simply feed the whole linearized AST into the encoders. We argue that such a simple process makes it difficult to extract the truly useful dependency relations from the overlong input sequence. It also incurs significant computational overhead since each node needs to apply self-attention to all other nodes in the AST. To encode the AST more effectively and efficiently, we propose AST-Trans in this paper which exploits two types of node relationships in the AST: ancestor-descendant and sibling relationships. It applies the tree-structured attention to dynamically allocate weights for relevant nodes and exclude irrelevant nodes based on these two relationships. We further propose an efficient implementation to support fast parallel computation for tree-structure attention. On the two code summarization datasets, experimental results show that AST-Trans significantly outperforms the state-of-the-arts while being times more efficient than standard transformers 11All the codes and data are available at https://github.com/zetang94/ICSE2022_AST_Trans.git.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510224","National Natural Science Foundation of China(grant numbers:61802167,61802095); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201250); NSF(grant numbers:2034508); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794079","tree-based neural network;source code summarization","Codes;Natural languages;Syntactics;Transformers;Computational efficiency;Grammar;Flow graphs","","14","","57","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Combinatorial Testing of RESTful APIs","H. Wu; L. Xu; X. Niu; C. Nie","State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","426","437","This paper presents RestCT, a systematic and fully automatic approach that adopts Combinatorial Testing (CT) to test RESTful APIs. RestCT is systematic in that it covers and tests not only the interactions of a certain number of operations in RESTful APIs, but also the interactions of particular input-parameters in every single operation. This is realised by a novel two-phase test case generation approach, which first generates a constrained sequence covering array to determine the execution orders of available operations, and then applies an adaptive strategy to generate and refine several constrained covering arrays to concretise input-parameters of each operation. RestCT is also automatic in that its application relies on only a given Swagger specification of RESTful APIs. The creation of CT test models (especially, the inferring of dependency relationships in both operations and input-parameters), and the generation and execution of test cases are performed without any human intervention. Experimental results on 11 real-world RESTful APIs demonstrate the effectiveness and efficiency of RestCT. In particular, RestCT can find eight new bugs, where only one of them can be triggered by the state-of-the-art testing tool of RESTful APIs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510151","National Key Research and De-velopment Program of China(grant numbers:2018YFBI003800); National Natural Science Foundation of China(grant numbers:61902174,62072226); Natural Science Foundation of Jiangsu Province(grant numbers:BK20190291); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794061","RESTful API;combinatorial testing;test case generation","Adaptation models;Systematics;Combinatorial testing;Computer bugs;Restful API;Adaptive arrays;Testing","","8","","49","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Towards Practical Robustness Analysis for DNNs based on PAC-Model Learning","R. Li; P. Yang; C. -C. Huang; Y. Sun; B. Xue; L. Zhang","SKLCS, Institute of Software, CAS, University of Chinese Academy of Sciences, China; SKLCS, Institute of Software, CAS, China; Pazhou Lab, Nanjing Institute of Software Technology, ISCAS, China; Queen's University Belfast, United Kingdom; SKLCS, Institute of Software, CAS, University of Chinese Academy of Sciences, China; SKLCS, Institute of Software, CAS, University of Chinese Academy of Sciences, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2189","2201","To analyse local robustness properties of deep neural networks (DNNs), we present a practical framework from a model learning perspective. Based on black-box model learning with scenario optimisation, we abstract the local behaviour of a DNN via an affine model with the probably approximately correct (PAC) guarantee. From the learned model, we can infer the corresponding PAC-model robustness property. The innovation of our work is the integration of model learning into PAC robustness analysis: that is, we construct a PAC guarantee on the model level instead of sample distribution, which induces a more faithful and accurate robustness evaluation. This is in contrast to existing statistical methods without model learning. We implement our method in a prototypical tool named DeepPAC. As a black-box method, DeepPAC is scalable and efficient, especially when DNNs have complex structures or high-dimensional inputs. We extensively evaluate DeepPAC, with 4 baselines (using formal verification, statistical methods, testing and adversarial attack) and 20 DNN models across 3 datasets, including MNIST, CIFAR-10, and ImageNet. It is shown that DeepPAC outperforms the state-of-the-art statistical method PROVERO, and it achieves more practical robustness analysis than the formal verification tool ERAN. Also, its results are consistent with existing DNN testing work like DeepGini.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510143","National Natural Science Foundation of China(grant numbers:61836005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794058","neural networks;PAC-model robustness;model learning;scenario optimization","Deep learning;Analytical models;Technological innovation;Statistical analysis;Neural networks;Robustness;Picture archiving and communication systems","","4","","86","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Sedar: Obtaining High-Quality Seeds for DBMS Fuzzing via Cross-DBMS SQL Transfer","J. Fu; J. Liang; Z. Wu; Y. Jiang","KLISS, BNRist, School of Software, Tsinghua University, China; KLISS, BNRist, School of Software, Tsinghua University, China; KLISS, BNRist, School of Software, Tsinghua University, China; KLISS, BNRist, School of Software, Tsinghua University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1799","1810","Effective DBMS fuzzing relies on high-quality initial seeds, which serve as the starting point for mutation. These initial seeds should incorporate various DBMS features to explore the state space thoroughly. While built-in test cases are typically used as initial seeds, many DBMSs lack comprehensive test cases, making it difficult to apply state-of-the-art fuzzing techniques directly. To address this, we propose Sedar which produces initial seeds for a target DBMS by transferring test cases from other DBMSs. The underlying insight is that many DBMSs share similar functionalities, allowing seeds that cover deep execution paths in one DBMS to be adapted for other DBMSs. The challenge lies in converting these seeds to a format supported by the grammar of the target database. Sedar follows a three-step process to generate seeds. First, it executes existing SQL test cases within the DBMS they were designed for and captures the schema information during execution. Second, it utilizes large language models (LLMs) along with the captured schema information to guide the generation of new test cases based on the responses from the LLM. Lastly, to ensure that the test cases can be properly parsed and mutated by fuzzers, Sedar temporarily comments out unparsable sections for the fuzzers and uncomments them after mutation. We integrate Sedar into the DBMS fuzzers SQUIRREL and Griffin, targeting DBMSs such as Virtuoso, Mon-etDB, DuckDB, and ClickHouse. Evaluation results demonstrate significant improvements in both fuzzers. Specifically, compared to SQUIRREL and Griffin with non-transferred seeds, Sedar enhances code coverage by 72.46%-214.84% and 21.40%-194.46%; compared to SQUIRREL and Griffin with native test cases of these DBMSs as initial seeds, incorporating the transferred seeds of Sedar results in an improvement in code coverage by 4.90%-16.20% and 9.73%-28.41 %. Moreover, Sedar discovered 70 new vulnerabilities, with 60 out of them being uniquely found by Sedar with transferred seeds, and 19 of them have been assigned with CVEs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548854","DBMS Fuzzing;Initial Seeds;Vulnerability Detection","Structured Query Language;Codes;Databases;Computer bugs;Fuzzing;Space exploration;Grammar","","","","48","","14 Jun 2024","","","IEEE","IEEE Conferences"
"ARCLIN: Automated API Mention Resolution for Unformatted Texts","Y. Huo; Y. Su; H. Zhang; M. R. Lyu","The Chinese University of Hong Kong, Hong Kong, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","138","149","Online technical forums (e.g., StackOverflow) are popular platforms for developers to discuss technical problems such as how to use a specific Application Programming Interface (API), how to solve the programming tasks, or how to fix bugs in their code. These discussions can often provide auxiliary knowledge of how to use the software that is not covered by the official documents. The automatic extraction of such knowledge may support a set of down-stream tasks like API searching or indexing. However, unlike official documentation written by experts, discussions in open forums are made by regular developers who write in short and informal texts, including spelling errors or abbreviations. There are three major challenges for the accurate APIs recognition and linking mentioned APIs from unstructured natural language documents to an entry in the API repository: (1) distinguishing API mentions from common words; (2) identifying API mentions without a fully qualified name; and (3) disambiguating API mentions with similar method names but in a different library. In this paper, to tackle these challenges, we propose an ARCLIN tool, which can effectively distinguish and link APIs without using human annotations. Specifically, we first design an API recognizer to automatically extract API mentions from natural language sentences by a Conditional Random Field (CRF) on the top of a Bi-directional Long Short-Term Memory (Bi-LSTM) module, then we apply a context-aware scoring mechanism to compute the mention-entry similarity for each entry in an API repository. Compared to previous approaches with heuristic rules, our proposed tool without manual inspection outperforms by 8% in a high-quality dataset Py-mention, which contains 558 mentions and 2,830 sentences from five popular Python libraries. To our best knowledge, ARCLIN is the first approach to achieve full automation of API mention resolution from unformatted text without manually collected labels.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793898","API;API disambiguation;text mining","Training;Text recognition;Natural languages;Manuals;Programming;Libraries;Software","","3","","43","","20 Jun 2022","","","IEEE","IEEE Conferences"
"EAGLE: Creating Equivalent Graphs to Test Deep Learning Libraries","J. Wang; T. Lutellier; S. Qian; H. V. Pham; L. Tan","Purdue University, West Lafayette, USA; University of Waterloo, Waterloo, Canada; Purdue University, West Lafayette, USA; University of Waterloo, Waterloo, Canada; Purdue University, West Lafayette, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","798","810","Testing deep learning (DL) software is crucial and challenging. Recent approaches use differential testing to cross-check pairs of implementations of the same functionality across different libraries. Such approaches require two DL libraries implementing the same functionality, which is often unavailable. In addition, they rely on a high-level library, Keras, that implements missing functionality in all supported DL libraries, which is prohibitively expensive and thus no longer maintained. To address this issue, we propose EAGLE, a new technique that uses differential testing in a different dimension, by using equivalent graphs to test a single DL implementation (e.g., a single DL library). Equivalent graphs use different Application Programming Interfaces (APIs), data types, or optimizations to achieve the same functionality. The rationale is that two equivalent graphs executed on a single DL implementation should produce identical output given the same input. Specifically, we design 16 new DL equivalence rules and propose a technique, EAGLE, that (1) uses these equivalence rules to build concrete pairs of equivalent graphs and (2) cross-checks the output of these equivalent graphs to detect inconsistency bugs in a DL library. Our evaluation on two widely-used DL libraries, i.e., Tensor Flow and PyTorch, shows that EAGLE detects 25 bugs (18 in Tensor Flow and 7 in PyTorch), including 13 previously unknown bugs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510165","NSF(grant numbers:2006688); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794119","software testing;deep learning;differential testing;graph equivalence","Deep learning;Tensors;Computer bugs;Libraries;Software;Optimization;Testing","","6","","49","","20 Jun 2022","","","IEEE","IEEE Conferences"
"VULGEN: Realistic Vulnerability Generation Via Pattern Mining and Deep Learning","Y. Nong; Y. Ou; M. Pradel; F. Chen; H. Cai","Washington State University, Pullman, WA, USA; The University of Texas at Dallas, Richardson, TX, USA; University of Stuttgart, Stuttgart, Germany; The University of Texas at Dallas, Richardson, TX, USA; Washington State University, Pullman, WA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2527","2539","Building new, powerful data-driven defenses against prevalent software vulnerabilities needs sizable, quality vulnerability datasets, so does large-scale benchmarking of existing defense solutions. Automatic data generation would promisingly meet the need, yet there is little work aimed to generate much-needed quality vulnerable samples. Meanwhile, existing similar and adaptable techniques suffer critical limitations for that purpose. In this paper, we present VULGEN, the first injection-based vulnerability-generation technique that is not limited to a particular class of vulnerabilities. VULGEN combines the strengths of deterministic (pattern-based) and probabilistic (deep-learning/DL-based) program transformation approaches while mutually overcoming respective weaknesses. This is achieved through close collaborations between pattern mining/application and DL-based injection localization, which separates the concerns with how and where to inject. By leveraging large, pretrained programming language modeling and only learning locations, VULGEN mitigates its own needs for quality vulnerability data (for training the localization model). Extensive evaluations show that VULGEN significantly outperforms a state-of-the-art (SOTA) pattern-based peer technique as well as both Transformer- and GNN-based approaches in terms of the percentages of generated samples that are vulnerable and those also exactly matching the ground truth (by 38.0-430.1% and 16.3-158.2%, respectively). The VULGEN-generated samples led to substantial performance improvements for two SOTA DL-based vulnerability detectors (by up to 31.8% higher in F1), close to those brought by the ground-truth real-world samples and much higher than those by the same numbers of existing synthetic samples.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172870","Software vulnerability;data generation;bug injection;pattern mining;deep learning;vulnerability detection","Training;Location awareness;Detectors;Benchmark testing;Probabilistic logic;Transformers;Software","","4","","50","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Do code refactorings influence the merge effort?","A. Oliveira; V. Neves; A. Plastino; A. C. Bibiano; A. Garcia; L. Murta","Instituto de Computação (IC), Universidade Federal Fluminense (UFF), Niterói, Brazil; Instituto de Computação (IC), Universidade Federal Fluminense (UFF), Niterói, Brazil; Instituto de Computação (IC), Universidade Federal Fluminense (UFF), Niterói, Brazil; Informatics Department, PUC-Rio, Rio de Janeiro, Brazil; Informatics Department, PUC-Rio, Rio de Janeiro, Brazil; Instituto de Computação (IC), Universidade Federal Fluminense (UFF), Niterói, Brazil",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","134","146","In collaborative software development, multiple contributors frequently change the source code in parallel to implement new features, fix bugs, refactor existing code, and make other changes. These simultaneous changes need to be merged into the same version of the source code. However, the merge operation can fail, and developer intervention is required to resolve the conflicts. Studies in the literature show that 10 to 20 percent of all merge attempts result in conflicts, which require the manual developer's intervention to complete the process. In this paper, we concern about a specific type of change that affects the structure of the source code and has the potential to increase the merge effort: code refactorings. We analyze the relationship between the occurrence of refactorings and the merge effort. To do so, we applied a data mining technique called association rule extraction to find patterns of behavior that allow us to analyze the influence of refactorings on the merge effort. Our experiments extracted association rules from 40,248 merge commits that occurred in 28 popular open-source projects. The results indicate that: (i) the occurrence of refactorings increases the chances of having merge effort; (ii) the more refactorings, the greater the chances of effort; (iii) the more refactorings, the greater the effort; and (iv) parallel refactorings increase even more the chances of having effort, as well as the intensity of it. The results obtained may suggest behavioral changes in the way refactorings are implemented by developer teams. In addition, they can indicate possible ways to improve tools that support code merging and those that recommend refactorings, considering the number of refactorings and merge effort attributes.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00023","CNPq(grant numbers:311955/2020-7,141054/2019-0,315750/2021-9); FAPERJ(grant numbers:E-26/010.101250/2018,E-26/010.002285/2019,E-26/211.033/2019,E-26/201.038/2021,E-26/201.139/2022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172766","Software Merge;Merge Effort;Refactoring;Association Rules;Data Mining","Computer languages;Codes;Source coding;Merging;Semantics;Software;Behavioral sciences","","1","","51","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"FuzzInMem: Fuzzing Programs via In-memory Structures","X. Liu; W. You; Y. Ye; Z. Zhang; J. Huang; X. Zhang","Purdue University West Lafayette, United States; Renmin University of China, Beijing, China; Purdue University West Lafayette, United States; Purdue University West Lafayette, United States; Renmin University of China, Beijing, China; Purdue University West Lafayette, United States",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1610","1622","In recent years, coverage-based greybox fuzzing has proven to be an effective and practical technique for discovering software vulnerabilities. The availability of American Fuzzy Loop (AFL) has facilitated numerous advances in overcoming challenges in fuzzing. However, the issue of mutating complex file formats, such as PDF, remains unresolved due to strict constraints. Existing fuzzers often produce mutants that fail to parse by applications, limited by bit/byte mutations performed on input files. Our observation is that most in-memory representations of file formats are simple, and well-designed applications have built-in printer functions to emit these structures as files. Thus, we propose a new technique that mutates the in-memory structures of inputs and utilizes printer functions to regenerate mutated files. Unlike prior approaches that require complex analysis to learn file format constraints, our technique leverages the printer function to preserve format constraints. We implement a prototype called FuzzINMEM and compare it with AFL as well as other state-of-the-art fuzzers, including AFL++, Mopt, Weizz, and FormatFuzzer. The results show that FuzzINMEM is scalable and substantially outperforms general-purpose fuzzers in terms of valid seed generation and path coverage. By applying FuzzINMEM to real-world applications, we found 29 unique vulnerabilities and were awarded 5 CVEs","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639172","National Natural Science Foundation of China (NSFC)(grant numbers:62002361); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549244","Fuzzing;Software testing;Program synthesis","Source coding;Instruments;Computer bugs;Prototypes;Fuzzing;Software;Printers","","","","57","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"DeepSample: DNN Sampling-Based Testing for Operational Accuracy Assessment","A. Guerriero; R. Pietrantuono; S. Russo","DIETI, Università degli Studi di Napoli Federico II, Napoli, Italy; DIETI, Università degli Studi di Napoli Federico II, Napoli, Italy; DIETI, Università degli Studi di Napoli Federico II, Napoli, Italy",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1472","1483","Deep Neural Networks (DNN) are core components for classification and regression tasks of many software systems. Companies incur in high costs for testing DNN with datasets representative of the inputs expected in operation, as these need to be manually labelled. The challenge is to select a representative set of test inputs as small as possible to reduce the labelling cost, while sufficing to yield unbiased high-confidence estimates of the expected DNN accuracy. At the same time, testers are interested in exposing as many DNN mispredictions as possible to improve the DNN, ending up in the need for techniques pursuing a threefold aim: small dataset size, trustworthy estimates, mispredictions exposure. This study presents DeepSample, a family of DNN testing techniques for cost-effective accuracy assessment based on probabilistic sampling. We investigate whether, to what extent, and under which conditions probabilistic sampling can help to tackle the outlined challenge. We implement five new sampling-based testing techniques, and perform a comprehensive comparison of such techniques and of three further state-of-the-art techniques for both DNN classification and regression tasks. Results serve as guidance for best use of sampling-based testing for faithful and high-confidence estimates of DNN accuracy in operation at low cost.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549007","Software testing;Deep Neural Networks;Sampling","Costs;Estimation;Artificial neural networks;Probabilistic logic;Software systems;Partitioning algorithms;Labeling","","","","34","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"XPERT: Empowering Incident Management with Query Recommendations via Large Language Models","Y. Jiang; C. Zhang; S. He; Z. Yang; M. Ma; S. Qin; Y. Kang; Y. Dang; S. Rajmohan; Q. Lin; D. Zhang","University of Michigan, Ann-Arbor, USA; Microsoft, China; Microsoft, China; Peking University, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China; Microsoft, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1121","1133","Large-scale cloud systems play a pivotal role in modern IT infrastructure. However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience. To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data. However, writing these queries can be challenging and time-consuming. This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at MICROSOFT. The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management. Building upon these valuable insights, we introduce XPERT, an end-to-end machine learning framework that automates KQL recommendation process. By leveraging historical incident data and large language models, XPERT generates customized KQL queries tailored to new incidents. Furthermore, XPERT incorporates a novel performance metric called XCORE, enabling a thorough evaluation of query quality from three comprehensive perspectives. We conduct extensive evaluations of XPERT, demonstrating its effectiveness in offline settings. Notably, we deploy XPERT in the real production environment of a large-scale incident management system in MICROSOFT, validating its efficiency in supporting incident management. To the best of our knowledge, this paper represents the first empirical study of its kind, and XPERT stands as a pioneering DSL query recommendation framework designed for incident management.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548240","Incident Management;Query Generation;Large Language Model","Measurement;Knowledge engineering;Production;Machine learning;Writing;User experience;Software reliability","","","","72","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Log-based Anomaly Detection with Deep Learning: How Far Are We?","V. -H. Le; H. Zhang","The University of Newcastle, NSW, Australia; The University of Newcastle, NSW, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1356","1367","Software-intensive systems produce logs for troubleshooting pur-poses. Recently, many deep learning models have been proposed to automatically detect system anomalies based on log data. These models typically claim very high detection accuracy. For example, most models report an F-measure greater than 0.9 on the commonly-used HDFS dataset. To achieve a profound understanding of how far we are from solving the problem of log-based anomaly detection, in this paper, we conduct an in-depth analysis of five state-of-the-art deep learning-based models for detecting system anomalies on four public log datasets. Our experiments focus on several aspects of model evaluation, including training data selection, data grouping, class distribution, data noise, and early detection ability. Our re-sults point out that all these aspects have significant impact on the evaluation, and that all the studied models do not always work well. The problem of log-based anomaly detection has not been solved yet. Based on our findings, we also suggest possible future work.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510155","Australian Research Council (ARC) Discovery(grant numbers:DP200102940,DP220103044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794117","Anomaly Detection;Log Analysis;Log Parsing;Deep Learning","Deep learning;Analytical models;Codes;Training data;Data models;Anomaly detection;Software engineering","","53","","55","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Better Automatic Program Repair by Using Bug Reports and Tests Together","M. Motwani; Y. Brun","University of Massachusetts, Amherst, Massachusetts, USA; University of Massachusetts, Amherst, Massachusetts, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1225","1237","Automated program repair is already deployed in industry, but concerns remain about repair quality. Recent research has shown that one of the main reasons repair tools produce incorrect (but seemingly correct) patches is imperfect fault localization (FL). This paper demonstrates that combining information from natural-language bug reports and test executions when localizing faults can have a significant positive impact on repair quality. For example, existing repair tools with such FL are able to correctly repair 7 defects in the Defects4J benchmark that no prior tools have repaired correctly. We develop, Blues, the first information-retrieval-based, statement-level FL technique that requires no training data. We further develop RAFL, the first unsupervised method for combining multiple FL techniques, which outperforms a supervised method. Using RAFL, we create SBIR by combining Blues with a spectrum-based (SBFL) technique. Evaluated on 815 real-world defects, SBIR consistently ranks buggy statements higher than its underlying techniques. We then modify three state-of-the-art repair tools, Arja, SequenceR, and SimFix, to use SBIR, SBFL, and Blues as their internal FL. We evaluate the quality of the produced patches on 689 real-world defects. Arja and SequenceR significantly benefit from SBIR: Arja using SBIR correctly repairs 28 defects, but only 21 using SBFL, and only 15 using Blues; SequenceR using SBIR correctly repairs 12 defects, but only 10 using SBFL, and only 4 using Blues. SimFix, (which has internal mechanisms to overcome poor FL), correctly repairs 30 defects using SBIR and SBFL, but only 13 using Blues. Our work is the first investigation of simultaneously using multiple software artifacts for automated program repair, and our promising findings suggest future research in this directions is likely to be fruitful.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00109","National Science Foundation(grant numbers:CCF-1763423,CCF-2210243); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172693","Automatic Program repair;Information retrieval based fault localization;Debugging;fault localization","Location awareness;Industries;Computer bugs;Training data;Maintenance engineering;Benchmark testing;Software","","6","","32","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Enabling dynamic metamodels through constraint-driven modeling","A. Demuth","Institute for Systems Engineering and Automation, Johannes Kepler University Linz, Austria",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1622","1624","Metamodels are commonly used in Model-Driven Engineering to define available model elements and structures. However, metamodels are likely to change during development for various reasons like requirement changes or evolving domain knowledge. Updating a metamodel typically leads to non-conformance issues with existing models. Hence, evolution strategies must be developed. Additionally, the tool implementation must also be updated to support the evolved metamodel. We propose the use of metamodel-independent tools with unified modeling concepts for working with all kinds of metamodels and models. By applying the Constraint-Driven Modeling approach and generating model constraints from metamodels automatically, we solve the described issues and enable dynamic, evolving metamodels. A prototype implementation has shown the feasibility of the approach and performance tests suggest that it also scales with increasing model sizes.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227223","Dynamic metamodeling;metamodel evolution;constraints;model consistency","Unified modeling language;Load modeling;Adaptation models;Runtime;Prototypes;Metamodeling","","1","","18","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Enhancing Deep Learning-based Vulnerability Detection by Building Behavior Graph Model","B. Yuan; Y. Lu; Y. Fang; Y. Wu; D. Zou; Z. Li; Z. Li; H. Jin","School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2262","2274","Software vulnerabilities have posed huge threats to the cyberspace security, and there is an increasing demand for automated vulnerability detection (VD). In recent years, deep learning-based (DL-based) vulnerability detection systems have been proposed for the purpose of automatic feature extraction from source code. Although these methods can achieve ideal performance on synthetic datasets, the accuracy drops a lot when detecting real-world vulnerability datasets. Moreover, these approaches limit their scopes within a single function, being not able to leverage the information between functions. In this paper, we attempt to extract the function's abstract behaviors, figure out the relationships between functions, and use this global information to assist DL-based VD to achieve higher performance. To this end, we build a Behavior Graph Model and use it to design a novel framework, namely VulBG. To examine the ability of our constructed Behavior Graph Model, we choose several existing DL-based VD models (e.g., TextCNN, ASTGRU, CodeBERT, Devign, and VulCNN) as our baseline models and conduct evaluations on two real-world datasets: the balanced $\text{FFMpeg}+\text{Qemu}$ dataset and the unbalanced $\text{Chrome} +\text{Debian}$ dataset. Experimental results indicate that VulBG enables all baseline models to detect more real vulnerabilities, thus improving the overall detection performance.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172844","Vulnerability Detection;Behavior Graph;Deep Learning","Source coding;Buildings;Cyberspace;Feature extraction;Software;Behavioral sciences;Security","","4","","61","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"make test-zesti: A symbolic execution solution for improving regression testing","P. Dan Marinescu; C. Cadar","Department of Computing, Imperial College London, London, UK; Department of Computing, Imperial College London, London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","716","726","Software testing is an expensive and time consuming process, often involving the manual creation of comprehensive regression test suites. However, current testing methodologies do not take full advantage of these tests. In this paper, we present a technique for amplifying the effect of existing test suites using a lightweight symbolic execution mechanism, which thoroughly checks all sensitive operations (e.g., pointer dereferences) executed by the test suite for errors, and explores additional paths around sensitive operations. We implemented this technique in a prototype system called ZESTI (Zero-Effort Symbolic Test Improvement), and applied it to three open-source code bases — GNU Coreutils, libdwarf and readelf — where it found 52 previously unknown bugs, many of which are out of reach of standard symbolic execution. Our technique works transparently to the tester, requiring no additional human effort or changes to source code or tests.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227146","regression testing;test improvement;symbolic execution","Testing;Computer bugs;Concrete;Manuals;Standards;Measurement;Open source software","","28","","42","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"DeMistify: Identifying On-Device Machine Learning Models Stealing and Reuse Vulnerabilities in Mobile Apps","P. Ren; C. Zuo; X. Liu; W. Diao; Q. Zhao; S. Guo","School of Cyber Science and Technology, Shandong University; Ohio State University; School of Cyber Science and Technology, Shandong University; School of Cyber Science and Technology, Shandong University; City University of Hong Kong; School of Cyber Science and Technology, Shandong University",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","479","491","Mobile apps have become popular for providing artificial intelligence (AI) services via on-device machine learning (ML) techniques. Unlike accomplishing these AI services on remote servers traditionally, these on-device techniques process sensitive information required by AI services locally, which can mitigate the severe con-cerns of the sensitive data collection on the remote side. However, these on-device techniques have to push the core of ML expertise (e.g., models) to smartphones locally, which are still subject to similar vulnerabilities on the remote clouds and servers, especially when facing the model stealing attack. To defend against these attacks, developers have taken various protective measures. Unfor-tunately, we have found that these protections are still insufficient, and on-device ML models in mobile apps could be extracted and reused without limitation. To better demonstrate its inadequate protection and the feasibility of this attack, this paper presents DeMistify, which statically locates ML models within an app, slices relevant execution components, and finally generates scripts auto-matically to instrument mobile apps to successfully steal and reuse target ML models freely. To evaluate DeMistify and demonstrate its applicability, we apply it on 1,511 top mobile apps using on-device ML expertise for several ML services based on their install numbers from Google Play and DeMistify can successfully execute 1250 of them (82.73%). In addition, an in-depth study is conducted to understand the on-device ML ecosystem in the mobile application.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548087","Android App;Machine Learning;On-device Model Reuse;Program Analysis","Analytical models;Biological system modeling;Ecosystems;Machine learning;Mobile applications;Servers;Task analysis","","1","","61","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Evaluating and Improving Hybrid Fuzzing","L. Jiang; H. Yuan; M. Wu; L. Zhang; Y. Zhang","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; University of Illinois Urbana-Champaign, Champaign, USA; Southern University of Science and Technology, Shenzhen, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","410","422","To date, various hybrid fuzzers have been proposed for maximal program vulnerability exposure by integrating the power of fuzzing strategies and concolic executors. While the existing hybrid fuzzers have shown their superiority over conventional coverage-guided fuzzers, they seldom follow equivalent evaluation setups, e.g., benchmarks and seed corpora. Thus, there is a pressing need for a comprehensive study on the existing hybrid fuzzers to provide implications and guidance for future research in this area. To this end, in this paper, we conduct the first extensive study on state-of-the-art hybrid fuzzers. Surprisingly, our study shows that the performance of existing hybrid fuzzers may not well generalize to other experimental settings. Meanwhile, their performance advantages over conventional coverage-guided fuzzers are overall limited. In addition, instead of simply updating the fuzzing strategies or concolic executors, updating their coordination modes potentially poses crucial performance impact of hybrid fuzzers. Accordingly, we propose CoFuzz to improve the effectiveness of hybrid fuzzers by upgrading their coordination modes. Specifically, based on the baseline hybrid fuzzer QSYM, CoFuzz adopts edge-oriented scheduling to schedule edges for applying concolic execution via an online linear regression model with Stochastic Gradient Descent. It also adopts sampling-augmenting synchronization to derive seeds for applying fuzzing strategies via the interval path abstraction and John walk as well as incrementally updating the model. Our evaluation results indicate that CoFuzz can significantly increase the edge coverage (e.g., 16.31% higher than the best existing hybrid fuzzer in our study) and expose around 2X more unique crashes than all studied hybrid fuzzers. Moreover, CoFuzz successfully detects 37 previously unknown bugs where 30 are confirmed with 8 new CVEs and 20 are fixed.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00045","National Natural Science Foundation of China(grant numbers:61902169); Shenzhen Peacock Plan(grant numbers:KQTD2016112514355531); National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172801","","Schedules;Image edge detection;Computer bugs;Linear regression;Stochastic processes;Pressing;Fuzzing","","10","","86","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"DeepFD: Automated Fault Diagnosis and Localization for Deep Learning Programs","J. Cao; M. Li; X. Chen; M. Wen; Y. Tian; B. Wu; S. -C. Cheung","The Hong Kong University of Science and Technology, and Guangzhou HKUST Fok Ying Tung Research Institute, China; The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China; University of Waterloo, Canada, and The Hong Kong University of Science and Technology, China; MIT-IBM Watson AI Lab, U.S.; The Hong Kong University of Science and Technology, and Guangzhou HKUST Fok Ying Tung Research Institute, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","573","585","As Deep Learning (DL) systems are widely deployed for mission-critical applications, debugging such systems becomes essential. Most existing works identify and repair suspicious neurons on the trained Deep Neural Network (DNN), which, unfortunately, might be a detour. Specifically, several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in DL programs. Besides, locating faulty neurons is not actionable for developers, while locating the faulty statements in DL programs can provide developers with more useful information for debugging. Though a few recent studies were proposed to pinpoint the faulty statements in DL programs or the training settings (e.g. too large learning rate), they were mainly designed based on predefined rules, leading to many false alarms or false negatives, especially when the faults are beyond their capabilities. In view of these limitations, in this paper, we proposed DeepFD, a learning-based fault diagnosis and localization framework which maps the fault localization task to a learning problem. In particu-lar, it infers the suspicious fault types via monitoring the runtime features extracted during DNN model training, and then locates the diagnosed faults in DL programs. It overcomes the limitations by identifying the root causes of faults in DL programs instead of neurons, and diagnosing the faults by a learning approach instead of a set of hard-coded rules. The evaluation exhibits the potential of DeepFD. It correctly diagnoses 52% faulty DL programs, compared with around half (27%) achieved by the best state-of-the-art works. Besides, for fault localization, DeepFD also outperforms the existing works, correctly locating 42% faulty programs, which almost doubles the best result (23%) achieved by the existing works.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510099","National Natural Science Foundation of China(grant numbers:61932021,62002125); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793970","Neural Networks;Fault Diagnosis;Fault Localization;Debugging","Location awareness;Fault diagnosis;Deep learning;Training;Runtime;Neurons;Debugging","","10","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Analyzing multi-agent systems with probabilistic model checking approach","S. Song; J. Hao; Y. Liu; J. Sun; H. -F. Leung; J. S. Dong","Graduate School for Integrative Sciences and Engineering, National University of Singapore, Singapore; Department of Computer Science and Engineering, Chinese University of Hong Kong, China; Temasek Lab, National University of Singapore, Singapore; ISTD, Singapore University of Technology and Design, Singapore; Department of Computer Science and Engineering, Chinese University of Hong Kong, China; School of Computing, National University of Singapore, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1337","1340","Multi-agent systems, which are composed of autonomous agents, have been successfully employed as a modeling paradigm in many scenarios. However, it is challenging to guarantee the correctness of their behaviors due to the complex nature of the autonomous agents, especially when they have stochastic characteristics. In this work, we propose to apply probabilistic model checking to analyze multi-agent systems. A modeling language called PMA is defined to specify such kind of systems, and LTL property and logic of knowledge combined with probabilistic requirements are supported to analyze system behaviors. Initial evaluation indicates the effectiveness of our current progress; meanwhile some challenges and possible solutions are discussed as our ongoing work.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227085","Multi-agent systems;Probabilistic model checking","Probabilistic logic;Analytical models;Educational institutions;Cognition;Semantics;Games;Multiagent systems","","7","","12","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Usability-Oriented Design of Liquid Types for Java","C. Gamboa; P. Canelas; C. Timperley; A. Fonseca","School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA; LASIGE, Faculdade de Ciências da, Universidade de Lisboa, Portugal",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1520","1532","Developers want to detect bugs as early in the development lifecycle as possible, as the effort and cost to fix them increases with the incremental development of features. Ultimately, bugs that are only found in production can have catastrophic consequences. Type systems are effective at detecting many classes of bugs during development, often providing immediate feedback both at compile-time and while typing due to editor integration. Unfortunately, more powerful static and dynamic analysis tools do not have the same success due to providing false positives, not being immediate, or not being integrated into the language. Liquid Types extend the language type system with predicates, augmenting the classes of bugs that the compiler or IDE can catch compared to the simpler type systems available in mainstream programming languages. However, previous implementations of Liquid Types have not used human-centered methods for designing or evaluating their extensions. Therefore, this paper investigates how Liquid Types can be integrated into a mainstream programming language, Java, by proposing a new design that aims to lower the barriers to entry and adapts to problems that Java developers commonly encounter at runtime. Following a participatory design methodology, we conducted a developer survey to design the syntax of LiquidJava, our prototype. To evaluate if the added effort to writing Liquid Types in Java would convince users to adopt them, we conducted a user study with 30 Java developers. The results show that LiquidJava helped users detect and fix more bugs and that Liquid Types are easy to interpret and learn with few resources. At the end of the study, all users reported interest in adopting LiquidJava for their projects.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00132","Fundação para a Ciência e a Tecnologia(grant numbers:UIDB/00408/2020,UIDP/00408/2020); AFRL(grant numbers:19-PAF00747); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172818","Usability;Java;Refinement Types;Liquid Types","Surveys;Java;Computer languages;Liquids;Runtime;Program processors;Computer bugs","","1","","49","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"MirrorTaint: Practical Non-intrusive Dynamic Taint Tracking for JVM-based Microservice Systems","Y. Ouyang; K. Shao; K. Chen; R. Shen; C. Chen; M. Xu; Y. Zhang; L. Zhang","University of Illinois, Urbana-Champaign, USA; Ant Group, Shanghai, China; Southern University of Science and Technology, Shenzhen, China; Peking University, Beijing, China; Ant Group, Shanghai, China; Ant Group, Shanghai, China; Southern University of Science and Technology, Shenzhen, China; University of Illinois, Urbana-Champaign, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2514","2526","Taint analysis, i.e., labeling data and propagating the labels through data flows, has been widely used for analyzing program information flows and ensuring system/data security. Due to its important applications, various taint analysis techniques have been proposed, including static and dynamic taint analysis. However, existing taint analysis techniques can be hardly applied to the rising microservice systems for industrial applications. To address such a problem, in this paper, we proposed the first practical non-intrusive dynamic taint analysis technique MirrorTaint for extensively supporting microservice systems on JVMs. In particular, by instrumenting the microservice systems, MirrorTaint constructs a set of data structures with their respective policies for labeling/propagating taints in its mirrored space. Such data structures are essentially non-intrusive, i.e., modifying no program meta-data or runtime system. Then, during program execution, MirrorTaint replicates the stack-based JVM instruction execution in its mirrored space on-the-fly for dynamic taint tracking. We have evaluated MirrorTaint against state-of-the-art dynamic and static taint analysis systems on various popular open-source microservice systems. The results demonstrate that MirrorTaint can achieve better compatibility, quite close precision and higher recall (97.9%/100.0%) than state-of-the-art Phosphor (100.0%/9.9%) and FlowDroid (100%/28.2%). Also, MirrorTaint incurs lower runtime overhead than Phosphor (although both are dynamic techniques). Moreover, we have performed a case study in Ant Group, a global billion-user FinTech company, to compare MirrorTaint and their mature developer-experience-based data checking system for automatically generated fund documents. The result shows that the developer experience can be incomplete, causing the data checking system to only cover 84.0% total data relations, while MirrorTaint can automatically find 99.0% relations with 100.0% precision. Lastly, we also applied MirrorTaint to successfully detect a recently wide-spread Log4j2 security vulnerability.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00210","National Natural Science Foundation of China(grant numbers:61902169); Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); NSF(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172616","dynamic taint analysis;microservice;JVM","Runtime;Instruments;Phosphors;Microservice architectures;Companies;Aerospace electronics;Benchmark testing","","1","","62","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"MUT: Human-in-the-Loop Unit Test Migration","Y. Gao; X. Hu; T. Xu; X. Xia; D. Lo; X. Yang","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China; Huawei, Hangzhou, China; Huawei, Hangzhou, China; School of Computing and Information Systems, Singapore Management University, Hangzhou, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, Hangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2832","2843","Test migration, which enables the reuse of test cases crafted with knowledge and creativity by testers across various platforms and programming languages, has exhibited effectiveness in mobile app testing. However, unit test migration at the source code level has not garnered adequate attention and exploration. In this paper, we propose a novel cross-language and cross-platform test migration methodology, named MUT, which consists of four modules: code mapping, test case filtering, test case translation, and test case adaptation. MUT initially calculates code mappings to establish associations between source and target projects, and identifies suitable unit tests for migration from the source project. Then, MUT's code translation component generates a syntax tree by parsing the code to be migrated and progressively converts each node in the tree, ultima tely generating the target tests, which are compiled and executed in the target project. Moreover, we develop a web tool to assist developers in test migration. The effectiveness of our approach has been validated on five prevalent functional domain projects within the open-source community. We migrate a total of 550 unit tests and submitted pull requests to augment test code in the target projects on GitHub. By the time of this paper submission, 253 of these tests have already been merged into the projects (including 197 unit tests in the Luliyucoordinate-LeetCode project and 56 unit tests in the Rangerlee-HtmlParser project). Through running these tests, we identify 5 bugs, and 2 functional defects, and submitted corresponding issues to the project. The evaluation substantiates that MUT's test migration is both viable and beneficial across programming languages and different projects.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639124","Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); National Natural Science Foundation of China(grant numbers:62141222); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548477","Unit Test;AST;Test Migration","Computer languages;Codes;Filtering;Source coding;Syntactics;Human in the loop;Mobile applications","","","","61","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Programming Assistant for Exception Handling with CodeBERT","Y. Cai; A. Yadavally; A. Mishra; G. Montejo; T. N. Nguyen","University of Texas at Dallas, Texas, USA; University of Texas at Dallas, Texas, USA; University of Texas at Dallas, Texas, USA; University of Texas at Dallas, Texas, USA; University of Texas at Dallas, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1146","1158","With practical code reuse, the code fragments from developers' fo-rums often migrate to applications. Owing to the incomplete nature of such fragments, they often lack the details on exception handling. The adaptation for exception handling to the codebase is not trivial as developers must learn and memorize what API methods could cause exceptions and what exceptions need to be handled. We propose Neurex, an exception handling recommender that learns from complete code, and accepts a given Java code snippet and recommends 1) if a try-catch block is needed, 2) what statements need to be placed in a try block, and 3) what exception types need to be caught in the catch clause. Inspired by the sequence chunking techniques in natural language processing, we design NEurex via a multitasking model with the fine-tuning of the large language model CodeBERT for these three exception handling recommen-dation tasks. Via the large language model, Neurex can learn the surrounding context, leading to better learning the dependencies among the API elements, and the relations between the statements and the corresponding exception types needed to be handled. Our empirical evaluation shows that Neurex correctly performs all three exception handling recommendation tasks in 71.5% of the cases with a F1-score of 70.2%, which is a relative improvement of 166% over the baseline. It achieves high F1-score from 98.2%-99.7% in try-catch block necessity checking (a relative improvement of up to 55.9% over the baselines). It also correctly decides both the need for try-catch block(s) and the statements to be placed in try blocks with the F1-scores of 74.7% and 87.1% at the instance and statement levels, an improvement of 129.1% and 44.9% over the baseline, respectively. Our extrinsic evaluation shows that Neurex relatively improves over the baseline by 56.5% in F1-score for detecting exception-related bugs in incomplete Android code snippets.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639188","NSF(grant numbers:CNS-2120386); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548665","AI4SE;Large Language Models;Automated Exception Handling","Java;Codes;Computer bugs;Programming;Multitasking;Natural language processing;Task analysis","","","","44","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"CC: Causality-Aware Coverage Criterion for Deep Neural Networks","Z. Ji; P. Ma; Y. Yuan; S. Wang","The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China; The Hong Kong University of Science and Technology, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1788","1800","Deep neural network (DNN) testing approaches have grown fast in recent years to test the correctness and robustness of DNNs. In particular, DNN coverage criteria are frequently used to evaluate the quality of a test suite, and a number of coverage criteria based on neuron-wise, layer-wise, and path-/trace-wise coverage patterns have been published to date. However, we see that existing criteria are insufficient to represent how one neuron would influence subsequent neurons; hence, we lack a concept of how neurons, when functioning as causes and effects, might jointly make a DNN prediction. Given recent advances in interpreting DNN internals using causal inference, we present the first causality-aware DNN coverage criterion, which evaluates a test suite by quantifying the extent to which the suite provides new causal relations for testing DNNs. Performing standard causal inference on DNNs presents both theoretical and practical hurdles. We introduce CC (causal coverage), a practical and efficient coverage criterion that integrates a set of optimizations using DNN domain-specific knowledge. We illustrate the efficacy of CC using diverse, real-world inputs and adversarial inputs, such as adversarial examples (AEs) and backdoor inputs. We demonstrate that CC outperforms previous DNN criteria under various settings with moderate cost.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172609","machine learning testing;Causality Analysis;Software Engineering","Costs;Neurons;Artificial neural networks;Robustness;Optimization;Standards;Testing","","6","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A Comprehensive Study of Real-World Bugs in Machine Learning Model Optimization","H. Guan; Y. Xiao; J. Li; Y. Liu; G. Bai","The University of Queensland, Brisbane, Australia; Southern University of Science and Technology, Shenzhen, China; Microsoft Software Technology Center Asia, Beijing, China; Southern University of Science and Technology, Shenzhen, China; The University of Queensland, Brisbane, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","147","158","Due to the great advance in machine learning (ML) techniques, numerous ML models are expanding their application domains in recent years. To adapt for resource-constrained platforms such as mobile and Internet of Things (IoT) devices, pre-trained models are often processed to enhance their efficiency and compactness, using optimization techniques such as pruning and quantization. Similar to the optimization process in other complex systems, e.g., program compilers and databases, optimizations for ML models can contain bugs, leading to severe consequences such as system crashes and financial loss. While bugs in training, compiling and deployment stages have been extensively studied, there is still a lack of systematic understanding and characterization of model optimization bugs (MOBs). In this work, we conduct the first empirical study to identify and characterize MOBs. We collect a comprehensive dataset containing 371 MOBs from TensorFlow and PyTorch, the most extensively used open-source ML frameworks, covering the entire development time span of their optimizers (May 2019 to August 2022). We then investigate the collected bugs from various perspectives, including their symptoms, root causes, life cycles, detection and fixes. Our work unveils the status quo of MOBs in the wild, and reveals their features on which future detection techniques can be based. Our findings also serve as a warning to the developers and the users of ML frameworks, and an appeal to our research community to enact dedicated countermeasures.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00024","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172690","Machine Learning;Model Optimization;Bugs","Training;Adaptation models;Analytical models;Systematics;Computer bugs;Machine learning;Internet of Things","","5","","54","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Model translations among big-step modeling languages","F. Faghih","School of Computer Science, University of Waterloo, Waterloo, ONT, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1555","1558","Model Driven Engineering (MDE) is a progressive area that tries to fill the gap between problem definition and software development. There are many modeling languages proposed for use in MDE. A challenge is how to provide automatic analysis for these models without having to create new analyzers for each different language. In this research, we tackle this problem for a family of modeling languages using a semantically configurable model translation framework.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227038","Model Translation;Big-Step Modeling Languages;Formal Analysis;Model Checking","Semantics;Computational modeling;Mathematical model;Analytical models;Unified modeling language;Syntactics;Educational institutions","","1","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Rete: Learning Namespace Representation for Program Repair","N. Parasaram; E. T. Barr; S. Mechtaev","University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1264","1276","A key challenge of automated program repair is finding correct patches in the vast search space of candidate patches. Real-world programs define large namespaces of variables that considerably contributes to the search space explosion. Existing program repair approaches neglect information about the program namespace, which makes them inefficient and increases the chance of test-overfitting. We propose Rete, a new program repair technique, that learns project-independent information about program namespace and uses it to navigate the search space of patches. Rete uses a neural network to extract project-independent information about variable CDU chains, def-use chains augmented with control flow. Then, it ranks patches by jointly ranking variables and the patch templates into which the variables are inserted. We evaluated Rete on 142 bugs extracted from two datasets, ManyBugs and BugsInPy. Our experiments demonstrate that ReTe generates six new correct patches that fix bugs that previous tools did not repair, an improvement of 31% and 59% over the existing state of the art.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172760","Program Repair;Deep Learning;Patch Prioritisation;Variable Representation","Navigation;Computer bugs;Neural networks;Maintenance engineering;Aerospace electronics;Explosions;Data mining","","4","","73","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Inferring method specifications from natural language API descriptions","R. Pandita; X. Xiao; H. Zhong; T. Xie; S. Oney; A. Paradkar","Department of Computer Science, North Carolina State University, Raleigh, USA; Department of Computer Science, North Carolina State University, Raleigh, USA; Laboratory for Internet Software Technologies, Institute of Software, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, North Carolina State University, Raleigh, USA; Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, USA; IBM Thomas J. Watson Research Center, Hawthorne, NY, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","815","825","Application Programming Interface (API) documents are a typical way of describing legal usage of reusable software libraries, thus facilitating software reuse. However, even with such documents, developers often overlook some documents and build software systems that are inconsistent with the legal usage of those libraries. Existing software verification tools require formal specifications (such as code contracts), and therefore cannot directly verify the legal usage described in natural language text in API documents against code using that library. However, in practice, most libraries do not come with formal specifications, thus hindering tool-based verification. To address this issue, we propose a novel approach to infer formal specifications from natural language text of API documents. Our evaluation results show that our approach achieves an average of 92% precision and 93% recall in identifying sentences that describe code contracts from more than 2500 sentences of API documents. Furthermore, our results show that our approach has an average 83% accuracy in inferring specifications from over 1600 sentences describing code contracts.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227137","","Contracts;Semantics;Natural languages;Libraries;Law;Accuracy","","98","4","41","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Evaluating the Impact of Experimental Assumptions in Automated Fault Localization","E. Soremekun; L. Kirschner; M. Böhme; M. Papadakis","Royal Holloway, University of London, UK; Saarland University, Germany; MPI-SP, Germany; SnT, Luxembourg",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","159","171","Much research on automated program debugging often assumes that bug fix location(s) indicate the faults' root causes and that root causes of faults lie within single code elements (statements). It is also often assumed that the number of statements a developer would need to inspect before finding the first faulty statement reflects debugging effort. Although intuitive, these three assumptions are typically used (55% of experiments in surveyed publications make at least one of these three assumptions) without any consideration of their effects on the debugger's effectiveness and potential impact on developers in practice. To deal with this issue, we perform controlled experimentation, split testing in particular, using 352 bugs from 46 open-source C programs, 19 Automated Fault Localization (AFL) techniques (18 statistical debugging formulas and dynamic slicing), two (2) state-of-the-art automated program repair (APR) techniques (GenProg and Angelix) and 76 professional developers. Our results show that these assumptions conceal the difficulty of debugging. They make AFL techniques appear to be (up to 38%) more effective, and make APR tools appear to be (2X) less effective. We also find that most developers (83%) consider these assumptions to be unsuitable for debuggers and, perhaps worse, that they may inhibit development productivity. The majority (66%) of developers prefer debugging diagnoses without these assumptions twice as much as with the assumptions. Our findings motivate the need to assess debuggers conservatively, i.e., without these assumptions.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172588","fault localization;program repair;user study","Location awareness;Productivity;Codes;Computer bugs;Debugging;Maintenance engineering;Fault location","","3","","85","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Do Automatic Test Generation Tools Generate Flaky Tests?","M. Gruber; M. F. Roslan; O. Parry; F. Scharnböck; P. McMinn; G. Fraser","BMW Group, University of Passau, Munich, Germany; University of Sheffield, Sheffield, United Kingdom; University of Sheffield, Sheffield, United Kingdom; University of Passau, Passau, Germany; University of Sheffield, Sheffield, United Kingdom; University of Passau, Passau, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","554","565","Non-deterministic test behavior, or flakiness, is common and dreaded among developers. Researchers have studied the issue and proposed approaches to mitigate it. However, the vast majority of previous work has only considered developer-written tests. The prevalence and nature of flaky tests produced by test generation tools remain largely unknown. We ask whether such tools also produce flaky tests and how these differ from developer-written ones. Further-more, we evaluate mechanisms that suppress flaky test generation. We sample 6 356 projects written in Java or Python. For each project, we generate tests using EvoSuite (Java) and Pynguin (Py-thon), and execute each test 200 times, looking for inconsistent outcomes. Our results show that flakiness is at least as common in generated tests as in developer-written tests. Nevertheless, existing flakiness suppression mechanisms implemented in EvoSuite are effective in alleviating this issue (71.7 % fewer flaky tests). Compared to developer-written flaky tests, the causes of generated flaky tests are distributed differently. Their non-deterministic behavior is more frequently caused by randomness, rather than by networking and concurrency. Using flakiness suppression, the remaining flaky tests differ significantly from any flakiness previously reported, where most are attributable to runtime optimizations and EvoSuite-internal resource thresholds. These insights, with the accompanying dataset, can help maintainers to improve test generation tools, give recommendations for developers using these tools, and serve as a foundation for future research in test flakiness or test generation.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548149","Test Generation;Flaky Tests;Empirical Study","Concurrent computing;Software testing;Java;Runtime;Test pattern generators;Optimization;Python","","","","68","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Synthesizing API usage examples","R. P. L. Buse; W. Weimer","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","782","792","Key program interfaces are sometimes documented with usage examples: concrete code snippets that characterize common use cases for a particular data type. While such documentation is known to be of great utility, it is burdensome to create and can be incomplete, out of date, or not representative of actual practice. We present an automatic technique for mining and synthesizing succinct and representative human-readable documentation of program interfaces. Our algorithm is based on a combination of path sensitive dataflow analysis, clustering, and pattern abstraction. It produces output in the form of well-typed program snippets which document initialization, method calls, assignments, looping constructs, and exception handling. In a human study involving over 150 participants, 82% of our generated examples were found to be at least as good at human-written instances and 94% were strictly preferred to state of the art code search.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227140","","Documentation;Concrete;Humans;Abstracts;Java;Algorithm design and analysis;Clustering algorithms","","94","1","39","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Automating test automation","S. Thummalapenta; S. Sinha; N. Singhania; S. Chandra","IBM Research, India; IBM Research, India; IBM Research, India; IBM Thomas J. Watson Research Center, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","881","891","Mention “test case”, and it conjures up the image of a script or a program that exercises a system under test. In industrial practice, however, test cases often start out as steps described in natural language. These are essentially directions a human tester needs to follow to interact with an application, exercising a given scenario. Since tests need to be executed repeatedly, such manual tests then have to go through test automation to create scripts or programs out of them. Test automation can be expensive in programmer time. We describe a technique to automate test automation. The input to our technique is a sequence of steps written in natural language, and the output is a sequence of procedure calls with accompanying parameters that can drive the application without human intervention. The technique is based on looking at the natural language test steps as consisting of segments that describe actions on targets, except that there can be ambiguity in identifying segments, in identifying the action in a segment, as well as in the specification of the target of the action. The technique resolves this ambiguity by backtracking, until it can synthesize a successful sequence of calls. We present an evaluation of our technique on professionally created manual test cases for two open-source web applications as well as a proprietary enterprise application. Our technique could automate over 82% of the steps contained in these test cases with no human intervention, indicating that the technique can reduce the cost of test automation quite effectively.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227131","","Manuals;Automation;Optimization;Humans;Natural languages;Programming profession","","47","5","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Industrial application of concolic testing approach: A case study on libexif by using CREST-BV and KLEE","Y. Kim; M. Kim; Y. J. Kim; Y. Jang","CS Department, KAIST, South Korea; CS Department, KAIST, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, Daejeon, KR; Samsung Electronics, South Korea",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1143","1152","As smartphones become popular, manufacturers such as Samsung Electronics are developing smartphones with rich functionality such as a camera and photo editing quickly, which accelerates the adoption of open source applications in the smartphone platforms. However, developers often do not know the detail of open source applications, because they did not develop the applications themselves. Thus, it is a challenging problem to test open source applications effectively in short time. This paper reports our experience of applying concolic testing technique to test libexif, an open source library to manipulate EXIF information in image files. We have demonstrated that concolic testing technique is effective and efficient at detecting bugs with modest effort in industrial setting. We also compare two concolic testing tools, CREST-BV and KLEE, in this testing project. Furthermore, we compare the concolic testing results with the analysis result of the Coverity Prevent static analyzer. We detected a memory access bug, a null pointer dereference bug, and four divide-by-zero bugs in libexif through concolic testing, none of which were detected by Coverity Prevent.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227105","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227105","","Testing;Computer bugs;Smart phones;Instruments;Search problems;Concrete;Cameras","","21","","29","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CLEAR: Contrastive Learning for API Recommendation","M. Wei; N. S. Harzevili; Y. Huang; J. Wang; S. Wang","York University, Toronto, Canada; York University, Toronto, Canada; Institute of Software Chinese Academy of Sciences; Institute of Software Chinese Academy of Sciences; York University, Toronto, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","376","387","Automatic API recommendation has been studied for years. There are two orthogonal lines of approaches for this task, i.e., information-retrieval-based (IR-based) and neural-based methods. Although these approaches were reported having remarkable performance, our observation shows that existing approaches can fail due to the following two reasons: 1) most IR-based approaches treat task queries as bag-of-words and use word embedding to represent queries, which cannot capture the sequential semantic information. 2) both the IR-based and the neural-based approaches are weak at distinguishing the semantic difference among lexically similar queries. In this paper, we propose CLEAR, which leverages BERT sen-tence embedding and contrastive learning to tackle the above two is-sues. Specifically, CLEAR embeds the whole sentence of queries and Stack Overflow (SO) posts with a BERT-based model rather than the bag-of-word-based word embedding model, which can preserve the semantic-related sequential information. In addition, CLEAR uses contrastive learning to train the BERT-based embedding model for learning precise semantic representation of programming termi-nologies regardless of their lexical information. CLEAR also builds a BERT-based re-ranking model to optimize its recommendation results. Given a query, CLEAR first selects a set of candidate SO posts via the BERT sentence embedding-based similarity to reduce search space. CLEAR further leverages a BERT-based re-ranking model to rank candidate SO posts and recommends the APIs from the ranked top SO posts for the query. Our experiment results on three different test datasets confirm the effectiveness of CLEAR for both method-level and class-level API recommendation. Compared to the state-of-the-art API recom-mendation approaches, CLEAR improves the MAP by 25%-187% at method-level and 10%-100% at class-level.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510159","Natural Sciences and Engineering Research Council of Canada; National Natural Science Foundation of China(grant numbers:62072442); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793955","API recommendation;contrastive learning;semantic difference","Training;Codes;Linux;Semantics;Bit error rate;Programming;Task analysis","","13","","53","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Using knowledge elicitation to improve Web effort estimation: Lessons from six industrial case studies","E. Mendes","College of IT, Zayed University, Dubai, UAE",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1112","1121","This paper details our experience building and validating six different expert-based Web effort estimation models for ICT companies in New Zealand and Brazil. All models were created using Bayesian networks, via eliciting knowledge from domain experts, and validated using data from past finished projects. Post-mortem interviews with the participating companies showed that they found the entire process extremely beneficial and worthwhile, and that all the models created remained in use by those companies.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227108","Web/software effort estimation;expert-based models;bayesian networks;project management","Companies;Estimation;Predictive models;Context;Accuracy;Bayesian methods;Web pages","","14","","25","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Dependency Facade: The Coupling and Conflicts between Android Framework and Its Customization","W. Jin; Y. Dai; J. Zheng; Y. Qu; M. Fan; Z. Huang; D. Huang; T. Liu","Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; University of California, Riverside, California, United States; Xi'an Jiaotong University, Xi'an, China; Honor Device Co., Ltd, Xi'an, China; Honor Device Co., Ltd, Xi'an, China; Xi'an Jiaotong University, Xi'an, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1674","1686","Mobile device vendors develop their customized Android OS (termed downstream) based on Google Android (termed upstream) to support new features. During daily independent development, the downstream also periodically merges changes of a new release from the upstream into its development branches, keeping in sync with the upstream. Due to a large number of commits to be merged, heavy code conflicts would be reported if auto-merge operations failed. Prior work has studied conflicts in this scenario. However, it is still unclear about the coupling between the downstream and the upstream (We term this coupling as the dependency facade), as well as how merge conflicts are related to this coupling. To address this issue, we first propose the DepFCD to reveal the dependency facade from three aspects, including interface-level dependencies that indicate a clear design boundary, intrusion-level dependencies which blur the boundary, and dependency constraints imposed by the upstream non-SDK restrictions. We then empirically investigate these three aspects (RQ1, RQ2, RQ3) and merge conflicts (RQ4) on the dependency facade. To support the study, we collect four open-source downstream projects and one industrial project, with 15 downstream and 15 corresponding upstream versions. Our study reveals interesting observations and suggests earlier mitigation of merge conflicts through a well-managed dependency facade. Our study will benefit the research about the coupling between upstream and downstream as well as the downstream maintenance practice.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00144","National Key R&D Program of China(grant numbers:2022YFB2703503); National Natural Science Foundation of China(grant numbers:62232014,62293501,62272377,62293502,72241433,61721002,62032010,62002280); Fundamental Research Funds for the Central Universities; China Postdoctoral Science Foundation(grant numbers:2020M683507,2019TQ0251,2020M673439); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172626","Android;downstream;dependencies;merge conflict","Couplings;Codes;Ecosystems;Maintenance engineering;Internet;Synchronization;Smart phones","","2","","52","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"UPCY: Safely Updating Outdated Dependencies","A. Dann; B. Hermann; E. Bodden","CodeShield GmbH, Paderborn, Germany; Technical University Dortmund, Dortmund, Germany; Heinz Nixdorf Institute & Fraunhofer IEM, Paderborn, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","233","244","Recent research has shown that developers hesitate to update dependencies and mistrust automated approaches such as Dependabot, since they are afraid of introducing incompatibilities that break their project. In fact, such approaches only suggest naïve updates for a single outdated library but do not ensure compatibility with other dependent libraries in the project. To alleviate this situation and support developers in finding updates with minimal incompatibilities, we present UPCY. UPCY applies the min-(s,t)-cut algorithm and leverages a graph database of Maven Central to identify a list of valid update steps to update a dependency to a target version while minimizing incompatibilities with other libraries. By executing 29,698 updates in 380 projects, we compare the effectiveness of UPCY with the naïve updates applied by state-of-the-art tools. We find that in 41.1% of the cases where the naïve approach fails UPCY generates updates with fewer incompatibilities, and even 70.1% of the generated updates have zero incompatibilities.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00031","German Research Foundation(grant numbers:160364472); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172511","Semantic versioning;Library updates;Package management;Dependency management;Software maintenance","Measurement;Java;Databases;Semantics;Static analysis;Maintenance engineering;Libraries","","1","","32","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"When and Why Test Generators for Deep Learning Produce Invalid Inputs: an Empirical Study","V. Riccio; P. Tonella","Università della Svizzera italiana, Lugano, Switzerland; Università della Svizzera italiana, Lugano, Switzerland",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1161","1173","Testing Deep Learning (DL) based systems inherently requires large and representative test sets to evaluate whether DL systems generalise beyond their training datasets. Diverse Test Input Generators (TIGs) have been proposed to produce artificial inputs that expose issues of the DL systems by triggering misbehaviours. Unfortunately, such generated inputs may be invalid, i.e., not recognisable as part of the input domain, thus providing an unreliable quality assessment. Automated validators can ease the burden of manually checking the validity of inputs for human testers, although input validity is a concept difficult to formalise and, thus, automate. In this paper, we investigate to what extent TIGs can generate valid inputs, according to both automated and human validators. We conduct a large empirical study, involving 2 different automated validators, 220 human assessors, 5 different TIGs and 3 classification tasks. Our results show that 84% artificially generated inputs are valid, according to automated validators, but their expected label is not always preserved. Automated validators reach a good consensus with humans (78% accuracy), but still have limitations when dealing with feature-rich datasets.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172704","software testing;deep learning","Deep learning;Training;Generators;Software;Quality assessment;Task analysis;Testing","","11","","61","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Disengagement in pair programming: Does it matter?","L. Plonka; H. Sharp; J. van der Linden","Centre for Research in Computing, Open University, Milton Keynes, UK; Centre for Research in Computing, Open University, Milton Keynes, UK; Centre for Research in Computing, Open University, Milton Keynes, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","496","506","Pair Programming (PP) requires close collaboration and mutual engagement. Most existing empirical studies of PP do not focus on developers' behaviour during PP sessions, and focus instead on the effects of PP such as productivity. However, disengagement, where a developer is not focusing on solving the task or understanding the problem and allows their partner to work by themselves, can hinder collaboration between developers and have a negative effect on their performance. This paper reports on an empirical study that investigates disengagement. Twenty-one industrial pair programming sessions were video and audio recorded and qualitatively analysed to investigate circumstances that lead to disengagement. We identified five reasons for disengagement: interruptions during the collaboration, the way the work is divided, the simplicity of the task involved, social pressure on inexperienced pair programmers, and time pressure. Our findings suggest that disengagement is sometimes acceptable and agreed upon between the developers in order to speed up problem solving. However, we also found episodes of disengagement where developers “drop out” of their PP sessions and are not able to follow their partner's work nor contribute to the task at hand, thus losing the expected benefits of pairing. Analysis of sessions conducted under similar circumstances but where mutual engagement was sustained identified three behaviours that help to maintain engagement: encouraging the novice to drive, verbalisation and feedback, and asking for clarification.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227166","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227166","collaboration;agile software development;empirical study","Collaboration;Programming;Interviews;Navigation;Companies;Focusing;Video recording","","12","","31","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"CodeFill: Multi-token Code Completion by Jointly learning from Structure and Naming Sequences","M. Izadi; R. Gismondi; G. Gousios","Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","401","412","Code completion is an essential feature of IDEs, yet current auto-completers are restricted to either grammar-based or NLP-based single token completions. Both approaches have significant draw-backs: grammar-based autocompletion is restricted in dynamically-typed language environments, whereas NLP-based autocompleters struggle to understand the semantics of the programming language and the developer's code context. In this work, we present CodeFill, a language model for autocompletion that combines learned structure and naming information. Using a parallel Transformer architecture and multi-task learning, CodeFill consumes sequences of source code token names and their equivalent AST token types. Uniquely, CodeFill is trained both for single-token and multi-token (statement) prediction, which enables it to learn long-range dependencies among grammatical and naming elements. We train CodeFill on two datasets, consisting of 29M and 425M lines of code, respectively. To make the evaluation more realistic, we develop a method to automatically infer points in the source code at which completion matters. We compare CodeFill against four baselines and two state-of-the-art models, GPT-C and TravTrans+. CodeFill surpasses all baselines in single token prediction (MRR: 70.9% vs. 66.2% and 67.8%) and outperforms the state of the art for multi-token prediction (ROUGE-L: 63.7% vs. 52.4% and 59.2%, for $n=4$ tokens). We publicly release our source code and datasets.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794048","Automatic Code Completion;Transformers;Multi-Task Learning;Types;Dynamically-typed Languages","Computer languages;Codes;Semantics;Computer architecture;Transformers;Multitasking;Software engineering","","23","","56","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"One Fuzzing Strategy to Rule Them All","M. Wu; L. Jiang; J. Xiang; Y. Huang; H. Cui; L. Zhang; Y. Zhang","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; The University of Hong Kong, Hong Kong, China; University of Illinois, Urbana-Champaign, USA; Southern University of Science and Technology, Shenzhen, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1634","1645","Coverage-guided fuzzing has become mainstream in fuzzing to automatically expose program vulnerabilities. Recently, a group of fuzzers are proposed to adopt a random search mechanism namely Havoc, explicitly or implicitly, to augment their edge exploration. However, they only tend to adopt the default setup of Havoc as an implementation option while none of them attempts to explore its power under diverse setups or inspect its rationale for potential improvement. In this paper, to address such issues, we conduct the first empirical study on Havoc to enhance the understanding of its characteristics. Specifically, we first find that applying the default setup of Havoc to fuzzers can significantly improve their edge coverage performance. Interestingly, we further observe that even simply executing Havoc itself without appending it to any fuzzer can lead to strong edge coverage performance and outper-form most of our studied fuzzers. Moreover, we also extend the execution time of Havoc and find that most fuzzers can not only achieve significantly higher edge coverage, but also tend to perform similarly (i.e., their performance gaps get largely bridged). Inspired by the findings, we further propose HavocMAB, which models the Havoc mutation strategy as a multi-armed bandit problem to be solved by dynamically adjusting the mutation strategy. The evaluation result presents that HavocMAB can significantly increase the edge coverage by 11.1% on average for all the benchmark projects compared with Havoc and even slightly outperform state-of-the-art QSYM which augments its computing resource by adopting three parallel threads. We further execute HavocMAB with three parallel threads and result in 9% higher average edge coverage over QSYM upon all the benchmark projects.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510174","National Natural Science Foundation of China(grant numbers:61902169); Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794101","","Instruction sets;Image edge detection;Fuzzing;Benchmark testing;Software engineering","","16","","56","","20 Jun 2022","","","IEEE","IEEE Conferences"
"AutoTransform: Automated Code Transformation to Support Modern Code Review Process","P. Thongtanunam; C. Pornprasit; C. Tantithamthavorn","The University of Melbourne, Australia; Monash University, Australia; Monash University, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","237","248","Code review is effective, but human-intensive (e.g., developers need to manually modify source code until it is approved). Recently, prior work proposed a Neural Machine Translation (NMT) approach to automatically transform source code to the version that is reviewed and approved (i.e., the after version). Yet, its performance is still suboptimal when the after version has new identifiers or literals (e.g., renamed variables) or has many code tokens. To address these limitations, we propose AutoTransform which leverages a Byte-Pair Encoding (BPE) approach to handle new tokens and a Transformer-based NMT architecture to handle long sequences. We evaluate our approach based on 14,750 changed methods with and without new tokens for both small and medium sizes. The results show that when generating one candidate for the after version (i.e., beam width = 1), our AUTOTRANSFORM can correctly transform 1,413 changed methods, which is 567% higher than the prior work, highlighting the substantial improvement of our approach for code transformation in the context of code review. This work contributes towards automated code transformation for code reviews, which could help developers reduce their effort in modifying source code during the code review process.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510067","the Australian Research Council's Discovery Early Career Researcher Award (DE-CRA) funding scheme(grant numbers:DE210101091); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793987","Code Reviews;Neural Machine Translation;Code Transformation","Codes;Transforms;Transformers;Encoding;Machine translation;Software engineering","","15","","66","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Automatic Detection of Performance Bugs in Database Systems using Equivalent Queries","X. Liu; Q. Zhou; J. Arulrai; A. Orso","Georgia Institute of Technology, Atlanta, GA, USA; Meta, Seattle, WA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","225","236","Because modern data-intensive applications rely heavily on database systems (DBMSs), developers extensively test these systems to elim-inate bugs that negatively affect functionality. Besides functional bugs, however, there is another important class of faults that negatively affect the response time of a DBMS, known as performance bugs. Despite their potential impact on end-user experience, performance bugs have received considerably less attention than functional bugs. To fill this gap, we present Amoeba, a technique and tool for automatically detecting performance bugs in DBMSs. The core idea behind Amoeba is to construct semantically equivalent query pairs, run both queries on the DBMS under test, and compare their response time. If the queries exhibit significantly different response times, that indicates the possible presence of a performance bug in the DBMS. To construct equivalent queries, we propose to use a set of structure and expression mutation rules especially targeted at un-covering performance bugs. We also introduce feedback mechanisms for improving the effectiveness and efficiency of the approach. We evaluate Amoeba on two widely-used DBMSs, namely PostgreSQL and CockroachDB, with promising results: Amoeba has so far dis-covered 39 potential performance bugs, among which developers have already confirmed 6 bugs and fixed 5 bugs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510093","NSF(grant numbers:CCF-1563991,CCF-0725202,IIS-1850342,IIS-1908984); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793961","Differential testing;database testing;query optimization","Computer bugs;Debugging;Database systems;Time factors;Optimization;Software engineering","","12","","48","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Decomposing Convolutional Neural Networks into Reusable and Replaceable Modules","R. Pan; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","524","535","Training from scratch is the most common way to build a Convolutional Neural Network (CNN) based model. What if we can build new CNN models by reusing parts from previously built CNN models? What if we can improve a CNN model by replacing (possibly faulty) parts with other parts? In both cases, instead of training, can we identify the part responsible for each output class (module) in the model(s) and reuse or replace only the desired output classes to build a model? Prior work has proposed decomposing dense-based networks into modules (one for each output class) to enable reusability and replace ability in various scenarios. However, this work is limited to the dense layers and is based on the one-to-one relationship between the nodes in consecutive layers. Due to the shared architecture in the CNN model, prior work cannot be adapted directly. In this paper, we propose to decompose a CNN model used for image classification problems into modules for each output class. These modules can further be reused or replaced to build a new model. We have evaluated our approach with CIFAR-10, CIFAR-100, and ImageNet tiny datasets with three variations of ResNet models and found that enabling decomposition comes with a small cost (1.77% and 0.85% for top-1 and top-5 accuracy, respectively). Also, building a model by reusing or replacing modules can be done with a 2.3% and 0.5% average loss of accuracy. Furthermore, reusing and replacing these modules reduces CO2e emission by ~37 times compared to training the model from scratch.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793875","deep learning;cnn;deep neural network;modularity;decomposition","Training;Adaptation models;Costs;Buildings;Computer architecture;Convolutional neural networks;Software engineering","","10","","42","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Incident-aware Duplicate Ticket Aggregation for Cloud Systems","J. Liu; S. He; Z. Chen; L. Li; Y. Kang; X. Zhang; P. He; H. Zhang; Q. Lin; Z. Xu; S. Rajmohan; D. Zhang; M. R. Lyu","The Chinese University of Hong Kong, Hong Kong SAR, China; Microsoft Research, Beijing, China; The Chinese University of Hong Kong, Hong Kong SAR, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; The Chinese University of Hong Kong, Shenzhen, China; Chongqing University, Chongqing, China; Microsoft Research, Beijing, China; Microsoft Azure, Redmond, USA; Microsoft 365, Redmond, USA; Microsoft Research, Beijing, China; The Chinese University of Hong Kong, Hong Kong SAR, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2299","2311","In cloud systems, incidents are potential threats to customer satisfaction and business revenue. When customers are affected by incidents, they often request customer support service (CSS) from the cloud provider by submitting a support ticket. Many tickets could be duplicate as they are reported in a distributed and uncoordinated manner. Thus, aggregating such duplicate tickets is essential for efficient ticket management. Previous studies mainly rely on tickets' textual similarity to detect duplication; however, duplicate tickets in a cloud system could carry semantically different descriptions due to the complex service dependency of the cloud system. To tackle this problem, we propose iPACK, an incident-aware method for aggregating duplicate tickets by fusing the failure information between the customer side (i.e., tickets) and the cloud side (i.e., incidents). We extensively evaluate iPACK on three datasets collected from the production environment of a large-scale cloud platform, Azure. The experimental results show that iPACK can precisely and comprehensively aggregate duplicate tickets, achieving an F1 score of 0.871~0.935 and outperforming state-of-the-art methods by 12.4%~31.2%.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00193","Australian Research Council (ARC) Discovery Projects(grant numbers:DP200102940,DP220103044); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172621","duplicate tickets;incidents;cloud systems;reliability","Root cause analysis;Aggregates;Semantics;Customer satisfaction;Production;Complexity theory;Software engineering","","8","","72","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Turn the Rudder: A Beacon of Reentrancy Detection for Smart Contracts on Ethereum","Z. Zheng; N. Zhang; J. Su; Z. Zhong; M. Ye; J. Chen","Sun Yat-sen University, China; Sun Yat-sen University, China; Sun Yat-sen University, China; Sun Yat-sen University, China; Sun Yat-sen University, China; Sun Yat-sen University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","295","306","Smart contracts are programs deployed on a blockchain and are immutable once deployed. Reentrancy, one of the most important vulnerabilities in smart contracts, has caused millions of dollars in financial loss. Many reentrancy detection approaches have been proposed. It is necessary to investigate the performance of these approaches to provide useful guidelines for their application. In this work, we conduct a large-scale empirical study on the capability of five well-known or recent reentrancy detection tools such as Mythril and Sailfish. We collect 230,548 verified smart contracts from Etherscan and use detection tools to analyze 139,424 contracts after deduplication, which results in 21,212 contracts with reentrancy issues. Then, we manually examine the defective functions located by the tools in the contracts. From the examination results, we obtain 34 true positive contracts with reentrancy and 21,178 false positive contracts without reentrancy. We also analyze the causes of the true and false positives. Finally, we evaluate the tools based on the two kinds of contracts. The results show that more than 99.8% of the reentrant contracts detected by the tools are false positives with eight types of causes, and the tools can only detect the reentrancy issues caused by call.value(), 58.8% of which can be revealed by the Ethereum's official IDE, Remix. Furthermore, we collect real-world reentrancy attacks reported in the past two years and find that the tools fail to find any issues in the corresponding contracts. Based on the findings, existing works on reentrancy detection appear to have very limited capability, and researchers should turn the rudder to discover and detect new reentrancy patterns except those related to call.value().","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00036","National Natural Science Foundation of China(grant numbers:62032025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172623","Smart contract;Reentrancy;Empirical study","Smart contracts;Blockchains;Software engineering;Guidelines","","8","","40","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Taintmini: Detecting Flow of Sensitive Data in Mini-Programs with Static Taint Analysis","C. Wang; R. Ko; Y. Zhang; Y. Yang; Z. Lin",The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University; The Ohio State University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","932","944","Mini-programs, which are programs running inside mobile super apps such as WeChat, often have access to privacy-sensitive information, such as location data and phone numbers, through APUs provided by the super apps. This access poses a risk of privacy sensitive data leaks, either accidentally from carelessly programmed mini-programs or intentionally from malicious ones. To address this concern, it is crucial to track the flow of sensitive data in mini-programs for either human analysis or automated tools. Although existing taint analysis techniques have been widely studied, they face unique challenges in tracking sensitive data flows in mini-programs, such as cross-language, cross-page, and cross-mini-program data flows. This paper presents a novel framework, Taintmini, which addresses these challenges by using a novel universal data flow graph approach that captures data flows within and across mini-programs. We have evaluated Taintminiwith 238,866 mini-programs and detect 27,184 that contain sensitive data flows. We have also applied Taintminito detect privacy leakage colluding mini-programs and identify 455 such programs from them that clearly violate privacy policy.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00086","DARPA(grant numbers:N6600120C4020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172538","Mini-programs;Taint analysis;Privacy leaks detection;Security;Empirical Study","Privacy;Data privacy;Social networking (online);Message services;Flow graphs;Faces;Software engineering","","5","","51","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Nessie: Automatically Testing JavaScript APIs with Asynchronous Callbacks","E. Arteca; S. Harner; M. Pradel; F. Tip","Northeastern University, USA; University of Stuttgart, Germany; University of Stuttgart, Germany; Northeastern University, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1494","1505","Previous algorithms for feedback-directed unit test generation iteratively create sequences of API calls by executing partial tests and by adding new API calls at the end of the test. These algorithms are challenged by a popular class of APIs: higher-order functions that receive callback arguments, which often are invoked asyn-chronously. Existing test generators cannot effectively test such APIs because they only sequence API calls, but do not nest one call into the callback function of another. This paper presents Nessie, the first feedback-directed unit test generator that supports nesting of API calls and that tests asynchronous callbacks. Nesting API calls enables a test to use values produced by an API that are available only once a callback has been invoked, and is often necessary to ensure that methods are invoked in a specific order. The core contributions of our approach are a tree-based representation of unit tests with callbacks and a novel algorithm to iteratively generate such tests in a feedback-directed manner. We evaluate our approach on ten popular JavaScript libraries with both asynchronous and synchronous callbacks. The results show that, in a comparison with LambdaTester, a state of the art test generation technique that only considers sequencing of method calls, Nessie finds more behavioral differences and achieves slightly higher coverage. Notably, Nessie needs to generate significantly fewer tests to achieve and exceed the coverage achieved by the state of the art.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793885","asynchronous programming;test generation;JavaScript;testing","Sequential analysis;Generators;Libraries;Behavioral sciences;Test pattern generators;Testing;Software engineering","","4","","45","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Rotten Apples Spoil the Bunch: An Anatomy of Google Play Malware","M. Cao; K. Ahmed; J. Rubin","Univ. of British Columbia, Canada; Univ. of British Columbia, Canada; Univ. of British Columbia, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1919","1931","This paper provides an in-depth analysis of Android malware that bypassed the strictest defenses of the Google Play application store and penetrated the official Android market between January 2016 and July 2021. We systematically identified 1,238 such malicious applications, grouped them into 134 families, and manually analyzed one application from 105 distinct families. During our manual analysis, we identified malicious payloads the applications execute, conditions guarding execution of the payloads, hiding techniques applications employ to evade detection by the user, and other implementation-level properties relevant for automated malware detection. As most applications in our dataset contain multiple payloads, each triggered via its own complex activation logic, we also contribute a graph-based representation showing activation paths for all application payloads in form of a control- and data-flow graph. Furthermore, we discuss the capabilities of existing malware detection tools, put them in context of the properties observed in the analyzed malware, and identify gaps and future research directions. We believe that our detailed analysis of the recent, evasive malware will be of interest to researchers and practitioners and will help further improve malware detection tools.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794132","Android;malware;dataset;malware detection;manual analysis","Codes;Manuals;Malware;Internet;Behavioral sciences;Payloads;Software engineering","","2","","109","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Carving UI Tests to Generate API Tests and API Specification","R. Yandrapally; S. Sinha; R. Tzoref-Brill; A. Mesbah","University of British Columbia, Vancouver, BC, Canada; IBM Research, NY, USA; IBM Research, Haifa, Israel; University of British Columbia, Vancouver, BC, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1971","1982","Modern web applications make extensive use of API calls to update the UI state in response to user events or server-side changes. For such applications, API-level testing can play an important role, in-between unit-level testing and UI-level (or end-to-end) testing. Existing API testing tools require API specifications (e.g., OpenAPI), which often may not be available or, when available, be inconsistent with the API implementation, thus limiting the applicability of automated API testing to web applications. In this paper, we present an approach that leverages UI testing to enable API-level testing for web applications. Our technique navigates the web application under test and automatically generates an API-level test suite, along with an OpenAPI specification that describes the application's server-side APIs (for REST-based web applications). A key element of our solution is a dynamic approach for inferring API endpoints with path parameters via UI navigation and directed API probing. We evaluated the technique for its accuracy in inferring API specifications and the effectiveness of the “carved” API tests. Our results on seven open-source web applications show that the technique achieves 98% precision and 56% recall in inferring endpoints. The carved API tests, when added to test suites generated by two automated REST API testing tools, increase statement coverage by 52% and 29% and branch coverage by 99% and 75%, on average. The main benefits of our technique are: (1) it enables API-level testing of web applications in cases where existing API testing tools are inapplicable and (2) it creates API-level test suites that cover server-side code efficiently while exercising APIs as they would be invoked from an application's web UI, and that can augment existing API test suites.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172784","Web Application Testing;API Testing;Test Generation;UI Testing;End-to-end Testing;Test Carving;API Specification Inference","Limiting;Codes;Navigation;Testing;Software engineering","","2","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"FlakeSync: Automatically Repairing Async Flaky Tests","S. Rahman; A. Shi","The University of Texas at Austin, Austin, Texas, USA; The University of Texas at Austin, Austin, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1673","1684","Regression testing is an important part of the development process but suffers from the presence of flaky tests. Flaky tests nondeter-ministically pass or fail when run on the same code, misleading developers about the correctness of their changes. A common type of flaky tests are async flaky tests that flakily fail due to timing-related issues such as asynchronous waits that do not return in time or different thread interleavings during execution. Developers commonly try to repair async flaky tests by inserting or increasing some wait time, but such repairs are unreliable. We propose FlakeSync, a technique for automatically repairing async flaky tests by introducing synchronization for a specific test execution. FlakeSync works by identifying a critical point, representing some key part of code that must be executed early w.r.t. other concurrently executing code, and a barrier point, representing the part of code that should wait until the critical point has been executed. FlakeSync can modify code to check when the critical point is executed and have the barrier point keep waiting until the critical point has been executed, essentially synchronizing these two parts of code for the specific test execution. Our evaluation of FlakeSync on known flaky tests from prior work shows that FlakeSync can automatically repair 83.75% of async flaky tests, and the resulting changes add a median overhead of only 1.00X the original test runtime. We submitted 10 pull requests with our changes to developers, with 3 already accepted and none rejected.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639115","NSF(grant numbers:CCF-2145774); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548464","flaky test repair;async flaky tests","Codes;Runtime;Source coding;Software algorithms;Maintenance engineering;Delays;Synchronization","","2","","45","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Garbage Collection Makes Rust Easier to Use: A Randomized Controlled Trial of the Bronze Garbage Collector","M. Coblenz; M. L. Mazurek; M. Hicks","University of Maryland College Park, Maryland, USA; University of Maryland College Park, Maryland, USA; University of Maryland College Park, Maryland, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1021","1032","Rust is a general-purpose programming language that is both type-and memory-safe. Rust does not use a garbage collector, but rather achieves these properties through a sophisticated, but complex, type system. Doing so makes Rust very efficient, but makes Rust relatively hard to learn and use. We designed Bronze, an optional, library-based garbage collector for Rust. To see whether Bronze could make Rust more usable, we conducted a randomized con-trolled trial with volunteers from a 633-person class, collecting data from 428 students in total. We found that for a task that required managing complex aliasing, Bronze users were more likely to complete the task in the time available, and those who did so required only about a third as much time (4 hours vs. 12 hours). We found no significant difference in total time, even though Bronze users re-did the task without Bronze afterward. Surveys indicated that ownership, borrowing, and lifetimes were primary causes of the challenges that users faced when using Rust.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793872","Rust;garbage collection;usability of programming languages;em-pirical study of programming languages;programming education","Computer languages;Education;Task analysis;Programming profession;Software engineering","","2","","1","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Domain Knowledge Matters: Improving Prompts with Fix Templates for Repairing Python Type Errors","Y. Peng; S. Gao; C. Gao; Y. Huo; M. R. Lyu","The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","12","24","As a dynamic programming language, Python has become increasingly popular in recent years. Although the dynamic type system of Python facilitates the developers in writing Python programs, it also brings type errors at runtime which are prevalent yet not easy to fix. There exist rule-based approaches for automatically repairing Python type errors. The approaches can generate accurate patches for the type errors covered by manually defined templates, but they require domain experts to design patch synthesis rules and suffer from low template coverage of real-world type errors. Learning-based approaches alleviate the manual efforts in designing patch synthesis rules and have become prevalent due to the recent advances in deep learning. Among the learning-based approaches, the prompt-based approach which leverages the knowledge base of code pretrained models via predefined prompts, obtains state-of-the-art performance in general program repair tasks. However, such prompts are manually defined and do not involve any specific clues for repairing Python type errors, resulting in limited effectiveness. How to automatically improve prompts with the domain knowledge for type error repair is challenging yet under-explored. In this paper, we present Typefix, a novel prompt-based approach with fix templates incorporated for repairing Python type errors. Typefix first mines generalized fix templates via a novel hierarchical clustering algorithm. The identified fix templates indicate the common edit patterns and contexts of existing type error fixes. Typefix then generates code prompts for code pretrained models by employing the generalized fix templates as domain knowledge, in which the masks are adaptively located for each type error instead of being pre-determined. Experiments on two benchmarks, including BUGSINPy and TYPEBUGS, show that Typefix successfully repairs 26 and 55 type errors, outperforming the best baseline approach by 9 and 14, respectively. Besides, the proposed fix template mining approach can cover 75% of developers' patches in both benchmarks, increasing the best rule-based approach PyTER by more than 30%.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548357","Type Error;Program Repair;Python","Codes;Runtime;Software algorithms;Clustering algorithms;Manuals;Maintenance engineering;Benchmark testing","","2","","59","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Fast and Precise Application Code Analysis using a Partial Library","A. Utture; J. Palsberg","University of California, Los Angeles, U.S.A.; University of California, Los Angeles, U.S.A.",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","934","945","Long analysis times are a key bottleneck for the widespread adoption of whole-program static analysis tools. Fortunately, however, a user is often only interested in finding errors in the application code, which constitutes a small fraction of the whole program. Current application-focused analysis tools overapproximate the effect of the library and hence reduce the precision of the analysis results. However, empirical studies have shown that users have high expectations on precision and will ignore tool results that don't meet these expectations. In this paper, we introduce the first tool QueryMax that significantly speeds up an application code analysis without dropping any precision. QueryMax acts as a pre-processor to an existing analysis tool to select a partial library that is most relevant to the analysis queries in the application code. The selected partial library plus the application is given as input to the existing static analysis tool, with the remaining library pointers treated as the bottom element in the abstract domain. This achieves a significant speedup over a whole-program analysis, at the cost of a few lost errors, and with no loss in precision. We instantiate and run experiments on QueryMax for a cast-check analysis and a null-pointer analysis. For a particular configuration, QueryMax enables these two analyses to achieve, relative to a whole-program analysis, an average recall of 87%, a precision of 100% and a geometric mean speedup of 10x.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510046","ONR(grant numbers:N00014-18-1-2037); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794098","Static Analysis","Codes;Costs;Static analysis;Libraries;Software engineering","","1","","34","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Badge: Prioritizing UI Events with Hierarchical Multi-Armed Bandits for Automated UI Testing","D. Ran; H. Wang; W. Wang; T. Xie","School of Computer Science, Peking University, China; School of EECS, Peking University, China; University of Illinois, Urbana-Champaign, USA; School of Computer Science, Peking University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","894","905","To assure high quality of mobile applications (apps for short), automated UI testing triggers events (associated with UI elements on app UIs) without human intervention, aiming to maximize code coverage and find unique crashes. To achieve high test effectiveness, automated UI testing prioritizes a UI event based on its exploration value (e.g., the increased code coverage of future exploration rooted from the UI event). Various strategies have been proposed to estimate the exploration value of a UI event without considering its exploration diversity (reflecting the variance of covered code entities achieved by explorations rooted from this UI event across its different triggerings), resulting in low test effectiveness, especially on complex mobile apps. To address the preceding problem, in this paper, we propose a new approach named Badge to prioritize UI events considering both their exploration values and exploration diversity for effective automated UI testing. In particular, we design a hierarchical multi-armed bandit model to effectively estimate the exploration value and exploration diversity of a UI event based on its historical explorations along with historical explorations rooted from UI events in the same UI group. We evaluate Badge on 21 highly popular industrial apps widely used by previous related work. Experimental results show that Badge outperforms state-of-the-art/practice tools with 18%-146% relative code coverage improvement and finding 1.19-5.20 × unique crashes, demonstrating the effectiveness of Badge. Further experimental studies confirm the benefits brought by Badge's individual algorithms.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00083","National Natural Science Foundation of China(grant numbers:62161146003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172611","GUI testing;mobile testing;mobile app;Android;multi-armed bandits;reinforcement learning","Codes;Fuzzing;Computer crashes;Mobile applications;Testing;Software engineering;Graphical user interfaces","","1","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Marco: A Stochastic Asynchronous Concolic Explorer","J. Hu; Y. Duan; H. Yin","University of California, Riverside; Singapore Management University; University of California, Riverside",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","704","715","Concolic execution is a powerful program analysis technique for code path exploration. Despite recent advances that greatly improved the efficiency of concolic execution engines, path constraint solving remains a major bottleneck of concolic testing. An intel-ligent scheduler for inputs/branches becomes even more crucial. Our studies show that the previously under-studied branch-flipping policy adopted by state-of-the-art concolic execution engines has several limitations. We propose to assess each branch by its potential for new code coverage from a global view, concerning the path divergence probability at each branch. To validate this idea, we implemented a prototype Marco and evaluated it against the state-of-the-art concolic executor on 30 real-world programs from Google's Fuzzbench, Binutils, and UniBench. The result shows that Marco can outperform the baseline approach and make continuous progress after the baseline approach terminates.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623301","NSF(grant numbers:2133487); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549382","","Codes;Stochastic processes;Prototypes;Internet;Engines;Testing;Software engineering","","","","53","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Buildsheriff: Change-Aware Test Failure Triage for Continuous Integration Builds","C. Zhang; B. Chen; X. Peng; W. Zhao","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","312","324","Test failures are one of the most common reasons for broken builds in continuous integration. It is expensive to diagnose all test failures in a build. As test failures are usually caused by a few underlying faults, triaging test failures with respect to their underlying root causes can save test failure diagnosis cost. Existing failure triage methods are mostly developed for triaging crash or bug reports, and hence not ap-plicable in the context of test failure triage in continuous integration. In this paper, we first present a large-scale empirical study on 163,371 broken builds caused by test failures to characterize test failures in real-world Java projects. Then, motivated by our study, we propose a new change-aware approach, BuildSheriff, to triage test failures in each continuous integration build such that test failures with the same root cause are put in the same cluster. Our evaluation on 200 broken builds has demonstrated that BuildSheriff can significantly improve the state-of-the-art methods on the triaging effectiveness.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510132","National Natural Science Foundation of China(grant numbers:61802067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793896","Test Failures;Failure Triage;Continuous Integration","Java;Costs;Computer bugs;Software engineering","","","","75","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Kind Controllers and Fast Heuristics for Non-Well-Separated GR(1) Specifications","A. Gorenstein; S. Maoz; J. O. Ringert","Tel Aviv University, Israel; Tel Aviv University, Israel; Bauhaus University, Weimar, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","315","326","Non-well-separation (NWS) is a known quality issue in specifications for reactive synthesis. The problem of NWS occurs when the synthesized system can avoid satisfying its guarantees by preventing the environment from being able to satisfy its assumptions. In this work we present two contributions to better deal with NWS. First, we show how to synthesize systems that avoid taking advantage of NWS, i.e., do not prevent the satisfaction of any environment assumption, even if possible. Second, we propose a set of heuristics for fast detection of NWS. Evaluation over benchmarks from the literature shows the effectiveness and significance of our work.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608131","European Research Council (ERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549534","reactive synthesis;GR(1);well-separation","Location awareness;Benchmark testing;Software engineering","","","","28","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Crossover in Parametric Fuzzing","K. Hough; J. Bell","Northeastern University, Boston, Massachusetts, United States; Northeastern University, Boston, Massachusetts, United States",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1585","1596","Parametric fuzzing combines evolutionary and generator-based fuzzing to create structured test inputs that exercise unique execution behaviors. Parametric fuzzers internally represent inputs as bit strings referred to as “parameter sequences”. Interesting parameter sequences are saved by the fuzzer and perturbed to create new in-puts without the need for type-specific operators. However, existing work on parametric fuzzing only uses mutation operators, which modify a single input; it does not incorporate crossover, an evolutionary operator that blends multiple inputs together. Crossover operators aim to combine advantageous traits from multiple inputs. However, the nature of parametric fuzzing limits the effectiveness of traditional crossover operators. In this paper, we propose linked crossover, an approach for using dynamic execution information to identify and exchange analogous portions of parameter sequences. We created an implementation of linked crossover for Java and evaluated linked crossover's ability to preserve advantageous traits. We also evaluated linked crossover's impact on fuzzer performance on seven real-world Java projects and found that linked crossover consistently performed as well as or better than three state-of-the-art parametric fuzzers and two other forms of crossover on both long and short fuzzing campaigns.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639160","National Science Foundation(grant numbers:CCF-2100037,CNS-2100015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548662","fuzz testing;test input generation;generator-based fuzzing;para-metric fuzzing;dynamic analysis","Java;Source coding;Fuzzing;Licenses;Software engineering","","","","57","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"PrettySmart: Detecting Permission Re-Delegation Vulnerability for Token Behaviors in Smart Contracts","Z. Zhong; Z. Zheng; H. -N. Dai; Q. Xue; J. Chen; Y. Nan","Sun Yat-sen University, Zhuhai, China; Sun Yat-sen University, Zhuhai, China; Hong Kong Baptist University, Hong Kong, China; Sun Yat-sen University, Guangzhou, China; Sun Yat-sen University, Guangzhou, China; Sun Yat-sen University, Zhuhai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2073","2084","As an essential component in Ethereum and other blockchains, token assets have been interacted with by diverse smart contracts. Effective permission policies of smart contracts must prevent token assets from being manipulated by unauthorized adversaries. Recent efforts have studied the accessibility of privileged functions or state variables to unauthorized users. However, little attention is paid to how publicly accessible functions of smart contracts can be manipulated by adversaries to steal users' digital assets. This attack is mainly caused by the permission re-delegation (PRD) vulnerability. In this work, we propose PRETTYSMART, a bytecode-level Permission re-delegation vulnerability detector for Smart contracts. Our study begins with an empirical study on 0.43 million open- source smart contracts, revealing that five types of widely-used permission constraints dominate 98% of the studied contracts. Accordingly, we propose a mechanism to infer these permission constraints, as well as an algorithm to identify constraints that can be bypassed by unauthorized adversaries. Based on the identification of permission constraints, we propose to detect whether adversaries could manipulate the privileged token management functionalities of smart contracts. The experimental results on real-world datasets demonstrate the effectiveness of the proposed Prettysmart, which achieves the highest precision score and detects 118 new PRD vulnerabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639140","National Natural Science Foundation of China(grant numbers:62032025); Hong Kong Baptist University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549644","Smart Contract;Permission Control;Vulnerability Detection","Smart contracts;Detectors;Blockchains;Software engineering","","","","41","","14 Jun 2024","","","IEEE","IEEE Conferences"
"CIT4DNN: Generating Diverse and Rare Inputs for Neural Networks Using Latent Space Combinatorial Testing","S. Dola; R. McDaniel; M. B. Dwyer; M. L. Soffa","University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1446","1458","Deep neural networks (DNN) are being used in a wide range of applications including safety-critical systems. Several DNN test generation approaches have been proposed to generate fault-revealing test inputs. However, the existing test generation approaches do not systematically cover the input data distribution to test DNNs with diverse inputs, and none of the approaches investigate the relationship between rare inputs and faults. We propose CIT4DNN, an automated black-box approach to generate DNN test sets that are feature-diverse and that comprise rare inputs. CIT4DNN constructs diverse test sets by applying combinatorial interaction testing to the latent space of generative models and formulates constraints over the geometry of the latent space to generate rare and fault-revealing test inputs. Evaluation on a range of datasets and models shows that CIT4DNN generated tests are more feature diverse than the state-of-the-art, and can target rare fault-revealing testing inputs more effectively than existing methods.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639106","National Science Foundation(grant numbers:2019239,2129824,2217071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548914","deep neural networks;test generation;test coverage;combinatorial interaction testing","Geometry;Combinatorial testing;Closed box;Artificial neural networks;Test pattern generators;Testing;Software engineering","","","","71","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Detecting Logic Bugs in Graph Database Management Systems via Injective and Surjective Graph Query Transformation","Y. Jiang; J. Liu; J. Ba; R. H. C. Yap; Z. Liang; M. Rigger","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","542","553","Graph Database Management Systems (GDBMSs) store graphs as data. They are used naturally in applications such as social net-works, recommendation systems and program analysis. However, they can be affected by logic bugs, which cause the GDBMSs to compute incorrect results and subsequently affect the applications relying on them. In this work, we propose injective and surjective Graph Query Transformation (GQT) to detect logic bugs in GDBMSs. Given a query Q, we derive a mutated query $Q^{\prime}$, so that either their result sets are: (i) semantically equivalent; or (ii) variant based on the mutation to be either a subset or superset of each other. When the expected relationship between the results does not hold, a logic bug in the GDBMS is detected. The key insight to mutate Q is that the graph pattern in graph queries enables systematic query transformations derived from injective and surjective mappings of the directed edge sets between Q and $Q^{\prime}$, We implemented injective and surjective Graph Query Transformation (GQT) as a tool called GraphGenie and evaluated it on 6 popular and mature GDBMSs. GraphGenie has found 25 unknown bugs, comprising 16 logic bugs, 3 internal errors, and 6 performance issues. Our results demonstrate the practicality and effectiveness of GraphGenie in detecting logic bugs in GDBMSs which has the potential for improving the reliability of applications relying on these GDBMSs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623307","National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548201","Graph Databases;Logic Bugs;Metamorphic Testing","Systematics;Image edge detection;Computer bugs;Reliability engineering;Database systems;Robustness;Software reliability","","","","56","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"BSHUNTER: Detecting and Tracing Defects of Bitcoin Scripts","P. Zheng; X. Luo; Z. Zheng",Sun Yat-sen University; The Hong Kong Polytechnic University; Sun Yat-sen University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","307","318","Supporting the most popular cryptocurrency, the Bitcoin platform allows its transactions to be programmable via its scripts. Defects in Bitcoin scripts will make users lose their bitcoins. However, there are few studies on the defects of Bitcoin scripts. In this paper, we conduct the first systematic investigation on the defects of Bitcoin scripts through three steps, including defect definition, defect detection, and exploitation tracing. First, we define six typical defects of scripts in Bitcoin history, namely unbinded-txid, simple-key, useless-sig, uncertain-sig, impossible-key, and never-true. Three are inspired by the community, and three are new from us. Second, we develop a tool to discover Bitcoin scripts with any of typical defects based on symbolic execution and enhanced by historical exact scripts. By analyzing all Bitcoin transactions from Oct. 2009 to Aug. 2022, we find that 383,544 transaction outputs are paid to the Bitcoin scripts with defects. The total amount of them is 3,115.43 BTC, which is around 60 million dollars at present. Third, in order to trace the exploitation of the defects, we instrument the Bitcoin VM to record the traces of the real-world spending transactions of the buggy scripts. We find that 84,130 output scripts are exploited. The implementation and non-harmful datasets are released.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00037","National Natural Science Foundation of China(grant numbers:62032025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172541","bitcoin;blockchain;smart contract","Systematics;Instruments;Bitcoin;History;Contracts;Software engineering","","","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SCVHUNTER: Smart Contract Vulnerability Detection Based on Heterogeneous Graph Attention Network","F. Luo; R. Luo; T. Chen; A. Qiao; Z. He; S. Song; Y. Jiang; S. Li",University of Electronic Science and Technology of China The Hong Kong Polytechnic University; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; University of Electronic Science and Technology of China; Tsinghua university; University of Electronic Science and Technology of China,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2098","2110","Smart contracts are integral to blockchain's growth, but their vulnerabilities pose a significant threat. Traditional vulnerability detection methods rely heavily on expert-defined complex rules that are labor-intensive and difficult to adapt to the explosive expansion of smart contracts. Some recent studies of neural network-based vulnerability detection also have room for improvement. Therefore, we propose SCVHUNTER, an extensible framework for smart contract vulnerability detection. Specifically, SCVHUNTER designs a heterogeneous semantic graph construction phase based on intermediate representations and a vulnerability detection phase based on a heterogeneous graph attention network for smart contracts. In particular, SCVHUNTER allows users to freely point out more important nodes in the graph, leveraging expert knowledge in a simpler way to aid the automatic capture of more information related to vulnerabilities. We tested SCVHUNTER on reentrancy, block info dependency, nested call, and transaction state dependency vulnerabilities. Results show remarkable performance, with accuracies of 93.72%, 91.07%, 85.41%, and 87.37% for these vulnerabilities, surpassing previous methods.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62332004,U22B2029,72304121); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549623","Blockchain;Smart Contract;Vulnerability Detection","Smart contracts;Semantics;Graph neural networks;Explosives;Blockchains;Software engineering","","","","80","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Verification of ORM-based Controllers by Summary Inference","G. Chawla; N. Aman; R. Komondoor; A. Bokil; N. Kharat","Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India; Indian Institute of Science, Bangalore, India",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2340","2351","In this work we describe a novel approach for modeling, analysis and verification of database-accessing applications that use the ORM (Object Relational Mapping) paradigm. Rather than directly analyze ORM code to check specific properties, our approach infers a general-purpose relational algebra summary of each controller in the application. This summary can then be fed into any off-the-shelf relational algebra solver to check for properties or specifications given by a developer. The summaries can also aid program understanding, and may have other applications. We have implemented our approach as a prototype tool that works for ‘Spring’ based MVC applications. A preliminary evaluation reveals that the approach is efficient, and gives good results while checking a set of properties given by human subjects.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794042","program analysis;database applications;relational algebra","Analytical models;Codes;Algebra;Prototypes;Software engineering","","","","28","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Generating Test Databases for Database-Backed Applications","C. Yan; S. Nath; S. Lu","Microsoft Research, Redmond, USA; Microsoft Research, Redmond, USA; University of Chicago, Chicago, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2048","2059","Database-backed applications are widely used. To effectively test these applications, one needs to design not only user inputs but also database states, which imposes unique challenges. First, valid database states have to satisfy complicated constraints determined by application semantics, and hence are difficult to synthesize. Second, the state space of a database is huge, as an application can contain tens to hundreds of tables with up to tens of fields per table. Making things worse, each test involving database operations takes significant time to run. Consequently, unhelpful database states and running tests on them can severely waste testing resources. We propose DBGRILLER, a tool that generates database states to facilitate thorough testing of database-backed applications. To effectively generate valid database states, DBGRILLER strategically injects minor mutation into existing database states and transforms part of the application-under-test into a stand-alone validity checker. To tackle the huge database state space and save testing time, DBGRILLER uses program analysis to identify a novel branch-projected DB view that can be used to filter out database states that are unlikely to increase the testing branch coverage. Our evaluation on 9 popular open-source database applications shows that DBGRILLER can effectively increase branch coverage of existing tests and expose previously unknown bugs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00173","NSF(grant numbers:CCF-2119184,CNS-1764039); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172586","Automated testing;Test data generation;database-backed application;database-state generation","Databases;Computer bugs;Semantics;Transforms;Testing;Software engineering","","","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Which of My Assumptions are Unnecessary for Realizability and Why Should I Care?","R. Shalom; S. Maoz","Tel Aviv University, Tel Aviv, Israel; Tel Aviv University, Tel Aviv, Israel",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","221","232","Specifications for reactive systems synthesis consist of assumptions and guarantees. However, some specifications may include unnecessary assumptions, i.e., assumptions that are not necessary for realizability. While the controllers that are synthesized from such specifications are correct, they are also inflexible and fragile; their executions will satisfy the specification's guarantees in only very specific environments. In this work we show how to detect unnecessary assumptions, and to transform any realizable specification into a corresponding realizable core specification, one that includes the same guarantees but no unnecessary assumptions. We do this by computing an assumptions core, a locally minimal subset of assumptions that suffices for realizability. Controllers that are synthesized from a core specification are not only correct but, importantly, more general; their executions will satisfy the specification's guarantees in more environments. We implemented our ideas in the Spectra synthesis environment, and evaluated their impact over different benchmarks from the literature. The evaluation provides evidence for the motivation and significance of our work, by showing (1) that unnecessary assumptions are highly prevalent, (2) that in almost all cases the fully-automated removal of unnecessary assumptions pays off in total synthesis time, and (3) that core specifications induce more general controllers whose reachable state space is larger but whose representation more memory efficient.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00030","European Research Council (ERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172665","Reactive synthesis;Formal specifications","Memory management;Transforms;Benchmark testing;Aerospace electronics;Software engineering","","","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A Study on the Pythonic Functional Constructs' Understandability","C. Zid; F. Zampetti; G. Antoniol; M. Di Penta","Polytechnique Montréal, Montréal, Québec, Canada; University of Sannio, Benevento, Italy; Polytechnique Montréal, Montréal, Québec, Canada; University of Sannio, Benevento, Italy",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2930","2942","The use of functional constructs in programming languages such as Python has been advocated to help write more concise source code, improve parallelization, and reduce side effects. Nevertheless, their usage could lead to understandability issues. This paper reports the results of a controlled experiment conducted with 209 developers to assess the understandability of given Pythonic functional constructs-namely lambdas, comprehensions, and map/reduce/-filter functions-if compared to their procedural alternatives. To address the study's goal, we asked developers to modify code using functional constructs or not, to compare the understandability of different implementations, and to provide insights about when and where it is preferable to use such functional constructs. Results of the study indicate that code snippets with lambdas are more straightforward to modify than the procedural alternatives. However, this is not the case for comprehension. Regarding the perceived understandability, code snippets relying on procedural implementations are considered more readable than their functional alternatives. Last but not least, while functional constructs may help write compact code, improving maintainability and performance, they are considered hard to debug. Our results can lead to better education in using functional constructs, prioritizing quality assurance activities, and enhancing tool support for developers.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549680","Functional Programming;Python;Program Comprehension;Em-pirical Study","Codes;Quality assurance;Source coding;Education;Software engineering;Python","","","","48","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Learning to Boost Disjunctive Static Bug-Finders","Y. Ko; H. Oh",Meta; Korea University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1097","1109","We present a new learning-based approach for accel-erating disjunctive static bug-finders. Industrial static bug-finders usually perform disjunctive analysis, differentiating program states along different execution paths of a program. Such path-sensitivity is essential for reducing false positives but it also increases analysis costs exponentially. Therefore, practical bug-finders use a state-selection heuristic to keep track of a small number of beneficial states only. However, designing a good heuristic for real-world programs is challenging; as a result, modern static bug-finders still suffer from low cost/bug-finding efficiency. In this paper, we aim to address this problem by learning effective state-selection heuristics from data. To this end, we present a novel data-driven technique that efficiently collects alarm-triggering traces, learns multiple candidate models, and adaptively chooses the best model tailored for each target program. We evaluate our approach with Infer and show that our technique significantly improves Infer's bug-finding efficiency for a range of open-source C programs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172638","machine learning;static analysis","Adaptation models;Costs;Software engineering","","","","41","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Semantic Analysis of Macro Usage for Portability","B. Pappas; P. Gazzillo","University of Central Florida, Orlando, United States; University of Central Florida, Orlando, United States",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","229","240","C is an unsafe language. Researchers have been developing tools to port C to safer languages such as Rust, Checked C, or Go. Existing tools, however, resort to preprocessing the source file first, then porting the resulting code, leaving barely recognizable code that loses macro abstractions. To preserve macro usage, porting tools need analyses that understand macro behavior to port to equivalent constructs. But macro semantics differ from typical functions, precluding simple syntactic transformations to port them. We introduce the first comprehensive framework for analyzing the portability of macro usage. We decompose macro behavior into 26 fine-grained properties and implement a program analysis tool, called Maki, that identifies them in real-world code with 94% accu-racy. We apply Maki to 21 programs containing a total of 86,199 macro definitions. We found that real-world macros are much more portable than previously known. More than a third (37%) are easy-to-port, and Maki provides hints for porting more complicated macros. We find, on average, 2x more easy-to-port macros and up to 7x more in the best case compared to prior work. Guided by Maki's output, we found and hand-ported macros in three real-world programs. We submitted patches to Linux maintainers that transform eleven macros, nine of which have been accepted.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623323","NSF(grant numbers:CCF-1840934,CCF-1941816); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548673","macros;C;program analysis","Codes;Linux;Semantics;Transforms;Syntactics;Kernel;Software engineering","","","","54","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Cross-Inlining Binary Function Similarity Detection","A. Jia; M. Fan; X. Xu; W. Jin; H. Wang; T. Liu","Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2758","2770","Binary function similarity detection plays an important role in a wide range of security applications. Existing works usually assume that the query function and target function share equal semantics and compare their full semantics to obtain the similarity. However, we find that the function mapping is more complex, especially when function inlining happens. In this paper, we will systematically investigate cross-inlining binary function similarity detection. We first construct a cross-inlining dataset by compiling 51 projects using 9 compilers, with 4 optimizations, to 6 architectures, with 2 inlining flags, which results in two datasets both with 216 combinations. Then we construct the cross-inlining function mappings by linking the common source functions in these two datasets. Through analysis of this dataset, we find that three cross-inlining patterns widely exist while existing work suffers when detecting cross-inlining binary function simi-larity. Next, we propose a pattern-based model named CI-Detector for cross-inlining matching. CI-Detector uses the attributed CFG to represent the semantics of binary functions and GNN to embed bi-nary functions into vectors. CI-Detector respectively trains a model for these three cross-inlining patterns. Finally, the testing pairs are input to these three models and all the produced similarities are aggregated to produce the final similarity. We conduct several experiments to evaluate CI-Detector. Results show that CI-Detector can detect cross-inlining pairs with a precision of 81% and a recall of 97%, which exceeds all state-of-the-art works.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549732","Cross-Inlining;Binary Similarity Detection;Inlining Pattern","Semantics;Vectors;Security;Pattern matching;Optimization;Testing;Software engineering","","","","84","","14 Jun 2024","","","IEEE","IEEE Conferences"
"It's Not a Feature, It's a Bug: Fault-Tolerant Model Mining from Noisy Data","F. Wallner; B. K. Aichernig; C. Burghard","Graz University of Technology, Graz, Austria; Graz University of Technology, Graz, Austria; AVL List GmbH, Graz, Austria",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","327","339","The mining of models from data finds widespread use in industry. There exists a variety of model inference methods for perfectly deterministic behaviour, however, in practice, the provided data often contains noise due to faults such as message loss or environmental factors that many of the inference algorithms have problems dealing with. We present a novel model mining approach using Partial Max-SAT solving to infer the best possible automaton from a set of noisy execution traces. This approach enables us to ignore the minimal number of presumably faulty observations to allow the construction of a deterministic automaton. No preprocessing of the data is required. The method's performance as well as a number of considerations for practical use are evaluated, including three industrial use cases, for which we inferred the correct models.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548908","Automata Learning;SAT solving;Partial Max-SAT;Model Inference;Non-Determinism","Learning automata;Software algorithms;Automata;Data models;Loss measurement;Inference algorithms;Software","","","","53","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated repair of HTML generation errors in PHP applications using string constraint solving","H. Samimi; M. Schäfer; S. Artzi; T. Millstein; F. Tip; L. Hendren","Computer Science Department, University of California, Los Angeles, USA; IBM T.J. Watson Research Center, Hawthorne, NY, USA; IBM T.J. Watson Research Center, Hawthorne, NY, USA; Computer Science Department, University of California, Los Angeles, USA; IBM T.J. Watson Research Center, Hawthorne, NY, USA; School of Computer Science, McGill University, Montreal, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","277","287","PHP web applications routinely generate invalid HTML. Modern browsers silently correct HTML errors, but sometimes malformed pages render inconsistently, cause browser crashes, or expose security vulnerabilities. Fixing errors in generated pages is usually straightforward, but repairing the generating PHP program can be much harder. We observe that malformed HTML is often produced by incorrect constant prints, i.e., statements that print string literals, and present two tools for automatically repairing such HTML generation errors. PHPQuickFix repairs simple bugs by statically analyzing individual prints. PHPRepair handles more general repairs using a dynamic approach. Based on a test suite, the property that all tests should produce their expected output is encoded as a string constraint over variables representing constant prints. Solving this constraint describes how constant prints must be modified to make all tests pass. Both tools were implemented as an Eclipse plugin and evaluated on PHP programs containing hundreds of HTML generation errors, most of which our tools were able to repair automatically.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227186","PHP;automated repair;string constraints","HTML;Maintenance engineering;Databases;Computer bugs;Browsers;Cascading style sheets;USA Councils","","63","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"WitchDoctor: IDE support for real-time auto-completion of refactorings","S. R. Foster; W. G. Griswold; S. Lerner","University of California, San Diego, La Jolla, CA, USA; University of California, San Diego, La Jolla, CA, USA; University of California, San Diego, La Jolla, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","222","232","Integrated Development Environments (IDEs) have come to perform a wide variety of tasks on behalf of the programmer, refactoring being a classic example. These operations have undeniable benefits, yet their large (and growing) number poses a cognitive scalability problem. Our main contribution is WitchDoctor - a system that can detect, on the fly, when a programmer is hand-coding a refactoring. The system can then complete the refactoring in the background and propose it to the user long before the user can complete it. This implies a number of technical challenges. The algorithm must be 1) highly efficient, 2) handle unparseable programs, 3) tolerate the variety of ways programmers may perform a given refactoring, 4) use the IDE's proven and familiar refactoring engine to perform the refactoring, even though the the refactoring has already begun, and 5) support the wide range of refactorings present in modern IDEs. Our techniques for overcoming these challenges are the technical contributions of this paper. We evaluate WitchDoctor's design and implementation by simulating over 5,000 refactoring operations across three open-source projects. The simulated user is faster and more efficient than an average human user, yet WitchDoctor can detect more than 90% of refactoring operations as they are being performed - and can complete over a third of refactorings before the simulated user does. All the while, WitchDoctor remains robust in the face of non-parseable programs and unpredictable refactoring scenarios. We also show that WitchDoctor is efficient enough to perform computation on a keystroke-by-keystroke basis, adding an average overhead of only 15 milliseconds per keystroke.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227191","refactoring;IDE;change detection;repository mining","Syntactics;History;Real time systems;Software;Engines;Data mining;Context","","54","2","23","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Build code analysis with symbolic evaluation","A. Tamrawi; H. A. Nguyen; H. V. Nguyen; T. N. Nguyen","Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","650","660","Build process is crucial in software development. However, the analysis support for build code is still limited. In this paper, we present SYMake, an infrastructure and tool for the analysis of build code in make. Due to the dynamic nature of make language, it is challenging to understand and maintain complex Makefiles. SYMake provides a symbolic evaluation algorithm that processes Makefiles and produces a symbolic dependency graph (SDG), which represents the build dependencies (i.e. rules) among files via commands. During the symbolic evaluation, for each resulting string value in an SDG that represents a part of a file name or a command in a rule, SYMake provides also an acyclic graph (called T-model) to represent its symbolic evaluation trace. We have used SYMake to develop algorithms and a tool 1) to detect several types of code smells and errors in Makefiles, and 2) to support build code refactoring, e.g. renaming a variable/target even if its name is fragmented and built from multiple substrings. Our empirical evaluation for SYMake's renaming on several real-world systems showed its high accuracy in entity renaming. Our controlled experiment showed that with SYMake, developers were able to understand Makefiles better and to detect more code smells as well as to perform refactoring more accurately.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227152","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227152","build code maintenance;build code analysis","Reactive power;Servers;Protocols;Concrete;Linux;Maintenance engineering","","42","2","40","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Concrete Constraint Guided Symbolic Execution","Y. Sun; G. Yang; S. Lv; Z. Li; L. Sun","Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China; The University of Queensland, Australia; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1496","1507","Symbolic execution is a popular program analysis technique. It systematically explores all feasible paths of a program but its scalability is largely limited by the path explosion problem, which causes the number of paths proliferates at runtime. A key idea in existing methods to mitigate this problem is to guide the selection of states for path exploration, which primarily relies on the features to represent program states. In this paper, we propose concrete constraint guided symbolic execution, which aims to cover more concrete branches and ultimately improve the overall code coverage during symbolic execution. Our key insight is based on the fact that symbolic execution strives to cover all symbolic branches while concrete branches are neglected, and directing symbolic execution toward uncovered concrete branches has a great potential to improve the overall code coverage. The experimental results demonstrate that our approach can improve the ability of KLEE to both increase code coverage and find more security violations on 10 open-source C programs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548219","Symbolic Execution;Data Dependency Analysis","Codes;Runtime;Scalability;Explosions;Security;Data mining","","","","57","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Cross-Domain Deep Code Search with Meta Learning","Y. Chai; H. Zhang; B. Shen; X. Gu","School of Software, Shanghai Jiao Tong University, China; The University of Newcastle, Australia; School of Software, Shanghai Jiao Tong University, China; School of Software, Shanghai Jiao Tong University, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","487","498","Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Un-like cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510125","National Natural Science Foundation of China(grant numbers:62102244); CCF-Baidu Open Fund(grant numbers:2021pp15002000); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793990","Code Search;Pre-trained Code Models;Meta Learning;Few-Shot Learning;Deep Learning","Structured Query Language;Adaptation models;Solid modeling;Java;Codes;Transfer learning;Data models","","4","","45","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Reliability Assurance for Deep Neural Network Architectures Against Numerical Defects","L. Li; Y. Zhang; L. Ren; Y. Xiong; T. Xie","Department of Computer Science, University of Illinois Urbana-Champaign; Department of Computer Sciences, University of Wisconsin-Madison; School of Computer Science, Peking University; School of Computer Science, Peking University; School of Computer Science, Peking University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1827","1839","With the widespread deployment of deep neural networks (DNNs), ensuring the reliability of DNN-based systems is of great importance. Serious reliability issues such as system failures can be caused by numerical defects, one of the most frequent defects in DNNs. To assure high reliability against numerical defects, in this paper, we propose the RANUM approach including novel techniques for three reliability assurance tasks: detection of potential numerical defects, confirmation of potential-defect feasibility, and suggestion of defect fixes. To the best of our knowledge, RANUM is the first approach that confirms potential-defect feasibility with failure-exhibiting tests and suggests fixes automatically. Extensive experiments on the benchmarks of 63 real-world DNN architectures show that RANUM outperforms state-of-the-art approaches across the three reliability assurance tasks. In addition, when the RANUM-generated fixes are compared with developers' fixes on open-source projects, in 37 out of 40 cases, RANUM-generated fixes are equivalent to or even better than human fixes.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00156","National Natural Science Foundation of China(grant numbers:62161146003); National Key Research and Development Program of China(grant numbers:2019YFE0198100); Innovation and Technology Commission of HKSAR(grant numbers:MHP/055/19); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172602","neural network;numerical defect;testing;fix","Source coding;Artificial neural networks;Computer architecture;Benchmark testing;Reliability;Task analysis;Optimization","","1","","64","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Developers' Visuo-spatial Mental Model and Program Comprehension","A. Bouraffa; G. -L. Fuhrmann; W. Maalej","Applied Software Technology, Universität Hamburg, Hamburg, Germany; Applied Software Technology, Universität Hamburg, Hamburg, Germany; Applied Software Technology, Universität Hamburg, Hamburg, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1920","1932","Previous works from research and industry have proposed a spatial representation of code in a canvas, arguing that a navigational code space confers developers the freedom to organise elements according to their understanding. By allowing developers to translate logical relatedness into spatial proximity, this code representation could aid in code navigation and comprehension. However, the association between developers' code comprehension and their visuo-spatial mental model of the code is not yet well understood. This mental model is affected on the one hand by the spatial code representation and on the other by the visuo-spatial working memory of developers. We address this knowledge gap by conducting an online experiment with 20 developers following a between-subject design. The control group used a conventional tab-based code visualization, while the experimental group used a code canvas to complete three code comprehension tasks. Furthermore, we measure the participants' visuo-spatial working memory using a Corsi Block test at the end of the tasks. Our results suggest that, overall, neither the spatial representation of code nor the visuo-spatial working memory of developers has a significant impact on comprehension performance. However, we identified significant differences in the time dedicated to different comprehension activities such as navigation, annotation, and UI interactions.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00163","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - Project(grant numbers:166725071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172613","Code comprehension;code navigation;developer productivity;IDE design;code visualization;cognitive studies","Industries;Visualization;Codes;Correlation;Navigation;Layout;Particle measurements","","1","","39","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"FAIR: Flow Type-Aware Pre-Training of Compiler Intermediate Representations","C. Niu; C. Li; V. Ng; D. Lo; B. Luo","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Human Language Technology Research Institute University of Texas at Dallas, Richardson, Texas, USA; School of Computing and Information Systems Singapore Management University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","378","389","While the majority of existing pre-trained models from code learn source code features such as code tokens and abstract syntax trees, there are some other works that focus on learning from compiler intermediate representations (IRs). Existing IR-based models typically utilize IR features such as instructions, control and data flow graphs (CDFGs), call graphs, etc. However, these methods confuse variable nodes and instruction nodes in a CDFG and fail to distinguish different types of flows, and the neural networks they use fail to capture long-distance dependencies and have over-smoothing and over-squashing problems. To address these weaknesses, we propose FAIR, a Flow type-Aware pre-trained model for IR that involves employing (1) a novel input representation of IR programs; (2) Graph Transformer to address over-smoothing, over-squashing and long-dependencies problems; and (3) five pre-training tasks that we specifically propose to enable FAIR to learn the semantics of IR tokens, flow type information, and the overall representation of IR. Experimental results show that FAIR can achieve state-of-the-art results on four code-related downstream tasks.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608136","NSF(grant numbers:2034508); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548636","","Codes;Source coding;Semantics;Neural networks;Syntactics;Transformers;Data models","","","","61","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Finding suitable programs: Semantic search with incomplete and lightweight specifications","K. T. Stolee","Department of Computer Science and Engineering, University of Nebraska, Lincoln, Lincolnshire, NE, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1571","1574","Finding suitable code for reuse is a common task for programmers. Two general approaches dominate the code search literature: syntactic and semantic. While queries for syntactic search are easy to compose, the results are often vague or irrelevant. On the other hand, a semantic search may return relevant results, but current techniques require developers to write specifications by hand, are costly as potentially matching code need to be executed to verify congruence with the specifications, or only return exact matches. In this work, we propose an approach for semantic search in which programmers specify lightweight, incomplete specifications and an SMT solver automatically identifies programs from a repository, encoded as constraints, that match the specifications. The repository of programs is automatically encoded offline so the search for matching programs is efficient. The program encodings cover various levels of abstraction to enable partial matches when no or few exact matches exists. We instantiate this approach on a subset of the Yahoo! Pipes mashup language, and plan to extend our techniques to more traditional programming languages as the research progresses.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227034","semantic search;program composition;code reuse;SMT solvers;constraints","Lattices;Semantics;Encoding;Concrete;Syntactics;Mashups","","5","","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Fast Deterministic Black-Box Context-Free Grammar Inference","M. R. Arefin; S. Shetiya; Z. Wang; C. Csallner","Computer Science and Engineering Department, University of Texas at Arlington, Arlington, Texas, USA; Computer Science and Engineering Department, University of Texas at Arlington, Arlington, Texas, USA; Department of Computer Science, Iowa State University, Ames, Iowa, USA; Computer Science and Engineering Department, University of Texas at Arlington, Arlington, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1434","1445","Black-box context-free grammar inference is a hard problem as in many practical settings it only has access to a limited number of example programs. The state-of-the-art approach Arvada heuristically generalizes grammar rules starting from flat parse trees and is non-deterministic to explore different generalization sequences. We observe that many of Arvada's generalization steps violate common language concept nesting rules. We thus propose to pre-structure input programs along these nesting rules, apply learnt rules recursively, and make black-box context-free grammar inference deterministic. The resulting Tree Vada yielded faster runtime and higher-quality grammars in an empirical comparison. The Treevada source code, scripts, evaluation parameters, and training data are open-source and publicly available (https://doi.org/10.6084/m9.figshare.23907738).","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639214","National Science Foundation(grant numbers:1911017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548677","Grammar inference;oracle;nested language concepts;bracket-implied nesting structure;deterministic synthesis","Runtime;Source coding;Closed box;Training data;Grammar","","","","46","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"When Neural Code Completion Models Size up the Situation: Attaining Cheaper and Faster Completion through Dynamic Model Inference","Z. Sun; X. Du; F. Song; S. Wang; L. Li","Beihang University, Beijing, China; Monash University Melbourne, Victoria, Australia; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; National University of Defense Technology, Changsha, China; Beijing Yunnan Key Laboratory of Software Engineering, Beihang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","906","917","Leveraging recent advancements in large language models, modern neural code completion models have demonstrated the capability to generate highly accurate code suggestions. However, their massive size poses challenges in terms of computational costs and environmental impact, hindering their widespread adoption in practical scenarios. Dynamic inference emerges as a promising solution, as it allocates minimal computation during inference while maintaining the model's performance. In this research, we explore dynamic inference within the context of code completion. Initially, we conducted an empirical investigation on GPT-2, focusing on the inference capabilities of intermediate layers for code completion. We found that 54.4% of tokens can be accurately generated using just the first layer, signifying significant computational savings potential. Moreover, despite using all layers, the model still fails to predict 14.5% of tokens correctly, and the subsequent completions continued from them are rarely considered helpful, with only a 4.2% Acceptance Rate. These findings motivate our exploration of dynamic inference in code completion and inspire us to enhance it with a decision-making mechanism that stops the generation of incorrect code. We thus propose a novel dynamic inference method specifically tailored for code completion models. This method aims not only to produce correct predictions with largely reduced computation but also to prevent incorrect predictions proactively. Our extensive evaluation shows that it can averagely skip 1.7 layers out of 16 layers in the models, leading to an 11.2% speedup with only a marginal 1.1 % reduction in ROUGE- L.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639120","National Natural Science Foundation of China (NSFC)(grant numbers:62072309); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549258","","Codes;Accuracy;Computational modeling;Decision making;Focusing;Predictive models;Dynamic scheduling","","","","39","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Modularizing While Training: A New Paradigm for Modularizing DNN Models","B. Qi; H. Sun; H. Zhang; R. Zhao; X. Gao","SKLSDE Lab, Beihang University, China; SKLSDE Lab, Beihang University, China; Chongqing University, China; SKLSDE Lab, Beihang University, China; SKLSDE Lab, Beihang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","353","364","Deep neural network (DNN) models have become increasingly crucial components of intelligent software systems. However, training a DNN model is typically expensive in terms of both time and computational resources. To address this issue, recent research has focused on reusing existing DNN models - borrowing the concept of software reuse in software engineering. However, reusing an entire model could cause extra overhead or inherit the weaknesses from the undesired functionalities. Hence, existing work proposes to de-compose an already trained model into modules, i.e., modularizing-after-training, to enable module reuse. Since the trained models are not built for modularization, modularizing-after-training may incur huge overhead and model accuracy loss. In this paper, we propose a novel approach that incorporates modularization into the model training process, i.e., modularizing-while-training (MwT). We train a model to be structurally modular through two loss functions that optimize intra-module cohesion and inter-module coupling. We have implemented the proposed approach for modularizing Convolutional Neural Network (CNN) models. The evaluation results on representative models demonstrate that MwT outperforms the existing state-of-the-art modularizing-after-training approach. Specifically, the accuracy loss caused by MwT is only 1.13 percentage points, which is less than that of the existing approach. The kernel retention rate of the modules generated by MwT is only 14.58%, with a reduction of 74.31% over the existing approach. Fur-thermore, the total time cost required for training and modularizing is only 108 minutes, which is half the time required by the existing approach. Our work demonstrates that MwT is a new and more effective paradigm for realizing DNN model modularization, offering a fresh perspective on achieving model reuse.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608135","National Natural Science Foundation of China(grant numbers:61972013,61972013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548345","DNN Modularization;Model Reuse;Modular Training;Convolutional Neural Network","Training;Couplings;Costs;Computational modeling;Transformers;Software systems;Convolutional neural networks","","","","52","","14 Jun 2024","","","IEEE","IEEE Conferences"
"EXSYST: Search-based GUI testing","F. Gross; G. Fraser; A. Zeller","University of Saarland, Saarbruecken, Germany; University of Saarland, Saarbruecken, Germany; University of Saarland, Saarbruecken, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1423","1426","Test generation tools commonly aim to cover structural artefacts of software, such as either the source code or the user interface. However, focusing only on source code can lead to unrealistic or irrelevant test cases, while only exploring a user interface often misses much of the underlying program behavior. Our EXSYST prototype takes a new approach by exploring user interfaces while aiming to maximize code coverage, thus combining the best of both worlds. Experiments show that such an approach can achieve high code coverage matching and exceeding the code coverage of traditional unit-based test generators; yet, by construction every test case is realistic and relevant, and every detected failure can be shown to be caused by a real sequence of input events.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227232","test case generation;system testing;GUI testing;test coverage","Graphical user interfaces;Testing;Calculators;Generators;Shape;Educational institutions","","23","2","10","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Large-scale test automation in the cloud (Invited industrial talk)","J. Penix","Google, Inc., USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1122","1122","Software development at Google is big and fast. The code base receives 20+ code changes per minute and 50% of the files change every month! Each product is developed and released from head relying on automated tests verifying the product behavior. Release frequency varies from multiple times per day to once every few weeks, depending on the product team. With such a huge, fast-moving codebase, it is possible for teams to get stuck spending a lot of time just keeping their build green. A continuous integration system should help by providing the exact change at which a test started failing, instead of a range of suspect changes or doing a lengthy binary-search for the offending change. We have built a system that uses dependency analysis to determine all the tests a change transitively affects and then runs only those tests for every change. The system is built on top of Googles cloud computing infrastructure enabling many builds to be executed concurrently, allowing the system to run affected tests as soon as a change is submitted. The use of smart tools and cloud computing infrastructure in the continuous integration system enables quick, effective feedback to development teams.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227247","","","","4","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Machine Learning is All You Need: A Simple Token-Based Approach for Effective Code Clone Detection","S. Feng; W. Suo; Y. Wu; D. Zou; Y. Liu; H. Jin","Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2745","2757","As software engineering advances and the code demand rises, the prevalence of code clones has increased. This phenomenon poses risks like vulnerability propagation, underscoring the growing importance of code clone detection techniques. While numerous code clone detection methods have been proposed, they often fall short in real-world code environments. They either struggle to identify code clones effectively or demand substantial time and computational resources to handle complex clones. This paper introduces a code clone detection method namely Toma using tokens and machine learning. Specifically, we extract token type sequences and employ six similarity calculation methods to generate feature vectors. These vectors are then input into a trained machine learning model for classification. To evaluate the effectiveness and scalability of Toma, we conduct experiments on the widely used BigCloneBench dataset. Results show that our tool outperforms token-based code clone detectors and most tree-based clone detectors, demonstrating high effectiveness and significant time savings.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548279","Code Clones;Machine Learning;Token","Codes;Scalability;Computational modeling;Cloning;Machine learning;Detectors;Feature extraction","","1","","70","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Jigsaw: Large Language Models meet Program Synthesis","N. Jain; S. Vaidyanath; A. Iyer; N. Natarajan; S. Parthasarathy; S. Rajamani; R. Sharma","Microsoft Research, Bangalore, India; Stanford University, Stanford, USA; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1219","1231","Large pre-trained language models such as GPT-3 [10], Codex [11], and Coogle's language model [7] are now capable of generating code from natural language specifications of programmer intent. We view these developments with a mixture of optimism and caution. On the optimistic side, such large language models have the potential to improve productivity by providing an automated AI pair programmer for every programmer in the world. On the cautionary side, since these large language models do not understand program semantics, they offer no guarantees about quality of the suggested code. In this paper, we present an approach to augment these large language models with post-processing steps based on program analysis and synthesis techniques, that understand the syntax and semantics of programs. Further, we show that such techniques can make use of user feedback and improve with usage. We present our experiences from building and evaluating such a tool Jigsaw, targeted at synthesizing code for using Python Pandas API using multi-modal inputs. Our experience suggests that as these large language models evolve for synthesizing code from intent, Jigsaw has an important role to play in improving the accuracy of the systems.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793546","Program Synthesis;Machine Learning","Productivity;Analytical models;Codes;Semantics;Natural languages;Buildings;Syntactics","","27","","46","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Domain-Specific Analysis of Mobile App Reviews Using Keyword-Assisted Topic Models","M. Tushev; F. Ebrahimi; A. Mahmoud","The Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, Louisiana; The Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, Louisiana; The Division of Computer Science and Engineering, Louisiana State University, Baton Rouge, Louisiana",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","762","773","Mobile application (app) reviews contain valuable information for app developers. A plethora of supervised and unsupervised techniques have been proposed in the literature to synthesize useful user feedback from app reviews. However, traditional supervised classification algorithms require extensive manual effort to label ground truth data, while unsupervised text mining techniques, such as topic models, often produce suboptimal results due to the sparsity of useful information in the reviews. To overcome these limitations, in this paper, we propose a fully automatic and unsupervised approach for extracting useful information from mobile app reviews. The proposed approach is based on keyATM, a keyword-assisted approach for generating topic models. keyATM overcomes the prob-lem of data sparsity by using seeding keywords extracted directly from the review corpus. These keywords are then used to generate meaningful domain-specific topics. Our approach is evaluated over two datasets of mobile app reviews sampled from the domains of Investing and Food Delivery apps. The results show that our approach produces significantly more coherent topics than traditional topic modeling techniques.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794110","","Text mining;Analytical models;Prototypes;Data models;Software;Mobile applications;Usability","","5","","87","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Pre-training by Predicting Program Dependencies for Vulnerability Analysis Tasks","Z. Liu; Z. Tang; J. Zhang; X. Xia; X. Yang","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; Zhejiang University, China; Zhejiang University, China; Huawei, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1863","1875","Vulnerability analysis is crucial for software security. Inspired by the success of pre-trained models on software engineering tasks, this work focuses on using pre-training techniques to enhance the understanding of vulnerable code and boost vulnerability analysis. The code understanding ability of a pre-trained model is highly related to its pre-training objectives. The semantic structure, e.g., control and data dependencies, of code is important for vulnerability analysis. However, existing pre-training objectives either ignore such structure or focus on learning to use it. The feasibility and benefits of learning the knowledge of analyzing semantic structure have not been investigated. To this end, this work proposes two novel pre-training objectives, namely Control Dependency Prediction (CDP) and Data Dependency Prediction (DDP), which aim to predict the statement-level control dependencies and token-level data dependencies, respectively, in a code snippet only based on its source code. During pre-training, CDP and DDP can guide the model to learn the knowledge required for analyzing fine-grained dependencies in code. After pre-training, the pre-trained model can boost the understanding of vulnerable code during fine-tuning and can directly be used to perform dependence analysis for both partial and complete functions. To demonstrate the benefits of our pre-training objectives, we pre-train a Transformer model named PDBERT with CDP and DDP, fine-tune it on three vulnerability analysis tasks, i.e., vulnerability detection, vulnerability classification, and vulnerability assessment, and also evaluate it on program dependence analysis. Experimental results show that PDBERT benefits from CDP and DDP, leading to state-of-the-art performance on the three downstream tasks. Also, PDBERT achieves F1-scores of over 99% and 94% for predicting control and data dependencies, respectively, in partial and complete functions.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62202420); Fundamental Research Funds for the Central Universities(grant numbers:226-2022-00064); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548173","Source Code Pre-training;Program Dependence Analysis;Vulnerability Detection;Vulnerability Classification;Vulnerability Assessment","Analytical models;Codes;Source coding;Semantics;Transformers;Software;Security","","","","70","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Causality-Based Neural Network Repair","B. Sun; J. Sun; L. H. Pham; T. Shi",Singapore Management University; Singapore Management University; Singapore Management University; Huawei Singapore,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","338","349","Neural networks have had discernible achievements in a wide range of applications. The wide-spread adoption also raises the concern of their dependability and reliability. Similar to traditional decision-making programs, neural networks can have defects that need to be repaired. The defects may cause unsafe behaviors, raise security concerns or unjust societal impacts. In this work, we address the problem of repairing a neural network for desirable properties such as fairness and the absence of backdoor. The goal is to construct a neural network that satisfies the property by (minimally) adjusting the given neural network's parameters (i.e., weights). Specifically, we propose CARE (CAusality-based REpair), a causality-based neural network repair technique that 1) performs causality-based fault localization to identify the ‘guilty’ neurons and 2) optimizes the parameters of the identified neurons to reduce the misbehavior. We have empirically evaluated CARE on various tasks such as backdoor removal, neural network repair for fairness and safety properties. Our experiment results show that CARE is able to repair all neural networks efficiently and effectively. For fairness repair tasks, CARE successfully improves fairness by 61.91 % on average. For backdoor removal tasks, CARE reduces the attack success rate from over 98% to less than 1 %. For safety property repair tasks, CARE reduces the property violation rate to less than 1 %. Results also show that thanks to the causality-based fault localization, CARE's repair focuses on the misbehavior and preserves the accuracy of the neural networks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510080","Huawei International(grant numbers:TC20210714014); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793926","Machine Learning with and for SE;Program Repair;Fault Localization","Location awareness;Fault diagnosis;Neurons;Maintenance engineering;Safety;Behavioral sciences;Security","","18","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"GameRTS: A Regression Testing Framework for Video Games","J. Yu; Y. Wu; X. Xie; W. Le; L. Ma; Y. Chen; J. Hu; F. Zhang","Singapore Management University, Singapore; NetEase Fuxi AI Lab, China; Singapore Management University, Singapore; Iowa State University, USA; University of Alberta, Canada; NetEase Fuxi AI Lab, China; NetEase Fuxi AI Lab, China; Zhejiang University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1393","1404","Continuous game quality assurance is of great importance to satisfy the increasing demands of users. To respond to game issues reported by users timely, game com-panies often create and maintain a large number of releases, updates, and tweaks in a short time. Regression testing is an essential technique adopted to detect regression issues during the evolution of the game software. However, due to the special characteristics of game software (e.g., frequent updates and long-running tests), traditional regression testing techniques are not directly applicable. To bridge this gap, in this paper, we perform an early exploratory study to investigate the challenges in regression testing of video games. We first performed empirical studies to better understand the game development process, bugs introduced during game evolution, and the context sensitivity. Based on the results of the study, we proposed the first regression test selection (RTS) technique for game software, which is a compromise between safety and practicality. In particular, we model the test suite of game software as a State Transition Graph (STG) and then perform the RTS on the STG. We establish the dependencies between the states/actions of STG and game files, including game art resources, game design files, and source code, and perform change impact analysis to identify the states/actions (in the STG) that potentially execute such changes. We implemented our framework in a tool, named GameRTS, and evaluated its usefulness on 10 tasks of a large-scale commercial game, including a total of 1,429 commits over three versions. The experimental results demonstrate the usefulness and effectiveness of GameRTS in game RTS. For most tasks, GameRTS only selected one trace from STG, which can significantly reduce the testing time. Furthermore, GameRTS detects all the regression bugs from the test evaluation suites. Compared with the file-level RTS, GameRTS selected fewer states/actions/traces (i.e., 13.77%, 23.97%, 6.85%). In addition, GameRTS identified 2 new critical regression bugs in the game.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172905","Game Testing;Regression Testing;Testing Cases Selection;State Transition Graph","Video games;Sensitivity;Source coding;Computer bugs;Games;Software;Safety","","2","","46","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Verifying Data Constraint Equivalence in FinTech Systems","C. Wang; G. Fan; P. Yao; F. Pan; C. Zhang","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Ant Group, Shenzhen, China; Zhejiang University, Hangzhou, China; Ant Group, Shenzhen, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1329","1341","Data constraints are widely used in FinTech systems for monitoring data consistency and diagnosing anomalous data manipulations. However, many equivalent data constraints are created redundantly during the development cycle, slowing down the FinTech systems and causing unnecessary alerts. We present EQDAC, an efficient decision procedure to determine the data constraint equivalence. We first propose the symbolic representation for semantic encoding and then introduce two light-weighted analyses to refute and prove the equivalence, respectively, which are proved to achieve in polynomial time. We evaluate EQDAC upon 30,801 data constraints in a FinTech system. It is shown that EQDAC detects 11,538 equivalent data constraints in three hours. It also supports efficient equivalence searching with an average time cost of 1.22 seconds, enabling the system to check new data constraints upon submission.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172850","Equivalence Verification;Data Constraints;Fin-Tech Systems","Costs;Semantics;Production;Companies;Maintenance engineering;Encoding;Monitoring","","3","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SnR: Constraint-Based Type Inference for Incomplete Java Code Snippets","Y. Dong; T. Gu; Y. Tian; C. Sun","David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada; Alibaba Group, China; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1982","1993","Code snippets are prevalent on websites such as Stack Overflow and are effective in demonstrating API usages concisely. However they are usually difficult to be used directly because most code snippets not only are syntactically incomplete but also lack dependency information, and thus do not compile. For example, Java snippets usually do not have import statements or required library names; only 6.88% of Java snippets on Stack Overflow include import statements necessary for compilation. This paper proposes SnR, a precise, efficient, constraint-based technique to automatically infer the exact types used in code snippets and the libraries containing the inferred types, to compile and therefore reuse the code snippets. Initially, SnR builds a knowledge base of APIs, i.e., various facts about the available APIs, from a corpus of Java libraries. Given a code snippet with missing import statements, SnR automatically extracts typing constraints from the snippet, solves the constraints against the knowledge base, and returns a set of APIs that satisfies the constraints to be imported into the snippet. We have evaluated SnR on a benchmark of 267 code snippets from Stack Overflow. SnR significantly outperforms the state-of-the-art tool Coster. SnR correctly infers 91.0% of the import statements, which makes 73.8% of the snippets compile, compared to 36.0% of the import statements and 9.0% of the snippets by Coster.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510061","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794034","type inference;constraint satisfaction;automated repair;datalog","Productivity;Java;Codes;Knowledge based systems;Transforms;Benchmark testing;Maintenance engineering","","1","","44","","20 Jun 2022","","","IEEE","IEEE Conferences"
"MetaLog: Generalizable Cross-System Anomaly Detection from Logs with Meta-Learning","C. Zhang; T. Jia; G. Shen; P. Zhu; Y. Li","Tsinghua University, Beijing, China; Institute for Artificial Intelligence, Peking University, Beijing, China; Linkedsee Technology (China) Limited, Beijing, China; Linkedsee Technology (China) Limited, Beijing, China; National Engineering Research Center for Software Engineering, Peking University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1899","1910","Log-based anomaly detection plays a crucial role in ensuring the stability of software. However, current approaches for log-based anomaly detection heavily depend on a vast amount of labeled his-torical data, which is often unavailable in many real-world systems. To mitigate this problem, we leverage the features of the abundant historical labeled logs of mature systems to help construct anomaly detection models of new systems with very few labels, that is, to generalize the model ability trained from labeled logs of mature systems to achieve anomaly detection on new systems with insufficient data labels. Specifically, we propose MetaLog, a generalizable cross-system anomaly detection approach. MetaLog first incorporates a globally consistent semantic embedding module to obtain log event semantic embedding vectors in a shared global space. Then it leverages the meta-learning paradigm to improve the model's generalization ability. We evaluate MetaLog's performance on four public log datasets (HDFS, BGL, OpenStack, and Thunderbird) from four different systems. Results show that MetaLog reaches over 80% F1-score when using only 1% labeled logs of the target system, showing similar performance with state-of-the-art supervised anomaly detection models trained with 100% labeled data. Besides, it outperforms state-of-art transfer-learning-based cross-system anomaly detection models by 20% in the same settings of 1% labeled training logs of the target system.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548351","Meta-learning;Anomaly detection;System logs","Metalearning;Training;Semantics;Feature extraction;Data models;Vectors;Stability analysis","","","","50","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Fuzzing Class Specifications","F. Molina; M. D'Amorim; N. Aguirre","University of Rio Cuarto and CONICET, Argentina; Federal University of Pernambuco, Brazil; University of Rio Cuarto and CONICET, Argentina",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1008","1020","Expressing class specifications via executable constraints is important for various software engineering tasks such as test generation, bug finding and automated debugging, but developers rarely write them. Techniques that infer specifications from code exist to fill this gap, but they are designed to support specific kinds of assertions and are difficult to adapt to support different assertion languages, e.g., to add support for quantification, or additional comparison operators, such as membership or containment. To address the above issue, we present SPECFUZZER, a novel technique that combines grammar-based fuzzing, dynamic invariant detection, and mutation analysis, to automatically produce class specifications. SPECFUZZER uses: (i) a fuzzer as a generator of candidate assertions derived from a grammar that is automatically obtained from the class definition; (ii) a dynamic invariant detector -Daikon- to filter out assertions invalidated by a test suite; and (iii) a mutation-based mechanism to cluster and rank assertions, so that similar constraints are grouped and then the stronger prioritized. Grammar-based fuzzing enables SPECFUZZER to be straightforwardly adapted to support different specification languages, by manipulating the fuzzing grammar, e.g., to include additional operators. We evaluate our technique on a benchmark of 43 Java methods employed in the evaluation of the state-of-the-art techniques GAssert and EvoSpex. Our results show that SPECFUZZER can easily support a more expressive assertion language, over which is more effective than GAssert and EvoSpex in inferring specifications, according to standard performance metrics.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510120","INES; CNPq(grant numbers:465614/2014-0); CAPES(grant numbers:88887.136410/2017-00); FACEPE(grant numbers:APQ-0399-1.03/17,PRONEX APQ/0388-1.03/14); Microsoft Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793973","Oracle problem;specification inference;grammar-based fuzzing","Measurement;Java;Fuzzing;Generators;Grammar;Specification languages;Test pattern generators","","6","","50","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Windranger: A Directed Greybox Fuzzer driven by Deviation Basic Blocks","Z. Du; Y. Li; Y. Liu; B. Mao","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2440","2451","Directed grey-box fuzzing (DGF) is a security testing technique that aims to steer the fuzzer towards predefined target sites in the program. To gain directedness, DGF prioritizes the seeds whose execution traces are closer to the target sites. Therefore, evaluating the distance between the execution trace of a seed and the target sites (aka, the seed distance) is important for DGF. The first directed grey-box fuzzer, AFLGo, uses an approach of calculating the basic block level distances during static analysis and accumulating the distances of the executed basic blocks to compute the seed distance. Following AFLGo, most of the existing state-of-the-art DGF techniques use all the basic blocks on the execution trace and only the control flow information for seed distance calculation. However, not every basic block is equally important and there are certain basic blocks where the execution trace starts to deviate from the target sites (aka, deviation basic blocks). In this paper, we propose a technique called Windranger which leverages deviation basic blocks to facilitate DGF. To identify the deviation basic blocks, Windranger applies both static reachability analysis and dynamic filtering. To conduct directed fuzzing, Windranger uses the deviation basic blocks and their related data flow information for seed distance calculation, mutation, seed prioritization as well as explore-exploit scheduling. We evaluated Windranger on 3 datasets consisting of 29 programs. The experiment results show that Windranger outperforms AFLGo, AFL, and FAIRFuzz by reaching the target sites 21%, 34%, and 37% faster and detecting the target crashes 44%, 66%, and 77% faster respectively. Moreover, we found a 0-day vulnerability with a CVE ID assigned in ffmpeg (a popular multimedia library extensively fuzzed by OSS-fuzz) with Windranger by supplying manually identified suspect locations as the target sites.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510197","Ministry of Education, Singapore; National Natural Science Foundation of China(grant numbers:61272078,62032010,62172201); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793549","Fuzz Testing;Directed Testing","Filtering;Static analysis;Fuzzing;Media;Libraries;Computer crashes;Security","","12","","50","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Revisiting Learning-based Commit Message Generation","J. Dong; Y. Lou; D. Hao; L. Tan","Key Laboratory of High Confidence Software Technologies (Peking University), MoE, School of Computer Science, Peking University, Beijing, China; School of Computer Science, Fudan University, Shanghai, China; Key Laboratory of High Confidence Software Technologies (Peking University), MoE, School of Computer Science, Peking University, Beijing, China; Department of Computer Science, Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","794","805","Commit messages summarize code changes and help developers understand the intention. To alleviate human efforts in writing commit messages, researchers have proposed various automated commit message generation techniques, among which learning-based techniques have achieved great success in recent years. However, existing evaluation on learning-based commit message generation relies on the automatic metrics (e.g., BLEU) widely used in natural language processing (NLP) tasks, which are aggregated scores calculated based on the similarity between generated commit messages and the ground truth. Therefore, it remains unclear what generated commit messages look like and what kind of commit messages could be precisely generated by existing learning-based techniques. To fill this knowledge gap, this work performs the first study to systematically investigate the detailed commit messages generated by learning-based techniques. In particular, we first investigate the frequent patterns of the commit messages generated by state-of-the-art learning-based techniques. Surprisingly, we find the majority (~90%) of their generated commit messages belong to simple patterns (i.e., addition/removal/fix/avoidance patterns). To further explore the reasons, we then study the impact of datasets, input representations, and model components. We surprisingly find that existing learning-based techniques have competitive performance even when the inputs are only represented by change marks (i.e., “+”/“-”/“ ”), It indicates that existing learning-based techniques poorly utilize syntax and semantics in the code while mostly focusing on change marks, which could be the major reason for generating so many pattern-matching commit messages. We also find that the pattern ratio in the training set might also positively affect the pattern ratio of generated commit messages; and model components might have different impact on the pattern ratio.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00075","National Natural Science Foundation of China(grant numbers:62232001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172560","Commit Message Generation;Deep Learning;Pattern-based","Training;Measurement;Codes;Semantics;Focusing;Writing;Syntactics","","2","","31","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Learning to Reduce False Positives in Analytic Bug Detectors","A. Kharkar; R. Z. Moghaddam; M. Jin; X. Liu; X. Shi; C. Clement; N. Sundaresan","Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1307","1316","Due to increasingly complex software design and rapid iterative development, code defects and security vulnerabilities are prevalent in modern software. In response, programmers rely on static analysis tools to regularly scan their codebases and find potential bugs. In order to maximize coverage, however, these tools generally tend to report a significant number of false positives, requiring developers to manually verify each warning. To address this problem, we propose a Transformer-based learning approach to identify false positive bug warnings. We demonstrate that our models can improve the precision of static analysis by 17.5%. In addition, we validated the generalizability of this approach across two major bug types: null dereference and resource leak.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794136","datasets;neural networks;gaze detection;text tagging","Training;Analytical models;Codes;Computer bugs;Static analysis;Detectors;Tagging","","11","","31","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Demystifying the Vulnerability Propagation and Its Evolution via Dependency Trees in the NPM Ecosystem","C. Liu; S. Chen; L. Fan; B. Chen; Y. Liu; X. Peng","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Cyber Science, Nankai University, Tianjin, China; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; School of Computer Science and Shanghai Key Laboratory of Data Science, Fudan University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","672","684","Third-party libraries with rich functionalities facilitate the fast development of JavaScript software, leading to the explosive growth of the NPM ecosystem. However, it also brings new security threats that vulnerabilities could be introduced through dependencies from third-party libraries. In particular, the threats could be excessively amplified by transitive dependencies. Existing research only considers direct dependencies or reasoning transitive dependencies based on reachability analysis, which neglects the NPM-specific dependency resolution rules as adapted during real installation, resulting in wrongly resolved dependencies. Consequently, further fine-grained analysis, such as precise vulnerability propagation and their evolution over time in dependencies, cannot be carried out precisely at a large scale, as well as deriving ecosystem-wide solutions for vulnerabilities in dependencies. To fill this gap, we propose a knowledge graph-based dependency resolution, which resolves the inner dependency relations of dependencies as trees (i.e., dependency trees), and investigates the security threats from vulnerabilities in dependency trees at a large scale. Specifically, we first construct a complete dependency-vulnerability knowledge graph (DVGraph) that captures the whole NPM ecosystem (over 10 million library versions and 60 million well-resolved dependency relations). Based on it, we propose a novel algorithm (DTResolver) to statically and precisely resolve dependency trees, as well as transitive vulnerability propagation paths, for each package by taking the official dependency resolution rules into account. Based on that, we carry out an ecosystem-wide empirical study on vulnerability propagation and its evolution in dependency trees. Our study unveils lots of useful findings, and we further discuss the lessons learned and solutions for different stakeholders to mitigate the vulnerability impact in NPM based on our findings. For example, we implement a dependency tree based vulnerability remediation method (DTReme) for NPM packages, and receive much better performance than the official tool (npm audit fix).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510142","National Natural Science Foundation of China(grant numbers:62102284); National Research Foundation, Singapore(grant numbers:AISG2-RP-2020-019); NRF(grant numbers:NRFI06-2020-0022-0001); National Research Foundation(grant numbers:NRF2018NCR-NSOE003-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794026","","Ecosystems;Libraries;Software;Explosives;Cognition;Security;Stakeholders","","19","","85","","20 Jun 2022","","","IEEE","IEEE Conferences"
"DescribeCtx: Context-Aware Description Synthesis for Sensitive Behaviors in Mobile Apps","S. Yang; Y. Wang; Y. Yao; H. Wang; Y. F. Ye; X. Xiao","Case Western Reserve University; University of Illinois at Urbana-Champaign; State Key Laboratory for Novel Software Technology, Nanjing University; Beijing University of Posts and Telecommunications; University of Notre Dame; Case Western Reserve University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","685","697","While mobile applications (i.e., apps) are becoming capable of handling various needs from users, their increasing access to sensitive data raises privacy concerns. To inform such sensitive behaviors to users, existing techniques propose to automatically identify explanatory sentences from app descriptions; however, many sensitive behaviors are not explained in the corresponding app descriptions. There also exist general techniques that translate code to sentences. However, these techniques lack the vocabulary to explain the uses of sensitive data and fail to consider the context (i.e., the app functionalities) of the sensitive behaviors. To address these limitations, we propose Describectx, a context-aware description synthesis approach that trains a neural machine translation model using a large set of popular apps, and generates app-specific descriptions for sensitive behaviors. Specifically, Describectx encodes three heterogeneous sources as input, i.e., vocabularies provided by privacy policies, behavior summary provided by the call graphs in code, and contextual information provided by GUI texts. Our evaluations on 1,262 Android apps show that, compared with existing baselines, Describectx produces more accurate descriptions (24.96 in BLEU) and achieves higher user ratings with respect to the reference sen-tences manually identified in the app descriptions.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510058","National Science Foundation(grant numbers:CCF-2046953,CNS-2028748); Collaborative Innovation Center of Novel Software Technology and Industrialization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793913","mobile apps;description synthesis;static analysis;deep learning","Training;Vocabulary;Privacy;Codes;Feature extraction;Behavioral sciences;Mobile applications","","3","","86","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Metadata invariants: Checking and inferring metadata coding conventions","M. Song; E. Tilevich","Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","694","704","As the prevailing programming model of enterprise applications is becoming more declarative, programmers are spending an increasing amount of their time and efforts writing and maintaining metadata, such as XML or annotations. Although metadata is a cornerstone of modern software, automatic bug finding tools cannot ensure that metadata maintains its correctness during refactoring and enhancement. To address this shortcoming, this paper presents metadata invariants, a new abstraction that codifies various naming and typing relationships between metadata and the main source code of a program. We reify this abstraction as a domain-specific language. We also introduce algorithms to infer likely metadata invariants and to apply them to check metadata correctness in the presence of program evolution. We demonstrate how metadata invariant checking can help ensure that metadata remains consistent and correct during program evolution; it finds metadata-related inconsistencies and recommends how they should be corrected. Similar to static bug finding tools, a metadata invariant checker identifies metadata-related bugs as a program is being refactored and enhanced. Because metadata is omnipresent in modern software applications, our approach can help ensure the overall consistency and correctness of software as it evolves.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227148","software maintenance;bug finding;refactoring;enhancement;frameworks;domain-specific languages;metadata;invariants","XML;Computer bugs;Inference algorithms;Programming;Java;Runtime;Syntactics","","9","","26","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models","T. Ahmed; S. Ghosh; C. Bansal; T. Zimmermann; X. Zhang; S. Rajmohan",UC Davis; Microsoft; Microsoft; Microsoft Research; Microsoft; Microsoft,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1737","1749","Incident management for cloud services is a complex process involving several steps and has a huge impact on both service health and developer productivity. On-call engineers require significant amount of domain knowledge and manual effort for root causing and mitigation of production incidents. Recent advances in artificial intelligence has resulted in state-of-the-art large language models like GPT-3.x (both GPT-3.0 and GPT-3.5), which have been used to solve a variety of problems ranging from question answering to text summarization. In this work, we do the first large-scale study to evaluate the effectiveness of these models for helping engineers root cause and mitigate production incidents. We do a rigorous study at Microsoft, on more than 40,000 incidents and compare several large language models in zero-shot, fine-tuned and multi-task setting using semantic and lexical metrics. Lastly, our human evaluation with actual incident owners show the efficacy and future potential of using artificial intelligence for resolving cloud incidents.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172904","Incident Management;Service Quality;GPT-3.x;Large Language Models","Productivity;Knowledge engineering;Semantics;Manuals;Multitasking;Question answering (information retrieval);Distance measurement","","21","","65","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Towards Causal Deep Learning for Vulnerability Detection","M. Rahman; I. Ceka; C. Mao; S. Chakraborty; B. Ray; W. Le","Iowa State University, Ames, IA, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Microsoft Research, Redmond, WA, USA; Columbia University, New York, NY, USA; Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1888","1898","Deep learning vulnerability detection has shown promising results in recent years. However, an important challenge that still blocks it from being very useful in practice is that the model is not robust under perturbation and it cannot generalize well over the out-of-distribution (OOD) data, e.g., applying a trained model to unseen projects in real world. We hypothesize that this is because the model learned non-robust features, e.g., variable names, that have spurious correlations with labels. When the perturbed and OOD datasets no longer have the same spurious features, the model prediction fails. To address the challenge, in this paper, we introduced causality into deep learning vulnerability detection. Our approach CausalVul consists of two phases. First, we designed novel perturbations to discover spurious features that the model may use to make predictions. Second, we applied the causal learning algorithms, specifically, do-calculus, on top of existing deep learning models to systematically remove the use of spurious features and thus promote causal based prediction. Our results show that CausalVul consistently improved the model accuracy, robustness and OOD performance for all the state-of-the-art models and datasets we experimented. To the best of our knowledge, this is the first work that introduces do calculus based causal learning to software engineering models and shows it's indeed useful for improving the model accuracy, robustness and generalization. Our replication package is located at https://figshare.com/s/0ffda320dcb96c24gef2.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549636","vulnerability detection;causality;spurious features","Deep learning;Knowledge engineering;Correlation;Perturbation methods;Predictive models;Prediction algorithms;Feature extraction","","1","","27","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"On Calibration of Pretrained Code Models","Z. Zhou; C. Sha; X. Peng","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","931","943","Pretrained code models have achieved notable success in the field of Software Engineering (SE). However, existing studies have pre-dominantly focused on improving model performance, with limited attention given to other critical aspects such as model calibration. Model calibration, which refers to the accurate estimation of predictive uncertainty, is a vital consideration in practical applications. Therefore, in order to advance the understanding of model cali-bration in SE, we conduct a comprehensive investigation into the calibration of pretrained code models in this paper. Our inves-tigation focuses on five pretrained code models and four code understanding tasks, including analyses of calibration in both in-distribution and out-of-distribution settings. Several key insights are uncovered: (1) pretrained code models may suffer from the issue of over-confidence; (2) temperature scaling and label smoothing are effective in calibrating code models in in-distribution data; (3) the issue of over-confidence in pretrained code models worsens in different out-of-distribution settings, and the effectiveness of temperature scaling and label smoothing diminishes. All materi-als used in our experiments are available at https://github.com/queserasera22/Calibration-of-Pretrained-Code-Models.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549419","Pretrained Code Models;Model Calibration;Model Reliability","Temperature distribution;Codes;Smoothing methods;Uncertainty;Reliability engineering;Data models;Calibration","","","","52","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Partial models: Towards modeling and reasoning with uncertainty","M. Famelis; R. Salay; M. Chechik","University of Toronto, Canada; University of Toronto, Canada; University of Toronto, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","573","583","Models are good at expressing information about software but not as good at expressing modelers' uncertainty about it. The highly incremental and iterative nature of software development nonetheless requires the ability to express uncertainty and reason with models containing it. In this paper, we build on our earlier work on expressing uncertainty using partial models, by elaborating an approach to reasoning with such models. We evaluate our approach by experimentally comparing it to traditional strategies for dealing with uncertainty as well as by conducting a case study using open source software. We conclude that we are able to reap the benefits of well-managed uncertainty while incurring minimal additional cost.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227159","","Uncertainty;Unified modeling language;Cognition;Finishing;Vocabulary;Encoding;Software","","77","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Generating REST API Specifications through Static Analysis","R. Huang; M. Motwani; I. Martinez; A. Orso","Georgia Institute of Technology, Atlanta, Georgia, USA; Georgia Institute of Technology, Atlanta, Georgia, USA; Georgia Institute of Technology, Atlanta, Georgia, USA; Georgia Institute of Technology, Atlanta, Georgia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1311","1323","Web Application Programming Interfaces (APIs) allow services to be accessed over the network. RESTful (or REST) APIs, which use the REpresentation State Transfer (REST) protocol, are a popular type of web API. To use or test REST APIs, developers use specifications written in standards such as OpenAPI. However, creating and maintaining these specifications is time-consuming and error-prone, especially as software evolves, leading to incomplete or inconsistent specifications that negatively affect the use and testing of the APIs. To address this problem, we present Respector (REST API specification generator), the first technique to employ static and symbolic program analysis to generate specifications for REST APIs from their source code. We evaluated Respector on 15 real-world APIs with promising results in terms of precision and recall in inferring endpoint methods, endpoint parameters, method responses, and parameter attributes, including constraints leading to successful HTTP responses or errors. Furthermore, these results could be further improved with additional engineering. Comparing the Respector-generated specifications with the developer-provided ones shows that Respector was able to identify many missing endpoint methods, parameters, constraints, and responses, along with some inconsistencies between developer-provided specifications and API implementations. Finally, Respector outperformed several techniques that infer specifications from annotations within API implementations or by invoking the APIs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639137","NSF(grant numbers:CCF-0725202); DOE(grant numbers:DE-FOA-0002460); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549615","REST APIs;OpenAPI specifications;documentation;static analysis","Annotations;Source coding;Static analysis;Software;HTTP;Generators;Standards","","","","61","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Augmenting test suites effectiveness by increasing output diversity","N. Alshahwan; M. Harman","CREST Centre, University College London, London, UK; CREST Centre, University College London, London, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1345","1348","The uniqueness (or otherwise) of test outputs ought to have a bearing on test effectiveness, yet it has not previously been studied. In this paper we introduce a novel test suite adequacy criterion based on output uniqueness. We propose 4 definitions of output uniqueness with varying degrees of strictness. We present a preliminary evaluation for web application testing that confirms that output uniqueness enhances fault-finding effectiveness. The approach outperforms random augmentation in fault finding ability by an overall average of 280% in 5 medium sized, real world web applications.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227083","SBSE;HTML output;Web applications","HTML;Testing;Educational institutions;Databases;Web pages;Instruments;Cloning","","26","","9","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Towards business processes orchestrating the physical enterprise with wireless sensor networks","F. Casati; F. Daniel; G. Dantchev; J. Eriksson; N. Finne; S. Karnouskos; P. M. Montera; L. Mottola; F. J. Oppermann; G. P. Picco; A. Quartulli; K. Römer; P. Spiess; S. Tranquillini; T. Voigt","University of Trento, Italy; University of Trento, Italy; University of Lübeck, Germany; Swedish Institute of Computer Science, Sweden; Swedish Institute of Computer Science, Sweden; Swedish Institute of Computer Science, Sweden; Acciona Infraestructuras S.A. (Spain); Swedish Institute of Computer Science, Sweden; University of Lubeck, Germany; University of Trento, Italy; University of Trento, Italy; University of Lubeck, Germany; University of Lübeck, Germany; University of Trento, Italy; Swedish Institute of Computer Science, Sweden",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1357","1360","The industrial adoption of wireless sensor networks (WSNs) is hampered by two main factors. First, there is a lack of integration of WSNs with business process modeling languages and back-ends. Second, programming WSNs is still challenging as it is mainly performed at the operating system level. To this end, we provide makeSense: a unified programming framework and a compilation chain that, from high-level business process specifications, generates code ready for deployment on WSN nodes.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227080","","Wireless sensor networks;Business;Programming;Protocols;Ventilation;Actuators;Program processors","","18","","5","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Modeling Cloud performance with Kriging","A. Gambi; G. Toffetti","University of Lugano, Switzerland; University of Lugano, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1439","1440","Cloud infrastructures allow service providers to implement elastic applications. These can be scaled at runtime to dynamically adjust their resources allocation to maintain consistent quality of service in response to changing working conditions, like flash crowds or periodic peaks. Providers need models to predict the system performances of different resource allocations to fully exploit dynamic application scaling. Traditional performance models such as linear models and queueing networks might be simplistic for real Cloud applications; moreover, they are not robust to change. We propose a performance modeling approach that is practical for highly variable elastic applications in the Cloud and automatically adapts to changing working conditions. We show the effectiveness of the proposed approach for the synthesis of a self-adaptive controller.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227075","Performance modeling;Cloud computing;Auto-Scaling;Surrogate Models","Adaptation models;Resource management;Computational modeling;Predictive models;Quality of service;Cloud computing;Virtual machining","","12","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Petri nets state space analysis in the cloud","M. Camilli","Dipartimento di Informatica e Comunicazione, Università degli Studi di Milano, Milan, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1638","1640","Several techniques for addressing the state space explosion problem in model checking have been studied. One of these is to use distributed memory and computation for storing and exploring the state space of the model of a system. In this report, we present and compare different multi-thread, distributed, and cloud approaches to face the state-space explosion problem. The experiments report shows the convenience (in particular) of cloud approaches.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227217","Petri nets;Real-Time systems;State-space explosion;State-space parallel exploration;Multithreaded computing;Distributed computing;Cloud computing;MapReduce","Computational modeling;Petri nets;Explosions;Analytical models;Space exploration;Instruction sets;Real time systems","","10","","15","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Interactive refinement of combinatorial test plans","I. Segall; R. Tzoref-Brill","Haifa Research Lab, IBM, Haifa, Israel; Haifa Research Lab, IBM, Haifa, Israel",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1371","1374","Combinatorial test design (CTD) is an effective test planning technique that reveals faulty feature interactions in a given system. The test space is modeled by a set of parameters, their respective values, and restrictions on the value combinations. A subset of the test space is then automatically constructed so that it covers all valid value combinations of every t parameters, where t is a user input. When applying CTD to real-life testing problems, it can often occur that the result of CTD cannot be used as is, and manual modifications to the tests are performed. One example is very limited resources that significantly reduce the number of tests that can be used. Another example is complex restrictions that are not captured in the model of the test space. The main concern is that manually modifying the result of CTD might potentially introduce coverage gaps that the user is unaware of. In this paper we present a tool that supports interactive modification of a combinatorial test plan, both manually and with tool assistance. For each modification, the tool displays the new coverage gaps that will be introduced, and enables the user to take educated decisions on what to include in the final set of tests.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227245","","Testing;Planning;Global Positioning System;Analytical models;Multiaccess communication;Graphical user interfaces;Educational institutions","","8","1","7","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Ten years of automated code analysis at Microsoft (Invited industrial talk)","W. Schulte","Microsoft Research, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1001","1001","Summary form only given. Based on a unique video stream analysis and combined with the Sony Smartcamera architecture, Blue Eye Video stand alone solution is able to determine how many persons are waiting in a queue, the customer behaviour when moving in a department store, airports, theatre or stadium.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227248","","","","2","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"SOA adoption in the Italian industry","M. Leotta; F. Ricca; M. Ribaudo; G. Reggio; E. Astesiano; T. Vernazza","DISI, Università di Genova, Italy; DISI, Università di Genova, Italy; DISI, Università di Genova, Italy; DISI, Università di Genova, Italy; DISI, Università di Genova, Italy; DIST, Università di Genova, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1441","1442","We conducted a personal opinion survey in two rounds - years 2008 and 2011 - with the aim of investigating the level of knowledge and adoption of SOA in the Italian industry. We are also interested in understanding what is the trend of SOA (positive or negative?) and what are the methods, technologies and tools really used in the industry. The main findings of this survey are the following: (1) SOA is a relevant phenomenon in Italy, (2) Web services and RESTFul services are well-known/used and (3) orchestration languages and UDDI are little known and used. These results suggest that in Italy SOA is interpreted in a more simplistic way with respect to the current/real definition (i.e., without the concepts of orchestration/choreography and registry). Currently, the adoption of SOA is medium/low with a stable/positive trend of pervasiveness.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227074","Industrial Survey;SOA;Web services;Rest","Semiconductor optical amplifiers;Service oriented architecture;Industries;Companies","","2","","5","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Mining application repository to recommend XML configuration snippets","S. Huang; Y. Q. Lu; Y. Xiao; W. Wang","Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1451","1452","Framework-based applications controlled by XML configuration files are quite popularly used in current commercial applications. However, most of these frameworks are complex or not well documented, which poses a great challenge for programmers to correctly utilize them. To overcome these difficulties, we propose a new tool to recommend XML configuration snippets automatically through mining tree patterns and pattern associations from the application repository with the aim of assisting the programmer to generate proper XML configurations during the production phase. In this demo, we showcase this tool by presenting the major techniques behind the tool and the typical usage scenarios of our tool.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227069","XML;code reuse;code generation","XML;Association rules;Syntactics;Context;Databases;Programming","","1","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Writing dynamic service orchestrations with DSOL","L. S. Pinto; G. Cugola; C. Ghezzi","Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1383","1386","We present the workflow language DSOL, its runtime system and the tools available to support the development of dynamic service orchestrations. DSOL aims at supporting dynamic, self-managed service compositions that can adapt to changes occurring at runtime.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227242","Service oriented computing;service orchestration;declarative language","Abstracts;Runtime;Concrete;Java;XML;Monitoring;Web services","","","","6","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"MASH: A tool for end-user plug-in composition","L. Mariani; F. Pastore","Department of Informatics Systems and Communication, University of Milano-Bicocca, Milano, Italy; Department of Informatics Systems and Communication, University of Milano-Bicocca, Milano, Italy",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1387","1390","Most of the modern Integrated Development Environments are developed with plug-in based architectures that can be extended with additional functionalities and plug-ins, according to user needs. However, extending an IDE is still a possibility restricted to developers with deep knowledge about the specific development environment and its architecture. In this paper we present MASH, a tool that eases the programming of Integrated Development Environments. The tool supports the definition of workflows that can be quickly designed to integrate functionalities offered by multiple plugins, without the need of knowing anything about the internal architecture of the IDE. Workflows can be easily reshaped every time an analysis must be modified, without the need of producing Java code and deploying components in the IDE. Early results suggest that this approach can effectively facilitate programming of IDEs.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227241","plug-in composition;end-user programming","Multi-stage noise shaping;Graphical user interfaces;Visualization;Programming;Engines;Debugging;Computer architecture","","","","4","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Digital formations of the powerful and the powerless (Keynote)","S. Sassen","Columbia University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","961","961","Summary form only given. This talk is a whirlwind tour through human auditory perception. First, there is a mention of the actual acoustical cues in a performance venue, and then the ear's effects are discussed. In this, some discussion of loudness comes first, along with a bit of the presumed mechanisms. This will be followed by discussion of binaural auditory cues such as ITD, ILD, and HRTF's, and then a bit of discussion on the mechanisms for direct perception vs. diffuse perception follow. A bit of an introduction to the psychology of hearing will be covered as well, in order to explain what happens to the information present on the auditory nerve. Along the way, requirements for reproducing this in a standard acoustic space will be addressed in several fashions. All in all, this talk will summarize many years of work (starting in the late 1800's) on hearing and spatial sensation, as well as a bit of acoustics, and end with some recommendations on where one might improve the presentation of audio in the modern world, either for rooms or “virtualization” applications.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227255","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"RoPGen: Towards Robust Code Authorship Attribution via Automatic Coding Style Transformation","Z. Li; G. Q. Chen; C. Chen; Y. Zou; S. Xu","University of Texas, San Antonio, USA; University of Texas, San Antonio, USA; Center for Research in Computer Vision, University of Central Florida, USA; Northeastern University, China; University of Colorado Colorado Springs, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1906","1918","Source code authorship attribution is an important problem often encountered in applications such as software forensics, bug fixing, and software quality analysis. Recent studies show that current source code authorship attribution methods can be compromised by attackers exploiting adversarial examples and coding style ma-nipulation. This calls for robust solutions to the problem of code authorship attribution. In this paper, we initiate the study on making Deep Learning (DL)-based code authorship attribution robust. We propose an innovative framework called Robust coding style Patterns Generation (RoPGen), which essentially learns authors' unique coding style patterns that are hard for attackers to manip-ulate or imitate. The key idea is to combine data augmentation and gradient augmentation at the adversarial training phase. This effectively increases the diversity of training examples, generates meaningful perturbations to gradients of deep neural networks, and learns diversified representations of coding styles. We evaluate the effectiveness of RoPGen using four datasets of programs written in C, C++, and Java. Experimental results show that RoPGen can significantly improve the robustness of DL-based code authorship attribution, by respectively reducing 22.8% and 41.0% of the success rate of targeted and untargeted attacks on average.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510181","National Science Foundation(grant numbers:#1812599,#2122631,#2115134); Army Research Office(grant numbers:#W911NF-17-1-0566); Colorado State Bill(grant numbers:18–086); National Natural Science Foundation of China(grant numbers:U1936211); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793924","Authorship attribution;source code;coding style;robustness;deep learning","Training;Deep learning;Java;Codes;Perturbation methods;Neural networks;Software quality","","8","","54","","20 Jun 2022","","","IEEE","IEEE Conferences"
"AidUI: Toward Automated Recognition of Dark Patterns in User Interfaces","S. M. Hasan Mansur; S. Salma; D. Awofisayo; K. Moran","Department of Computer Science, George Mason University, Fairfax, VA; Department of Computer Science, George Mason University, Fairfax, VA; Department of Computer, Science Duke University, Durham, NC; Department of Computer Science, George Mason University, Fairfax, VA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1958","1970","Past studies have illustrated the prevalence of UI dark patterns, or user interfaces that can lead end-users toward (unknowingly) taking actions that they may not have intended. Such deceptive UI designs can be either intentional (to benefit an online service) or unintentional (through complicit design practices) and can result in adverse effects on end users, such as oversharing personal information or financial loss. While significant research progress has been made toward the development of dark pattern taxonomies across different software domains, developers and users currently lack guidance to help recognize, avoid, and navigate these often subtle design motifs. However, automated recognition of dark patterns is a challenging task, as the instantiation of a single type of pattern can take many forms, leading to significant variability. In this paper, we take the first step toward understanding the extent to which common UI dark patterns can be automatically recognized in modern software applications. To do this, we introduce AidUI, a novel automated approach that uses computer vision and natural language processing techniques to recognize a set of visual and textual cues in application screenshots that signify the presence of ten unique UI dark patterns, allowing for their detection, classification, and localization. To evaluate our approach, we have constructed ContextDP, the current largest dataset of fully-localized UI dark patterns that spans 175 mobile and 83 web UI screenshots containing 301 dark pattern instances. The results of our evaluation illustrate that AidUI achieves an overall precision of 0.66, recall of 0.67, F1-score of 0.65 in detecting dark pattern instances, reports few false positives, and is able to localize detected patterns with an IoU score of 0.84. Furthermore, a significant subset of our studied dark patterns can be detected quite reliably (F1 score of over 0.82), and future research directions may allow for improved detection of additional patterns. This work demonstrates the plausibility of developing tools to aid developers in recognizing and appropriately rectifying deceptive UI patterns.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00166","NSF(grant numbers:CCF-2132285,CCF-1955853); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172754","Dark Pattern;UI Analysis;UI Design","Location awareness;Visualization;Navigation;Taxonomy;User interfaces;Software;Pattern recognition","","5","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SugarC: Scalable Desugaring of Real-World Preprocessor Usage into Pure C","Z. Patterson; Z. Zhang; B. Pappas; S. Wei; P. Gazzillo","The University of Texas at Dallas, USA; The University of Texas at Dallas, USA; University of Central Florida, USA; The University of Texas at Dallas, USA; University of Central Florida, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2056","2067","Variability-aware analysis is critical for ensuring the quality of con-figurable C software. An important step toward the development of variability-aware analysis at scale is to transform real-world C soft-ware that uses both C and preprocessor into pure C code, by replacing the preprocessor's compile-time variability with C's runtime-variability. In this work, we design and implement a desugaring tool, SugarC, that transforms away real-world preprocessor usage. SugarC augments C's formal grammar specification with translation rules, performs simultaneous type checking during de sugaring, and introduces numerous optimizations to address challenges that appear in real-world preprocessor usage. The experiments on DesugarBench, a benchmark consisting of 108 manually-created programs, show that SugarC supports many more language features than two existing desugaring tools. When applied on three real-world configurable C software, SugarC desugared 774 out of 813 files in the three programs, taking at most ten minutes in the worst case and less than two minutes for 95% of the C files.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3512763","NSF(grant numbers:CCF-1840934,CCF-1816951); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793944","C preprocessor;syntax-directed translation;desugaring","Codes;Computer bugs;C languages;Transforms;Manuals;Syntactics;Software","","3","","47","","20 Jun 2022","","","IEEE","IEEE Conferences"
"OJXPERF: Featherlight Object Replica Detection for Java Programs","B. Li; H. Xu; Q. Zhao; P. Su; M. Chabbi; S. Jiao; X. Liu","North Carolina State University, Raleigh, North Carolina, USA; College of William and Mary, Williamsburg, Virginia, USA; North Carolina State University, Raleigh, North Carolina, USA; University of California, Merced, Merced, California, USA; Scalable Machines Research; North Carolina State University, Raleigh, North Carolina, USA; North Carolina State University, Raleigh, North Carolina, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1558","1570","Memory bloat is an important source of inefficiency in complex production software, especially in software written in managed languages such as Java. Prior approaches to this problem have focused on identifying objects that outlive their life span. Few studies have, however, looked into whether and to what extent myriad objects of the same type are identical. A quantitative assessment of identical objects with code-level attribution can assist developers in refactoring code to eliminate object bloat, and favor reuse of existing object(s). The result is reduced memory pressure, reduced allocation and garbage collection, enhanced data locality, and reduced re-computation, all of which result in superior performance. We develop OJXPerf, a lightweight sampling-based profiler, which probabilistically identifies identical objects. OJXPerf employs hardware performance monitoring units (PMU) in conjunction with hardware debug registers to sample and compare field values of different objects of the same type allocated at the same calling context but potentially accessed at different program points. The result is a lightweight measurement – a combination of object allocation contexts and usage contexts ordered by duplication frequency. This class of duplicated objects is relatively easier to optimize. OJXPerf incurs 9% runtime and 6% memory overheads on average. We empirically show the benefit of OJXPerf by using its profiles to instruct us to optimize a number of Java programs, including well-known benchmarks and real-world applications. The results show a noticeable reduction in memory usage (up to 11%) and a significant speedup (up to 25%).","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510083","NSF(grant numbers:2050007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794091","","Java;Runtime;Codes;Software;Hardware;Registers;Frequency measurement","","1","","66","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Motorease: Automated Detection of Motor Impairment Accessibility Issues in Mobile App UIs","A. Krishnavajjala; S. H. Mansur; J. Jose; K. Moran","George Mason University, Farifax, VA, USA; George Mason University, Fairfax, VA, USA; South Lakes High School, Reston, VA, USA; University of Central FL, Orlando, FL, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2580","2592","Recent research has begun to examine the potential of automatically finding and fixing accessibility issues that manifest in software. However, while recent work makes important progress, it has generally been skewed toward identifying issues that affect users with certain disabilities, such as those with visual or hearing impairments. However there are other groups of users with different types of disabilities that also need software tooling support to improve their experience. As such, this paper aims to automatically identify accessibility issues that affect users with motor-impairments. To move toward this goal, this paper introduces a novel approach, called Motorease, capable of identifying accessibility issues in mobile app UIs that impact motor-impaired users. Motor-impaired users often have limited ability to interact with touch-based devices, and instead may make use of a switch or other assistive mechanism - hence UIs must be designed to support both limited touch gestures and the use of assistive devices. Motorease adapts computer vision and text processing techniques to enable a semantic understanding of app UI screens, enabling the detection of violations related to four popular, previously unexplored UI design guidelines that support motor-impaired users, including: (i) visual touch target size, (ii) expanding sections, (iii) persisting elements, and (iv) adjacent icon visual distance. We evaluate Motorease on a newly derived benchmark, called Motorcheck, that contains 555 manually annotated examples of violations to the above accessibility guidelines, across 1599 screens collected from 70 applications via a mobile app testing tool. Our experiments illustrate that Motorease is able to identify violations with an average accuracy of ≈90%, and a false positive rate of less than 9%, outperforming baseline techniques.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639167","NSF(grant numbers:CCF-1955853,CNS-2132285); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548877","accessibility;mobile apps;screen understanding","Visualization;Design methodology;Semantics;Switches;Motors;Software;Mobile applications","","","","94","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"TRACED: Execution-Aware Pre-Training for Source Code","Y. Ding; B. Steenhoek; K. Pei; G. Kaiser; W. Le; B. Ray","Columbia University, New York, NY, USA; Iowa State University, Ames, IA, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Iowa State University, Ames, IA, USA; Columbia University, New York, NY, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","416","427","Most existing pretrained language models for source code focus on learning the static code text, typically augmented with static code structures (abstract syntax tree, dependency graphs, etc.). However, program semantics will not be fully exposed before the real execution. Without an understanding of the program execution, statically pretrained models fail to comprehensively capture the dynamic code properties, such as the branch coverage and the runtime variable values, and they are consequently less effective at code understanding tasks, such as retrieving semantic clones and detecting software vulnerabilities. To close the gap between the static nature of language models and the dynamic characteristics of programs, we introduce TRACED, an execution-aware pretraining strategy for source code. Specifically, we pretrain code language models with a combination of source code, executable inputs, and corresponding execution traces. Our goal is to teach code models the complicated execution logic during the pretraining, enabling the model to statically es-timate the dynamic code properties without repeatedly executing code during task-specific fine-tuning. To illustrate the effectiveness of our proposed approach, we fine-tune and evaluate TRACED on three downstream tasks: static execution estimation, clone retrieval, and vulnerability detection. The empirical results show that TRACED relatively improves the statically pretrained code models by 12.4% for complete execution path prediction and by 25.2% for runtime variable value predictions. TRACED also significantly outperforms statically pretrained models in clone retrieval and vulnerability detection across four public benchmarks.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608140","NSF(grant numbers:CCF-2313054,CCF-2313055,CCF-1815494,CCF-210740,CCF-1845893,IIS-2221943); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549736","","Codes;Runtime;Source coding;Semantics;Cloning;Syntactics;Predictive models","","2","","55","","14 Jun 2024","","","IEEE","IEEE Conferences"
"FedDebug: Systematic Debugging for Federated Learning Applications","W. Gill; A. Anwar; M. A. Gulzar","Computer Science Department, Virginia Tech, Blacksburg, USA; Computer Science and Engineering Department, University of Minnesota Twin Cities, Minneapolis, USA; Computer Science Department, Virginia Tech, Blacksburg, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","512","523","In Federated Learning (FL), clients independently train local models and share them with a central aggregator to build a global model. Impermissibility to access clients' data and collaborative training make FL appealing for applications with data-privacy concerns, such as medical imaging. However, these FL characteristics pose unprecedented challenges for debugging. When a global model's performance deteriorates, identifying the responsible rounds and clients is a major pain point. Developers resort to trial-and-error debugging with subsets of clients, hoping to increase the global model's accuracy or let future FL rounds retune the model, which are time-consuming and costly. We design a systematic fault localization framework, Fedde-bug,that advances the FL debugging on two novel fronts. First, Feddebug enables interactive debugging of realtime collaborative training in FL by leveraging record and replay techniques to construct a simulation that mirrors live FL. Feddebug'sbreakpoint can help inspect an FL state (round, client, and global model) and move between rounds and clients' models seam-lessly, enabling a fine-grained step-by-step inspection. Second, Feddebug automatically identifies the client(s) responsible for lowering the global model's performance without any testing data and labels-both are essential for existing debugging techniques. Feddebug's strengths come from adapting differential testing in conjunction with neuron activations to determine the client(s) deviating from normal behavior. Feddebug achieves 100% accuracy in finding a single faulty client and 90.3% accuracy in finding multiple faulty clients. Feddebug's interactive de-bugging incurs 1.2% overhead during training, while it localizes a faulty client in only 2.1% of a round's training time. With FedDebug,we bring effective debugging practices to federated learning, improving the quality and productivity of FL application developers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172839","software debugging;federated learning;testing;client;fault localization;neural networks;CNN","Training;Location awareness;Fault diagnosis;Adaptation models;Systematics;Federated learning;Collaboration","","2","","59","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Demystifying Privacy Policy of Third-Party Libraries in Mobile Apps","K. Zhao; X. Zhan; L. Yu; S. Zhou; H. Zhou; X. Luo; H. Wang; Y. Liu",The Hong Kong Polytechnic University; Southern University of Science and Technology; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; The Hong Kong Polytechnic University; Huazhong University of Science and Technology; Southern University of Science and Technology,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1583","1595","The privacy of personal information has received significant attention in mobile software. Although researchers have designed methods to identify the conflict between app behavior and privacy policies, little is known about the privacy compliance issues relevant to third-party libraries (TPLs). The regulators enacted articles to regulate the usage of personal information for TPLs (e.g., the CCPA requires businesses clearly notify consumers if they share consumers' data with third parties or not). However, it remains challenging to investigate the privacy compliance issues of TPLs due to three reasons: 1) Difficulties in collecting TPLs' privacy policies. In contrast to Android apps, which are distributed through markets like Google Play and must provide privacy policies, there is no unique platform for collecting privacy policies of TPLs. 2) Difficulties in analyzing TPL's user privacy access behaviors. TPLs are mainly provided in binary files, such as jar or aar, and their whole functionalities usually cannot be executed independently without host apps. 3) Difficulties in identifying consistency between TPL's functionalities and privacy policies, and host app's privacy policy and data sharing with TPLs. This requires analyzing not only the privacy policies of TPLs and host apps but also their functionalities. In this paper, we propose an automated system named ATPChecker to analyze whether Android TPLs comply with the privacy-related regulations. We construct a data set that contains a list of 458 TPLs, 247 TPL's privacy policies, 187 TPL's binary files and 641 host apps and their privacy policies. Then, we analyze the bytecode of TPLs and host apps, design natural language processing systems to analyze privacy policies, and implement an expert system to identify TPL usage-related regulation compliance. The experimental results show that 23% TPLs violate regulation requirements for providing privacy policies. Over 47% TPLs miss disclosing data usage in their privacy policies. Over 65% host apps share user data with TPLs while 65% of them miss disclosing interactions with TPLs. Our findings remind developers to be mindful of TPL usage when developing apps or writing privacy policies to avoid violating regulations,","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172865","Privacy policy;third-party library;Android","Privacy;Data privacy;Regulators;Operating systems;Writing;Regulation;Libraries","","7","","79","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Streamlining Java Programming: Uncovering Well-Formed Idioms with Idiomine","Y. Yang; X. Hu; X. Xia; D. Lo; X. Yang","The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China; Zhejiang University, China; Singapore Management University, Singapore; The State Key Laboratory of Blockchain and Data Security, Zhejiang University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2844","2855","Code idioms are commonly used patterns, techniques, or practices that aid in solving particular problems or specific tasks across multiple software projects. They can improve code quality, performance, and maintainability, and also promote program standardization and reuse across projects. However, identifying code idioms is significantly challenging, as existing studies have still suffered from three main limitations. First, it is difficult to recognize idioms that span non-contiguous code lines. Second, identifying idioms with intricate data flow and code structures can be challenging. More-over, they only extract dataset-specific idioms, so common idioms or well-established code/design patterns that are rarely found in datasets cannot be identified. To overcome these limitations, we propose a novel approach, named Idiomine, to automatically extract generic and specific idioms from both Java projects and libraries. We perform program analysis on Java functions to transform them into concise PDGs, for integrating the data flow and control flow of code fragments. We then develop a novel chain structure, Data-driven Control Chain (DCC), to extract sub-idioms that possess contiguous semantic meanings from PDGs. After that, we utilize GraphCodeBERT to generate code embeddings of these sub-idioms and perform density-based clustering to obtain frequent sub-idioms. We use heuristic rules to identify interrelated sub-idioms among the frequent ones. Finally, we employ ChatGPT to synthesize interrelated sub-idioms into potential code idioms and infer real idioms from them. We conduct well-designed experiments and a user study to evaluate Idiomine's correctness and the practical value of the extracted idioms. Our experimental results show that Idiomine effectively extracts more idioms with better performance in most metrics. We compare our approach with Haggis and ChatGPT, Idiomine outperforms them by 22.8% and 35.5% in Idiom Set Precision (ISP) and by 9.7% and 22.9% in Idiom Coverage (IC) when extracting idioms from libraries. Idiomine also extracts almost twice the size of idioms than the baselines, exhibiting its ability to identify complete idioms. Our user study indicates that idioms extracted by Idiomine are well-formed and semantically clear. Moreover, we conduct a qualitative and quantitative analysis to investigate the primary functionalities of Idiomine's extracted idioms from various projects and libraries.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548071","Code Idiom Mining;Code Pattern;Large Language Model (LLM);Clustering","Java;Codes;Statistical analysis;Transforms;Standardization;Chatbots;Libraries","","","","69","","14 Jun 2024","","","IEEE","IEEE Conferences"
"PREACH: A Heuristic for Probabilistic Reachability to Identify Hard to Reach Statements","S. Saha; M. Downing; T. Brennan; T. Bultan","University of California, Santa Barbara, Santa Barbara, CA, USA; University of California, Santa Barbara, Santa Barbara, CA, USA; University of California, Santa Barbara, Santa Barbara, CA, USA; University of California, Santa Barbara, Santa Barbara, CA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1706","1717","We present a heuristic for approximating the likelihood of reaching a given program statement using 1) branch selectivity (representing the percentage of values that satisfy a branch condition), which we compute using model counting, 2) dependency analysis, which we use to identify input-dependent branch conditions that influence statement reachability, 3) abstract interpretation, which we use to identify the set of values that reach a branch condition, and 4) a discrete-time Markov chain model, which we construct to capture the control flow structure of the program together with the selectivity of each branch. Our experiments indicate that our heuristic-based probabilistic reachability analysis tool PReach can identify hard to reach statements with high precision and accuracy in benchmarks from software verification and testing competitions, Apache Commons Lang, and the DARPA STAC program. We provide a detailed comparison with probabilistic symbolic execution and statistical symbolic execution for the purpose of identifying hard to reach statements. PREACH achieves comparable precision and accuracy to both probabilistic and statistical symbolic execution for bounded execution depth and better precision and accuracy when execution depth is unbounded and the number of program paths grows exponentially. Moreover, PReach is more scalable than both probabilistic and statistical symbolic execution.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510227","NSF(grant numbers:CCF-2008660,CCF-1901098,CCF-1817242); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794044","","Analytical models;Computational modeling;Government;Benchmark testing;Probability;Model checking;Probabilistic logic","","","","42","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Graph-based pattern-oriented, context-sensitive source code completion","A. T. Nguyen; T. T. Nguyen; H. A. Nguyen; A. Tamrawi; H. V. Nguyen; J. Al-Kofahi; T. N. Nguyen","Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA; Electrical and Computer Engineering Department, Iowa State University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","69","79","Code completion helps improve developers' programming productivity. However, the current support for code completion is limited to context-free code templates or a single method call of the variable on focus. Using software libraries for development, developers often repeat API usages for certain tasks. Thus, a code completion tool could make use of API usage patterns. In this paper, we introduce GraPacc, a graph-based, pattern-oriented, context-sensitive code completion approach that is based on a database of such patterns. GraPacc represents and manages the API usage patterns of multiple variables, methods, and control structures via graph-based models. It extracts the context-sensitive features from the code under editing, e.g. the API elements on focus and their relations to other code elements. Those features are used to search and rank the patterns that are most fitted with the current code. When a pattern is selected, the current code will be completed via a novel graph-based code completion algorithm. Empirical evaluation on several real-world systems shows that GraPacc has a high level of accuracy in code completion.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227205","pattern-based code completion;API usage pattern","Feature extraction;Context;Databases;Graphical user interfaces;Libraries;Pattern matching;Layout","","85","4","36","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Behavioral validation of JFSL specifications through model synthesis","C. Ghezzi; A. Mocci","Politecnico di Milano, DeepSE Group, DEI, Milano, Italy; CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","936","946","Contracts are a popular declarative specification technique to describe the behavior of stateful components in terms of pre/post conditions and invariants. Since each operation is specified separately in terms of an abstract implementation, it may be hard to understand and validate the resulting component behavior from contracts in terms of method interactions. In particular, properties expressed through algebraic axioms, which specify the effect of sequences of operations, require complex theorem proving techniques to be validated. In this paper, we propose an automatic small-scope based approach to synthesize incomplete behavioral abstractions for contracts expressed in the JFSL notation. The proposed abstraction technique enables the possibility to check that the contract behavior is coherent with behavioral properties expressed as axioms of an algebraic specifications. We assess the applicability of our approach by showing how the synthesis methodology can be applied to some classes of contract-based artifacts like specifications of data abstractions and requirement engineering models.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227126","contracts;specifications;model synthesis;behavioral validation","Contracts;Observers;Context;Metals;Abstracts;Algebra;Algorithm design and analysis","","1","","22","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"DEAR: A Novel Deep Learning-based Approach for Automated Program Repair","Y. Li; S. Wang; T. N. Nguyen","New Jersey Inst. of Technology, New Jersey, USA; New Jersey Inst. of Technology, New Jersey, USA; University of Texas, Dallas, Texas, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","511","523","The existing deep learning (DL)-based automated program repair (APR) models are limited in fixing general software defects. We present DEAR, a DL-based approach that supports fixing for the general bugs that require dependent changes at once to one or mul-tiple consecutive statements in one or multiple hunks of code. We first design a novel fault localization (FL) technique for multi-hunk, multi-statement fixes that combines traditional spectrum-based (SB) FL with deep learning and data-flow analysis. It takes the buggy statements returned by the SBFL model, detects the buggy hunks to be fixed at once, and expands a buggy statement $s$ in a hunk to include other suspicious statements around s. We design a two-tier, tree-based LSTM model that incorporates cycle training and uses a divide-and-conquer strategy to learn proper code transformations for fixing multiple statements in the suitable fixing context consisting of surrounding subtrees. We conducted several experiments to evaluate DEAR on three datasets: Defects4J (395 bugs), BigFix (+26k bugs), and CPatMiner (+44k bugs). On Defects4J dataset, DEAR outperforms the baselines from 42%-683% in terms of the number of auto-fixed bugs with only the top-1 patches. On BigFix dataset, it fixes 31–145 more bugs than existing DL-based APR models with the top-1 patches. On CPatMiner dataset, among 667 fixed bugs, there are 169 (25.3%) multi-hunk/multi-statement bugs. DEAR fixes 71 and 164 more bugs, including 52 and 61 more multi-hunk/multi-statement bugs, than the state-of-the-art, DL-based APR models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793900","Automated Program Repair;Deep Learning;Fault Localization","Deep learning;Training;Location awareness;Analytical models;Codes;Computer bugs;Maintenance engineering","","16","","45","","20 Jun 2022","","","IEEE","IEEE Conferences"
"RUNNER: Responsible UNfair NEuron Repair for Enhancing Deep Neural Network Fairness","T. Li; Y. Cao; J. Zhang; S. Zhao; Y. Huang; A. Liu; Q. Guo; Y. Liu","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Beihang University, China; Institute of High Performance Computing (IHPC), Centre for Frontier AI Research (CFAR), A*STAR, Singapore; Nanyang Technological University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","77","89","Deep Neural Networks (DNNs), an emerging software technology, have achieved impressive results in a variety of fields. However, the discriminatory behaviors towards certain groups (a.k.a. unfairness) of DNN models increasingly become a social concern, especially in high-stake applications such as loan approval and criminal risk assessment. Although there has been a number of works to improve model fairness, most of them adopt an adversary to either expand the model architecture or augment training data, which introduces excessive computational overhead. Recent work diagnoses responsible unfair neurons first and fixes them with selective retraining. Unfortunately, existing diagnosis process is time-consuming due to multi-step training sample analysis, and selective retraining may cause a performance bottleneck due to indirectly adjusting unfair neurons on biased samples. In this paper, we propose Responsible UNfair NEuron Repair (RUNNER) that improves existing works in three key aspects: (1) efficiency: we design the Importance-based Neuron Diagnosis that identifies responsible unfair neurons in one step with a novel importance criterion of neurons; (2) effectiveness: we design the Neuron Stabilizing Retraining by adding a loss term that measures the activation distance of responsible unfair neurons from different subgroups in all sources; (3) generalization: we investigate the effectiveness on both structured tabular data and large-scale unstructured image data, which is often ignored in prior studies. Our extensive experiments across 5 datasets show that RUUNER can effectively and efficiently diagnose and repair the DNNs regarding unfairness. On average, our approach significantly reduces computing overhead from 341.7s to 29.65s, and achieves improved fairness up to 79.3%. Besides, RUNNER also keeps state-of-the-art results on the unstructured dataset.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548361","Deep Learning Repair;Fairness;Model Interpretation","Training;Computational modeling;Neurons;Training data;Artificial neural networks;Maintenance engineering;Loss measurement","","","","70","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Quantifying Permissiveness of Access Control Policies","W. Eiers; G. Sankaran; A. Li; E. O'Mahony; B. Prince; T. Bultan","University of California Santa Barbara, Santa Barbara, CA, USA; University of California Santa Barbara, Santa Barbara, CA, USA; University of California Santa Barbara, Santa Barbara, CA, USA; University of California Santa Barbara, Santa Barbara, CA, USA; University of California Santa Barbara, Santa Barbara, CA, USA; University of California Santa Barbara, Santa Barbara, CA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1805","1817","Due to ubiquitous use of software services, protecting the confidentiality of private information stored in compute clouds is becoming an increasingly critical problem. Although access control specification languages and libraries provide mechanisms for protecting confidentiality of information, without verification and validation techniques that can assist developers in writing policies, complex policy specifications are likely to have errors that can lead to unintended and unauthorized access to data, possibly with disastrous consequences. In this paper, we present a quantitative and differential policy analysis framework that not only identifies if one policy is more permissive than another policy, but also quantifies the relative permissiveness of access control policies. We quantify permissiveness of policies using a model counting constraint solver. We present a heuristic that transforms constraints extracted from access control policies and significantly improves the model counting performance. We demonstrate the effectiveness of our approach by applying it to policies written in Amazon's AWS Identity and Access Management (IAM) policy language and Microsoft's Azure policy language.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510233","NSF(grant numbers:CCF-2008660,CCF-1901098,CCF-1817242); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794078","Formal Methods;Access Control;Validation and Verification;Privacy","Access control;Statistical analysis;Soft sensors;Transforms;Writing;Maintenance engineering;Libraries","","","","66","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"MVD: Memory-Related Vulnerability Detection Based on Flow-Sensitive Graph Neural Networks","S. Cao; X. Sun; L. Bo; R. Wu; B. Li; C. Tao","Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Xiamen University, Xiamen, China; Yangzhou University, Yangzhou, China; Nanjing University of Aeronautics and Astronautics, Nanjing, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1456","1468","Memory-related vulnerabilities constitute severe threats to the security of modern software. Despite the success of deep learning-based approaches to generic vulnerability detection, they are still limited by the underutilization of flow information when applied for detecting memory-related vulnerabilities, leading to high false positives. In this paper, we propose MVD, a statement-level Memory-related Vulnerability Detection approach based on flow-sensitive graph neural networks (FS-GNN). FS-GNN is employed to jointly embed both unstructured information (i.e., source code) and structured information (i.e., control- and data-flow) to capture implicit memory-related vulnerability patterns. We evaluate MVD on the dataset which contains 4,353 real-world memory-related vulnerabilities, and compare our approach with three state-of-the-art deep learning-based approaches as well as five popular static analysis-based memory detectors. The experiment results show that MVD achieves better detection accuracy, outperforming both state-of-the-art DL-based and static analysis-based approaches. Furthermore, MVD makes a great trade-off between accuracy and efficiency.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510219","National Natural Science Foundation of China(grant numbers:61872312,61972335,62002309,61902329); Six Talent Peaks Project in Jiangsu Province(grant numbers:RJFW-053); Nanjing University(grant numbers:KFKT2020B15,KFKT2020B16); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794007","Memory-Related Vulnerability;Vulnerability Detection;Graph Neural Networks;Flow Analysis","Analytical models;Codes;Semantics;Detectors;Graph neural networks;Software;Security","","33","","72","","20 Jun 2022","","","IEEE","IEEE Conferences"
"On the Evaluation of Neural Code Summarization","E. Shi; Y. Wang; L. Du; J. Chen; S. Han; H. Zhang; D. Zhang; H. Sun",Xi'an Jiaotong University; Microsoft Research; Microsoft Research; Tianjin University; Microsoft Research; The University of Newcastle; Microsoft Research; Xi'an Jiaotong University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1597","1608","Source code summaries are important for program comprehension and maintenance. However, there are plenty of programs with missing, outdated, or mismatched summaries. Recently, deep learning techniques have been exploited to automatically generate summaries for given code snippets. To achieve a profound understanding of how far we are from solving this problem and provide suggestions to future research, in this paper, we conduct a systematic and in-depth analysis of 5 state-of-the-art neural code summarization models on 6 widely used BLEU variants, 4 pre-processing operations and their combinations, and 3 widely used datasets. The evaluation results show that some important factors have a great influence on the model evaluation, especially on the performance of models and the ranking among the models. However, these factors might be easily overlooked. Specifically, (1) the BLEU metric widely used in existing work of evaluating code summarization models has many variants. Ignoring the differences among these variants could greatly affect the validity of the claimed results. Besides, we discover and resolve an important and previously unknown bug in BLEU calculation in a commonly-used software package. Furthermore, we conduct human evaluations and find that the metric BLEU-DC is most correlated to human perception; (2) code pre-processing choices can have a large (from −18% to +25%) impact on the summarization performance and should not be neglected. We also explore the aggregation of pre-processing combinations and boost the performance of models; (3) some important char-acteristics of datasets (corpus sizes, data splitting methods, and duplication ratios) have a significant impact on model evaluation. Based on the experimental results, we give actionable suggestions for evaluating code summarization and choosing the best method in different scenarios. We also build a shared code summarization toolbox to facilitate future research.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510060","National Key R&D Program of China(grant numbers:2017YFA0700800); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794127","Code summarization;Empirical study;Deep learning;Evaluation","Measurement;Analytical models;Codes;Systematics;Smoothing methods;Software packages;Data models","","21","","72","","20 Jun 2022","","","IEEE","IEEE Conferences"
"DeepDiagnosis: Automatically Diagnosing Faults and Recommending Actionable Fixes in Deep Learning Programs","M. Wardat; B. D. Cruz; W. Le; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","561","572","Deep Neural Networks (DNNs) are used in a wide variety of applications. However, as in any software application, DNN-based apps are afflicted with bugs. Previous work observed that DNN bug fix patterns are different from traditional bug fix patterns. Furthermore, those buggy models are non-trivial to diagnose and fix due to inexplicit errors with several options to fix them. To support developers in locating and fixing bugs, we propose DeepDiagnosis, a novel debugging approach that localizes the faults, reports error symptoms and suggests fixes for DNN programs. In the first phase, our technique monitors a training model, periodically checking for eight types of error conditions. Then, in case of problems, it reports messages containing sufficient information to perform actionable repairs to the model. In the evaluation, we thoroughly examine 444 models - 53 real-world from GitHub and Stack Overflow, and 391 curated by AUTOTRAINER. DeepDiagnosis provides superior accuracy when compared to UMLUAT and DeepLocalize. Our technique is faster than AUTOTRAINER for fault localization. The results show that our approach can support additional types of models, while state-of-the-art was only able to handle classification ones. Our technique was able to report bugs that do not manifest as numerical errors during training. Also, it can provide actionable insights for fix whereas DeepLocalize can only report faults that lead to numerical errors during training. DeepDiagnosis manifests the best capabilities of fault detection, bug localization, and symptoms identification when compared to other approaches.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510071","National Science Foundation(grant numbers:CNS-21-20448,CCF-19-34884); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794035","deep neural networks;fault location;debugging;program analysis;deep learning bugs","Training;Location awareness;Deep learning;Computer bugs;Neural networks;Software;Numerical models","","11","","49","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Preempting Flaky Tests via Non-Idempotent-Outcome Tests","A. Wei; P. Yi; Z. Li; T. Xie; D. Marinov; W. Lam",Stanford University; Peking University; University of Illinois; Peking University; University of Illinois; George Mason University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1730","1742","Regression testing can greatly help in software development, but it can be seriously undermined by flaky tests, which can both pass and fail, seemingly nondeterministically, on the same code commit. Flaky tests are an emerging topic in both research and industry. Prior work has identified multiple categories of flaky tests, developed techniques for detecting these flaky tests, and analyzed some detected flaky tests. To proactively detect, i.e., preempt, flaky tests, we propose to detect non-idempotent-outcome (NIO) tests, a novel category related to flaky tests. In particular, we run each test twice in the same test execution environment, e.g., run each Java test twice in the same Java Virtual Machine. A test is NIO if it passes in the first run but fails in the second. Each NIO test has side effects and “self-pollutes” the state shared among test runs. We perform experiments on both Java and Python open-source projects, detecting 223 NIO Java tests and 138 NIO Python tests. We have inspected all 361 detected tests and opened pull requests that fix 268 tests, with 192 already accepted, only 6 rejected, and the remaining 70 pending.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510170","US NSF(grant numbers:CCF-1763788,CCF-1956374); Natural Science Foundation of China(grant numbers:62161146003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793904","","Industries;Java;Codes;Virtual machining;Open source software;Python;Testing","","9","","100","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study","Q. Guo; J. Cao; X. Xie; S. Liu; X. Li; B. Chen; X. Peng","Tianjin University, Tianjin, China; Fudan University, Shanghai, China; Singapore Management University, Singapore; Nanyang Technological University, Singapore; Tianjin University, Tianjin, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","390","402","Code review is an essential activity for ensuring the quality and maintainability of software projects. However, it is a time-consuming and often error-prone task that can significantly impact the development process. Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive performance in various natural language processing tasks, suggesting its potential to automate code review processes. However, it is still unclear how well ChatGPT performs in code review tasks. To fill this gap, in this paper, we conduct the first empirical study to understand the capabilities of ChatGPT in code review tasks, specifically focusing on automated code refinement based on given code reviews. To conduct the study, we select the existing benchmark CodeReview and construct a new code review dataset with high quality. We use CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison with ChatGPT. Our results show that ChatGPT outperforms CodeRe-viewer in code refinement tasks. Specifically, our results show that ChatGPT achieves higher EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art method achieves only 15.50 and 62.88 on a high-quality code review dataset. We further identify the root causes for ChatGPT's underperformance and propose several strategies to mitigate these challenges. Our study provides insights into the potential of ChatGPT in automating the code review process, and highlights the potential research directions.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623306","National Key R&D Project(grant numbers:2021YFF1201102); National Natural Science Foundation of China(grant numbers:61872262); National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548119","Automating Code Review;Activities Automated Code Refinement;ChatGPT Empirical Study","Codes;Reviews;Focusing;Benchmark testing;Chatbots;Software;Task analysis","","6","","46","","14 Jun 2024","","","IEEE","IEEE Conferences"
"On Using GUI Interaction Data to Improve Text Retrieval-Based Bug Localization","J. Mahmud; N. De Silva; S. A. Khan; S. H. Mostafavi; S. H. Mansur; O. Chaparro; A. Marcus; K. Moran","University of Central Florida, Orlando, FL, USA; William & Mary, Williamsburg, VA, USA; George Mason University, Fairfax, VA, USA; George Mason University, Fairfax, VA, USA; George Mason University, Fairfax, VA, USA; William & Mary, Williamsburg, VA, USA; George Mason University, Fairfax, VA, USA; University of Central Florida, Orlando, FL, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","466","478","One of the most important tasks related to managing bug reports is localizing the fault so that a fix can be applied. As such, prior work has aimed to automate this task of bug localization by formulating it as an information retrieval problem, where potentially buggy files are retrieved and ranked according to their textual similarity with a given bug report. However, there is often a notable semantic gap between the information contained in bug reports and identifiers or natural language contained within source code files. For user-facing software, there is currently a key source of information that could aid in bug localization, but has not been thoroughly investigated – information from the graphical user interface (GUI). In this paper, we investigate the hypothesis that, for end user-facing applications, connecting information in a bug report with information from the GUI, and using this to aid in retrieving potentially buggy files, can improve upon existing techniques for text retrieval-based bug localization. To examine this phenomenon, we conduct a comprehensive empirical study that augments four baseline text-retrieval techniques for bug localization with GUI interaction information from a reproduction scenario to (i) filter out potentially irrelevant files, (ii) boost potentially relevant files, and (iii) reformulate text-retrieval queries. To carry out our study, we source the current largest dataset of fully-localized and reproducible real bugs for Android apps, with corresponding bug reports, consisting of 80 bug reports from 39 popular open-source apps. Our results illustrate that augmenting traditional techniques with GUI information leads to a marked increase in effectiveness across multiple metrics, including a relative increase in Hits@10 of 13-18%. Additionally, through further analysis, we find that our studied augmentations largely complement existing techniques, pushing additional buggy files into the top-10 results while generally preserving top ranked files from the baseline techniques.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608139","U.S. NSF(grant numbers:CCF-1910976,CCF-2343057,CCF-1955837,CCF-2007246,CCF-1955853); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548359","Bug Localization;GUI;Natural Language Processing;Mobile apps","Location awareness;Measurement;Source coding;Computer bugs;Semantics;Natural languages;Software","","3","","101","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Comparison and Evaluation of Clone Detection Techniques with Different Code Representations","Y. Wang; Y. Ye; Y. Wu; W. Zhang; Y. Xue; Y. Liu","University of Science and Technology of China, China; University of Science and Technology of China, China; Nanyang Technological University, Singapore; University of Science and Technology of China, China; University of Science and Technology of China, China; Nanyang Technological University, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","332","344","As one of bad smells in code, code clones may increase the cost of software maintenance and the risk of vulnerability propagation. In the past two decades, numerous clone detection technologies have been proposed. They can be divided into text-based, token-based, tree-based, and graph-based approaches according to their code representations. Different code representations abstract the code details from different perspectives. However, it is unclear which code representation is more effective in detecting code clones and how to combine different code representations to achieve ideal performance. In this paper, we present an empirical study to compare the clone detection ability of different code representations. Specifically, we reproduce 12 clone detection algorithms and divide them into different groups according to their code representations. After analyzing the empirical results, we find that token and tree representations can perform better than graph representation when detecting simple code clones. However, when the code complexity of a code pair increases, graph representation becomes more effective. To make our findings more practical, we perform manual analysis on open-source projects to seek a possible distribution of different clone types in the open-source community. Through the results, we observe that most clone pairs belong to simple code clones. Based on this observation, we discard heavyweight graph-based clone detection algorithms and conduct combination experiments to find out a suitable combination of token-based and tree-based approaches for achieving scalable and effective code clone detection. We develop the suitable combination into a tool called TACC and evaluate it with other state-of-the-art code clone detectors. Experimental results indicate that TACC performs better and has the ability to detect large-scale code clones.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00039","National Research Foundation Singapore; National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172753","Clone Detection;Empirical Study;Code Representation;Large Scale","Software maintenance;Codes;Costs;Scalability;Cloning;Manuals;Detectors","","3","","69","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Precise Divide-By-Zero Detection with Affirmative Evidence","Y. Guo; J. Zhou; P. Yao; Q. Shi; C. Zhang","The Hong Kong University of Science and Technology, Hong Kong, China; Ant Group, China; The Hong Kong University of Science and Technology, Hong Kong, China; Ant Group, China; The Hong Kong University of Science and Technology, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1718","1729","The static detection of divide-by-zero, a common programming error, is particularly prone to false positives because conventional static analysis reports a divide-by-zero bug whenever it cannot prove the safety property – the divisor variable is not zero in all executions. When reasoning the program semantics over a large number of under-constrained variables, conventional static analyses significantly loose the bounds of divisor variables, which easily fails the safety proof and leads to a massive number of false positives. We propose a static analysis to detect divide-by-zero bugs taking additional evidence for under-constrained variables into consideration. Based on an extensive empirical study of known divide-by-zero bugs, we no longer arbitrarily report a bug once the safety verification fails. Instead, we actively look for affirmative evidences, namely source evidence and bound evidence, that imply a high possibility of the bug to be triggerable at runtime. When applying our tool Wit to the real-world software such as the Linux kernel, we have found 72 new divide-by-zero bugs with a low false positive rate of 22%.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510066","Innovation and Technology Commission(grant numbers:RGC16206517,ITS/440/18FP,PRP/004/21FX); Ant Group; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794017","Static program analysis;bug detection;divide-by-zero","Runtime;Linux;Computer bugs;Semantics;Static analysis;Programming;Software","","3","","32","","20 Jun 2022","","","IEEE","IEEE Conferences"
"RPG: Rust Library Fuzzing with Pool-based Fuzz Target Generation and Generic Support","Z. Xu; B. Wu; C. Wen; B. Zhang; S. Qin; M. He","CSSE, Shenzhen University, Shenzhen, China; CSSE, Shenzhen University, Shenzhen, China; Guangzhou Institute of Technology, Xidian University, Guangzhou, China; CSSE, Shenzhen University, Shenzhen, China; Fermat Labs, Huawei, Hong Kong, China; Fermat Labs, Huawei, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1521","1533","Rust libraries are ubiquitous in Rust-based software development. Guaranteeing their correctness and reliability requires thorough analysis and testing. Fuzzing is a popular bug-finding solution, yet it requires writing fuzz targets for libraries. Recently, some automatic fuzz target generation methods have been proposed. However, two challenges remain: (1) how to generate diverse API sequences that prioritize unsafe code and interactions to reveal bugs in Rust libraries; (2) how to provide support for the generic APIs and verify both syntactic and semantic validity of the fuzz targets to enable more comprehensive testing of Rust libraries. In this paper, we propose RPG, an automatic fuzz target synthesis technique to support Rust library fuzzing. RPG uses a pool-based search to generate diverse and unsafe API sequences, and synthesizes fuzz targets with generic support and validity check. The experimental results demonstrate that RPG enhances both the quality of the generated fuzz targets and the bug-finding ability through pool-based generation and generic support, substantially outperforming the state-of-the-art. Moreover, RPG has discovered 25 previously unknown bugs from 50 well-known Rust libraries available on Crates.io.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639102","China Postdoctoral Science Foundation(grant numbers:2023M723736); CCF-Huawei Populus Grove Fund(grant numbers:CCF-HuaweiFM202205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548184","Rust;Fuzzing;Library Testing;Fuzz Target Generation","Computer bugs;Semantics;Fuzzing;Writing;Syntactics;Libraries;Software reliability","","1","","55","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Inference and Test Generation Using Program Invariants in Chemical Reaction Networks","M. C. Gerten; A. L. Marsh; J. I. Lathrop; M. B. Cohen; A. S. Miner; T. H. Klinge","Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1193","1205","Chemical reaction networks (CRNs) are an emerging distributed computational paradigm where programs are encoded as a set of abstract chemical reactions. CRNs can be compiled into DNA strands which perform the computations in vitro, creating a foundation for intelligent nanodevices. Recent research proposed a software testing framework for stochastic CRN programs in simulation, however, it relies on existing program specifications. In practice, specifications are often lacking and when they do exist, transforming them into test cases is time-intensive and can be error prone. In this work, we propose an inference technique called ChemFlow which extracts 3 types of invariants from an existing CRN model. The extracted invariants can then be used for test generation or model validation against program implementations. We applied ChemFlow to 13 CRN programs ranging from toy examples to real biological models with hundreds of reactions. We find that the invariants provide strong fault detection and often exhibit less flakiness than specification derived tests. In the biological models we showed invariants to developers and they confirmed that some of these point to parts of the model that are biologically incorrect or incomplete suggesting we may be able to use ChemFlow to improve model quality.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510176","NSF(grant numbers:CCF #1909688,FET #1900716); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794130","chemical reaction networks;test generation;invariants;Petri nets","Software testing;Biological system modeling;Toy manufacturing industry;Stochastic processes;Chemical reactions;Nanoscale devices;Test pattern generators","","1","","58","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"FADATest: Fast and Adaptive Performance Regression Testing of Dynamic Binary Translation Systems","J. Wu; J. Dong; R. Fang; W. Zhang; W. Wang; D. Zuo","Harbin Institute of Technology, China; Harbin Institute of Technology, China; University of Georgia, USA; University of Georgia, USA; University of Georgia, USA; Harbin Institute of Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","896","908","Dynamic binary translation (DBT) is the cornerstone of many im-portant applications. In practice, however, it is quite difficult to maintain the performance efficiency of a DBT system due to its inherent complexity. Although performance regression testing is an effective approach to detect potential performance regression issues, it is not easy to apply performance regression testing to DBT sys-tems, because of the natural differences between DBT systems and common software systems and the limited availability of effective test programs. In this paper, we present FADATest, which devises several novel techniques to address these challenges. Specifically, FADATest automatically generates adaptable test programs from existing real benchmark programs of DBT systems according to the runtime characteristics of the benchmarks. The test programs can then be used to achieve highly efficient and adaptive performance regression testing of DBT systems. We have implemented a proto-type of FADATest. Experimental results show that FADATest can successfully uncover the same performance regression issues across the evaluated versions of two popular DBT systems, QEMU and Valgrind, as the original benchmark programs. Moreover, the testing efficiency is improved significantly on two different hardware platforms powered by x86-64 and AArch64, respectively.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510169","University of Georgia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793905","Performance regression testing;DBT;Test program generation","Adaptive systems;Runtime;Codes;Prototypes;Benchmark testing;Software systems;Hardware","","","","42","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Translation Validation for JIT Compiler in the V8 JavaScript Engine","S. Kwon; J. Kwon; W. Kang; J. Lee; K. Heo","KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; KAIST, Daejeon, Korea; Amazon, Austin, Texas, USA; KAIST, Daejeon, Korea",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2195","2206","We present TURBOTV, a translation validator for the JavaScript (JS) just-in-time (JIT) compiler of V8. WhileJS engines have become a crucial part of various software systems, their emerging adaption of JIT compilation makes it increasingly challenging to ensure their correctness. We tackle this problem with an SMT-based translation validation (TV) that checks whether a specific compilation is semantically correct. We formally define the semantics of IR of Turbofan (jit compiler of V8) as SMT encoding. For efficient validation, we design a staged strategy for JS JIT compilers. This allows us to decompose the whole correctness checking into simpler ones. Furthermore, we utilize fuzzing to achieve practical TV. We generate a large number of JS functions using a fuzzer to trigger various optimization passes of Turbofan and validate their compilation using TURBOTV. Lastly, we demonstrate that TURBOTV can also be used for cross-language TV. We show that TURBOTV can validate the translation chain from LLVM IR to Turbofan Ir, collaborating with an off-the-shelf TV tool for LLVM. We evaluated Turbotv on various sets of JS and LLVM programs. Turbotv effectively validated a large number of compilations of Turbofan with a low false positive rate and discovered a new miscompilation in LLVM.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639189","National Research Foundation of Korea (NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548576","Translation Validation;Javascript Engine;JIT Compiler;IR;Fuzzing","TV;Semantics;Fuzzing;Software systems;Encoding;Engines;Optimization","","","","39","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Towards Finding Accounting Errors in Smart Contracts","B. Zhang","Purdue University West Lafayette, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1697","1709","Bugs in smart contracts may have devastating effects as they tend to cause financial loss. According to a recent study, accounting bugs are the most common kind of bugs in smart contracts that are beyond automated tools during pre-deployment auditing. The reason lies in that these bugs are usually in the core business logic and hence contract-specific. They are analogous to functional bugs in traditional software, which are largely beyond automated bug finding tools whose effectiveness hinges on uniform and machine checkable characteristics of bugs. It was also reported that accounting bugs are the second-most difficult to find through manual auditing, due to the need of understanding underlying business models. We observe that a large part of business logic in smart contracts can be modeled by a few primitive operations like those in a bank, such as deposit, withdraw, loan, and pay-off, or by their combinations. The properties of these operations can be clearly defined and checked by an abstract type system that models high-order information such as token units, scaling factors, and financial types. We hence develop a novel type propagation and checking system with the aim of identifying accounting bugs. Our evaluation on a large set of 57 existing accounting bugs in 29 real-world projects shows that 58% of the accounting bugs are type errors. Our system catches 87.9% of these type errors. In addition, applying our technique to auditing a large project in a very recent auditing contest has yielded the identification of 6 zero-day accounting bugs with 4 leading to direct fund loss","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549285","Blockchain;Smart Contract;Accounting Error;Type Checking","Computer bugs;Smart contracts;Manuals;Fasteners;Software;Logic;Business","","","","79","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Compiler-Directed Migrating API Callsite of Client Code","H. Zhong; N. Meng","Shanghai Jiao Tong University, China; Virginia Polytechnic Institute and State University, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2796","2807","API developers evolve software libraries to fix bugs, add new features, or refactor code, but the evolution can introduce API-breaking changes (e.g., API renaming). To benefit from such evolution, the programmers of client projects have to repetitively upgrade the callsites of libraries, since API-breaking changes introduce many compilation errors. It is tedious and error-prone to resolve such errors, especially when programmers are often unfamiliar with the API usages of newer versions. To migrate client code, the prior approaches either mine API mappings or learn edit scripts, but both the research lines have inherent limitations. For example, mappings alone cannot handle complex cases, and there is no sufficient source (e.g., migration commits) for learning edit scripts. In this paper, we propose a new research direction. When a library is replaced with a newer version, each type of API-breaking change introduces a type of compilation error. For example, renaming the name of an API method causes undefined-method errors at its callsites. Based on this observation, we propose to resolve errors that are introduced by migration, according to their locations and types that are reported by compilers. In this way, a migration tool can incrementally migrate complex cases, even without any change examples. Towards this direction, we propose the first approach, called Libcatch. It defines 14 migration operators, and in a compiler-directed way, it exploits the combinations of migration operators to generate migration solutions, until its predefined criteria are satisfied. We conducted two evaluations. In the first evaluation, we use Libcatch to handle 123 migration tasks. Libcatch reduced migration-related compilation errors for 92.7% of tasks, and eliminated such errors for 32.4% of tasks. We inspect the tasks whose errors are eliminated, and find that 33.9% of them produce identical edits to manual migration edits. In the second evaluation, we use two tools and Libcatch to migrate 15 real client projects in the wild. Libcatch resolved all compilation errors of 7 projects, and reduced the compilation errors of 6 other projects to no more than two errors. As a comparison, the compared two tools reduced the compilation errors of only 1 project.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548302","Code migration;Compiler;API library","Codes;Software libraries;Computer bugs;Task analysis","","","","81","","14 Jun 2024","","","IEEE","IEEE Conferences"
"An Empirical Study of Data Disruption by Ransomware Attacks","Y. Hou; L. Guo; C. Zhou; Y. Xu; Z. Yin; S. Li; C. Sun; Y. Jiang","BNRist, Tsinghua University, Beijing, China; BNRist, Tsinghua University, Beijing, China; BNRist, Tsinghua University, Beijing, China; BNRist, Tsinghua University, Beijing, China; BNRist, Tsinghua University, Beijing, China; National University of Defense Technology, Changsha, China; Waterloo University, Waterloo, Canada; BNRist, Tsinghua University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1984","1995","The threat of ransomware to the software ecosystem has become increasingly alarming in recent years, raising a demand for large-scale and comprehensive ransomware analysis to help develop more effective countermeasures against unknown attacks. In this paper, we first collect a real-world dataset Maraudermap, consisting of 7,796 active ransomware samples, and analyze their behaviors of disrupting data in victim systems. All samples are executed in iso-lated testbeds to collect all perspectives of six categories of runtime behaviors, such as API calls, I/O accesses, and network traffic. The total logs volume is up to 1.98 TiB. By assessing collected behaviors, we present six critical findings throughout ransomware attacks' data reconnaissance, data tampering, and data exfiltration phases. Based on our findings, we propose three corresponding mitigation strategies to detect ransomware during each phase. Experimental results show that they can enhance the capability of state-of-the-art anti-ransomware tools. We report a preliminary result of a 41%-69% increase in detection rate with no additional false positives, showing that our insights are helpful.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639090","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548284","Ransomware;Data Disruption;Runtime Behaviors;Mitigation Strate-gies;Empirical Study","Runtime;Ecosystems;Telecommunication traffic;Reconnaissance;Software;Ransomware","","","","56","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated oracle creation support, or: How I learned to stop worrying about fault propagation and love mutation testing","M. Staats; G. Gay; M. P. E. Heimdahl","Division of Web Science & Technology, Korea Advanced Institute of Science & Technology; Department of Computer Science and Engineering, University of Minnesota; University of Minnesota, Minneapolis, MN, US",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","870","880","In testing, the test oracle is the artifact that determines whether an application under test executes correctly. The choice of test oracle can significantly impact the effectiveness of the testing process. However, despite the prevalence of tools that support the selection of test inputs, little work exists for supporting oracle creation. In this work, we propose a method of supporting test oracle creation. This method automatically selects the oracle data — the set of variables monitored during testing — for expected value test oracles. This approach is based on the use of mutation analysis to rank variables in terms of fault-finding effectiveness, thus automating the selection of the oracle data. Experiments over four industrial examples demonstrate that our method may be a cost-effective approach for producing small, effective oracle data, with fault finding improvements over current industrial best practice of up to 145.8% observed.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227132","testing;test oracles;oracle data;oracle selection;verification","Testing;Training;Monitoring;Aerospace electronics;Greedy algorithms;Software systems","","33","","32","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Semantic-Enhanced Static Vulnerability Detection in Baseband Firmware","Y. Liu; C. Zhang; F. Li; Y. Li; J. Zhou; J. Wang; L. Zhan; Y. Liu; W. Huo","Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Nanyang Technological University, Singapore; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China; Institute of Information Engineering, CAS; School of Cyber Security, UCAS, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2135","2146","Cellular network is the infrastructure of mobile communication. Baseband firmware, which carries the implementation of cellular network, has critical security impact on its vulnerabilities. To handle the inherent complexity in cellular communication, cellular protocols are usually implemented as message-centric systems, containing the common message processing phase and message specific handling phase. Though the latter takes most of the code (99.67%) and exposed vulnerabilities (74%), it is rather under-studied: existing detectors either cannot sufficiently analyze it or focused on analyzing the former phase. To fill this gap, we proposed a novel semantic-enhanced static vulnerability detector named BVFinder focusing on message specific phase vulnerability detection. Generally, it identifies a vulnerability by locating whether a predefined sensitive memory operation is tainted by any attacker-controllable input. Specifically, to reach high automation and preciseness, it made two key improvements: a semantic-based taint source identification and an enhanced taint propagation. The former employs semantic search techniques to identify registers and memory offsets that carry attacker-controllable inputs. This is achieved by matching the inputs to their corresponding message and data types using textual features and addressing patterns within the assemblies. On the other hand, the latter technology guarantees effective taint propagation by employing additional indirect call resolution algorithms. The evaluation shows that BVFinder outperforms the state-of-the-art detectors by detecting three to four times of amount of vulnerabilities in the dataset. Till now, BVFinder has found four zero-day vulnerabilities, with four CVEs and 12,410 USD bounty assigned. These vulnerabilities can potentially cause remote code execution to phones using Samsung shannon baseband, affecting hundreds of millions of end devices.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548256","Cellular Baseband;Static Taint Analysis;Vulnerabilities","Cellular networks;Codes;Baseband;Automation;Semantic search;Detectors;Registers","","","","51","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Extending static analysis by mining project-specific rules","B. Sun; G. Shu; A. Podgurski; B. Robinson","EECS Department, Case Western Reserve University, Cleveland, OH, USA; EECS Department, Case Western Reserve University, Cleveland, OH, USA; EECS Department, Case Western Reserve University, Cleveland, OH, USA; ABB Corporate Research Center, Raleigh, NC, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1054","1063","Commercial static program analysis tools can be used to detect many defects that are common across applications. However, such tools currently have limited ability to reveal defects that are specific to individual projects, unless specialized checkers are devised and implemented by tool users. Developers do not typically exploit this capability. By contrast, defect mining tools developed by researchers can discover project-specific defects, but they require specialized expertise to employ and they may not be robust enough for general use. We present a hybrid approach in which a sophisticated dependence-based rule mining tool is used to discover project-specific programming rules, which are then transformed automatically into checkers that a commercial static analysis tool can run against a code base to reveal defects. We also present the results of an empirical study in which this approach was applied successfully to two large industrial code bases. Finally, we analyze the potential implications of this approach for software development practice.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227114","static program analysis;defect mining;program dependence graphs","Programming;XML;Generators;Engines;Data mining;Transforms;Software","","12","1","36","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"SAPIENTML: Synthesizing Machine Learning Pipelines by Learning from Human-Written Solutions","R. K. Saha; A. Ura; S. Mahajan; C. Zhu; L. Li; Y. Hu; H. Yoshida; S. Khurshid; M. R. Prasad","Fujitsu Research of America, Inc.; Fujitsu Ltd.; Fujitsu Research of America, Inc.; The University of Texas at Austin; University of Illinois at Urbana-Champaign; The University of Texas at Austin; Fujitsu Research of America, Inc.; The University of Texas at Austin; Fujitsu Research of America, Inc.",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1932","1944","Automatic machine learning, or AutoML, holds the promise of truly democratizing the use of machine learning (ML), by substantially automating the work of data scientists. However, the huge combinatorial search space of candidate pipelines means that current AutoML techniques, generate sub-optimal pipelines, or none at all, especially on large, complex datasets. In this work we propose an AutoML technique SapientML, that can learn from a corpus of existing datasets and their human-written pipelines, and efficiently generate a high-quality pipeline for a predictive task on a new dataset. To combat the search space explosion of AutoML, SapientML employs a novel divide-and-conquer strategy realized as a three-stage program synthesis approach, that reasons on successively smaller search spaces. The first stage uses meta-learning to predict a set of plausible ML components to constitute a pipeline. In the second stage, this is then refined into a small pool of viable concrete pipelines using a pipeline dataflow model derived from the corpus. Dynamically evaluating these few pipelines, in the third stage, provides the best solution. We instantiate SapientML as part of a fully automated tool-chain that creates a cleaned, labeled learning corpus by mining Kaggle, learns from it, and uses the learned models to then synthesize pipelines for new predictive tasks. We have created a training corpus of 1,094 pipelines spanning 170 datasets, and evaluated SapientML on a set of 41 benchmark datasets, including 10 new, large, real-world datasets from Kaggle, and against 3 state-of-the-art AutoML tools and 4 baselines. Our evaluation shows that SapientML produces the best or comparable accuracy on 27 of the benchmarks while the second best tool fails to even produce a pipeline on 9 of the instances. This difference is amplified on the 10 most challenging benchmarks, where SapientML wins on 9 instances with the other tools failing to produce pipelines on 4 or more benchmarks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794084","Program Synthesis;Machine Learning;AutoML;Program Analysis","Training;Pipelines;Machine learning;Benchmark testing;Predictive models;Explosions;Data mining","","1","","52","","20 Jun 2022","","","IEEE","IEEE Conferences"
"DeepSTL - From English Requirements to Signal Temporal Logic","J. He; E. Bartocci; D. Ničković; H. Isakovic; R. Grosu","Technische Universität Wien, Vienna, Austria; Technische Universität Wien, Vienna, Austria; AIT Austrian Institute of Technology, Vienna, Austria; Technische Universität Wien, Vienna, Austria; Technische Universität Wien, Vienna, Austria",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","610","622","Formal methods provide very powerful tools and techniques for the design and analysis of complex systems. Their practical application remains however limited, due to the widely accepted belief that formal methods require extensive expertise and a steep learning curve. Writing correct formal specifications in form of logical formulas is still considered to be a difficult and error prone task. In this paper we propose DeepSTL, a tool and technique for the translation of informal requirements, given as free English sentences, into Signal Temporal Logic (STL), a formal specification language for cyber-physical systems, used both by academia and advanced research labs in industry. A major challenge to devise such a translator is the lack of publicly available informal requirements and formal specifications. We propose a two-step workflow to address this challenge. We first design a grammar-based generation technique of synthetic data, where each output is a random STL formula and its associated set of possible English translations. In the second step, we use a state-of-the-art transformer-based neural translation technique, to train an accurate attentional translator of English to STL. The experimental results show high translation quality for patterns of English requirements that have been well trained, making this workflow promising to be extended for processing more complex translation tasks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794051","Requirements Engineering;Formal Specification;Signal Temporal Logic (STL);Machine Translation","Industries;Natural languages;Computer architecture;Writing;Cyber-physical systems;Transformers;Formal specifications","","8","","60","","20 Jun 2022","","","IEEE","IEEE Conferences"
"BEDIVFUZZ: Integrating Behavioral Diversity into Generator-based Fuzzing","H. L. Nguyen; L. Grunske","Humboldt-Universität zu Berlin, Germany; Humboldt-Universität zu Berlin, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","249","261","A popular metric to evaluate the performance of fuzzers is branch coverage. However, we argue that focusing solely on covering many different branches (i.e., the richness) is not sufficient since the majority of the covered branches may have been exercised only once, which does not inspire a high confidence in the reliability of the covered code. Instead, the distribution of the executed branches (i.e., the evenness) should also be considered. That is, behavioral diversity is only given if the generated inputs not only trigger many different branches, but also trigger them evenly often with diverse inputs. We introduce BEDIVFUZZ, a feedback-driven fuzzing technique for generator-based fuzzers. BEDIVFUZZ distinguishes between structure-preserving and structure-changing mutations in the space of syntactically valid inputs, and biases its mutation strategy towards validity and behavioral diversity based on the received program feedback. We have evaluated BEDIVFUZZ on Ant, Maven, Rhino, Closure, Nashorn, and Tomcat. The results show that BE-DIVFUZZ achieves better behavioral diversity than the state of the art, measured by established biodiversity metrics, namely the Hill numbers, from the field of ecology.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793964","Structure-aware fuzzing;behavioral diversity;random testing","Measurement;Codes;Focusing;Fuzzing;Ecology;Behavioral sciences;Reliability","","9","","54","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Muffin: Testing Deep Learning Libraries via Neural Architecture Fuzzing","J. Gu; X. Luo; Y. Zhou; X. Wang","Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Lab. of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1418","1430","Deep learning (DL) techniques are proven effective in many chal-lenging tasks, and become widely-adopted in practice. However, previous work has shown that DL libraries, the basis of building and executing DL models, contain bugs and can cause severe con-sequences. Unfortunately, existing testing approaches still cannot comprehensively exercise DL libraries. They utilize existing trained models and only detect bugs in model inference phase. In this work we propose Muffin to address these issues. To this end, Muffin applies a specifically-designed model fuzzing approach, which al-lows it to generate diverse DL models to explore the target library, instead of relying only on existing trained models. Muffin makes differential testing feasible in the model training phase by tailoring a set of metrics to measure the inconsistencies between different DL libraries. In this way, Muffin can best exercise the library code to detect more bugs. To evaluate the effectiveness of Muffin, we conduct experiments on three widely-used DL libraries. The results demonstrate that Muffin can detect 39 new bugs in the latest release versions of popular DL libraries, including Tensorflow, CNTK, and Theano.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510092","National Key R&D Program of China(grant numbers:2020YFA0711400); Natural Science Foundation of Shanghai(grant numbers:22ZR1407900); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793922","Deep Learning Testing;Library Testing;Model Generation;Fuzzing","Training;Deep learning;Phase measurement;Codes;Computer bugs;Fuzzing;Libraries","","9","","55","","20 Jun 2022","","","IEEE","IEEE Conferences"
"GraphFuzz: Library API Fuzzing with Lifetime-aware Dataflow Graphs","H. Green; T. Avgerinos","ForAllSecure, U.S.A.; ForAllSecure, U.S.A.",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1070","1081","We present the design and implementation of GraphFuzz, a new structure-, coverage- and object lifetime-aware fuzzer capable of automatically testing low-level Library APIs. Unlike other fuzzers, GraphFuzz models sequences of executed functions as a dataflow graph, thus enabling it to perform graph-based mutations both at the data and at the execution trace level. GraphFuzz comes with an automated specification generator to minimize the developer integration effort. We use GraphFuzz to analyze Skia-the rigorously tested Google Chrome graphics library-and benchmark GraphFuzz-generated fuzzing harnesses against hand-optimized, painstakingly written libFuzzer harnesses. We find that GraphFuzz generates test cases that achieve 2-3x more code coverage on average with minimal development effort, and also uncovered previous unknown defects in the process. We demonstrate GraphFuzz's applicability on low-level APIs by analyzing four additional open-source libraries and finding dozens of previously unknown defects. All security relevant findings have already been reported and fixed by the developers. Last, we open-source GraphFuzz under a permissive license and provide code to reproduce all results in this paper.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793910","fuzzing;graph;security;structure aware","Graphics;Codes;Fuzzing;Benchmark testing;Generators;Security","","5","","27","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Smart Contract and DeFi Security Tools: Do They Meet the Needs of Practitioners?","S. Chaliasos; M. A. Charalambous; L. Zhou; R. Galanopoulou; A. Gervais; D. Mitropoulos; B. Livshits","Imperial College London, United Kingdom; Imperial College London, United Kingdom; Imperial College London, United Kingdom; University College London, United Kingdom; National and Kapodistrian University of Athens, Greece; University College London, United Kingdom; Imperial College London, United Kingdom",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","716","728","The growth of the decentralized finance (DeFi) ecosystem built on blockchain technology and smart contracts has led to an increased demand for secure and reliable smart contract development. However, attacks targeting smart contracts are increasing, causing an estimated $6.45 billion in financial losses. Researchers have proposed various automated security tools to detect vulnerabilities, but their real-world impact remains uncertain. In this paper, we aim to shed light on the effectiveness of au-tomated security tools in identifying vulnerabilities that can lead to high-profile attacks, and their overall usage within the indus-try. Our comprehensive study encompasses an evaluation of five SoTA automated security tools, an analysis of 127 high-impact real-world attacks resulting in $2.3 billion in losses, and a survey of 49 developers and auditors working in leading DeFi protocols. Our findings reveal a stark reality: the tools could have prevented a mere 8% of the attacks in our dataset, amounting to $149 million out of the $2.3 billion in losses. Notably, all preventable attacks were related to reentrancy vulnerabilities. Furthermore, practition-ers distinguish logic-related bugs and protocol layer vulnerabilities as significant threats that are not adequately addressed by existing security tools. Our results emphasize the need to develop specialized tools catering to the distinct demands and expectations of developers and auditors. Further, our study highlights the necessity for continuous advancements in security tools to effectively tackle the ever-evolving challenges confronting the DeFi ecosystem.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548356","Blockchain;Security;Smart Contracts;Ethereum;Empirical Evaluation;Security Tools;Surveys","Surveys;Smart contracts;Computer bugs;Ecosystems;Finance;Decentralized applications;Blockchains","","3","","64","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"LogShrink: Effective Log Compression by Leveraging Commonality and Variability of Log Data","X. Li; H. Zhang; V. -H. Le; P. Chen","Sun Yat-sen University, Guangzhou, China; Chongqing University, Chongqing, China; The University of Newcastle, NSW, Australia; Sun Yat-sen University, Guangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","254","265","Log data is a crucial resource for recording system events and states during system execution. However, as systems grow in scale, log data generation has become increasingly explosive, leading to an expensive overhead on log storage, such as several petabytes per day in production. To address this issue, log compression has become a crucial task in reducing disk storage while allowing for further log analysis. Unfortunately, existing general-purpose and log-specific compression methods have been limited in their ability to utilize log data characteristics. To overcome these limitations, we conduct an empirical study and obtain three major observations on the characteristics of log data that can facilitate the log compression task. Based on these observations, we propose LogShrink, a novel and effective log compression method by leveraging commonality and variability of log data. An analyzer based on longest common subsequence and entropy techniques is proposed to iden-tify the latent commonality and variability in log messages. The key idea behind this is that the commonality and variability can be exploited to shrink log data with a shorter representation. Besides, a clustering-based sequence sampler is introduced to accelerate the commonality and variability analyzer. The extensive experimental results demonstrate that LogShrink can exceed baselines in compression ratio by 16% to 356% on average while preserving a reasonable compression speed.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608129","National Natural Science Foundation of China(grant numbers:62272495); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548753","Log Compression;Data Compression;Log Analysis;Clustering","Computer languages;Costs;Production;C++ languages;Compressors;Explosives;Entropy","","3","","62","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Concrat: An Automatic C-to-Rust Lock API Translator for Concurrent Programs","J. Hong; S. Ryu","School of Computing KAIST, Daejeon, South Korea; School of Computing KAIST, Daejeon, South Korea",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","716","728","Concurrent programs suffer from data races. To prevent data races, programmers use locks. However, programs can eliminate data races only when they acquire and release correct locks at correct timing. The lock API of C, in which people have developed a large portion of legacy system programs, does not validate the correct use of locks. On the other hand, Rust, a recently developed system programming language, provides a lock API that guarantees the correct use of locks via type checking. This makes rewriting legacy system programs in Rust a promising way to retrofit safety into them. Unfortunately, manual C-to-Rust translation is extremely laborious due to the discrepancies between their lock APIs. Even the state-of-the-art automatic C-to-Rust translator retains the C lock API, expecting developers to replace them with the Rust lock API. In this work, we propose an automatic tool to replace the C lock API with the Rust lock API. It facilitates C-to-Rust translation of concurrent programs with less human effort than the current practice. Our tool consists of a Rust code transformer that takes a lock summary as an input and a static analyzer that efficiently generates precise lock summaries. We show that the transformer is scalable and widely applicable while preserving the semantics; it transforms 66 KLOC in 2.6 seconds and successfully handles 74% of real-world programs. We also show that the analyzer is scalable and precise; it analyzes 66 KLOC in 4.3 seconds.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00069","National Research Foundation of Korea(grant numbers:2022R1A2C200366011,2021R1A5A1021944); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172746","","Concurrent computing;Semantics;Transforms;Manuals;Programming;Aging;Transformers","","2","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"FlashSyn: Flash Loan Attack Synthesis via Counter Example Driven Approximation","Z. Chen; S. M. Beillahi; F. Long","University of Toronto, Toronto, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1749","1761","In decentralized finance (DeFi), lenders can offer flash loans to bor-rowers, i.e., loans that are only valid within a blockchain transaction and must be repaid with fees by the end of that transaction. Unlike normal loans, flash loans allow borrowers to borrow large assets without upfront collaterals deposits. Malicious adversaries use flash loans to gather large assets to exploit vulnerable DeFi protocols. In this paper, we introduce a new framework for automated syn-thesis of adversarial transactions that exploit DeFi protocols using flash loans. To bypass the complexity of a DeFi protocol, we propose a new technique to approximate the DeFi protocol functional behaviors using numerical methods (polynomial approximation and nearest-neighbor interpolation). We then construct an optimization query using the approximated functions of the DeFi protocol to find an adversarial attack constituted of a sequence of functions invocations with optimal parameters that gives the maximum profit. To improve the accuracy of the approximation, we propose a novel counterexample driven approximation refinement technique. We implement our framework in a tool named FlashSyn. We evaluate FlashSyn on 16 DeFi protocols that were victims to flash loan attacks and 2 DeFi protocols from Damn Vulnerable DeFi challenges. FlashSyn automatically synthesizes an adversarial attack for 16 of the 18 benchmarks, demonstrating its effectiveness in finding possible flash loan attacks.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548683","program synthesis;program analysis;blockchain;smart contracts;vulnerability detection;flash loan","Interpolation;Protocols;Smart contracts;Finance;Decentralized applications;Vectors;Polynomials","","2","","83","","14 Jun 2024","","","IEEE","IEEE Conferences"
"FuzzSlice: Pruning False Positives in Static Analysis Warnings Through Function-Level Fuzzing","A. Murali; N. S. Mathews; M. Alfadel; M. Nagappan; M. Xu","University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada; University of Waterloo, Waterloo, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","778","790","Manual confirmation of static analysis reports is a daunting task. This is due to both the large number of warnings and the high density of false positives among them. Fuzzing techniques have been proposed to verify static analysis warnings. However, a major limitation is that fuzzing the whole project to reach all static analysis warnings is not feasible. This can take several days and exponential machine time to increase code coverage linearly. Therefore, we propose Fuzzslice, a novel framework that au-tomatically prunes possible false positives among static analysis warnings. Unlike prior work that mostly focuses on confirming true positives among static analysis warnings, which inevitably requires end-to-end fuzzing, Fuzzslice focuses on ruling out potential false positives, which are the majority in static analysis reports. The key insight that we base our work on is that a warning that does not yield a crash when fuzzed at the function level in a given time budget is a possible false positive. To achieve this, Fuzzslice first aims to generate compilable code slices at the function level. Then, Fuzzslice fuzzes these code slices instead of the entire binary to prune possible false positives. Fuzzslice is also unlikely to misclassify a true bug as a false positive because the crashing input can be reproduced by a fuzzer at the function level as well. We evaluate Fuzzslice on the Juliet synthetic dataset and real-world complex C projects: openssl, tmux and openssh-portable. Our evaluation shows that the ground truth in the Juliet dataset had 864 false positives which were all detected by Fuzzslice. For the open-source repositories, we were able to get the developers from two of these open-source repositories to independently label these warnings. Fuzzslice automatically identifies 33 out of 53 false positives confirmed by developers in these two repositories. This implies that Fuzzslice can reduce the number of false positives by 62.26% in the open-source repositories and by 100% in the Juliet dataset.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548082","Fuzzing;Static analysis warning;vulnerability","Codes;Computer bugs;Static analysis;Manuals;Fuzzing;Task analysis;Synthetic data","","1","","56","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries","Y. Deng; C. S. Xia; C. Yang; S. D. Zhang; S. Yang; L. Zhang","University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","841","853","Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TITANFUZZ work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries (and beyond). However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive pretraining corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced. To fill this gap, this paper proposes FuzzGPT, the first approach to priming LLMs to synthesize unusual programs for fuzzing. Fuz-zGPT is mainly built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/ semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and Codegen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruction-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TITANFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623343","NSF(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548124","","Deep learning;Image edge detection;Computer bugs;Semantics;Fuzzing;Chatbots;Libraries","","1","","87","","14 Jun 2024","","","IEEE","IEEE Conferences"
"EDEFuzz: A Web API Fuzzer for Excessive Data Exposures","L. Pan; S. Cohney; T. Murray; V. -T. Pham","The University of Melbourne, Melbourne, Australia; The University of Melbourne, Melbourne, Australia; The University of Melbourne, Melbourne, Australia; The University of Melbourne, Melbourne, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","530","541","APIs often transmit far more data to client applications than they need, and in the context of web applications, often do so over public channels. This issue, termed Excessive Data Exposure (EDE), was OWASP's third most significant API vulnerability of 2019. However, there are few automated tools-either in research or industry-to effectively find and remediate such issues. This is unsurprising as the problem lacks an explicit test oracle: the vulnerability does not manifest through explicit abnormal behaviours (e.g., program crashes or memory access violations). In this work, we develop a metamorphic relation to tackle that challenge and build the first fuzzing tool-that we call EDEFUZZ-to systematically detect EDEs. EDEFuzz can significantly reduce false negatives that occur during manual inspection and ad-hoc text-matching techniques, the current most-used approaches. We tested EDEFuzz against the sixty-nine applicable targets from the Alexa Top-200 and found 33,365 potential leaks-illustrating our tool's broad applicability and scalability. In a more-tightly controlled experiment of eight popular websites in Australia, EDEFuzz achieved a high true positive rate of 98.65% with minimal configuration, illustrating our tool's accuracy and efficiency.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3608133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549670","","Accuracy;Virtual assistants;Scalability;Manuals;Inspection;Fuzzing;Computer crashes","","1","","39","","14 Jun 2024","","","IEEE","IEEE Conferences"
"An Empirical Study on Oculus Virtual Reality Applications: Security and Privacy Perspectives","H. Guo; H. -N. Dai; X. Luo; Z. Zheng; G. Xu; F. He","Hong Kong Baptist University, Hong Kong, China; Hong Kong Baptist University, Hong Kong, China; The Hong Kong Polytechnic University, Hong Kong, China; Sun Yat-sen University, Zhuhai, China; Hong Kong Baptist University, Hong Kong, China; Hong Kong Baptist University, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1958","1970","Although Virtual Reality (VR) has accelerated its prevalent adoption in emerging metaverse applications, it is not a fundamentally new technology. On one hand, most VR operating systems (OS) are based on off-the-shelf mobile OS (e.g., Android). As a result, VR apps also inherit privacy and security deficiencies from conventional mobile apps. On the other hand, in contrast to conventional mobile apps, VR apps can achieve immersive experience via diverse VR devices, such as head-mounted displays, body sensors, and controllers though achieving this requires the extensive collection of privacy-sensitive human biometrics (e.g., hand-tracking and face-tracking data). Moreover, VR apps have been typically implemented by 3D gaming engines (e.g., Unity), which also contain intrinsic security vulnerabilities. Inappropriate use of these technologies may incur privacy leaks and security vulnerabilities although these issues have not received significant attention compared to the proliferation of diverse VR apps. In this paper, we develop a security and privacy assessment tool, namely the VR-SP detector for VR apps. The VR-SP detector has integrated program static analysis tools and privacy-policy analysis methods. Using the VR-SP detector, we conduct a comprehensive empirical study on 500 popular VR apps. We obtain the original apps from the popular Oculus and SideQuest app stores and extract APK files via the Meta Oculus Quest 2 device. We evaluate security vulnerabilities and privacy data leaks of these VR apps by VR app analysis, taint analysis, and privacy-policy analysis. We find that a number of security vulnera-bilities and privacy leaks widely exist in VR apps. Moreover, our results also reveal conflicting representations in the privacy policies of these apps and inconsistencies of the actual data collection with the privacy-policy statements of the apps. Based on these findings, we make suggestions for the future development of VR apps.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639082","National Natural Science Foundation of China(grant numbers:62032025); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548719","Virtual Reality;Metaverse;Static Analysis;Security and Privacy","Privacy;Data privacy;Three-dimensional displays;Metaverse;Operating systems;Detectors;Static analysis","","","","64","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Revealing Hidden Threats: An Empirical Study of Library Misuse in Smart Contracts","M. Huang; J. Chen; Z. Jiang; Z. Zheng","Sun Yat-Sen University, China; Sun Yat-Sen University, China; Sun Yat-Sen University, China; Sun Yat-Sen University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","291","302","Smart contracts are Turing-complete programs that execute on the blockchain. Developers can implement complex contracts, such as auctions and lending, on Ethereum using the Solidity programming language. As an object-oriented language, Solidity provides libraries within its syntax to facilitate code reusability and reduce development complexity. Library misuse refers to the incorrect writing or usage of libraries, resulting in unexpected results, such as introducing vulnerabilities during library development or incorporating an unsafe library during contract development. Library misuse could lead to contract defects that cause financial losses. Currently, there is a lack of research on library misuse. To fill this gap, we collected more than 500 audit reports from the official websites of five audit companies and 223,336 real-world smart contracts from Etherscan to measure library popularity and library misuse. Then, we defined eight general patterns for library misuse; three of them occurring during library development and five during library utilization, which covers the entire library lifecycle. To validate the practicality of these patterns, we manually analyzed 1,018 realworld smart contracts and publicized our dataset. We identified 905 misuse cases across 456 contracts, indicating that library misuse is a widespread issue. Three patterns of misuse are found in more than 50 contracts, primarily due to developers lacking security awareness or underestimating negative impacts. Additionally, our research revealed that vulnerable libraries on Ethereum continue to be employed even after they have been deprecated or patched. Our findings can assist contract developers in preventing library misuse and ensuring the safe use of libraries.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623335","National Key R&D Program of China(grant numbers:2022YFB2702203); National Natural Science Foundation of China(grant numbers:62032025,62002393); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549634","Blockchain;Ethereum;Library Misuse;Empirical Study","Computer languages;Current measurement;Smart contracts;Companies;Writing;Syntactics;Libraries","","","","73","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Safe Low-Level Code Without Overhead is Practical","S. Pirelli; G. Candea",EPFL; EPFL,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2173","2184","Developers write low-level systems code in unsafe programming languages due to performance concerns. The lack of safety causes bugs and vulnerabilities that safe languages avoid. We argue that safety without run-time overhead is possible through type invariants that prove the safety of potentially unsafe operations. We empirically show that Rust and C# can be extended with such features to implement safe network device drivers without run-time overhead, and that Ada has these features already.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172739","programming languages;safety;performance","Performance evaluation;Computer languages;Codes;Computer bugs;Programming;Safety;C# languages","","","","46","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"ReClues: Representing and Indexing Failures in Parallel Debugging with Program Variables","Y. Song; X. Zhang; X. Xie; Q. Liu; R. Gao; C. Xing","School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; Sonos Inc., Santa Barbara, USA; School of Computer Science, Wuhan University, Wuhan, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1359","1371","Failures with different root causes can greatly disrupt multi-fault localization, therefore, categorizing failures into distinct groups according to the culprit fault is highly important. In such a failure indexing task, the crux lies in the failure proximity, which comprises two points, i.e., how to effectively represent failures (e.g., extract the signature of failures) and how to properly measure the distance between those proxies for failures. Existing research has proposed a variety of failure proximities. The majority of them extract signatures of failures from execution coverage or suspiciousness ranking lists, and accordingly employ the Euclid or the Kendall tau distances, etc. However, such strategies may not properly reflect the essential characteristics of failures, thus resulting in unsatisfactory effectiveness. In this paper, we propose a new failure proximity, namely, the program variable-based failure proximity, and further present a novel failure indexing approach, ReClues. Specifically, ReClues utilizes the run-time values of program variables to represent failures, and designs a set of rules to measure the similarity between them. Experimental results demonstrate the competitiveness of ReClues: it can achieve 44.12% and 27.59% improvements in faults number estimation, as well as 47.56% and 26.27% improvements in clustering effectiveness, compared with the state-of-the-art technique in this field, in simulated and real-world environments, respectively.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639098","National Natural Science Foundation of China(grant numbers:62250610224,61972289,61832009); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549232","Failure proximity;Clustering;Failure indexing;Parallel debugging;Program variable","Measurement;Location awareness;Deep learning;Estimation;Debugging;Fingerprint recognition;Benchmark testing","","","","87","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Hard to Read and Understand Pythonic Idioms? Deldiom and Explain Them in Non-Idiomatic Equivalent Code","Z. Zhang; Z. Xing; D. Zhao; Q. Lu; X. Xu; L. Zhu","Australian National University & CSIRO's Data61, Canberra, Australia; CSIRO's Data61 & Australian, National University, Canberra, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia; CSIRO's Data61, Sydney, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2808","2819","The Python community strives to design pythonic idioms so that Python users can achieve their intent in a more concise and efficient way. According to our analysis of 154 questions about challenges of understanding pythonic idioms on Stack Overflow, we find that Python users face various challenges in comprehending pythonic idioms. And the usage of pythonic idioms in 7,577 GitHub projects reveals the prevalence of pythonic idioms. By using a statistical sampling method, we find pythonic idioms result in not only lexical conciseness but also the creation of variables and functions, which indicates it is not straightforward to map back to non-idiomatic code. And usage of pythonic idioms may even cause potential negative effects such as code redundancy, bugs and performance degradation. To alleviate such readability issues and negative effects, we develop a transforming tool, DeIdiom, to automatically transform idiomatic code into equivalent non-idiomatic code. We test and review over 7,572 idiomatic code instances of nine pythonic idioms (list/set/diet-comprehension, chain-comparison, truth-value-test, loop-else, assign-multi-targets, for-multi-targets, star), the result shows the high accuracy of DeIdiom. Our user study with 20 partici-pants demonstrates that explanatory non-idiomatic code generated by DeIdiom is useful for Python users to understand pythonic idioms correctly and efficiently, and leads to a more positive appre-ciation of pythonic idioms.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549697","Pythonic Idioms;Code Transformation;Program Comprehension","Codes;Reviews;Redundancy;Stars;Transforms;Sampling methods;Faces","","","","52","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"DrAsync: Identifying and Visualizing Anti-Patterns in Asynchronous JavaScript","A. Turcotte; M. D. Shah; M. W. Aldrich; F. Tip","Northeastern University, Boston, MA, USA; Northeastern University, Boston, MA, USA; Tufts University, Medford, MA, USA; Northeastern University, Boston, MA, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","774","785","Promises and async/await have become popular mechanisms for implementing asynchronous computations in JavaScript, but despite their popularity, programmers have difficulty using them. This paper identifies 8 anti-patterns in promise-based JavaScript code that are prevalent across popular JavaScript repositories. We present a light-weight static analysis for automatically detecting these anti-patterns. This analysis is embedded in an interactive visualization tool that additionally relies on dynamic analysis to visualize promise lifetimes and instances of anti-patterns executed at run time. By enabling the user to navigate between promises in the visualization and the source code fragments that they originate from, problems and optimization opportunities can be identified. We implement this approach in a tool called DrAsync, and found 2.6K static instances of anti-patterns in 20 popular JavaScript repositories. Upon examination of a subset of these, we found that the majority of problematic code reported by DrAsync could be eliminated through refactoring. Further investigation revealed that, in a few cases, the elimination of anti-patterns reduced the time needed to execute the refactored code fragments. Moreover, DrAsync's visualization of promise lifetimes and relationships provides additional insight into the execution behavior of asynchronous programs and helped identify further optimization opportunities.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510097","National Science Foundation(grant numbers:CCF-1715153,CCF-1930604,CCF-1907727); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793912","JavaScript;asynchronous programming;program analysis;visualization","Visualization;Codes;Navigation;Static analysis;Performance analysis;Behavioral sciences;Optimization","","","","32","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Block-based Programming for Two-Armed Robots: A Comparative Study","F. Fronchetti; N. Ritschel; L. Schorr; C. Barfield; G. Chang; R. Spinola; R. Holmes; D. C. Shepherd","Virginia Commonwealth University, Richmond, Virginia, USA; University of British Columbia, Vancouver, British Columbia, Canada; Virginia Commonwealth University, Richmond, Virginia, USA; Virginia Commonwealth University, Richmond, Virginia, USA; Virginia Commonwealth University, Richmond, Virginia, USA; Virginia Commonwealth University, Richmond, Virginia, USA; University of British Columbia, Vancouver, British Columbia, Canada; Louisiana State University, Baton Rouge, Louisiana, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","505","516","Programming industrial robots is difficult and expensive. Although recent work has made substantial progress in making it accessible to a wider range of users, it is often limited to simple programs and its usability remains untested in practice. In this article, we introduce Duplo, a block-based programming environment that allows end-users to program two-armed robots and solve tasks that require coordination. Duplo positions the program for each arm side-by-side, using the spatial relationship between blocks from each program to represent parallelism in a way that end-users can easily understand. This design was proposed by previous work, but not implemented or evaluated in a realistic programming setting. We performed a randomized experiment with 52 participants that evaluated Duplo on a complex programming task that contained several sub-tasks. We compared Duplo with RobotStudio Online YuMi, a commercial solution, and found that Duplo allowed participants to solve the same task faster and with greater success. By analyzing the information collected during our user study, we further identified factors that explain this performance difference, as well as remaining barriers, such as debugging issues and difficulties in interacting with the robot. This work represents another step towards allowing a wider audience of non-professionals to program, which might enable the broader deployment of robotics.","1558-1225","979-8-4007-0217-4","","NSF(grant numbers:2024561); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548642","two-armed;robots;end-users;block-based;programming","Visualization;Robot kinematics;Parallel processing;Manipulators;Industrial robots;Task analysis;Usability","","","","49","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Verifying Declarative Smart Contracts","H. Chen; L. Lu; B. Massey; Y. Wang; B. T. Loo","ShanghaiTech University, Shanghai, China; University of Pennsylvania, Philadelphia, PA, USA; University of Pennsylvania, Philadelphia, PA, USA; Simon Fraser University, Burnaby, BC, Canada; University of Pennsylvania, Philadelphia, PA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2207","2218","Smart contracts manage a large number of digital assets nowa-days. Bugs in these contracts have led to significant financial loss. Verifying the correctness of smart contracts is, therefore, an important task. This paper presents an automated safety verification tool, DCV, that targets declarative smart contracts written in De-Con, a logic-based domain-specific language for smart contract implementation and specification. DCV proves safety properties by mathematical induction and can automatically infer inductive invariants using heuristic patterns, without annotations from the developer. Our evaluation on 23 benchmark contracts shows that DCV is effective in verifying smart contracts adapted from public repositories, and can verify contracts not supported by other tools. Furthermore, DCV significantly outperforms baseline tools in verification time.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639203","NSF(grant numbers:CNS-2104882,CNS-2107147); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548754","Smart contracts;declarative programming;formal verification","Smart contracts;Semantics;Manuals;Benchmark testing;Mathematical models;Safety;Logic","","","","47","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"CoCoSoDa: Effective Contrastive Learning for Code Search","E. Shi; Y. Wang; W. Gu; L. Du; H. Zhang; S. Han; D. Zhang; H. Sun","Xi'an Jiaotong University; School of Software Engineering, Sun Yat-sen University; The Chinese University of Hong Kong; Microsoft Research; Chongqing University; Microsoft Research; Microsoft Research; Xi'an Jiaotong University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2198","2210","Code search aims to retrieve semantically relevant code snippets for a given natural language query. Recently, many approaches employing contrastive learning have shown promising results on code representation learning and greatly improved the performance of code search. However, there is still a lot of room for improvement in using contrastive learning for code search. In this paper, we propose CoCoSoDa to effectively utilize contrastive learning for code search via two key factors in contrastive learning: data augmentation and negative samples. Specifically, soft data augmentation is to dynamically masking or replacing some tokens with their types for input sequences to generate positive samples. Momentum mechanism is used to generate large and consistent representations of negative samples in a mini-batch through maintaining a queue and a momentum encoder. In addition, multimodal contrastive learning is used to pull together representations of code-query pairs and push apart the unpaired code snippets and queries. We conduct extensive experiments to evaluate the effectiveness of our approach on a large-scale dataset with six programming languages. Experimental results show that: (1) CoCoSoDa outperforms 18 baselines and especially exceeds CodeBERT, GraphCodeBERT, and UniXcoder by 13.3%, 10.5%, and 5.9% on average MRR scores, respectively. (2) The ablation studies show the effectiveness of each component of our approach. (3) We adapt our techniques to several different pre-trained models such as RoBERTa, CodeBERT, and GraphCodeBERT and observe a significant boost in their performance in code search. (4) Our model performs robustly under different hyper-parameters. Furthermore, we perform qualitative and quantitative analyses to explore reasons behind the good performance of our model.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00185","National Key R&D Program of China(grant numbers:2017YFA0700800); Fundamental Research Funds for the Central Universities(grant numbers:xtr072022001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172679","code search;contrastive learning;soft data augmentation;momentum mechanism","Representation learning;Adaptation models;Computer languages;Codes;Statistical analysis;Source coding;Natural languages","","11","","85","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"VarCLR: Variable Semantic Representation Pre-training via Contrastive Learning","Q. Chen; J. Lacomis; E. J. Schwartz; G. Neubig; B. Vasilescu; C. L. Goues",Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University Software Engineering Institute; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2327","2339","Variable names are critical for conveying intended program behavior. Machine learning-based program analysis methods use variable name representations for a wide range of tasks, such as suggesting new variable names and bug detection. Ideally, such methods could capture semantic relationships between names beyond syntactic similarity, e.g., the fact that the names average and mean are similar. Unfortunately, previous work has found that even the best of previous representation approaches primarily capture “relatedness” (whether two variables are linked at all), rather than “similarity” (whether they actually have the same meaning). We propose Varclr, a new approach for learning semantic representations of variable names that effectively captures variable similarity in this stricter sense. We observe that this problem is an excellent fit for contrastive learning, which aims to minimize the distance between explicitly similar inputs, while maximizing the distance between dissimilar inputs. This requires labeled training data, and thus we construct a novel, weakly-supervised variable renaming dataset mined from GitHub edits. We show that Varclr enables the effective application of sophisticated, general-purpose language models like BERT, to variable name representation and thus also to related downstream tasks like variable name similarity search or spelling correction. Varclr produces models that significantly outperform the state-of-the-art on IDBENCH, an existing benchmark that explicitly captures variable similarity (as distinct from relatedness). Finally, we contribute a release of all data, code, and pre-trained models, aiming to provide a drop-in replacement for variable representations used in either existing or future program analyses that rely on variable names.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510162","National Science Foundation(grant numbers:1815287,1910067); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793917","","Codes;Semantics;Computer bugs;Bit error rate;Training data;Syntactics;Data models","","10","","88","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Faster or Slower? Performance Mystery of Python Idioms Unveiled with Empirical Evidence","Z. Zhang; Z. Xing; X. Xia; X. Xu; L. Zhu; Q. Lu","Australian National University, Australia; Australian National University, Australia; Software Engineering Application Technology Lab, Huawei, China; Data61, CSIRO, Australia; Data61, CSIRO, Australia; Data61, CSIRO, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1495","1507","The usage of Python idioms is popular among Python developers in a formative study of 101 Python idiom performance related questions on Stack Overflow, we find that developers often get confused about the performance impact of Python idioms and use anecdotal toy code or rely on personal project experience which is often contradictory in performance outcomes. There has been no large-scale, systematic empirical evidence to reconcile these performance debates. In the paper, we create a large synthetic dataset with 24,126 pairs of non-idiomatic and functionally-equivalent idiomatic code for the nine unique Python idioms identified in [1], and reuse a large real-project dataset of 54,879 such code pairs provided in [1]. We develop a reliable performance measurement method to compare the speedup or slowdown by idiomatic code against non-idiomatic counterpart, and analyze the performance discrepancies between the synthetic and real-project code, the relationships between code features and performance changes, and the root causes of performance changes at the bytecode level. We summarize our findings as some actionable suggestions for using Python idioms.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172843","","Measurement;Codes;Systematics;Toy manufacturing industry;Reliability;Python;Synthetic data","","6","","52","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SeeHow: Workflow Extraction from Programming Screencasts through Action-Aware Video Analytics","D. Zhao; Z. Xing; X. Xia; D. Ye; X. Xu; L. Zhu","Australian National University and CSIRO's data61, Australia; Australian National University and CSIRO's data61, Australia; Software Engineering Application Technology Lab, Huawei, China; Tencent AI Lab, China; CSIRO's data61, Australia; CSIRO's data61, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1946","1957","Programming screencasts (e.g., video tutorials on Youtube or live coding stream on Twitch) are important knowledge source for developers to learn programming knowledge, especially the workflow of completing a programming task. Nonetheless, the image nature of programming screencasts limits the accessibility of screencast content and the workflow embedded in it, resulting in a gap to access and interact with the content and workflow in programming screencasts. Existing non-intrusive methods are limited to extract either primitive human-computer interaction (HCI) actions or coarse-grained video fragments. In this work, we leverage Computer Vision (CV) techniques to build a programming screencast analysis tool which can automatically extract code-line editing steps (enter text, delete text, edit text and select text) from screencasts. Given a programming screencast, our approach outputs a sequence of coding steps and code snippets involved in each step, which we refer to as programming workflow. The proposed method is evaluated on 41 hours of tutorial videos and live coding screencasts with diverse programming environments. The results demonstrate our tool can extract code-line editing steps accurately and the extracted workflow steps can be intuitively understood by developers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00165","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172636","Screencast;Computer vision;Workflow extraction;Action recognition","Human computer interaction;Computer vision;Video on demand;Codes;Visual analytics;Tutorials;Programming","","2","","37","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Coca: Improving and Explaining Graph Neural Network-Based Vulnerability Detection Systems","S. Cao; X. Sun; X. Wu; D. Lo; L. Bo; B. Li; W. Liu","Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Singapore Management University, Singapore; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China; Yangzhou University, Yangzhou, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1911","1923","Recently, Graph Neural Network (GNN)-based vulnerability detection systems have achieved remarkable success. However, the lack of explainability poses a critical challenge to deploy black-box models in security-related domains. For this reason, several approaches have been proposed to explain the decision logic of the detection model by providing a set of crucial statements positively contributing to its predictions. Unfortunately, due to the weakly-robust detection models and suboptimal explanation strategy, they have the danger of revealing spurious correlations and redundancy issue. In this paper, we propose Coca, a general framework aiming to 1) enhance the robustness of existing GNN-based vulnerability detection models to avoid spurious explanations; and 2) provide both concise and effective explanations to reason about the detected vulnerabilities. Coca consists of two core parts referred to as Trainer and Explainer. The former aims to train a detection model which is robust to random perturbation based on combina-torial contrastive learning, while the latter builds an explainer to derive crucial code statements that are most decisive to the detected vulnerability via dual-view causal inference as explanations. We apply Coca over three typical GNN-based vulnerability detectors. Experimental results show that Coca can effectively mitigate the spurious correlation issue, and provide more useful high-quality explanations.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639168","National Natural Science Foundation of China(grant numbers:62202414,61972335,62002309); Six Talent Peaks Project in Jiangsu Province(grant numbers:RJFW-053); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548474","Contrastive Learning;Causal Inference;Explainability","Correlation;Codes;Perturbation methods;Redundancy;Detectors;Predictive models;Robustness","","","","83","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated Detection of Password Leakage from Public GitHub Repositories","R. Feng; Z. Yan; S. Peng; Y. Zhang","Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","175","186","The prosperity of the GitHub community has raised new concerns about data security in public repositories. Practitioners who manage authentication secrets such as textual passwords and API keys in the source code may accidentally leave these texts in the public repositories, resulting in secret leakage. If such leakage in the source code can be automatically detected in time, potential damage would be avoided. With existing approaches focusing on detecting secrets with distinctive formats (e.g., API keys, cryptographic keys in PEM format), textual passwords, which are ubiquitously used for authentication, fall through the crack. Given that textual passwords could be virtually any strings, a naive detection scheme based on regular expression performs poorly. This paper presents PassFinder, an automated approach to effectively detecting password leakage from public repositories that involve various programming languages on a large scale. PassFinder utilizes deep neural networks to unveil the intrinsic characteristics of textual passwords and understand the semantics of the code snippets that use textual passwords for authentication, i.e., the contextual information of the passwords in the source code. Using this new technique, we performed the first large-scale and longitudinal analysis of password leakage on GitHub. We inspected newly uploaded public code files on GitHub for 75 days and found that password leakage is pervasive, affecting over sixty thousand repositories. Our work contributes to a better understanding of password leakage on GitHub, and we believe our technique could promote the security of the open-source ecosystem.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510150","National Science Foundation of China(grant numbers:61872237); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794113","Password;Mining Software Repositories;Deep Learning;GitHub","Codes;Semantics;Ecosystems;Neural networks;Authentication;Focusing;Passwords","","9","","75","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Nalin: learning from Runtime Behavior to Find Name-Value Inconsistencies in Jupyter Notebooks","J. Patra; M. Pradel","University of Stuttgart, Germany; University of Stuttgart, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1469","1481","Variable names are important to understand and maintain code. If a variable name and the value stored in the variable do not match, then the program suffers from a name-value inconsistency, which is due to one of two situations that developers may want to fix: Either a correct value is referred to through a misleading name, which negatively affects code understandability and maintainability, or the correct name is bound to a wrong value, which may cause unexpected runtime behavior. Finding name-value inconsistencies is hard because it requires an understanding of the meaning of names and knowledge about the values assigned to a variable at runtime. This paper presents Nalin, a technique to automatically detect name-value inconsistencies. The approach combines a dynamic analysis that tracks assignments of values to names with a neural machine learning model that predicts whether a name and a value fit together. To the best of our knowledge, this is the first work to formulate the problem of finding coding issues as a classification problem over names and runtime values. We apply Nalin to 106,652 real-world Python programs, where meaningful names are particularly important due to the absence of statically declared types. Our results show that the classifier detects name-value inconsistencies with high accuracy, that the warnings reported by Nalin have a precision of 80% and a recall of 76% w.r.t. a ground truth created in a user study, and that our approach complements existing techniques for finding coding issues.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510144","European Research Council (ERC)(grant numbers:851895); German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794092","Neural software analysis;identifier names;learning-based bug detection","Analytical models;Runtime;Codes;Computer bugs;Machine learning;Predictive models;Encoding","","2","","60","","20 Jun 2022","","","IEEE","IEEE Conferences"
"MAFT: Efficient Model-Agnostic Fairness Testing for Deep Neural Networks via Zero-Order Gradient Search","Z. Wang; M. Zhang; J. Yang; B. Shao; M. Zhang","East China Normal University; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University; East China Normal University; East China Normal University; East China Normal University",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1484","1495","Deep neural networks (DNNs) have shown powerful performance in various applications and are increasingly being used in decision-making systems. However, concerns about fairness in DNNs always persist. Some efficient white-box fairness testing methods about individual fairness have been proposed. Nevertheless, the devel-opment of black-box methods has stagnated, and the performance of existing methods is far behind that of white-box methods. In this paper, we propose a novel black-box individual fairness testing method called Model-Agnostic Fairness Testing (MAFT). By leveraging MAFT, practitioners can effectively identify and address discrimination in DL models, regardless of the specific algorithm or architecture employed. Our approach adopts lightweight procedures such as gradient estimation and attribute perturbation rather than nontrivial procedures like symbol execution, rendering it significantly more scalable and applicable than existing methods. We demonstrate that MAFT achieves the same effectiveness as state-of-the-art white-box methods whilst improving the applicability to large-scale networks. Compared to existing black-box approaches, our approach demonstrates distinguished performance in discovering fairness violations w.r.t effectiveness (~ 14.69X) and efficiency (~ 32.58X).","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548533","software bias;fairness testing;test case generation;deep neural network","Gradient methods;Perturbation methods;Closed box;Symbols;Computer architecture;Artificial neural networks;Rendering (computer graphics)","","","","51","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Predicting Performance and Accuracy of Mixed-Precision Programs for Precision Tuning","Y. Wang; C. Rubio-González","University of California, Davis, United States of America; University of California, Davis, United States of America",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","152","164","A mixed-precision program is a floating-point program that utilizes different precisions for different operations, providing the opportunity of balancing the trade-off between accuracy and performance. Precision tuning aims to find a mixed-precision version of a program that improves its performance while maintaining a given accuracy. Unfortunately, existing precision tuning approaches are either limited to small-scale programs, or suffer from efficiency issues. In this paper, we propose FPLEARNER, a novel approach that addresses these limitations. Our insight is to leverage a Machine Learning based technique, Graph Neural Networks, to learn the representation of mixed-precision programs to predict their performance and accuracy. Such prediction models can then be used to accelerate the process of dynamic precision tuning by reducing the number of program runs. We create a dataset of mixed-precision programs from five diverse HPC applications for training our models, which achieve 96.34% F1 score in performance prediction and 97.03% F1 score in accuracy prediction. FPLEARNER improves the time efficiency of two dynamic precision tuners, Precimonious and HIFPTUNER, by an average of 25.54% and up to 61.07% while achieving precision tuning results of comparable or better quality.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623338","National Science Foundation(grant numbers:CCF-1750983); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548640","program representation;Graph Neural Networks;floating point;mixed precision;numerical software;program optimization;precision tuning","Training;Tuners;Codes;Machine learning;Documentation;Predictive models;Graph neural networks","","","","71","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Verifying client-side input validation functions using string analysis","M. Alkhalaf; T. Bultan; J. L. Gallegos","Computer Science Department, University of California, Santa Barbara, CA, USA; Computer Science Department, University of California, Santa Barbara, CA, USA; Computer Science Department, University of California, Santa Barbara, CA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","947","957","Client-side computation in web applications is becoming increasingly common due to the popularity of powerful client-side programming languages such as JavaScript. Clientside computation is commonly used to improve an application's responsiveness by validating user inputs before they are sent to the server. In this paper, we present an analysis technique for checking if a client-side input validation function conforms to a given policy. In our approach, input validation policies are expressed using two regular expressions, one specifying the maximum policy (the upper bound for the set of inputs that should be allowed) and the other specifying the minimum policy (the lower bound for the set of inputs that should be allowed). Using our analysis we can identify two types of errors 1) the input validation function accepts an input that is not permitted by the maximum policy, or 2) the input validation function rejects an input that is permitted by the minimum policy. We implemented our analysis using dynamic slicing to automatically extract the input validation functions from web applications and using automata-based string analysis to analyze the extracted functions. Our experiments demonstrate that our approach is effective in finding errors in input validation functions that we collected from real-world applications and from tutorials and books for teaching JavaScript.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227124","","Electronic mail;Doped fiber amplifiers;Reactive power;Browsers;HTML;Algorithm design and analysis;Lattices","","16","2","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Making sense of healthcare benefits","J. Bnayahu; M. Goldstein; M. Nisenson; Y. Simionovici","IBM Haifa Research Laboratory, Haifa, Israel; IBM Haifa Research Laboratory, Haifa, Israel; IBM Haifa Research Laboratory, Haifa, Israel; IBM Haifa Research Laboratory, Haifa, Israel",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1034","1043","A key piece of information in healthcare is a patient's benefit plan. It details which treatments and procedures are covered by the health insurer (or payer), and at which conditions. While the most accurate and complete implementation of the plan resides in the payers claims adjudication systems, the inherent complexity of these systems forces payers to maintain multiple repositories of benefit information for other service and regulatory needs. In this paper we present a technology that deals with this complexity. We show how a large US health payer benefited from using the visualization, search, summarization and other capabilities of the technology. We argue that this technology can be used to improve productivity and reduce error rate in the benefits administration workflow, leading to lower administrative overhead and cost for health payers, which benefits both payers and patients.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227116","","Insurance;Search engines;Medical services;Complexity theory;Engines;Data mining;Natural languages","","","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Retrieval-Based Prompt Selection for Code-Related Few-Shot Learning","N. Nashid; M. Sintaha; A. Mesbah","University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2450","2462","Large language models trained on massive code corpora can generalize to new tasks without the need for task-specific fine-tuning. In few-shot learning, these models take as input a prompt, composed of natural language instructions, a few instances of task demonstration, and a query and generate an output. However, the creation of an effective prompt for code-related tasks in few-shot learning has received little attention. We present a technique for prompt creation that automatically retrieves code demonstrations similar to the developer task, based on embedding or frequency analysis. We apply our approach, Cedar, to two different programming languages, statically and dynamically typed, and two different tasks, namely, test assertion generation and program repair. For each task, we compare Cedar with state-of-the-art task-specific and fine-tuned models. The empirical results show that, with only a few relevant code demonstrations, our prompt creation technique is effective in both tasks with an accuracy of 76% and 52% for exact matches in test assertion generation and program repair tasks, respectively. For assertion generation, Cedar outperforms existing task-specific and fine-tuned models by 333% and 11%, respectively. For program repair, Cedar yields 189% better accuracy than task-specific models and is competitive with recent fine-tuned models. These findings have practical implications for practitioners, as Cedar could potentially be applied to multilingual and multitask settings without task or language-specific training with minimal examples and effort.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172590","Large Language Models;Transformers;Few-shot learning;Program repair;Test assertion generation","Training;Computer languages;Codes;Source coding;Natural languages;Maintenance engineering;Chatbots","","38","","93","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Neural Program Repair with Execution-based Backpropagation","H. Ye; M. Martinez; M. Monperrus","KTH Royal Institute of Technology, Sweden; Université Polytechnique, France; KTH Royal Institute of Technology, Sweden",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1506","1518","Neural machine translation (NMT) architectures have achieved promising results for automatic program repair. Yet, they have the limitation of generating low-quality patches (e.g., not compilable patches). This is because the existing works only optimize a purely syntactic loss function based on characters and tokens without incorporating program-specific information during neural network weight optimization. In this paper, we propose a novel program repair model called RewardRepair. The core novelty of RewardRepair is to improve NMT-based program repair with a loss function based on program compilation and test execution information, rewarding the network to produce patches that compile and that do not overfit. We conduct several experiments to evaluate RewardRepair showing that it is feasible and effective to use compilation and test execution results to optimize the underlying neural repair model. RewardRepair correctly repairs 207 bugs over four benchmarks. we report on repair success for 121 bugs that are fixed for the first time in the literature. Also, RewardRepair produces up to 45.3% of compilable patches, an improvement over the 39% by the state-of-the-art.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510222","Knut and Alice Wallenberg Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793856","automated program repair","Backpropagation;Training;Computer bugs;Semantics;Neural networks;Maintenance engineering;Syntactics","","36","","76","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Template-based Neural Program Repair","X. Meng; X. Wang; H. Zhang; H. Sun; X. Liu; C. Hu","SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; Chongqing University, Chongqing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1456","1468","In recent years, template-based and NMT-based automated program repair methods have been widely studied and achieved promising results. However, there are still disadvantages in both methods. The template-based methods cannot fix the bugs whose types are beyond the capabilities of the templates and only use the syntax information to guide the patch synthesis, while the NMT-based methods intend to generate the small range of fixed code for better performance and may suffer from the OOV (Out-of-vocabulary) problem. To solve these problems, we propose a novel template-based neural program repair approach called TENURE to combine the template-based and NMT- based methods. First, we build two large-scale datasets for 35 fix templates from template-based method and one special fix template (single-line code generation) from NMT-based method, respectively. Second, the encoder-decoder models are adopted to learn deep semantic features for generating patch intermediate representations (IRs) for different templates. The optimized copy mechanism is also used to alleviate the OOV problem. Third, based on the combined patch IRs for different templates, three tools are developed to recover real patches from the patch IRs, replace the unknown tokens, and filter the patch candidates with compilation errors by leveraging the project-specific information. On Defects4J-vl.2, TENURE can fix 79 bugs and 52 bugs with perfect and Ochiai fault localization, respectively. It is able to repair 50 and 32 bugs as well on Defects4J-v2.0. Compared with the existing template-based and NMT-based studies, TENURE achieves the best performance in all experiments.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172686","automated program repair;fix templates;neural machine translation;deep learning","Location awareness;Codes;Source coding;Computer bugs;Semantics;Maintenance engineering;Benchmark testing","","6","","55","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Towards Automatically Repairing Compatibility Issues in Published Android Apps","Y. Zhao; L. Li; K. Liu; J. Grundy","Monash University, Melbourne, Australia; Monash University, Melbourne, Australia; Huawei, Hangzhou, China; Monash University, Melbourne, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2142","2153","The heavy fragmentation of the Android ecosystem has led to se-vere compatibility issues with apps, including those that crash at runtime or cannot be installed on certain devices but work well on other devices. To address this problem, various approaches have been proposed to detect and fix compatibility issues automatically. However, these all come with various limitations on fixing the com-patibility issues, e.g., can only fix one specific type of issues, cannot deal with multi-invocation issues in a single line and issues in re-leased apps. To overcome these limitations, we propose a generic approach that aims at fixing more types of compatibility issues in released Android apps. To this end, our prototype tool, Repair-Droid, provides a generic app patch description language for users to create fix templates for compatibility issues. The created tem-plates will then be leveraged by RepairDroid to automatically fix the corresponding issue at the bytecode level (e.g., right before users install the app). RepairDroid can support template creations for OS-induced, device-specific and inter-callback compatibility issues detected by three state-of-the-art approaches. Our experimental re-sults show that RepairDroid can fix 7,660 out of 8,976 compatibility issues in 1,000 randomly selected Google Play apps. RepairDroid is generic to configure new compatibility issues and outperforms the state-of-the-art on effectively repairing compatibility issues in released Android apps.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510128","National Natural Science Foundation of China(grant numbers:62172214); National Key R&D Program of China(grant numbers:2020AAA0107704); Natural Science Foundation of Jiangsu Province, China(grant numbers:BK20210279); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794093","Android;Compatibility Issue;Automated Program Repair","Runtime;Operating systems;Ecosystems;Prototypes;Maintenance engineering;Computer crashes;Internet","","5","","58","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Online Summarizing Alerts through Semantic and Behavior Information","J. Chen; P. Wang; W. Wang","Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1646","1657","Alerts, which record details about system failures, are crucial data for monitoring a online service system. Due to the complex correlation between system components, a system failure usually triggers a large number of alerts, making the traditional manual handling of alerts insufficient. Thus, automatically summarizing alerts is a problem demanding prompt solution. This paper tackles this challenge through a novel approach based on supervised learning. The proposed approach, OAS (Online Alert Summarizing), first learns two types of information from alerts, semantic information and behavior information, respectively. Then, OAS adopts a specific deep learning model to aggregate semantic and behavior repre-sentations of alerts and thus determines the correlation between alerts. OAS is able to summarize the newly reported alert online. Extensive experiments, which are conducted on real alert datasets from two large commercial banks, demonstrate the efficiency and the effectiveness of OAS.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793860","alert summary;online service systems;system maintenance","Deep learning;Correlation;Aggregates;Semantics;Supervised learning;Manuals;Maintenance engineering","","4","","36","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Demystifying Android Non-SDK APls: Measurement and Understanding","S. Yang; R. Li; J. Chen; W. Diao; S. Guo","School of Cyber Science and Technology, Shandong University; School of Cyber Science and Technology, Shandong University; National University of Defense Technology; School of Cyber Science and Technology, Shandong University; School of Cyber Science and Technology, Shandong University",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","647","658","During the Android app development, the SDK is essential, which provides rich APIs to facilitate the implementations of functional-ities. However, in the Android framework, there still exist plenty of non-SDK APIs that are not well documented. These non-SDK APIs can be invoked through unconventional ways, such as Java reflection. On the other hand, these APIs are not stable and may be changed or even removed in future Android versions, providing no guarantee for compatibility. From Android 9 (API level 28), Google began to strictly restrict the use of non-SDK APIs, and the corresponding checking mechanism has been integrated into the Android OS. In this work, we systematically study the use and design of Android non-SDK APIs. Notably, we propose four research questions covering the restriction mechanism, the present usage status, malicious usage, and the API list evolution. To answer these questions, we conducted a large-scale measurement based on over 200K apps and the source code of three recent Android versions. As a result, a series of exciting and valuable findings are obtained. For example, Google's restriction is not strong enough and can still be bypassed. Besides, app developers use only a tiny part of non-SDK APIs. Our work provides new knowledge to the research community and can help researchers improve the Android API designs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510045","National Natural Science Foundation of China(grant numbers:61902148); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793966","Android Non-SDK APIs;API Design and Evolution","Knowledge engineering;Java;Codes;Market research;Reflection;Internet;Smart phones","","4","","45","","20 Jun 2022","","","IEEE","IEEE Conferences"
"ITER: Iterative Neural Repair for Multi-Location Patches","H. Ye; M. Monperrus","Carnegie Mellon University, United States; KTH Royal Institute of Technology, Sweden",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","90","102","Automated program repair (APR) has achieved promising results, especially using neural networks. Yet, the overwhelming majority of patches produced by APR tools are confined to one single location. When looking at the patches produced with neural repair, most of them fail to compile, while a few uncompilable ones go in the right direction. In both cases, the fundamental problem is to ignore the potential of partial patches. In this paper, we propose an iterative program repair paradigm called ITER founded on the concept of improving partial patches until they become plausible and correct. First, ITER iteratively improves partial single-location patches by fixing compilation errors and further refining the previously generated code. Second, ITER iteratively improves partial patches to construct multi-location patches, with fault localization re-execution. ITER is implemented for Java based on battle-proven deep neural networks and code representation. ITER is evaluated on 476 bugs from 10 open-source projects in Defects4J 2.0. ITER succeeds in repairing 15.5% of them, including 9 uniquely repaired multi-location bugs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548352","","Location awareness;Java;Codes;Computer bugs;Refining;Artificial neural networks;Maintenance engineering","","2","","62","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Adhere: Automated Detection and Repair of Intrusive Ads","Y. Yan; Y. Zheng; X. Liu; N. Medvidovic; W. Wang","University of Southern California, Los Angeles, CA, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; University at Buffalo, SUNY, Buffalo, NY, USA; University of Southern California, Los Angeles, CA, USA; University of Southern California, Los Angeles, CA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","486","498","Today, more than 3 million websites rely on online advertising revenue. Despite the monetary incentives, ads often frustrate users by disrupting their experience, interrupting content, and slowing browsing. To improve ad experiences, leading media associations define Better Ads Standards for ads that are below user expectations. However, little is known about how well websites comply with these standards and whether existing approaches are sufficient for developers to quickly resolve such issues. In this paper, we propose Adhere, a technique that can detect intrusive ads that do not comply with Better Ads Standards and suggest repair proposals. Adhere works by first parsing the initial web page to a DOM tree to search for potential static ads, and then using mutation observers to monitor and detect intrusive (dynamic/static) ads on the fly. To handle ads' volatile nature, Adhere includes two detection algorithms for desktop and mobile ads to identify different ad violations during three phases of page load events. It recursively applies the detection algorithms to resolve nested layers of DOM elements inserted by ad delegations. We evaluate Adhere on Alexa Top 1 Million Websites. The results show that Adhere is effective in detecting violating ads and suggesting repair proposals. Comparing to the current available alternative, Adhere detected intrusive ads on 4,656 more mobile websites and 3,911 more desktop websites, and improved recall by 16.6% and accuracy by 4.2%.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172610","ad experience;advertising practice;Better Ads Standards","Virtual assistants;Web pages;Maintenance engineering;Observers;Media;Proposals;Detection algorithms","","1","","64","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Duetcs: Code Style Transfer through Generation and Retrieval","B. Chen; Z. Abedjan","TU Berlin, Berlin, Germany; Leibniz Universität Hannover & L3S Research Center, Hannover, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2362","2373","Coding style has direct impact on code comprehension. Automatically transferring code style to user's preference or consistency can facilitate project cooperation and maintenance, as well as maximize the value of open-source code. Existing work on automating code stylization is either limited to code formatting or requires human supervision in pre-defining style checking and transformation rules. In this paper, we present unsupervised methods to assist automatic code style transfer for arbitrary code styles. The main idea is to leverage Big Code database to learn style and content embedding separately to generate or retrieve a piece of code with the same functionality and the desired target style. We carefully encode style and content features, so that a style embedding can be learned from arbitrary code. We explored the capabilities of novel attention-based style generation models and meta-learning and implemented our ideas in DUETCS. We complement the learning-based approach with a retrieval mode, which uses the same embeddings to directly search for the desired piece of code in Big Code. Our experiments show that DUETCS captures more style aspects than existing baselines.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172516","","Symbiosis;Metalearning;Codes;Databases;Instruments;Maintenance engineering;Encoding","","1","","36","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"JLeaks: A Featured Resource Leak Repository Collected From Hundreds of Open-Source Java Projects","T. Liu; W. Ji; X. Dong; W. Yao; Y. Wang; H. Liu; H. Peng; Y. Wang","Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China; Beijing Institute of Technology, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1723","1735","High-quality defect repositories are vital in defect detection, local-ization, and repair. However, existing repositories collected from open-source projects are either small-scale or inadequately labeled and packed. This paper systematically summarizes the program-ming APIs of system resources (i.e., file, socket, and thread) in Java. Additionally, this paper demonstrates the exceptions that may cause resource leaks in the chained and nested streaming operations. A semi-automatic toolchain is built to improve the efficiency of de-fect extraction, including automatic building for large legacy Java projects. Accordingly, 1,094 resource leaks were collected from 321 open-source projects on GitHub. This repository, named JLeaks, was built by round-by-round filtering and cross-validation, involving the review of approximately 3,185 commits from hundreds of projects. JLeaks is currently the largest resource leak repository, and each defect in JLeaks is well-labeled and packed, including causes, locations, patches, source files, and compiled bytecode files for 254 defects. We have conducted a detailed analysis of JLeaks for defect distribution, root causes, and fix approaches. We compare JLeaks with two well-known resource leak repositories, and the results show that JLeaks is more informative and complete, with high availability, uniqueness, and consistency. Additionally, we show the usability of JLeaks in two application scenarios. Future studies can leverage our repository to encourage better design and implementation of defect-related algorithms and tools.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation of China(grant numbers:62232003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548558","Resource leak;Defect repository;Open-source projects;Java language","Java;Codes;Reviews;Sockets;Maintenance engineering;Resource management;Usability","","","","56","","14 Jun 2024","","","IEEE","IEEE Conferences"
"KnowLog: Knowledge Enhanced Pretrained Language Model for Log Understanding","L. Ma; W. Yang; B. Xu; S. Jiang; B. Fei; J. Liang; M. Zhou; Y. Xiao","Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; School of Computer Science and Technology, Donghua University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; School of Data Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China; Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, Shanghai, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","365","377","Logs as semi-structured text are rich in semantic information, making their comprehensive understanding crucial for automated log analysis. With the recent success of pretrained language models in natural language processing, many studies have leveraged these models to understand logs. Despite their successes, existing pretrained language models still suffer from three weaknesses. Firstly, these models fail to understand domain-specific terminol-ogy, especially abbreviations. Secondly, these models struggle to adequately capture the complete log context information. Thirdly, these models have difficulty in obtaining universal representations of different styles of the same logs. To address these challenges, we introduce KnowLog, a knowledge-enhanced pretrained language model for log understanding. Specifically, to solve the previous two challenges, we exploit abbreviations and natural language de-scriptions of logs from public documentation as local and global knowledge, respectively, and leverage this knowledge by designing novel pretraining tasks for enhancing the model. To solve the last challenge, we design a contrastive learning-based pretraining task to obtain universal representations. We evaluate KnowLog by fine-tuning it on six different log understanding tasks. Extensive experiments demonstrate that KnowLog significantly enhances log understanding and achieves state-of-the-art results compared to existing pretrained language models without knowledge enhancement. Moreover, we conduct additional experiments in transfer learning and low-resource scenarios, showcasing the substantial advantages of KnowLog. Our source code and detailed experimental data are available at https://github.com/LeaperOvO/KnowLog.","1558-1225","979-8-4007-0217-4","","National Key Research and Development Project(grant numbers:2020AAA0109302); National Natural Science Foundation of China(grant numbers:u2033209); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548568","pretrained language model;knowledge enhancement;log understanding","Knowledge engineering;Flowcharts;Source coding;Transfer learning;Semantics;Documentation;Natural language processing","","","","65","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Dynamic Update for Synthesized GR(1) Controllers","G. Amram; S. Maoz; I. Segall; M. Yossef",Tel Aviv University; Tel Aviv University; Nokia Bell Labs; Tel Aviv University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","786","797","Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. GR(1) is an expressive fragment of LTL that enables efficient synthesis and has been recently used in different contexts and application domains. In this paper we investigate the dynamic-update problem for GR(1): updating the behavior of an already running synthesized controller such that it would safely and dynamically, without stopping, start conforming to a modified, up-to-date specification. We formally define the dynamic-update problem and present a sound and complete solution that is based on the computation of a bridge-controller. We implemented the work in the Spectra synthesis and execution environment and evaluated it over benchmark specifications. The evaluation shows the efficiency and effectiveness of using dynamic updates. The work advances the state-of-the-art in reactive synthesis and opens the way to its use in application domains where dynamic updates are a necessary requirement.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510054","European Research Council (ERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794083","Reactive synthesis;GR(1);Dynamic update","Bridges;Synthesizers;Dynamics;Switches;Maintenance engineering;Benchmark testing;Behavioral sciences","","","","40","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Curiosity-Driven Testing for Sequential Decision-Making Process","J. He; Z. Yang; J. Shi; C. Yang; K. Kim; B. Xu; X. Zhou; D. Lo","Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore; North Carolina State University, Raleigh, United State; Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2034","2047","Sequential decision-making processes (SDPs) are fundamental for complex real-world challenges, such as autonomous driving, robotic control, and traffic management. While recent advances in Deep Learning (DL) have led to mature solutions for solving these complex problems, SDMs remain vulnerable to learning unsafe behaviors, posing significant risks in safety-critical applications. However, developing a testing framework for SDMs that can identify a diverse set of crash-triggering scenarios remains an open challenge. To address this, we propose CUREFuzz, a novel curiosity-driven black-box fuzz testing approach for SDMs. CUREFuzz proposes a curiosity mechanism that allows a fuzzer to effectively explore novel and diverse scenarios, leading to improved detection of crash-triggering scenarios. Additionally, we introduce a multi-objective seed selection technique to balance the exploration of novel sce-narios and the generation of crash-triggering scenarios, thereby optimizing the fuzzing process. We evaluate CUREFuzz on various SDMs and experimental results demonstrate that CUREFuzz out-performs the state-of-the-art method by a substantial margin in the total number of faults and distinct types of crash-triggering scenarios. We also demonstrate that the crash-triggering scenarios found by CUREFuzz can repair SDMs, highlighting CUREFuzz as a valuable tool for testing SDMs and optimizing their performance.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639149","National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549275","Fuzz Testing;Sequential Decision Making;Deep Learning","Deep learning;Decision making;Process control;Closed box;Fuzzing;Maintenance engineering;Computer crashes","","","","88","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"PyTy: Repairing Static Type Errors in Python","Y. W. Chow; L. Di Grazia; M. Pradel","University of Stuttgart, Germany; University of Stuttgart, Germany; University of Stuttgart, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1058","1070","Gradual typing enables developers to annotate types of their own choosing, offering a flexible middle ground between no type annotations and a fully statically typed language. As more and more code bases get type-annotated, static type checkers detect an increasingly large number of type errors. Unfortunately, fixing these errors requires manual effort, hampering the adoption of gradual typing in practice. This paper presents PyTy, an automated program repair approach targeted at statically detectable type errors in Python. The problem of repairing type errors deserves specific attention because it exposes particular repair patterns, offers a warning message with hints about where and how to apply a fix, and because gradual type checking serves as an automatic way to validate fixes. We addresses this problem through three contributions: (i) an empirical study that investigates how developers fix Python type errors, showing a diverse set of fixing strategies with some recurring patterns; (ii) an approach to automatically extract type error fixes, which enables us to create a dataset of 2,766 error-fix pairs from 176 GitHub repositories, named PyTyDefects; (iii) the first learning-based re-pair technique for fixing type errors in Python. Motivated by the relative data scarcity of the problem, the neural model at the core of PyTy is trained via cross-lingual transfer learning. Our evaluation shows that PyTy offers fixes for ten frequent categories of type errors, successfully addressing 85.4% of 281 real-world errors. This effectiveness outperforms state-of-the-art large language models asked to repair type errors (by 2.1x) and complements a previous technique aimed at type errors that manifest at runtime. Finally, 20 out of 30 pull requests with PyTy-suggested fixes have been merged by developers, showing the usefulness of PyTy in practice.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548748","Automatic Program Repair;Type Annotation;Transfer Learning","Deep learning;Runtime;Transfer learning;Manuals;Debugging;Maintenance engineering;Writing","","","","56","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Testing Database Engines via Query Plan Guidance","J. Ba; M. Rigger",National University of Singapore; National University of Singapore,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2060","2071","Database systems are widely used to store and query data. Test oracles have been proposed to find logic bugs in such systems, that is, bugs that cause the database system to compute an incorrect result. To realize a fully automated testing approach, such test oracles are paired with a test case generation technique; a test case refers to a database state and a query on which the test oracle can be applied. In this work, we propose the concept of Query Plan Guidance (QPG) for guiding automated testing towards “interesting” test cases. SQL and other query languages are declarative. Thus, to execute a query, the database system translates every operator in the source language to one of the potentially many so-called physical operators that can be executed; the tree of physical operators is referred to as the query plan. Our intuition is that by steering testing towards exploring a variety of unique query plans, we also explore more interesting behaviors-some of which are potentially incorrect. To this end, we propose a mutation technique that gradually applies promising mutations to the database state, causing the DBMS to create potentially unseen query plans for subsequent queries. We applied our method to three mature, widely-used, and extensively-tested database systems-SQLite, TiDB, and CockroachDB-and found 53 unique, previously unknown bugs. Our method exercises $4.85-408.48\times$ more unique query plans than a naive random generation method and $7.46\times$ more than a code coverage guidance method. Since most database systems-including commercial ones-expose query plans to the user, we consider QPG a generally applicable, black-box approach and believe that the core idea could also be applied in other contexts (e.g., to measure the quality of a test suite).","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172874","automated testing;test case generation","Structured Query Language;Codes;Computer bugs;Closed box;Database systems;Behavioral sciences;Software measurement","","11","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Inferring and Applying Type Changes","A. Ketkar; O. Smirnov; N. Tsantalis; D. Dig; T. Bryksin","Uber Technologies Inc., USA; JetBrains Research, St Petersburg University, Russia; Concordia University, Canada; University of Colorado Boulder, USA; JetBrains Research HSE University, Russia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1206","1218","Developers frequently change the type of a program element and update all its references to increase performance, security, or maintainability. Manually performing type changes is tedious, error-prone, and it overwhelms developers. Researchers and tool builders have proposed advanced techniques to assist developers when performing type changes. A major obstacle in using these techniques is that the developer has to manually encode rules for defining the type changes. Handcrafting such rules is difficult and often involves multiple trial-error iterations. Given that open-source repositories contain many examples of type-changes, if we could infer the adaptations, we would eliminate the burden on developers. We introduce TC-Infer, a novel technique that infers rewrite rules that capture the required adaptations from the version histories of open source projects. We then use these rules (expressed in the Comby language) as input to existing type change tools. To evaluate the effectiveness of TC-Infer, we use it to infer 4,931 rules for 605 popular type changes in a corpus of 400K commits. Our results show that TC-Infer deduced rewrite rules for 93% of the most popular type change patterns. Our results also show that the rewrite rules produced by TC-Infer are highly effective at applying type changes (99.2% precision and 93.4% recall). To advance the existing tooling we released IntelliTC, an interactive and configurable refactoring plugin for IntelliJ IDEA to perform type changes.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510115","NSF(grant numbers:CCF-1553741,CNS-1941898); NSERC(grant numbers:RGPIN2018-05095); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794046","Refactoring;source code mining;type change;type migration","Java;Codes;Automation;History;Security;DSL;Open source software","","7","","61","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"ACAV: A Framework for Automatic Causality Analysis in Autonomous Vehicle Accident Recordings","H. Sun; C. M. Poskitt; Y. Sun; J. Sun; Y. Chen","ShanghaiTech University, China; Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore; ShanghaiTech University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1248","1260","The rapid progress of autonomous vehicles (AVs) has brought the prospect of a driverless future closer than ever. Recent fatalities, however, have emphasized the importance of safety validation through large-scale testing. Multiple approaches achieve this fully automatically using high-fidelity simulators, i.e., by generating diverse driving scenarios and evaluating autonomous driving systems (ADSs) against different test oracles. While effective at finding violations, these approaches do not identify the decisions and actions that caused them-information that is critical for improving the safety of ADSs. To address this challenge, we propose ACAV, an automated framework designed to conduct causality analyses for AV accident recordings in two stages. First, we apply feature extraction schemas based on the messages exchanged between ADS modules, and use a weighted voting method to discard frames of the recording unrelated to the accident. Second, we use safety specifications to identify safety-critical frames and deduce causal events by applying CAT-our causal analysis tool-to a station-time graph. We evaluated ACAV on the Apollo ADS, finding that it can identify five distinct types of causal events in 93.64% of 110 accident recordings generated by an AV testing engine. We further evaluated ACAV on 1206 accident recordings collected from versions of Apollo injected with specific faults, finding that it can correctly identify causal events in 96.44% of the accidents triggered by prediction errors, and 85.73% of the accidents triggered by planning errors.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548641","Autonomous driving system;test reduction;causality","Fault diagnosis;Web and internet services;Cause effect analysis;Recording;Safety;Software reliability;Autonomous vehicles","","","","64","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Is unsafe an Achilles' Heel? A Comprehensive Study of Safety Requirements in Unsafe Rust Programming","M. Cui; S. Sun; H. Xu; Y. Zhou","School of Computer Science, Fudan University, China; School of Computer Science, Fudan University, China; School of Computer Science, Fudan University, China; School of Computer Science, Fudan University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1298","1310","Rust is an emerging, strongly-typed programming language focusing on efficiency and memory safety. With increasing projects adopting Rust, knowing how to use Unsafe Rust is crucial for Rust security. We observed that the description of safety requirements needs to be unified in Unsafe Rust programming. Current unsafe API documents in the standard library exhibited variations, including inconsistency and insufficiency. To enhance Rust security, we suggest unsafe API documents to list systematic descriptions of safety requirements for users to follow. In this paper, we conducted the first comprehensive empirical study on safety requirements across unsafe boundaries. We studied unsafe API documents in the standard library and defined 19 safety properties (SP). We then completed the data labeling on 416 unsafe APIs while analyzing their correlation to find interpretable results. To validate the practical usability and SP coverage, we categorized existing Rust CVEs until 2023-07-08 and performed a statistical analysis of std unsafe API usage toward the crates.io ecosystem. In addition, we conducted a user survey to gain insights into four aspects from experienced Rust programmers. We finally received 50 valid responses and confirmed our classification with statistical significance.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639075","National Natural Science Foundation of China(grant numbers:62372304); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549515","Unsafe Rust;Safety Property;Rustdoc;CVE;User Survey;Undefined Behavior","Surveys;Computer languages;Systematics;Programming;Libraries;Safety;System software","","","","76","","14 Jun 2024","","","IEEE","IEEE Conferences"
"PUS: A Fast and Highly Efficient Solver for Inclusion-based Pointer Analysis","P. Liu; Y. Li; B. Swain; J. Huang","Texas A&M University, College Station, USA; Texas A&M University, College Station, USA; Texas A&M University, College Station, USA; Texas A&M University, College Station, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1781","1792","A crucial performance bottleneck in most interprocedural static analyses is solving pointer analysis constraints. We present Pus, a highly efficient solver for inclusion-based pointer analysis. At the heart of Pus is a new constraint solving algorithm that signifi-cantly advances the state-of-the-art. Unlike the existing algorithms (i.e., wave and deep propagation) which construct a holistic constraint graph, at each stage Pus only considers partial constraints that causally affect the final fixed-point computation. In each iteration Pus extracts a small causality subgraph and it guarantees that only processing the causality subgraph is sufficient to reach the same global fixed point. Our extensive evaluation of Pus on a wide range of real-world large complex programs yields highly promising results. Pus is able to analyze millions of lines of code such as PostgreSQL in 10 minutes on a commodity laptop. On average, Pus is more than 7x faster in solving context-sensitive constraints, and more than 2x faster in solving context-insensitive constraints compared to the state of the art wave and deep propagation algorithms. Moreover, Pus has been used to find tens of previous unknown bugs in high-profile codebases including Linux, Redis, and Memcached.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794135","Static Analysis;Pointer Analysis;Causality Subgraph","Heart;Portable computers;Codes;Linux;Software algorithms;Computer bugs;Static analysis","","","","35","","20 Jun 2022","","","IEEE","IEEE Conferences"
"CBCD: Cloned buggy code detector","J. Li; M. D. Ernst","DNV Research and Innovation, Hovik, Norway; University of Washington, Seattle, WA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","310","320","Developers often copy, or clone, code in order to reuse or modify functionality. When they do so, they also clone any bugs in the original code. Or, different developers may independently make the same mistake. As one example of a bug, multiple products in a product line may use a component in a similar wrong way. This paper makes two contributions. First, it presents an empirical study of cloned buggy code. In a large industrial product line, about 4% of the bugs are duplicated across more than one product or file. In three open source projects (the Linux kernel, the Git version control system, and the PostgreSQL database) we found 282, 33, and 33 duplicated bugs, respectively. Second, this paper presents a tool, CBCD, that searches for code that is semantically identical to given buggy code. CBCD tests graph isomorphism over the Program Dependency Graph (PDG) representation and uses four optimizations. We evaluated CBCD by searching for known clones of buggy code segments in the three projects and compared the results with text-based, token-based, and AST-based code clone detectors, namely Simian, CCFinder, Deckard, and CloneDR. The evaluation shows that CBCD is fast when searching for possible clones of the buggy code in a large system, and it is more precise for this purpose than the other code clone detectors.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227183","Validation;Debugging aids","Cloning;Computer bugs;Optimization;Linux;Complexity theory;Kernel;Detectors","","77","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Asking and answering questions about unfamiliar APIs: An exploratory study","E. Duala-Ekoko; M. P. Robillard","School of Computer Science, McGill University, Montreal, QUE, Canada; School of Computer Science, McGill University, Montreal, QUE, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","266","276","The increasing size of APIs and the increase in the number of APIs available imply developers must frequently learn how to use unfamiliar APIs. To identify the types of questions developers want answered when working with unfamiliar APIs and to understand the difficulty they may encounter answering those questions, we conducted a study involving twenty programmers working on different programming tasks, using unfamiliar APIs. Based on the screen captured videos and the verbalization of the participants, we identified twenty different types of questions programmers ask when working with unfamiliar APIs, and provide new insights to the cause of the difficulties programmers encounter when answering questions about the use of APIs. The questions we have identified and the difficulties we observed can be used for evaluating tools aimed at improving API learning, and in identifying areas of the API learning process where tool support is missing, or could be improved.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227187","","Programming;XML;Videos;Usability;Documentation;Production facilities;Navigation","","58","","26","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Understanding integer overflow in C/C++","W. Dietz; P. Li; J. Regehr; V. Adve","Department of Computer Science, University of Illinois, Urbana-Champaign, USA; School of Computing, University of Utah, USA; School of Computing, University of Utah, USA; Department of Computer Science, University of Illinois, Urbana-Champaign, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","760","770","Integer overflow bugs in C and C++ programs are difficult to track down and may lead to fatal errors or exploitable vulnerabilities. Although a number of tools for finding these bugs exist, the situation is complicated because not all overflows are bugs. Better tools need to be constructed - but a thorough understanding of the issues behind these errors does not yet exist. We developed IOC, a dynamic checking tool for integer overflows, and used it to conduct the first detailed empirical study of the prevalence and patterns of occurrence of integer overflows in C and C++ code. Our results show that intentional uses of wraparound behaviors are more common than is widely believed; for example, there are over 200 distinct locations in the SPEC CINT2000 benchmarks where overflow occurs. Although many overflows are intentional, a large number of accidental overflows also occur. Orthogonal to programmers' intent, overflows are found in both well-defined and undefined flavors. Applications executing undefined operations can be, and have been, broken by improvements in compiler optimizations. Looking beyond SPEC, we found and reported undefined integer overflows in SQLite, PostgreSQL, SafeInt, GNU MPC and GMP, Firefox, GCC, LLVM, Python, BIND, and OpenSSL; many of these have since been fixed. Our results show that integer overflow issues in C and C++ are subtle and complex, that they are common even in mature, widely used programs, and that they are widely misunderstood by developers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227142","integer overflow;integer wraparound;undefined behavior","Optimization;Standards;Semantics;Program processors;Runtime;Computer bugs;Weapons","","20","","20","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Automated detection of client-state manipulation vulnerabilities","A. Møller; M. Schwarz","Department of Computer Science, Aarhus University, Denmark; Department of Computer Science, Aarhus University, Denmark",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","749","759","Web application programmers must be aware of a wide range of potential security risks. Although the most common pitfalls are well described and categorized in the literature, it remains a challenging task to ensure that all guidelines are followed. For this reason, it is desirable to construct automated tools that can assist the programmers in the application development process by detecting weaknesses. Many vulnerabilities are related to web application code that stores references to application state in the generated HTML documents to work around the statelessness of the HTTP protocol. In this paper, we show that such client-state manipulation vulnerabilities are amenable to tool supported detection. We present a static analysis for the widely used frameworks Java Servlets, JSP, and Struts. Given a web application archive as input, the analysis identifies occurrences of client state and infers the information flow between the client state and the shared application state on the server. This makes it possible to check how client-state manipulation performed by malicious users may affect the shared application state and cause leakage or modifications of sensitive information. The warnings produced by the tool help the application programmer identify vulnerabilities. Moreover, the inferred information can be applied to configure a security filter that automatically guards against attacks. Experiments on a collection of open source web applications indicate that the static analysis is able to effectively help the programmer prevent client-state manipulation vulnerabilities.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227143","Web application security;information flow analysis;static analysis","HTML;Servers;Security;Electronic mail;Java;Libraries;Safety","","2","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"$\mu AFL$: Non-intrusive Feedback-driven Fuzzing for Microcontroller Firmware","W. Li; J. Shi; F. Li; J. Lin; W. Wang; L. Guan","State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, School of Cyber Security, UCAS, Beijing, China; Department of Computer Science, The University of Georgia, Athens, Georgia, USA; Department of Electrical Engineering and Computer Science, The University of Kansas, Lawrence, Kansas, USA; School of Cyber Security, University of Science and Technology of China, Hefei, Anhui, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, The University of Georgia, Athens, Georgia, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1","12","Fuzzing is one of the most effective approaches to finding software flaws. However, applying it to microcontroller firmware incurs many challenges. For example, rehosting-based solutions cannot accurately model peripheral behaviors and thus cannot be used to fuzz the corresponding driver code. In this work, we present $\mu$ AFL, a hardware-in-the-loop approach to fuzzing microcontroller firmware. It leverages debugging tools in existing embedded system development to construct an AFL-compatible fuzzing framework. Specifically, we use the debug dongle to bridge the fuzzing environment on the PC and the target firmware on the microcontroller device. To collect code coverage information without costly code instrumentation, $\mu$ AFL relies on the ARM ETM hardware debugging feature, which transparently collects the instruction trace and streams the results to the PC. However, the raw ETM data is obscure and needs enormous computing resources to recover the actual instruction flow. We therefore propose an alternative representation of code coverage, which retains the same path sensitivity as the original AFL algorithm, but can directly work on the raw ETM data without matching them with disassembled instructions. To further reduce the workload, we use the DWT hardware feature to selectively collect runtime information of interest. We evaluated $\mu$ AFL on two real evaluation boards from two major vendors: NXP and STMicroelectronics. With our prototype, we discovered ten zero-day bugs in the driver code shipped with the SDK of STMicroelectronics and three zero-day bugs in the SDK of NXP. Eight CVEs have been allocated for them. Considering the wide adoption of vendor SDKs in real products, our results are alarming.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510208","NSF(grant numbers:IIS-2014552); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794037","firmware security;fuzzing;microcontroller;IoT;ETM","Codes;Embedded systems;Microcontrollers;Computer bugs;Prototypes;Fuzzing;Hardware","","5","","49","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Eadro: An End-to-End Troubleshooting Framework for Microservices on Multi-source Data","C. Lee; T. Yang; Z. Chen; Y. Su; M. R. Lyu","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China; Sun Yat-sen University, Guangzhou, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1750","1762","The complexity and dynamism of microservices pose significant challenges to system reliability, and thereby, automated troubleshooting is crucial. Effective root cause localization after anomaly detection is crucial for ensuring the reliability of microservice systems. However, two significant issues rest in existing approaches: (1) Microservices generate traces, system logs, and key performance indicators (KPIs), but existing approaches usually consider traces only, failing to understand the system fully as traces cannot depict all anomalies; (2) Troubleshooting microservices generally contains two main phases, i.e., anomaly detection and root cause localization. Existing studies regard these two phases as independent, ignoring their close correlation. Even worse, inaccurate detection results can deeply affect localization effectiveness. To overcome these limitations, we propose Eadro, the first end-to-end framework to integrate anomaly detection and root cause localization based on multi-source data for troubleshooting large-scale microservices. The key insights of Eadro are the anomaly manifestations on different data sources and the close connection between detection and localization. Thus, Eadro models intra-service behaviors and inter-service dependencies from traces, logs, and KPIs, all the while leveraging the shared knowledge of the two phases via multi-task learning. Experiments on two widely-used benchmark microservices demonstrate that Eadro outperforms state-of-the-art approaches by a large margin. The results also show the usefulness of integrating multi-source data. We also release our code and data to facilitate future research.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00150","National Natural Science Foundation of China(grant numbers:62202511); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172617","Microservices;Root Cause Localization;Anomaly Detection;Traces","Location awareness;Codes;Soft sensors;Microservice architectures;Multitasking;Behavioral sciences;Reliability","","14","","70","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"ATM: Black-box Test Case Minimization based on Test Code Similarity and Evolutionary Search","R. Pan; T. A. Ghaleb; L. Briand","School of EECS University of Ottawa, Ottawa, Canada; School of EECS University of Ottawa, Ottawa, Canada; School of EECS University of Ottawa, Ottawa, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1700","1711","Executing large test suites is time and resource consuming, sometimes impossible, and such test suites typically contain many redundant test cases. Hence, test case (suite) minimization is used to remove redundant test cases that are unlikely to detect new faults. However, most test case minimization techniques rely on code coverage (white-box), model-based features, or requirements specifications, which are not always (entirely) accessible by test engineers. Code coverage analysis also leads to scalability issues, especially when applied to large industrial systems. Recently, a set of novel techniques was proposed, called FAST-R, relying solely on test case code for test case minimization, which appeared to be much more efficient than white-box techniques. However, it achieved a comparable low fault detection capability for Java projects, thus making its application challenging in practice. In this paper, we propose ATM (AST-based Test case Minimizer), a similarity-based, search-based test case minimization technique, taking a specific budget as input, that also relies exclusively on the source code of test cases but attempts to achieve higher fault detection through finer-grained similarity analysis and a dedicated search algorithm. ATM transforms test case code into Abstract Syntax Trees (AST) and relies on four tree-based similarity measures to apply evolutionary search, specifically genetic algorithms, to minimize test cases. We evaluated the effectiveness and efficiency of ATM on a large dataset of 16 Java projects with 661 faulty versions using three budgets ranging from 25% to 75% of test suites. ATM achieved significantly higher fault detection rates (0.82 on average), compared to FAST-R (0.61 on average) and random minimization (0.52 on average), when running only 50% of the test cases, within practically acceptable time (1.1 - 4.3 hours, on average, per project version), given that minimization is only occasionally applied when many new test cases are created (major releases). Results achieved for other budgets were consistent.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00146","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172509","Test case minimization;Test suite reduction;Tree-based similarity;AST;Genetic algorithm;Black-box testing","Java;Codes;Fault detection;Closed box;Transforms;Syntactics;Minimization","","5","","40","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Operand-Variation-Oriented Differential Analysis for Fuzzing Binding Calls in PDF Readers","S. Guo; X. Wan; W. You; B. Liang; W. Shi; Y. Zhang; J. Huang; J. Zhang","School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","95","107","Binding calls of embedded scripting engines introduce a serious attack surface in PDF readers. To effectively test binding calls, the knowledge of parameter types is necessary. Unfortunately, due to the absence or incompleteness of documentation and the lack of sufficient samples, automatic type reasoning for binding call parameters is a big challenge. In this paper, we propose a novel operand-variation-oriented differential analysis approach, which automatically extracts features from execution traces as oracles for inferring parameter types. In particular, the parameter types of a binding call are inferred by executing the binding call with different values of different types and investigating which types cause an expected effect on the instruction operands. The inferred type information is used to guide the test generation in fuzzing. Through the evaluation on two popular PDF readers (Adobe Reader and Foxit Reader), we demonstrated the accuracy of our type reasoning method and the effectiveness of the inferred type information for improving fuzzing in both code coverage and vulnerability discovery. We found 38 previously unknown security vulnerabilities, 26 of which were certified with CVE numbers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00020","National Natural Science Foundation of China(grant numbers:62002361,U1836209,62272465,62272464,62132020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172882","binding call;PDF reader;type reasoning;fuzzing","Codes;Documentation;Fuzzing;Portable document format;Feature extraction;Cognition;Test pattern generators","","1","","87","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Improving Smart Contract Security with Contrastive Learning-Based Vulnerability Detection","Y. Chen; Z. Sun; Z. Gong; D. Hao","Key Lab of HCST (PKU), MOE, School of Computer Science, Peking University, Beijing, China; Science & Technology on Integrated Information System Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Key Lab of HCST (PKU), MOE, School of Computer Science, Peking University, Beijing, China; Key Lab of HCST (PKU), MOE, School of Computer Science, Peking University, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1924","1934","Currently, smart contract vulnerabilities (SCVs) have emerged as a major factor threatening the transaction security of blockchain. Existing state-of-the-art methods rely on deep learning to mitigate this threat. They treat each input contract as an independent entity and feed it into a deep learning model to learn vulnerability patterns by fitting vulnerability labels. It is a pity that they disregard the correlation between contracts, failing to consider the commonalities between contracts of the same type and the differences among contracts of different types. As a result, the performance of these methods falls short of the desired level. To tackle this problem, we propose a novel Contrastive Learning Enhanced Automated Recognition Approach for Smart Contract Vulnerabilities, named Clear. In particular, Clear employs a con-trastive learning (CL) model to capture the fine-grained correlation information among contracts and generates correlation labels based on the relationships between contracts to guide the training pro-cess of the CL model. Finally, it combines the correlation and the semantic information of the contract to detect SCVs. Through an empirical evaluation of a large-scale real-world dataset of over 40K smart contracts and compare 13 state-of-the-art baseline methods. We show that Clear achieves (1) optimal performance over all base-line methods; (2) 9.73%-39.99% higher F1-score than existing deep learning methods.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639173","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549161","Smart contract;Vulnerability detection;Deep learning;Contrastive learning","Deep learning;Training;Correlation;Smart contracts;Semantics;Fitting;Blockchains","","1","","42","","14 Jun 2024","","","IEEE","IEEE Conferences"
"GrammarT5: Grammar-Integrated Pretrained Encoder-Decoder Neural Model for Code","Q. Zhu; Q. Liang; Z. Sun; Y. Xiong; L. Zhang; S. Cheng","Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; Science & Technology on Integrated Information System Laboratory, Institute of Software, Chinese Academy of Sciences, Beijing, China; Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; Key Laboratory of HCST (PKU), MoE SCS, Peking University, Beijing, China; ZTE Corporation, Chengdu, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","918","930","Pretrained models for code have exhibited promising performance across various code-related tasks, such as code summarization, code completion, code translation, and bug detection. However, despite their success, the majority of current models still represent code as a token sequence, which may not adequately capture the essence of the underlying code structure. In this work, we propose GrammarT5, a grammar-integrated encoder-decoder pretrained neural model for code. GrammarT5 employs a novel grammar-integrated representation, Tokenized Grammar Rule Sequence (TGRS), for code. TGRS is constructed based on the grammar rule sequence utilized in syntax-guided code generation and integrates syntax information with code tokens within an appropriate input length. Furthermore, we suggest at-taching language flags to help GrammarT5 differentiate between grammar rules of various programming languages. Finally, we in-troduce two novel pretraining tasks-Edge Prediction (EP), and Sub-Tree Prediction (STP) to learn syntactic information. Experiments were conducted on five code-related tasks using eleven datasets, demonstrating that GrammarT5 achieves state-of-the-art (SOTA) performance on most tasks in comparison to models of the same scale. Additionally, the paper illustrates that the proposed pretraining tasks and language flags can enhance GrammarT5 to better capture the syntax and semantics of code.","1558-1225","979-8-4007-0217-4","","National Key Research and Development Program of China(grant numbers:2022YFB4501902); National Natural Science Foundation of China(grant numbers:62161146003,62232001,62232003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549313","neural networks;pretrained model;text tagging","Computer languages;Codes;Semantics;Syntactics;Tagging;Predictive models;Transformers","","","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Hypertesting of Programs: Theoretical Foundation and Automated Test Generation","M. Pasqua; M. Ceccato; P. Tonella","Dept. of Computer Science, University of Verona, Verona, Italy; Dept. of Computer Science, University of Verona, Verona, Italy; Software Institute, Universitá della Svizzera italiana, Lugano, Switzerland",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1409","1420","Hyperproperties are used to define correctness requirements that involve relations between multiple program executions. This allows, for instance, to model security and concurrency requirements, which cannot be expressed by means of trace properties. In this paper, we propose a novel systematic approach for auto-mated testing of hyperproperties. Our contribution is both foundational and practical. On the foundational side, we define a hyper-testing framework, which includes a novel hypercoverage adequacy criterion designed to guide the synthesis of test cases for hyper-properties. On the practical side, we instantiate such framework by implementing HyperFuzz and HyperEvo, two test generators targeting the Non-Interference security requirement, that rely respectively on fuzzing and search algorithms. Experimental results show that the proposed hypercoverage ad-equacy criterion correlates with the capability of a hypertest to expose hyperproperty violations and that both HyperFuzz and Hy-perEvo achieve high hypercoverage and high vulnerability exposure with no false alarms (by construction). While they both outperform the state-of-the-art dynamic taint analysis tool Phosphor, HyperEvo is more effective than HyperFuzz on some benchmark programs.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548590","Search-based testing;Hyperproperties;Information flows;Security testing;Code coverage criteria","Systematics;Phosphors;Metaheuristics;Fuzzing;Benchmark testing;Search problems;Performance analysis","","","","38","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Make LLM a Testing Expert: Bringing Human-Like Interaction to Mobile GUI Testing via Functionality-Aware Decisions","Z. Liu; C. Chen; J. Wang; M. Chen; B. Wu; X. Che; D. Wang; Q. Wang","State Key Laboratory of Intelligent Game, Beijing, China; Technical University of Munich, Munich, Germany; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China; State Key Laboratory of Intelligent Game, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1222","1234","Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32% in activity coverage, and detects 31% more bugs at a faster rate. Moreover, GPTDroid identifies 53 new bugs on Google Play, of which 35 have been confirmed and fixed.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639180","National Natural Science Foundation of China(grant numbers:62232016,62072442,62272445); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548314","Automated GUI testing;Large language model","Computer bugs;Training data;Chatbots;Question answering (information retrieval);Internet;Mobile applications;Task analysis","","","","89","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"What Do They Capture? - A Structural Analysis of Pre-Trained Language Models for Source Code","Y. Wan; W. Zhao; H. Zhang; Y. Sui; G. Xu; H. Jin","School of Computer Science and Technology, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China; University of Newcastle, Australia; School of Computer Science, University of Technology Sydney, Australia; School of Computer Science, University of Technology Sydney, Australia; School of Computer Science and Technology, Huazhong University of Science and Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2377","2388","Recently, many pre-trained language models for source code have been proposed to model the context of code and serve as a basis for downstream code intelligence tasks such as code completion, code search, and code summarization. These models leverage masked pre-training and Transformer and have achieved promising results. However, currently there is still little progress regarding interpretability of existing pre-trained code models. It is not clear why these models work and what feature correlations they can capture. In this paper, we conduct a thorough structural analysis aiming to provide an interpretation of pre-trained language models for source code (e.g., CodeBERT, and GraphCodeBERT) from three distinctive perspectives: (1) attention analysis, (2) probing on the word embedding, and (3) syntax tree induction. Through comprehensive analysis, this paper reveals several insightful findings that may inspire future studies: (1) Attention aligns strongly with the syntax structure of code. (2) Pre-training language models of code can preserve the syntax structure of code in the intermediate representations of each Transformer layer. (3) The pre-trained models of code have the ability of inducing syntax trees of code. Theses findings suggest that it may be helpful to incorporate the syntax structure of code into the process of pre-training for better code representations.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510050","National Natural Science Foundation of China(grant numbers:62102157); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794032","Code representation;deep learning;pre-trained language model;probing;attention analysis;syntax tree induction","Training;Representation learning;Analytical models;Codes;Correlation;Syntactics;Transformers","","14","","45","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Stride: Search-based deterministic replay in polynomial time via bounded linkage","J. Zhou; X. Xiao; C. Zhang","Department of Computer Science and Engineering, The Prism Research Group, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Prism Research Group, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Prism Research Group, Hong Kong University of Science and Technology, Hong Kong, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","892","902","Deterministic replay remains as one of the most effective ways to comprehend concurrent bugs. Existing approaches either maintain the exact shared read-write linkages with a large runtime overhead or use exponential off-line algorithms to search for a feasible interleaved execution. In this paper, we propose Stride, a hybrid solution that records the bounded shared memory access linkages at runtime and infers an equivalent interleaving in polynomial time, under the sequential consistency assumption. The recording scheme eliminates the need for synchronizing the shared read operations, which results in a significant overhead reduction. Comparing to the previous state-of-the-art approach of deterministic replay, Stride reduces, on average, 2.5 times of runtime overhead and produces, on average, 3.88 times smaller logs.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227130","Concurrency;Replaying;Debugging","Couplings;Instruction sets;Schedules;Law;Runtime;Instruments","","12","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"PTPDroid: Detecting Violated User Privacy Disclosures to Third-Parties of Android Apps","Z. Tan; W. Song","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","473","485","Android apps frequently access personal information to provide customized services. Since such information is sensitive in general, regulators require Android app vendors to publish privacy policies that describe what information is collected and why it is collected. Existing work mainly focuses on the types of the collected data but seldom considers the entities that collect user privacy, which could falsely classify problematic declarations about user privacy collected by third-parties into clear disclosures. To address this problem, we propose PTPDroid, a flow-to-policy consistency checking approach and an automated tool, to comprehensively uncover from the privacy policy the violated disclosures to third-parties. Our experiments on real-world apps demonstrate the effectiveness and superiority of PTPDroid, and our empirical study on 1,000 popular real-world apps reveals that violated user privacy disclosures to third-parties are prevalent in practice.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172832","Android app;privacy policy;third-party entities;violation detection;taint analysis;empirical study","Privacy;Data privacy;Codes;Regulators;Static analysis;Benchmark testing;Natural language processing","","4","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"APICAD: Augmenting API Misuse Detection through Specifications from Code and Documents","X. Wang; L. Zhao","Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China; Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, School of Cyber Science and Engineering, Wuhan University, Wuhan, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","245","256","Using API should follow its specifications. Otherwise, it can bring security impacts while the functionality is damaged. To detect API misuse, we need to know what its specifications are. In addition to being provided manually, current tools usually mine the majority usage in the existing codebase as specifications, or capture specifications from its relevant texts in human language. However, the former depends on the quality of the codebase itself, while the latter is limited to the irregularity of the text. In this work, we observe that the information carried by code and documents can complement each other. To mitigate the demand for a high-quality codebase and reduce the pressure to capture valid information from texts, we present APICAD to detect API misuse bugs of C/C++ by combining the specifications mined from code and documents. On the one hand, we effectively build the contexts for API invocations and mine specifications from them through a frequency-based method. On the other hand, we acquire the specifications from documents by using lightweight keyword-based and NLP-assisted techniques. Finally, the combined specifications are generated for bug detection. Experiments show that APICAD can handle diverse API usage semantics to deal with different types of API misuse bugs. With the help of APICAD, we report 153 new bugs in Curl, Httpd, OpenSSL and Linux kernel, 145 of which have been confirmed and 126 have applied our patches.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00032","National Natural Science Foundation of China(grant numbers:62172305); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172771","","Codes;Text analysis;Linux;Computer bugs;Semantics;Prototypes;Benchmark testing","","3","","72","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Aries: Efficient Testing of Deep Neural Networks via Labeling-Free Accuracy Estimation","Q. Hu; Y. Guo; X. Xie; M. Cordy; M. Papadakis; L. Ma; Y. L. Traon","University of Luxembourg, Luxembourg; Luxembourg Institute of Science and Technology, Luxembourg; Singapore Management University, Singapore; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Alberta, Canada; University of Luxembourg, Luxembourg",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1776","1787","Deep learning (DL) plays a more and more important role in our daily life due to its competitive performance in industrial application domains. As the core of DL-enabled systems, deep neural networks (DNNs) need to be carefully evaluated to ensure the produced models match the expected requirements. In practice, the de facto standard to assess the quality of DNNs in the industry is to check their performance (accuracy) on a collected set of labeled test data. However, preparing such labeled data is often not easy partly because of the huge labeling effort, i.e., data labeling is labor-intensive, especially with the massive new incoming unlabeled data every day. Recent studies show that test selection for DNN is a promising direction that tackles this issue by selecting minimal representative data to label and using these data to assess the model. However, it still requires human effort and cannot be automatic. In this paper, we propose a novel technique, named Aries, that can estimate the performance of DNNs on new unlabeled data using only the information obtained from the original test data. The key insight behind our technique is that the model should have similar prediction accuracy on the data which have similar distances to the decision boundary. We performed a large-scale evaluation of our technique on two famous datasets, CIFAR-10 and Tiny-ImageNet, four widely studied DNN models including ResNetl0l and DenseNetl21, and 13 types of data transformation methods. Results show that the estimated accuracy by Aries is only 0.03% - 2.60% off the true accuracy. Besides, Aries also outperforms the state-of-the-art labeling-free methods in 50 out of 52 cases and selection-labeling-based methods in 96 out of 128 cases.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00152","Luxembourg National Research Funds (FNR)(grant numbers:C18/IS/126697 67/STELLAR/LeTraon); JSPS KAKENHI(grant numbers:JP20H04168); JST-Mirai Program(grant numbers:JPMJMI20B8); Natural Sciences and Engineering Research Council of Canada(grant numbers:RGPIN-2021-02549,RGPAS-2021-00034,DGECR-2021-00019); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172681","deep learning testing;performance estimation;distribution shift","Deep learning;Uncertainty;Estimation;Artificial neural networks;Predictive models;Data models;Labeling","","3","","49","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Axis: Automatically fixing atomicity violations through solving control constraints","P. Liu; C. Zhang","Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","299","309","Atomicity, a general correctness criterion in concurrency programs, is often violated in real-world applications. The violations are difficult for developers to fix, making automatic bug fixing techniques attractive. The state of the art approach aims at automating the manual fixing process but cannot provide any theoretical reasoning and guarantees. We provide an automatic approach that applies well-studied discrete control theory to guarantee deadlocks are not introduced and maximal preservation of the concurrency of the original code. Under the hood, we reduce the problem of violation fixing to a constraint solving problem using the Petri net model. Our evaluation on 13 subjects shows that the slowdown incurred by our patches is only 40% of that of the state of the art. With the deadlock-free guarantee, our patches incur moderate overhead (around 10%), which is a worthwhile cost for safety.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227184","","Equations;System recovery;Mathematical model;Vectors;Computer bugs;Concurrent computing;Cognition","","39","1","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Amplifying tests to validate exception handling code","P. Zhang; S. Elbaum","Computer Science and Engineering Department, University of Nebraska, Lincoln, Lincolnshire, NE, USA; Computer Science and Engineering Department, University of Nebraska, Lincoln, Lincolnshire, NE, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","595","605","Validating code handling exceptional behavior is difficult, particularly when dealing with external resources that may be noisy and unreliable, as it requires: 1) the systematic exploration of the space of exceptions that may be thrown by the external resources, and 2) the setup of the context to trigger specific patterns of exceptions. In this work we present an approach that addresses those difficulties by performing an exhaustive amplification of the space of exceptional behavior associated with an external resource that is exercised by a test suite. Each amplification attempts to expose a program exception handling construct to new behavior by mocking an external resource so that it returns normally or throws an exception following a predefined pattern. Our assessment of the approach indicates that it can be fully automated, is powerful enough to detect 65% of the faults reported in the bug reports of this kind, and is precise enough that 77% of the detected anomalies correspond to faults fixed by the developers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227157","Test transformation;exception handling","Space exploration;Aerospace electronics;Instruments;Androids;Humanoid robots;Noise measurement;Media","","38","1","28","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Uncovering performance problems in Java applications with reference propagation profiling","D. Yan; G. Xu; A. Rountev","Department of Computer Science and Engineering, Ohio State Uinversity, USA; Department of Computer Science, University of California, Irvine, USA; Department of Computer Science and Engineering, Ohio State Uinversity, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","134","144","Many applications suffer from run-time bloat: excessive memory usage and work to accomplish simple tasks. Bloat significantly affects scalability and performance, and exposing it requires good diagnostic tools. We present a novel analysis that profiles the run-time execution to help programmers uncover potential performance problems. The key idea of the proposed approach is to track object references, starting from object creation statements, through assignment statements, and eventually statements that perform useful operations. This propagation is abstracted by a representation we refer to as a reference propagation graph. This graph provides path information specific to reference producers and their run-time contexts. Several client analyses demonstrate the use of reference propagation profiling to uncover runtime inefficiencies. We also present a study of the properties of reference propagation graphs produced by profiling 36 Java programs. Several cases studies discuss the inefficiencies identified in some of the analyzed programs, as well as the significant improvements obtained after code optimizations.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227199","","Resource management;Vectors;Context;Data structures;Receivers;Java;Optimization","","18","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Learning Graph-based Code Representations for Source-level Functional Similarity Detection","J. Liu; J. Zeng; X. Wang; Z. Liang",National University of Singapore; National University of Singapore; University of Science and Technology of China; University of Science and Technology of China,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","345","357","Detecting code functional similarity forms the basis of various software engineering tasks. However, the detection is challenging as functionally similar code fragments can be implemented differently, e.g., with irrelevant syntax. Recent studies incorporate program dependencies as semantics to identify syntactically different yet semantically similar programs, but they often focus only on local neighborhoods (e.g., one-hop dependencies), limiting the expressiveness of program semantics in modeling functionalities. In this paper, we present Tailor that explicitly exploits deep graph-structured code features for functional similarity detection. Given source-level programs, Tailor first represents them into code property graphs (CPGs) - which combine abstract syntax trees, control flow graphs, and data flow graphs - to collectively reason about program syntax and semantics. Then, Tailor learns representations of CPGs by applying a CPG-based neural network (CPGNN) to iteratively propagate information on them. It improves over prior work on code representation learning through a new graph neural network (GNN) tailored to CPG structures instead of the off-the-shelf GNNs used previously. We systematically evaluate Tailor on C and Java programs using two public benchmarks. Experimental results show that Tailor outperforms the state-of-the-art approaches, achieving 99.8% and 99.9% F-scores in code clone detection and 98.3% accuracy in source code classification.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172499","","Representation learning;Codes;Source coding;Semantics;Cloning;Syntactics;Graph neural networks","","8","","86","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Revisiting Android App Categorization","M. Alecci; J. Samhi; T. F. Bissyandé; J. Klein","SnT, University of Luxembourg, Luxembourg, Luxembourg; CISPA Helmholtz Center for Information Security, Saarbrücken, Germany; SnT, University of Luxembourg, Luxembourg, Luxembourg; SnT, University of Luxembourg, Luxembourg, Luxembourg",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2518","2529","Numerous tools rely on automatic categorization of Android apps as part of their methodology. However, incorrect categorization can lead to inaccurate outcomes, such as a malware detector wrongly flagging a benign app as malicious. One such example is the SlideIT Free Keyboard app, which has over 500 000 downloads on Google Play. Despite being a “Keyboard” app, it is often wrongly categorized alongside “Language” apps due to the app's description focusing heavily on language support, resulting in incorrect analysis out-comes, including mislabeling it as a potential malware when it is actually a benign app. Hence, there is a need to improve the categorization of Android apps to benefit all the tools relying on it. In this paper, we present a comprehensive evaluation of existing Android app categorization approaches using our new ground-truth dataset. Our evaluation demonstrates the notable superior-ity of approaches that utilize app descriptions over those solely relying on data extracted from the APK file, while also leaving space for potential improvement in the former category. Thus, we propose two innovative approaches that effectively outperform the performance of existing methods in both description-based and APK-based methodologies. Finally, by employing our novel description-based approach, we have successfully demonstrated that adopting a higher-performing categorization method can significantly benefit tools reliant on app categorization, leading to an improvement in their overall performance. This highlights the sig-nificance of developing advanced and efficient app categorization methodologies for improved results in software engineering tasks.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639094","FNR(grant numbers:NCER22/IS/16570468/NCER-FT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549370","Android Security;Static Analysis;App Categorization","Keyboards;Focusing;Detectors;Malware;Internet;Data mining;Task analysis","","2","","61","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Malcertain: Enhancing Deep Neural Network Based Android Malware Detection by Tackling Prediction Uncertainty","H. Li; G. Xu; L. Wang; X. Xiao; X. Luo; G. Xu; H. Wang","Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Beijing University of Posts and Telecommunications, China; Arizona State University, USA; The Hong Kong Polytechnic University, China; Harbin Institute of Technology, Shenzhen, China; Huazhong University of Science and Technology, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1850","1862","The long-lasting Android malware threat has attracted significant research efforts in malware detection. In particular, by modeling malware detection as a classification problem, machine learning based approaches, especially deep neural network (DNN) based approaches, are increasingly being used for Android malware detection and have achieved significant improvements over other detection approaches such as signature-based approaches. However, as Android malware evolve rapidly and the presence of adversarial samples, DNN models trained on early constructed samples often yield poor decisions when used to detect newly emerging samples. Fundamentally, this phenomenon can be summarized as the uncertainly in the data (noise or randomness) and the weakness in the training process (insufficient training data). Overlooking these uncertainties poses risks in the model predictions. In this paper, we take the first step to estimate the prediction uncertainty of DNN models in malware detection and leverage these estimates to enhance Android malware detection techniques. Specifically, be-sides training a DNN model to predict malware, we employ several uncertainty estimation methods to train a Correction Model that de-termines whether a sample is correctly or incorrectly predicted by the DNN model. We then leverage the estimated uncertainty output by the Correction Model to correct the prediction results, improving the accuracy of the DNN model. Experimental results show that our proposed Malcertain effectively improves the accuracy of the underlying DNN models for Android malware detection by around 21% and significantly improves the detection effectiveness of adversarial Android malware samples by up to 94.38%. Our research sheds light on the promising direction that leverages prediction uncertainty to improve prediction-based software engineering tasks.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549703","Android Malware Detection;Uncertainty;DNN","Training;Measurement;Uncertainty;Accuracy;Estimation;Training data;Artificial neural networks","","1","","78","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Traces of Memorisation in Large Language Models for Code","A. Al-Kaswan; M. Izadi; A. Van Deursen","Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","944","955","Large language models have gained significant popularity because of their ability to generate human-like text and potential applications in various fields, such as Software Engineering. Large language models for code are commonly trained on large unsanitised corpora of source code scraped from the internet. The content of these datasets is memorised and can be extracted by attackers with data extraction attacks. In this work, we explore memorisation in large language models for code and compare the rate of memorisation with large language models trained on natural language. We adopt an existing benchmark for natural language and construct a benchmark for code by identifying samples that are vulnerable to attack. We run both benchmarks against a variety of models, and perform a data extraction attack. We find that large language models for code are vulnerable to data extraction attacks, like their natural language counterparts. From the training data that was identified to be potentially extractable we were able to extract 47% from a CodeGen-Mono-16B code completion model. We also observe that models memorise more, as their parameter count grows, and that their pretraining data are also vulnerable to attack. We also find that data carriers are memorised at a higher rate than regular code or documentation and that different model architectures memorise different samples. Data leakage has severe outcomes, so we urge the research community to further investigate the extent of this phenomenon using a wider range of models and extraction techniques in order to build safeguards to mitigate this issue.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548792","Large Language Models;Privacy;Memorisation;Data Leakage","Codes;Natural languages;Memory architecture;Training data;Games;Documentation;Benchmark testing","","1","","53","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"On Extracting Specialized Code Abilities from Large Language Models: A Feasibility Study","Z. Li; C. Wang; P. Ma; C. Liu; S. Wang; D. Wu; C. Gao; Y. Liu","The Hong Kong University of Science and Technology, Hong Kong SAR, China; The Chinese University of Hong Kong, Hong Kong SAR, China; The Hong Kong University of Science and Technology, Hong Kong SAR, China; National University of Singapore, Singapore, Singapore; The Hong Kong University of Science and Technology, Hong Kong SAR, China; Nanyang Technological University, Singapore, Singapore; Harbin Institute of Technology, Shenzhen, China; Nanyang Technological University, Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","893","905","Recent advances in large language models (LLMs) significantly boost their usage in software engineering. However, training a well-performing LLM demands a substantial workforce for data collection and annotation. Moreover, training datasets may be proprietary or partially open, and the process often requires a costly GPU cluster. The intellectual property value of commercial LLMs makes them attractive targets for imitation attacks, but creating an imitation model with comparable parameters still incurs high costs. This motivates us to explore a practical and novel direction: slicing commercial black-box LLMs using medium-sized backbone models. In this paper, we explore the feasibility of launching imitation attacks on LLMs to extract their specialized code abilities, such as “code synthesis” and “code translation:’ We systematically investigate the effectiveness of launching code ability extraction attacks under different code-related tasks with multiple query schemes, including zero-shot, in-context, and Chain-of-Thought. We also design response checks to refine the outputs, leading to an effective imitation training process. Our results show promising outcomes, demonstrating that with a reasonable number of queries, attackers can train a medium-sized backbone model to replicate specialized code behaviors similar to the target LLMs. We summarize our findings and insights to help researchers better understand the threats posed by imitation attacks, including revealing a practical attack surface for generating adversarial code examples against LLMs.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548878","Large Language Models;Imitation Attacks","Training;Codes;Costs;Annotations;Graphics processing units;Closed box;Intellectual property","","","","91","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Data-Driven Evidence-Based Syntactic Sugar Design","D. OBrien; R. Dyer; T. N. Nguyen; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; University of Nebraska-Lincoln, Lincoln, NE, USA; Computer Science Department, University of Texas at Dallas, Dallas, Texas, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2506","2517","Programming languages are essential tools for developers, and their evolution plays a crucial role in supporting the activities of developers. One instance of programming language evolution is the introduction of syntactic sugars, which are additional syntax elements that provide alternative, more readable code constructs. However, the process of designing and evolving a programming language has traditionally been guided by anecdotal experiences and intuition. Recent advances in tools and methodologies for mining open-source repositories have enabled developers to make data-driven software engineering decisions. In light of this, this paper proposes an approach for motivating data-driven programming evolution by applying frequent subgraph mining techniques to a large dataset of 166,827,154 open-source Java methods. The dataset is mined by generalizing Java control-flow graphs to capture broad programming language usages and instances of duplication. Frequent subgraphs are then extracted to identify potentially impactful opportunities for new syntactic sugars. Our diverse results demonstratex the benefits of the proposed technique by identifying new syntactic sugars involving a variety of programming constructs that could be implemented in Java, thus simplifying frequent code idioms. This approach can potentially provide valuable insights for Java language designers, and serve as a proof-of-concept for data-driven programming language design and evolution.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639580","National Science Foundation(grant numbers:CCF-15-18897,CNS-15-13263,CCF-19-34884,CNS-21-20448,CNS-21-20386,CCF-22-23812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549572","syntactic sugars;data-driven language design;subgraph mining","Computer languages;Java;Codes;Syntactics;Programming;Data mining;Sugar","","","","43","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"ChatGPT-Resistant Screening Instrument for Identifying Non-Programmers","R. Serafini; C. Otto; S. A. Horstmann; A. Naiakshina","Ruhr University Bochum, Bochum, Germany; Ruhr University Bochum, Bochum, Germany; Ruhr University Bochum, Bochum, Germany; Ruhr University Bochum, Bochum, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2231","2243","To ensure the validity of software engineering and IT security studies with professional programmers, it is essential to identify participants without programming skills. Existing screening questions are efficient, cheating robust, and effectively differentiate programmers from non-programmers. However, the release of ChatGPT raises concerns about their continued effectiveness in identifying non-programmers. In a simulated attack, we showed that Chat-GPT can easily solve existing screening questions. Therefore, we designed new ChatGPT-resistant screening questions using visual concepts and code comprehension tasks. We evaluated 28 screening questions in an online study with 121 participants involving programmers and non-programmers. Our results showed that questions using visualizations of well-known programming concepts performed best in differentiating between programmers and non-programmers. Participants prompted to use ChatGPT struggled to solve the tasks. They considered ChatGPT ineffective and changed their strategy after a few screening questions. In total, we present six ChatGPT-resistant screening questions that effectively identify non-programmers. We provide recommendations on setting up a ChatGPT-resistant screening instrument that takes less than three minutes to complete by excluding 99.47% of non-programmers while including 94.83% of programmers.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639075","Deutsche Forschungsgemeinschaft (DFG, German Research Foundation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549231","chatgpt;programmer screening;developer study;study protection","Visualization;Codes;Instruments;Switches;Chatbots;Security;Task analysis","","","","54","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Prism: Decomposing Program Semantics for Code Clone Detection Through Compilation","H. Li; S. Wang; W. Quan; X. Gong; H. Su; J. Zhang","College of Computer Science, Nankai University, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China; College of Computer Science, Nankai University, Tianjin, China; National University of Defense Technology, Changsha, China; College of Computer Science, Nankai University, Tianjin, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2681","2693","Code clone detection (CCD) is of critical importance in software engineering, while semantic similarity is a key evaluation factor for CCD. The embedding technique, which represents an object using a numerical vector, is utilized to generate code representations, where code snippets with similar semantics (clone pairs) should have similar vectors. However, due to the diversity and flexibility of high-level program languages, the code representation of clone pairs may be inconsistent. Assembly code provides the program execution trace and can normalize the diversity of high-level languages in terms of the program behavior semantics. After revisiting the assembly language, we find that different assembly codes can align with the computational logic and memory access patterns of cloned pairs. Therefore, the use of multiple assembly languages can capture the behavior semantics to enhance the understanding of programs. Thus, we propose Prism, a new method for code clone detection fusing behavior semantics from multiple architecture assembly code, which directly captures multilingual domains' syntax and semantic information. Additionally, we introduce a multi-feature fusion strategy that leverages global information interaction to expand the representation space. This fusion process allows us to capture the complementary information from each feature and leverage the relationships between them to create a more expressive representation of the code. After testing the OJClone dataset, the Prism model exhibited exceptional performance with precision and recall scores of 0.999 and 0.999, respectively.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548251","Code Clone Detection;Behavior Semantics;CISC and RISC;Feature Fusion","Charge coupled devices;Codes;Semantics;Cloning;Computer architecture;Syntactics;Vectors","","","","65","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Fairify: Fairness Verification of Neural Networks","S. Biswas; H. Rajan","School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1546","1558","Fairness of machine learning (ML) software has become a major concern in the recent past. Although recent research on testing and improving fairness have demonstrated impact on real-world software, providing fairness guarantee in practice is still lacking. Certification of ML models is challenging because of the complex decision-making process of the models. In this paper, we proposed Fairify, an SMT-based approach to verify individual fairness property in neural network (NN) models. Individual fairness ensures that any two similar individuals get similar treatment irrespective of their protected attributes e.g., race, sex, age. Verifying this fairness property is hard because of the global checking and non-linear computation nodes in NN. We proposed sound approach to make individual fairness verification tractable for the developers. The key idea is that many neurons in the NN always remain inactive when a smaller part of the input domain is considered. So, Fairify leverages white-box access to the models in production and then apply formal analysis based pruning. Our approach adopts input partitioning and then prunes the NN for each partition to provide fairness certification or counterexample. We leveraged interval arithmetic and activation heuristic of the neurons to perform the pruning as necessary. We evaluated Fairify on 25 real-world neural networks collected from four different sources, and demonstrated the effectiveness, scalability and performance over baseline and closely related work. Fairify is also configurable based on the domain and size of the NN. Our novel formulation of the problem can answer targeted verification queries with relaxations and counterexamples, which have practical implications.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00134","NSF(grant numbers:CCF-19-34884,CCF-22-23812,CNS-21-20448); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172654","fairness;verification;machine learning","Computational modeling;Scalability;Neurons;Artificial neural networks;Production;Machine learning;Biological neural networks","","6","","74","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"ContraBERT: Enhancing Code Pre-trained Models via Contrastive Learning","S. Liu; B. Wu; X. Xie; G. Meng; Y. Liu","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Singapore Management University, Singapore; SKLOIS, Institute of Information Engineering, Chinese Academy of Sciences, China; Nanyang Technological University, Singapore",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2476","2487","Large-scale pre-trained models such as CodeBERT, GraphCodeBERT have earned widespread attention from both academia and industry. Attributed to the superior ability in code representation, they have been further applied in multiple downstream tasks such as clone detection, code search and code translation. However, it is also observed that these state-of-the-art pre-trained models are susceptible to adversarial attacks. The performance of these pre-trained models drops significantly with simple perturbations such as renaming variable names. This weakness may be inherited by their downstream models and thereby amplified at an unprecedented scale. To this end, we propose an approach namely ContraBERT that aims to improve the robustness of pre-trained models via contrastive learning. Specifically, we design nine kinds of simple and complex data augmentation operators on the programming language (PL) and natural language (NL) data to construct different variants. Furthermore, we continue to train the existing pre-trained models by masked language modeling (MLM) and contrastive pre-training task on the original samples with their augmented variants to enhance the robustness of the model. The extensive ex-periments demonstrate that ContraBERT can effectively improve the robustness of the existing pre-trained models. Further study also confirms that these robustness-enhanced models provide improvements as compared to original models over four popular downstream tasks.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172726","Code Pre-trained Models;Contrastive Learning;Model Robustness","Industries;Computer languages;Codes;Perturbation methods;Natural languages;Cloning;Data augmentation","","14","","76","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Finding Causally Different Tests for an Industrial Control System","C. M. Poskitt; Y. Chen; J. Sun; Y. Jiang","Singapore Management University, Singapore; ShanghaiTech University, China; Singapore Management University, Singapore; Tsinghua University, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2578","2590","Industrial control systems (ICSs) are types of cyber-physical systems in which programs, written in languages such as ladder logic or structured text, control industrial processes through sensing and actuating. Given the use of ICSs in critical infrastructure, it is important to test their resilience against manipulations of sensor/actuator inputs. Unfortunately, existing methods fail to test them comprehensively, as they typically focus on finding the simplest-to-craft manipulations for a testing goal, and are also unable to determine when a test is simply a minor permutation of another, i.e. based on the same causal events. In this work, we propose a guided fuzzing approach for finding 'meaningfully different’ tests for an ICS via a general formalisation of sensor/actuator-manipulation strategies. Our algorithm identifies the causal events in a test, generalises them to an equivalence class, and then updates the fuzzing strategy so as to find new tests that are causally different from those already identified. An evaluation of our approach on a real-world water treatment system shows that it is able to find 106% more causally different tests than the most comparable fuzzer. While we focus on diversifying the test suite of an ICS, our formalisation may be useful for other fuzzers that intercept communication channels.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172721","Cyber-physical systems;fuzzing;test diversity;equivalence classes;causality","Integrated circuits;Process control;Communication channels;Fuzzing;Model checking;Mathematical models;Sensors","","2","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Testing Graph Database Systems via Equivalent Query Rewriting","Q. Mang; A. Fang; B. Yu; H. Chen; P. He","School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1762","1773","Graph Database Management Systems (GDBMS), which utilize graph models for data storage and execute queries via graph tra-versals, have seen ubiquitous usage in real-world scenarios such as recommendation systems, knowledge graphs, and social networks. Much like Relational Database Management Systems (RDBMS), GDBMS are not immune to bugs. These bugs typically manifest as logic errors that yield incorrect results (e.g., omitting a node that should be included), performance bugs (e.g., long execution time caused by redundant graph scanning), and exception issues (e.g., unexpected or missing exceptions). This paper adapts Equivalent Query Rewriting (EQR) to GDBMS testing. EQR rewrites a GDBMS query into equivalent ones that trigger distinct query plans, and checks whether they exhibit discrepancies in system behaviors. To facilitate the realization of EQR, we propose a general concept called Abstract Syntax Graph (ASG). Its core idea is to embed the semantics of a base query into the paths of a graph, which can be utilized to generate new queries with customized properties (e.g., equivalence). Given a base query, an ASG is constructed and then an equivalent query can be gener-ated by finding paths collectively carrying the complete semantics of the base query. To this end, we further design Random Walk Covering (RWC), a simple yet effective path covering algorithm. As a practical implementation of these ideas, we develop a tool GRev, which has successfully detected 22 previously unknown bugs across 5 popular GDBMS, with 15 of them being confirmed. In particular, 14 of the detected bugs are related to improper implementation of graph data retrieval in GDBMS, which is challenging to identify for existing techniques.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639200","National Natural Science Foundation of China(grant numbers:62102340); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549434","Graph databases;Metamorphic testing;Query rewriting","Social networking (online);Computer bugs;Semantics;Relational databases;Syntactics;Database systems;Logic","","","","44","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Deep Learning or Classical Machine Learning? An Empirical Study on Log-Based Anomaly Detection","B. Yu; J. Yao; Q. Fu; Z. Zhong; H. Xie; Y. Wu; Y. Ma; P. He","School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Huawei Cloud Computing Technologies CO., LTD, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China; Huawei Cloud Computing Technologies CO., LTD, China; Huawei Cloud Computing Technologies CO., LTD, China; School of Data Science, The Chinese University of Hong Kong, Shenzhen (CUHK-Shenzhen), China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","403","415","While deep learning (DL) has emerged as a powerful technique, its benefits must be carefully considered in relation to computational costs. Specifically, although DL methods have achieved strong performance in log anomaly detection, they often require extended time for log preprocessing, model training, and model inference, hindering their adoption in online distributed cloud systems that require rapid deployment of log anomaly detection service. This paper investigates the superiority of DL methods compared to simpler techniques in log anomaly detection. We evaluate basic algorithms (e.g., KNN, SLFN) and DL approaches (e.g., CNN) on five public log anomaly detection datasets (e.g., HDFS). Our findings demonstrate that simple algorithms outperform DL methods in both time efficiency and accuracy. For instance, on the Thunderbird dataset, the K-nearest neighbor algorithm trains 1,000 times faster than NeuralLog while achieving a higher F1-Score by 0.0625. We also identify three factors contributing to this phenomenon, which are: (1) redundant log preprocessing strategies, (2) dataset simplicity, and (3) the nature of binary classification in log anomaly detection. To assess the necessity of DL, we propose LightAD, an architecture that optimizes training time, inference time, and performance score. With automated hyper-parameter tuning, LightAD allows fair comparisons among log anomaly detection models, enabling engineers to evaluate the suitability of complex DL methods. Our findings serve as a cautionary tale for the log anomaly detection community, highlighting the need to critically analyze datasets and research tasks before adopting DL approaches. Researchers proposing computationally expensive models should benchmark their work against lightweight algorithms to ensure a comprehensive evaluation.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623308","National Natural Science Foundation of China(grant numbers:62102340); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549148","Log analysis;anomaly detection;dataset;empirical study","Training;Deep learning;Computational modeling;Computer architecture;Benchmark testing;Task analysis;Anomaly detection","","2","","89","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Triggers for Reactive Synthesis Specifications","G. Amram; D. Ma'ayan; S. Maoz; O. Pistiner; J. O. Ringert","Tel Aviv University, Israel; Tel Aviv University, Israel; Tel Aviv University, Israel; Tel Aviv University, Israel; Bauhaus University Weimar, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","729","741","Reactive synthesis is an automated procedure to obtain a correct-by-construction reactive system from its temporal logic specification. Two of the main challenges in bringing reactive synthesis to practice are its very high worst-case complexity and the difficulty of writing declarative specifications using basic LTL operators. To address the first challenge, researchers have suggested the GR(1) fragment of LTL, which has an efficient poly-nomial time symbolic synthesis algorithm. To address the second challenge, specification languages include higher-level constructs that aim at allowing engineers to write succinct and readable specifications. One such construct is the triggers operator, as supported, e.g., in the Property Specification Language (PSL). In this work we introduce triggers into specifications for reactive synthesis. The effectiveness of our contribution relies on a novel encoding of regular expressions using symbolic finite automata (SFA) and on a novel semantics for triggers that, in contrast to PSL triggers, admits an efficient translation into GR(1). We show that our triggers are expressive and succinct, and prove that our encoding is optimal. We have implemented our ideas on top of the Spectra language and synthesizer. We demonstrate the usefulness and effectiveness of using triggers in specifications for synthesis, as well as the challenges involved in using them, via a study of more than 300 triggers written by undergraduate students who participated in a project class on writing specifications for synthesis. To the best of our knowledge, our work is the first to introduce triggers into specifications for reactive synthesis.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172724","Reactive synthesis;Formal specifications","Synthesizers;Semantics;Automata;Writing;Encoding;Specification languages;Computational efficiency","","1","","52","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Decomposing a Recurrent Neural Network into Modules for Enabling Reusability and Replacement","S. M. Imtiaz; F. Batole; A. Singh; R. Pan; B. D. Cruz; H. Rajan","Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; IBM Research, Yorktown Heights, NY, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1020","1032","Can we take a recurrent neural network (RNN) trained to translate between languages and augment it to support a new natural language without retraining the model from scratch? Can we fix the faulty behavior of the RNN by replacing portions associated with the faulty behavior? Recent works on decomposing a fully connected neural network (FCNN) and convolutional neural network (CNN) into modules have shown the value of engineering deep models in this manner, which is standard in traditional SE but foreign for deep learning models. However, prior works focus on the image-based multi-class classification problems and cannot be applied to RNN due to (a) different layer structures, (b) loop structures, (c) different types of input-output architectures, and (d) usage of both non-linear and logistic activation functions. In this work, we propose the first approach to decompose an RNN into modules. We study different types of RNNs, i.e., Vanilla, LSTM, and GRU. Further, we show how such RNN modules can be reused and replaced in various scenarios. We evaluate our approach against 5 canonical datasets (i.e., Math QA, Brown Corpus, Wiki-toxicity, Cline OOS, and Tatoeba) and 4 model variants for each dataset. We found that decomposing a trained model has a small cost (Accuracy: -0.6%, BLEU score: +0.10%). Also, the decomposed modules can be reused and replaced without needing to retrain.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172723","recurrent neural networks;decomposing;modules;modularity","Deep learning;Recurrent neural networks;Costs;Natural languages;Computer architecture;Behavioral sciences;Convolutional neural networks","","1","","45","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Trace-based Multi-Dimensional Root Cause Localization of Performance Issues in Microservice Systems","C. Zhang; Z. Dong; X. Peng; B. Zhang; M. Chen","Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1347","1358","Modern microservice systems have become increasingly complicated due to the dynamic and complex interactions and runtime environment. It leads to the system vulnerable to performance issues caused by a variety of reasons, such as the runtime environments, communications, coordinations, or implementations of services. Traces record the detailed execution process of a request through the system and have been widely used in performance issues diagnosis in microservice systems. By identifying the execution processes and attribute value combinations that are common in anomalous traces but rare in normal traces, engineers may localize the root cause of a performance issue into a smaller scope. However, due to the complex structure of traces and the large number of attribute combinations, it is challenging to find the root cause from the huge search space. In this paper, we propose TraceContrast, a trace-based multidimensional root cause localization approach. TraceContrast uses a sequence representation to describe the complex structure of a trace with attributes of each span. Based on the representation, it combines contrast sequential pattern mining and spectrum analysis to localize multidimensional root causes efficiently. Experimental studies on a widely used microservice benchmark show that TraceContrast outperforms existing approaches in both multidimensional and instance-dimensional root cause localization with significant accuracy advantages. Moreover, Trace-Contrast is efficient and its efficiency can be further improved by parallel execution.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549362","Microservice;Root Cause Analysis;Tracing","Location awareness;Runtime environment;Accuracy;Microservice architectures;Benchmark testing;Data mining;Spectral analysis","","","","51","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Green AI: Do Deep Learning Frameworks Have Different Costs?","S. Georgiou; M. Kechagia; T. Sharma; F. Sarro; Y. Zou",Queen's University; University College London; Dalhousie Uninversity; University College London; Queen's University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1082","1094","The use of Artificial Intelligence (AI), and more specifically of Deep Learning (DL), in modern software systems, is nowadays widespread and continues to grow. At the same time, its usage is energy de-manding and contributes to the increased CO2 emissions, and has a great financial cost as well. Even though there are many studies that examine the capabilities of DL, only a few focus on its green aspects, such as energy consumption. This paper aims at raising awareness of the costs incurred when using different DL frameworks. To this end, we perform a thorough empirical study to measure and compare the energy consumption and run-time performance of six different DL models written in the two most popular DL frameworks, namely PYTORCH and TENSORFLOW. We use a well-known benchmark of DL models, Deep LEARNINGEXAMPLES, created by NVIDIA, to compare both the training and inference costs of DL. Finally, we manually investigate the functions of these frameworks that took most of the time to execute in our experiments. The results of our empirical study reveal that there is a statistically significant difference between the cost incurred by the two DL frameworks in 94% of the cases studied. While Tensorflow achieves significantly better energy and run-time performance than PYTORCH, and with large effect sizes in 100% of the cases for the training phase, PYTORCH instead exhibits significantly better energy and run-time performance than TENSORFLOW in the inference phase for 66% of the cases, always, with large effect sizes. Such a large difference in performance costs does not, however, seem to affect the accuracy of the models produced, as both frameworks achieve comparable scores under the same configurations. Our manual analysis, of the documentation and source code of the functions examined, reveals that such a difference in performance costs is under-documented, in these frameworks. This suggests that developers need to improve the documentation of their DL frameworks, the source code of the functions used in these frameworks, as well as to enhance existing DL algorithms.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510221","ERC(grant numbers:741278); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793951","Energy consumption;run-time performance;deep learning;APIS","Training;Deep learning;Energy consumption;Costs;Codes;Documentation;Manuals","","25","","89","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Learning Deep Semantics for Test Completion","P. Nie; R. Banerjee; J. J. Li; R. J. Mooney; M. Gligoric","UT, Austin, USA; UT, Austin, USA; UT, Austin, USA; UT, Austin, USA; UT, Austin, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2111","2123","Writing tests is a time-consuming yet essential task during software development. We propose to leverage recent advances in deep learning for text and code generation to assist developers in writing tests. We formalize the novel task of test completion to automatically complete the next statement in a test method based on the context of prior statements and the code under test. We develop TECo-a deep learning model using code semantics for test completion. The key insight underlying TECO is that predicting the next statement in a test method requires reasoning about code execution, which is hard to do with only syntax-level data that existing code completion models use. Teco extracts and uses six kinds of code semantics data, including the execution result of prior statements and the execution context of the test method. To provide a testbed for this new task, as well as to evaluate TECO, we collect a corpus of 130,934 test methods from 1,270 open-source Java projects. Our results show that Teco achieves an exact-match accuracy of 18, which is 29% higher than the best baseline using syntax-level data only. When measuring functional correctness of generated next statement, Teco can generate runnable code in 29% of the cases compared to 18% obtained by the best baseline. Moreover, Teco is sianificantly better than prior work on test oracle generation.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172620","test completion;deep neural networks;programming language semantics","Deep learning;Measurement;Java;Codes;Semantics;Writing;Predictive models","","14","","91","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Towards language-independent Brown Build Detection","D. Olewicki; M. Nayrolles; B. Adams","Polytechnique Montréal, Montréal, Canada; Ubisoft Montréal, Montréal, Canada; Queen's University, Kingston, Canada",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2177","2188","In principle, continuous integration (CI) practices allow modern software organizations to build and test their products after each code change to detect quality issues as soon as possible. In reality, issues with the build scripts (e.g., missing dependencies) and/or the presence of “flaky tests” lead to build failures that essentially are false positives, not indicative of actual quality problems of the source code. For our industrial partner, which is active in the video game industry, such “brown builds” not only require multidisci-plinary teams to spend more effort interpreting or even re-running the build, leading to substantial redundant build activity, but also slows down the integration pipeline. Hence, this paper aims to prototype and evaluate approaches for early detection of brown build results based on textual similarity to build logs of prior brown builds. The approach is tested on 7 projects (6 closed-source from our industrial collaborators and 1 open-source, Graphviz). We find that our model manages to detect brown builds with a mean F1-score of 53% on the studied projects, which is three times more than the best baseline considered, and at least as good as human experts (but with less effort). Furthermore, we found that cross-project prediction can be used for a project's onboarding phase, that a training set of 30-weeks works best, and that our retraining heuristics keep the F1-score higher than the baseline, while retraining only every 4–5 weeks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793972","Brown Build;Build automation;Continuous integration;Classification;Concept drift","Training;Solid modeling;Time-frequency analysis;Codes;Switches;Predictive models;Solids","","6","","38","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Semantic Image Fuzzing of AI Perception Systems","T. Woodlief; S. Elbaum; K. Sullivan","University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA; University of Virginia, Charlottesville, Virginia, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1958","1969","Perception systems enable autonomous systems to interpret raw sensor readings of the physical world. Testing of perception systems aims to reveal misinterpretations that could cause system failures. Current testing methods, however, are inadequate. The cost of human interpretation and annotation of real-world input data is high, so manual test suites tend to be small. The simulation-reality gap reduces the validity of test results based on simulated worlds. And methods for synthesizing test inputs do not provide corresponding expected interpretations. To address these limitations, we developed semSensFuzz, a new approach to fuzz testing of perception systems based on semantic mutation of test cases that pair realworld sensor readings with their ground-truth interpretations. We implemented our approach to assess its feasibility and potential to improve software testing for perception systems. We used it to generate 150,000 semantically mutated image inputs for five state-of-the-art perception systems. We found that it synthesized tests with novel and subjectively realistic image inputs, and that it discovered inputs that revealed significant inconsistencies between the specified and computed interpretations. We also found that it produced such test cases at a cost that was very low compared to that of manual semantic annotation of real-world images.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510212","University of Virginia SEAS Fellowship(grant numbers:NSF#1924777,NSF#1909414); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793988","semantic fuzzing;autonomous systems;perception","Costs;Annotations;Autonomous systems;Semantics;Manuals;Fuzzing;Artificial intelligence","","4","","44","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Resource Usage and Optimization Opportunities in Workflows of GitHub Actions","I. Bouzenia; M. Pradel","University of Stuttgart, Stuttgart, Germany; University of Stuttgart, Stuttgart, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","279","290","Continuous integration and continuous delivery (CI/CD) has become a prevalent practice in software development. GitHub Actions is emerging as a popular platform for implementing CI/CD pipelines, called workflows, especially because the platform of-fers 2,000 minutes of computation for free to public repositories each month. To understand what these resources are used for and whether CI/CD could be more efficient, this paper presents the first comprehensive empirical study of resource usage and optimization opportunities of GitHub Action workflows. Our findings show that CI/CD imposes significant costs, e.g., $504 per year for an average paid-tier repository. The majority of the used resources is consumed by testing and building (91.2%), which is triggered by pull requests (50.7%), pushes (30.9%), and regularly scheduled workflows (15.5%). While existing optimizations, such as caching (adopted by 32.9% of paid-tier repositories), demonstrate a positive impact, they overall remain underutilized. This result underscores the need for enhanced documentation and tools to guide develop-ers toward more resource-efficient workflows. Moreover, we show that relatively simple changes in the platform, such as deactivating scheduled workflows when repositories are inactive, could result in reductions of execution time between 1.1% and 31.6% over the impacted workflows. Overall, we envision our findings to help improve the resource efficiency of CI/CD pipelines.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548699","","Costs;Pipelines;Ecosystems;Documentation;Complexity theory;Resource management;Optimization","","1","","41","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Automated Summarization of Stack Overflow Posts","B. Kou; M. Chen; T. Zhang","Purdue University, West Lafayette, USA; University of Southern California, Los Angeles, USA; Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1853","1865","Software developers often resort to Stack Overflow (SO) to fill their programming needs. Given the abundance of relevant posts, navigating them and comparing different solutions is tedious and time-consuming. Recent work has proposed to automatically summarize SO posts to concise text to facilitate the navigation of SO posts. However, these techniques rely only on information retrieval methods or heuristics for text summarization, which is insufficient to handle the ambiguity and sophistication of natural language. This paper presents a deep learning based framework called Assortfor SO post summarization. Assortincludes two complementary learning methods, $\mathbf{Assort}_{S}$ and $\mathbf{Assort}_{IS}$, to address the lack of labeled training data for SO post summarization. $\mathbf{Assort}_{S}$ is designed to directly train a novel ensemble learning model with BERT embeddings and domain-specific features to account for the unique characteristics of SO posts. By contrast, $\mathbf{Assort}_{IS}$ is designed to reuse pre-trained models while addressing the domain shift challenge when no training data is present (i.e., zero-shot learning). Both $\mathbf{Assort}_{S}$ and $\mathbf{Assort}_{IS}$ outperform six existing techniques by at least 13% and 7% respectively in terms of the F1 score. Furthermore, a human study shows that participants significantly preferred summaries generated by $\mathbf{Assort}_{S}$ and $\mathbf{Assort}_{IS}$ over the best baseline, while the preference difference between $\mathbf{Assort}_{S}$ and $\mathbf{Assort}_{IS}$ was small.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172574","Stack Overflow;Text Summarization;Deep Learning","Learning systems;Navigation;Natural languages;Training data;Programming;Information retrieval;Data models","","1","","71","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"A Comprehensive Study of Learning-Based Android Malware Detectors Under Challenging Environments","C. Gao; G. Huang; H. Li; B. Wu; Y. Wu; W. Yuan","Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Huazhong University of Science and Technology, China; Nanyang Technological University, Singapore; Huazhong University of Science and Technology, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","115","127","Recent years have witnessed the proliferation of learning-based Android malware detectors. These detectors can be categorized into three types, String-based, Image-based and Graph-based. Most of them have achieved good detection performance under the ideal setting. In reality, however, detectors often face out-of-distribution samples due to the factors such as code obfuscation, concept drift (e.g., software development technique evolution and new malware category emergence), and adversarial examples (AEs). This problem has attracted increasing attention, but there is a lack of comparative studies that evaluate the existing various types of detectors under these challenging environments. In order to fill this gap, we select 12 representative detectors from three types of detectors, and evaluate them in the challenging scenarios involving code obfuscation, concept drift and AEs, respectively. Experimental results reveal that none of the evaluated detectors can maintain their ideal-setting detection performance, and the performance of different types of detectors varies significantly under various challenging environments. We identify several factors contributing to the performance deterioration of detectors, including the limitations of feature extraction methods and learning models. We also analyze the reasons why the detectors of different types show significant performance differences when facing code obfuscation, concept drift and AEs. Finally, we provide practical suggestions from the perspectives of users and researchers, respectively. We hope our work can help understand the detectors of different types, and provide guidance for enhancing their performance and robustness.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548991","Android Malware Detection;Machine Learning;Code Obfuscation;Concept Drift;Adversarial Examples","Codes;Detectors;Feature extraction;Malware;Robustness;Security;Faces","","1","","63","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Inferring Data Preconditions from Deep Learning Models for Trustworthy Prediction in Deployment","S. Ahmed; H. Gao; H. Rajan","Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA; Dept. of Computer Science, Iowa State University, Ames, IA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","440","452","Deep learning models are trained with certain assumptions about the data during the development stage and then used for prediction in the deployment stage. It is important to reason about the trustworthiness of the model's predictions with unseen data during deployment. Existing methods for specifying and verifying traditional software are insufficient for this task, as they cannot handle the complexity of DNN model architecture and expected outcomes. In this work, we propose a novel technique that uses rules derived from neural network computations to infer data preconditions for a DNN model to determine the trustworthiness of its predictions. Our approach, DeepInfer involves introducing a novel abstraction for a trained DNN model that enables weakest precondition reasoning using Dijkstra's Predicate Transformer Semantics. By deriving rules over the inductive type of neural network abstract representation, we can overcome the matrix dimensionality issues that arise from the backward nonlinear computation from the output layer to the input layer. We utilize the weakest precondition computation using rules of each kind of activation function to compute layer-wise precondition from the given postcondition on the final output of a deep neural network. We extensively evaluated DeepInfer on 29 real-world DNN models using four different datasets collected from five different sources and demonstrated the utility, effectiveness, and performance improvement over closely related work. DeepInjer efficiently detects correct and incorrect predictions of high-accuracy models with high recall (0.98) and high F-1 score (0.84) and has significantly improved over the prior technique, Self Checker. The average runtime overhead of DeepInfer is low, 0.22 sec for all the unseen datasets. We also compared runtime overhead using the same hardware settings and found that DeepInfer is 3.27 times faster than Self Checker, the state-of-the-art in this area.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623333","National Science Foundation(grant numbers:CCF-15-18897,CNS-15-13263,CNS-21-20448,CCF-19-34884,CCF-22-23812); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548090","Deep neural networks;weakest precondition;trustworthiness","Deep learning;Runtime;Computational modeling;Semantics;Artificial neural networks;Predictive models;Transformers","","","","76","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"An Empirical Study on Low GPU Utilization of Deep Learning Jobs","Y. Gao; Y. He; X. Li; B. Zhao; H. Lin; Y. Liang; J. Zhong; H. Zhang; J. Wang; Y. Zeng; K. Gui; J. Tong; M. Yang","Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Peking University, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Chongqing University, Chongqing, China; Tsinghua University, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China; Microsoft Research, Beijing, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1171","1183","Deep learning plays a critical role in numerous intelligent software applications. Enterprise developers submit and run deep learning jobs on shared, multi-tenant platforms to efficiently train and test models. These platforms are typically equipped with a large number of graphics processing units (GPUs) to expedite deep learning computations. However, certain jobs exhibit rather low utilization of the allocated GPUs, resulting in substantial resource waste and reduced development productivity. This paper presents a comprehensive empirical study on low GPU utilization of deep learning jobs, based on 400 real jobs (with an average GPU utilization of 50% or less) collected from Microsoft's internal deep learning platform. We discover 706 low-GPU-utilization issues through meticulous examination of job metadata, execution logs, runtime metrics, scripts, and programs. Furthermore, we identify the common root causes and propose corresponding fixes. Our main findings include: (1) Low GPU utilization of deep learning jobs stems from insufficient GPU computations and interruptions caused by non-GPU tasks; (2) Approximately half (46.03%) of the issues are attributed to data operations; (3) 45.18% of the issues are related to deep learning models and manifest during both model training and evaluation stages; (4) Most (84.99%) low-GPU-utilization issues could be fixed with a small number of code/script modifications. Based on the study results, we propose potential research directions that could help developers utilize GPUs better in cloud-based platforms.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548248","deep learning jobs;GPU utilization;empirical study","Deep learning;Training;Productivity;Measurement;Runtime;Computational modeling;Graphics processing units","","","","85","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Reducing confounding bias in predicate-level statistical debugging metrics","R. Gore; P. F. Reynolds","Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","463","473","Statistical debuggers use data collected during test case execution to automatically identify the location of faults within software. Recent work has applied causal inference to eliminate or reduce control and data flow dependence confounding bias in statement-level statistical debuggers. The result is improved effectiveness. This is encouraging but motivates two novel questions: (1) how can causal inference be applied in predicate-level statistical debuggers and (2) what other biases can be eliminated or reduced. Here we address both questions by providing a model that eliminates or reduces control flow dependence and failure flow confounding bias within predicate-level statistical debuggers. We present empirical results demonstrating that our model significantly improves the effectiveness of a variety of predicate-level statistical debuggers, including those that eliminate or reduce only a single source of confounding bias.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227169","automated debugging;fault localization","Debugging;Sensitivity;Adaptation models;Instruments;Computational modeling;Switches","","24","","27","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Active refinement of clone anomaly reports","Lucia; D. Lo; L. Jiang; A. Budi","School of Information Systems, Singapore Management University; School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","397","407","Software clones have been widely studied in the recent literature and shown useful for finding bugs because inconsistent changes among clones in a clone group may indicate potential bugs. However, many inconsistent clone groups are not real bugs (true positives). The excessive number of false positives could easily impede broad adoption of clone-based bug detection approaches. In this work, we aim to improve the usability of clone-based bug detection tools by increasing the rate of true positives found when a developer analyzes anomaly reports. Our idea is to control the number of anomaly reports a user can see at a time and actively incorporate incremental user feedback to continually refine the anomaly reports. Our system first presents top few anomaly reports from the list of reports generated by a tool in its default ordering. Users then either accept or reject each of the reports. Based on the feedback, our system automatically and iteratively refines a classification model for anomalies and re-sorts the rest of the reports. Our goal is to present the true positives to the users earlier than the default ordering. The rationale of the idea is based on our observation that false positives among the inconsistent clone groups could share common features (in terms of code structure, programming patterns, etc.), and these features can be learned from the incremental user feedback. We evaluate our refinement process on three sets of clone-based anomaly reports from three large real programs: the Linux Kernel (C), Eclipse, and ArgoUML (Java), extracted by a clone-based anomaly detection tool. The results show that compared to the original ordering of bug reports, we can improve the rate of true positives found (i.e., true positives are found faster) by 11%, 87%, and 86% for Linux kernel, Eclipse, and ArgoUML, respectively.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227175","","Cloning;Computer bugs;Feature extraction;Engines;Linux;Kernel;Programming","","8","","42","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"DeepTraLog: Trace-Log Combined Microservice Anomaly Detection through Graph-based Deep Learning","C. Zhang; X. Peng; C. Sha; K. Zhang; Z. Fu; X. Wu; Q. Lin; D. Zhang","Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Microsoft Research, China; Microsoft Research, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","623","634","A microservice system in industry is usually a large-scale dis-tributed system consisting of dozens to thousands of services run-ning in different machines. An anomaly of the system often can be reflected in traces and logs, which record inter-service interactions and intra-service behaviors respectively. Existing trace anomaly detection approaches treat a trace as a sequence of service invocations. They ignore the complex structure of a trace brought by its invocation hierarchy and parallel/asynchronous invocations. On the other hand, existing log anomaly detection approaches treat a log as a sequence of events and cannot handle microservice logs that are distributed in a large number of services with complex interactions. In this paper, we propose DeepTraLog, a deep learning based microservice anomaly detection approach. DeepTraLog uses a unified graph representation to describe the complex structure of a trace together with log events embedded in the structure. Based on the graph representation, DeepTraLog trains a GGNNs based deep SVDD model by combing traces and logs and detects anom-alies in new traces and the corresponding logs. Evaluation on a microservice benchmark shows that DeepTraLog achieves a high precision (0.93) and recall (0.97), outperforming state-of-the-art trace/log anomaly detection approaches with an average increase of 0.37 in F1-score. It also validates the efficiency of DeepTraLog, the contribution of the unified graph representation, and the impact of the configurations of some key parameters.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793918","Microservice;Anomaly Detection;Log Analysis;Tracing;Graph Neural Network;Deep Learning","Deep learning;Industries;Microservice architectures;Benchmark testing;Behavioral sciences;Time factors;Anomaly detection","","42","","44","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding","D. Wang; Z. Jia; S. Li; Y. Yu; Y. Xiong; W. Dong; X. Liao","National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; National University of Defense Technology, China; Fudan University, Shanghai, China; National University of Defense Technology, China; National University of Defense Technology, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","287","298","With the great success of pre-trained models, the pretrain-then-fine tune paradigm has been widely adopted on downstream tasks for source code understanding. However, compared to costly training a large-scale model from scratch, how to effectively adapt pre-trained models to a new task has not been fully explored. In this paper, we propose an approach to bridge pre-trained models and code-related tasks. We exploit semantic-preserving transformation to enrich downstream data diversity, and help pre-trained models learn semantic features invariant to these semantically equivalent transformations. Further, we introduce curriculum learning to or-ganize the transformed data in an easy-to-hard manner to fine-tune existing pre-trained models. We apply our approach to a range of pre-trained models, and they significantly outperform the state-of-the-art models on tasks for source code understanding, such as algorithm classification, code clone detection, and code search. Our experiments even show that without heavy pre-training on code data, natural language pre-trained model RoBERTa fine-tuned with our lightweight approach could outperform or rival existing code pre-trained models fine-tuned on the above tasks, such as CodeBERT and GraphCodeBERT. This finding suggests that there is still much room for improvement in code pre-trained models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510062","National Natural Science Foundation of China(grant numbers:61690203,61872373,62032019,U1936213); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793959","fine-tuning;data augmentation;curriculum learning;test-time aug-mentation","Training;Adaptation models;Codes;Natural languages;Semantics;Cloning;Data models","","26","","58","","20 Jun 2022","","","IEEE","IEEE Conferences"
"An Empirical Study of Deep Learning Models for Vulnerability Detection","B. Steenhoek; M. M. Rahman; R. Jiles; W. Le","Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2237","2248","Deep learning (DL) models of code have recently reported great progress for vulnerability detection. In some cases, DL-based models have outperformed static analysis tools. Although many great models have been proposed, we do not yet have a good understanding of these models. This limits the further advancement of model robustness, debugging, and deployment for the vulnerability detection. In this paper, we surveyed and reproduced 9 state-of-the-art (SOTA) deep learning models on 2 widely used vulnerability detection datasets: Devign and MSR. We investigated 6 research questions in three areas, namely model capabilities, training data, and model interpretation. We experimentally demonstrated the variability between different runs of a model and the low agreement among different models' outputs. We investigated models trained for specific types of vulnerabilities compared to a model that is trained on all the vulnerabilities at once. We explored the types of programs DL may consider “hard” to handle. We investigated the relations of training data sizes and training data composition with model performance. Finally, we studied model interpretations and analyzed important features that the models used to make predictions. We believe that our findings can help better understand model results, provide guidance on preparing training data, and improve the robustness of the models. All of our datasets, code, and results are available at https://doi.org/10.6084/m9.figshare.20791240.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00188","U.S. National Science Foundation(grant numbers:1816352); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172583","deep learning;vulnerability detection;empirical study","Deep learning;Analytical models;Codes;Training data;Static analysis;Debugging;Predictive models","","21","","47","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"On the Importance of Building High-quality Training Datasets for Neural Code Search","Z. Sun; L. Li; Y. Liu; X. Du; L. Li","Monash University, Melbourne, Victoria, Australia; Tongji University, Shanghai, China; Tongji University, Shanghai, China; Monash University, Melbourne, Victoria, Australia; Monash University, Melbourne, Victoria, Australia",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1609","1620","The performance of neural code search is significantly influenced by the quality of the training data from which the neural models are derived. A large corpus of high-quality query and code pairs is demanded to establish a precise mapping from the natural language to the programming language. Due to the limited availability, most widely-used code search datasets are established with compromise, such as using code comments as a replacement of queries. Our empirical study on a famous code search dataset reveals that over one-third of its queries contain noises that make them deviate from natural user queries. Models trained through noisy data are faced with severe performance degradation when applied in real-world scenarios. To improve the dataset quality and make the queries of its samples semantically identical to real user queries is critical for the practical usability of neural code search. In this paper, we propose a data cleaning framework consisting of two subsequent filters: a rule-based syntactic filter and a model-based semantic filter. This is the first framework that applies semantic query cleaning to code search datasets. Experimentally, we evaluated the effectiveness of our framework on two widely-used code search models and three manually-annotated code retrieval benchmarks. Training the popular DeepCS model with the filtered dataset from our framework improves its performance by 19.2% MRR and 21.3% Answer@l, on average with the three validation benchmarks.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510160","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793971","Code search;dataset;data cleaning;deep learning","Training;Codes;Computational modeling;Semantics;Training data;Benchmark testing;Data models","","17","","57","","20 Jun 2022","","","IEEE","IEEE Conferences"
"KNOD: Domain Knowledge Distilled Tree Decoder for Automated Program Repair","N. Jiang; T. Lutellier; Y. Lou; L. Tan; D. Goldwasser; X. Zhang","Purdue University, West Lafayette, USA; University of Alberta, Alberta, Canada; Fudan University, Shanghai, China; Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA; Purdue University, West Lafayette, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1251","1263","Automated Program Repair (APR) improves soft-ware reliability by generating patches for a buggy program automatically. Recent APR techniques leverage deep learning (DL) to build models to learn to generate patches from existing patches and code corpora. While promising, DL-based APR techniques suffer from the abundant syntactically or semantically incorrect patches in the patch space. These patches often disobey the syntactic and semantic domain knowledge of source code and thus cannot be the correct patches to fix a bug. We propose a DL-based APR approach KNOD, which in-corporates domain knowledge to guide patch generation in a direct and comprehensive way. KNOD has two major novelties, including (1) a novel three-stage tree decoder, which directly generates Abstract Syntax Trees of patched code according to the inherent tree structure, and (2) a novel domain-rule distillation, which leverages syntactic and semantic rules and teacher-student distributions to explicitly inject the domain knowledge into the decoding procedure during both the training and inference phases. We evaluate KNOD on three widely-used benchmarks. KNOD fixes 72 bugs on the Defects4J v1.2, 25 bugs on the QuixBugs, and 50 bugs on the additional Defects4J v2.0 benchmarks, outperforming all existing APR tools.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00111","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172873","Automated Program Repair;Abstract Syntax Tree;Deep Learning","Training;Codes;Source coding;Computer bugs;Semantics;Syntactics;Benchmark testing","","17","","65","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Type4Py: Practical Deep Similarity Learning-Based Type Inference for Python","A. M. Mir; E. Latoškinas; S. Proksch; G. Gousios","Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands; Meta, Menlo Park, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2241","2252","Dynamic languages, such as Python and Javascript, trade static typing for developer flexibility and productivity. Lack of static typing can cause run-time exceptions and is a major factor for weak IDE support. To alleviate these issues, PEP 484 introduced optional type annotations for Python. As retrofitting types to existing code-bases is error-prone and laborious, machine learning (ML)-based approaches have been proposed to enable automatic type infer-ence based on existing, partially annotated codebases. However, previous ML-based approaches are trained and evaluated on human-provided type annotations, which might not always be sound, and hence this may limit the practicality for real-world usage. In this paper, we present TYPE4Py, a deep similarity learning-based hier-archical neural network model. It learns to discriminate between similar and dissimilar types in a high-dimensional space, which results in clusters of types. Likely types for arguments, variables, and return values can then be inferred through the nearest neigh-bor search. Unlike previous work, we trained and evaluated our model on a type-checked dataset and used mean reciprocal rank (MRR) to reflect the performance perceived by users. The obtained results show that TYPE4Py achieves an MRR of 77.1 %, which is a substantial improvement of 8.1% and 16.7% over the state-of-the-art approaches Typilus and Typewriter, respectively. Finally, to aid developers with retrofitting types, we released a Visual Stu-dio Code extension, which uses TYPE4Py to provide ML-based type auto-completion for Python.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510124","H2020(grant numbers:825328); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793925","Type Inference;Similarity Learning;Machine Learning;Mean Reciprocal Rank;Python","Productivity;Visualization;Codes;Annotations;Neural networks;Machine learning;Python","","17","","66","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"History-Driven Test Program Synthesis for JVM Testing","Y. Zhao; Z. Wang; J. Chen; M. Liu; M. Wu; Y. Zhang; L. Zhang","College of Intelligence and Computing, Tianjin University, China; College of Intelligence and Computing, Tianjin University, China; College of Intelligence and Computing, Tianjin University, China; College of Intelligence and Computing, Tianjin University, China; Southern University of Science and Technology, China; Southern University of Science and Technology, China; University of Illinois Urbana-Champaign, United States",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1133","1144","Java Virtual Machine (JVM) provides the runtime environment for Java programs, which allows Java to be “write once, run anywhere”. JVM plays a decisive role in the correctness of all Java programs running on it. Therefore, ensuring the correctness and robustness of JVM implementations is essential for Java programs. To date, various techniques have been proposed to expose JVM bugs via generating potential bug-revealing test programs. However, the diversity and effectiveness of test programs generated by existing research are far from enough since they mainly focus on minor syntactic/semantic mutations. In this paper, we propose JavaTailor, the first history-driven test program synthesis technique, which synthesizes diverse test programs by weaving the ingredients extracted from JVM historical bug-revealing test programs into seed programs for covering more JVM behaviors/paths. More specifically, JavaTailor first extracts five types of code ingredients from the historical bug-revealing test programs. Then, to synthesize diverse test programs, it iteratively inserts the extracted ingredients into the seed programs and strengthens their interactions via introducing extra data dependencies between them. Finally, JavaTailor employs these synthesized test programs to differentially test JVMs. Our experimental results on popular JVM implementations (i.e., HotSpot and OpenJ9) show that JavaTailor outperforms the state-of-the-art technique in generating more diverse and effective test programs, e.g., test programs generated by JavaTailor can achieve higher JVM code coverage and detect many more unique inconsistencies than the state-of-the-art technique. Furthermore, JavaTailor has detected 10 previously unknown bugs, 6 of which have been confirmed/fixed by developers.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510059","National Natural Science Foundation of China(grant numbers:62002256,61872263); National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794053","Java Virtual Machine;Program Synthesis;JVM Testing;Compiler Testing","Java;Runtime environment;Codes;Computer bugs;Semantics;Syntactics;Virtual machining","","16","","55","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Many-Objective Reinforcement Learning for Online Testing of DNN-Enabled Systems","F. Ul Haq; D. Shin; L. C. Briand","University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1814","1826","Deep Neural Networks (DNNs) have been widely used to perform real-world tasks in cyber-physical systems such as Autonomous Driving Systems (ADS). Ensuring the correct behavior of such DNN-Enabled Systems (DES) is a crucial topic. Online testing is one of the promising modes for testing such systems with their application environments (simulated or real) in a closed loop, taking into account the continuous interaction between the systems and their environments. However, the environmental variables (e.g., lighting conditions) that might change during the systems' operation in the real world, causing the DES to violate requirements (safety, functional), are often kept constant during the execution of an online test scenario due to the two major challenges: (1) the space of all possible scenarios to explore would become even larger if they changed and (2) there are typically many requirements to test simultaneously. In this paper, we present MORLOT (Many-Objective Rein-forcement Learning for Online Testing), a novel online testing approach to address these challenges by combining Reinforcement Learning (RL) and many-objective search. MORLOT leverages RL to incrementally generate sequences of environmental changes while relying on many-objective search to determine the changes so that they are more likely to achieve any of the uncovered objectives. We empirically evaluate MORLOT using CARLA, a high-fidelity simulator widely used for autonomous driving research, integrated with Transfuser, a DNN-enabled ADS for end-to-end driving. The evaluation results show that MORLOT is significantly more effective and efficient than alternatives with a large effect size. In other words, MORLOT is a good option to test DES with dynamically changing environments while accounting for multiple safety requirements.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00155","NSERC of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172658","DNN Testing;Reinforcement learning;Many objective search;Self-driving cars;Online testing","Q-learning;Systems operation;Scalability;Lighting;Search problems;Safety;Task analysis","","13","","42","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Detecting False Alarms from Automatic Static Analysis Tools: How Far are We?","H. J. Kang; K. L. Aw; D. Lo","Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","698","709","Automatic static analysis tools (ASATs), such as Findbugs, have a high false alarm rate. The large number of false alarms produced poses a barrier to adoption. Researchers have proposed the use of machine learning to prune false alarms and present only actionable warnings to developers. The state-of-the-art study has identified a set of “Golden Features” based on metrics computed over the characteristics and history of the file, code, and warning. Recent studies show that machine learning using these features is extremely effective and that they achieve almost perfect performance. We perform a detailed analysis to better understand the strong performance of the “Golden Features”. We found that several studies used an experimental procedure that results in data leakage and data duplication, which are subtle issues with significant implications. Firstly, the ground-truth labels have leaked into features that measure the proportion of actionable warnings in a given context. Secondly, many warnings in the testing dataset appear in the training dataset. Next, we demonstrate limitations in the warning oracle that determines the ground-truth labels, a heuristic comparing warnings in a given revision to a reference revision in the future. We show the choice of reference revision influences the warning distribution. Moreover, the heuristic produces labels that do not agree with human oracles. Hence, the strong performance of these techniques previously seen is overoptimistic of their true performance if adopted in practice. Our results convey several lessons and provide guidelines for evaluating false alarm detectors.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510214","National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793908","static analysis;false alarms;data leakage;data duplication","Training;Measurement;Codes;Static analysis;Machine learning;Detectors;History","","12","","64","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Improving Java Deserialization Gadget Chain Mining via Overriding-Guided Object Generation","S. Cao; X. Sun; X. Wu; L. Bo; B. Li; R. Wu; W. Liu; B. He; Y. Ouyang; J. Li",Yangzhou University; Yangzhou University; Yangzhou University; Yangzhou University; Yangzhou University; Xiamen University; Yangzhou University; Ant Group; Ant Group; Ant Group,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","397","409","Java (de)serialization is prone to causing security-critical vulnerabilities that attackers can invoke existing methods (gadgets) on the application's classpath to construct a gadget chain to perform malicious behaviors. Several techniques have been proposed to statically identify suspicious gadget chains and dynamically generate injection objects for fuzzing. However, due to their incomplete support for dynamic program features (e.g., Java runtime polymorphism) and ineffective injection object generation for fuzzing, the existing techniques are still far from satisfactory. In this paper, we first performed an empirical study to investigate the characteristics of Java deserialization vulnerabilities based on our manually collected 86 publicly known gadget chains. The empirical results show that 1) Java deserialization gadgets are usually exploited by abusing runtime polymorphism, which enables attackers to reuse serializable overridden methods; and 2) attackers usually invoke exploitable overridden methods (gadgets) via dynamic binding to generate injection objects for gadget chain construction. Based on our empirical findings, we propose a novel gadget chain mining approach, GCMiner, which captures both explicit and implicit method calls to identify more gadget chains, and adopts an overriding-guided object generation approach to generate valid injection objects for fuzzing. The evaluation results show that GCMiner significantly outperforms the state-of-the-art techniques, and discovers 56 unique gadget chains that cannot be identified by the baseline approaches.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172888","Java deserialization vulnerability;gadget chain;method overriding;exploit generation","Java;Runtime;Fuzzing;Behavioral sciences;Object recognition","","9","","67","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"AChecker: Statically Detecting Smart Contract Access Control Vulnerabilities","A. Ghaleb; J. Rubin; K. Pattabiraman","University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada; University of British Columbia, Vancouver, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","945","956","As most smart contracts have a financial nature and handle valuable assets, smart contract developers use access control to protect assets managed by smart contracts from being misused by malicious or unauthorized people. Unfortunately, programming languages used for writing smart contracts, such as Solidity, were not designed with a permission-based security model in mind. Therefore, smart contract developers implement access control checks based on their judgment and in an adhoc manner, which results in several vulnerabilities in smart contracts, called access control vulnerabilities. Further, the in-consistency in implementing access control makes it difficult to reason about whether a contract meets access control needs and is free of access control vulnerabilities. In this work, we propose AChecker - an approach for detecting access control vulnerabilities. Unlike prior work, AChecker does not rely on pre-defined patterns or contract transactions history. Instead, it infers access control implemented in smart contracts via static data-flow analysis. Moreover, the approach performs further symbolic-based analysis to distinguish cases when unauthorized people can obtain control of the contract as intended functionality. We evaluated AChecker on three public datasets of real-world smart contracts, including one which consists of contracts with assigned access control CVEs, and compared its effectiveness with eight analysis tools. The evaluation results showed that AChecker outperforms these tools in terms of both precision and recall. In addition, AChecker flagged vulnerabilities in 21 frequently-used contracts on Ethereum blockchain with 90% precision.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172877","Smart contract;security;access control;data-flow analysis","Access control;Solid modeling;Computer languages;Smart contracts;Static analysis;Writing;Blockchains","","9","","36","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Prioritizing Mutants to Guide Mutation Testing","S. J. Kaufman; R. Featherman; J. Alvin; B. Kurtz; P. Ammann; R. Just","University of Washington, Seattle, Washington, USA; University of Washington, Seattle, Washington, USA; University of Massachusetts, Amherst, Massachusetts, USA; George Mason University, Fairfax, Virginia, USA; University of Washington, Seattle, Washington, USA; George Mason University, Fairfax, Virginia, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1743","1754","Mutation testing offers concrete test goals (mutants) and a rigorous test efficacy criterion, but it is expensive due to vast numbers of mutants, many of which are neither useful nor actionable. Prior work has focused on selecting representative and sufficient mutant subsets, measuring whether a test set that is mutation-adequate for the subset is equally adequate for the entire set. However, no known industrial application of mutation testing uses or even computes mutation adequacy, instead focusing on iteratively presenting very few mutants as concrete test goals for developers to write tests. This paper (1) articulates important differences between mutation analysis, where measuring mutation adequacy is of interest, and mutation testing, where mutants are of interest insofar as they serve as concrete test goals to elict effective tests; (2) introduces a new measure of mutant usefulness, called test completeness advancement probability (TCAP); (3) introduces an approach to prioritizing mutants by incrementally selecting mutants based on their predicted TCAP; and (4) presents simulations showing that TCAP-based prioritization of mutants advances test completeness more rapidly than prioritization with the previous state-of-the-art.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510187","National Science Foundation(grant numbers:CCF-1942055); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793974","mutation testing;mutant selection;mutant utility;test completeness advancement probability;TCAP;machine learning","Analytical models;Codes;Current measurement;Semantics;Focusing;Predictive models;Syntactics","","9","","55","","20 Jun 2022","","","IEEE","IEEE Conferences"
"CHRONOS: Time-Aware Zero-Shot Identification of Libraries from Vulnerability Reports","Y. Lyu; T. Le-Cong; H. J. Kang; R. Widyasari; Z. Zhao; X. -B. D. Le; M. Li; D. Lo",Singapore Management University; Singapore Management University; Singapore Management University; Singapore Management University; Singapore Management University; The University of Melbourne; Nanjing University; Singapore Management University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1033","1045","Tools that alert developers about library vulnerabilities depend on accurate, up-to-date vulnerability databases which are maintained by security researchers. These databases record the libraries related to each vulnerability. However, the vulnerability reports may not explicitly list every library and human analysis is required to determine all the relevant libraries. Human analysis may be slow and expensive, which motivates the need for automated approaches. Researchers and practitioners have proposed to automatically identify libraries from vulnerability reports using extreme multi-label learning (XML). While state-of-the-art XML techniques showed promising performance, their experimental settings do not practically fit what happens in reality. Previous studies randomly split the vulnerability reports data for training and testing their models without considering the chronological order of the reports. This may unduly train the models on chronologically newer reports while testing the models on chronologically older ones. However, in practice, one often receives chronologically new reports, which may be related to previously unseen libraries. Under this practical setting, we observe that the performance of current XML techniques declines substantially, e.g., F1 decreased from 0.7 to 0.24 under experiments without and with consideration of chronological order of vulnerability reports. We propose a practical library identification approach, namely Chronos, based on zero-shot learning. The novelty of Chronos is three-fold. First, Chronos fits into the practical pipeline by considering the chronological order of vulnerability reports. Second, Chronos enriches the data of the vulnerability descriptions and labels using a carefully designed data enhancement step. Third, Chronos exploits the temporal ordering of the vulnerability reports using a cache to prioritize prediction of versions of libraries that recently had reports of vulnerabilities. In our experiments, Chronos achieves an average F1-score of 0.75, 3x better than the best XML-based approach. Data enhancement and the time-aware adjustment improve Chronos over the vanilla zero-shot learning model by 27% in average F1.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00094","National Research Foundation, Singapore; National University of Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172641","zero-shot learning;library identification;unseen labels;extreme multi-label classification;vulnerability reports","Training;Databases;Pipelines;XML;Libraries;Data models;Security","","8","","68","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Analyzing User Perspectives on Mobile App Privacy at Scale","P. Nema; P. Anthonysamy; N. Taft; S. T. Peddinti","Google, Bangalore, India; Google, Zurich, Switzerland; Google, Mountain View, USA; Google, Mountain View, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","112","124","In this paper we present a methodology to analyze users‘ con-cerns and perspectives about privacy at scale. We leverage NLP techniques to process millions of mobile app reviews and extract privacy concerns. Our methodology is composed of a binary clas-sifier that distinguishes between privacy and non-privacy related reviews. We use clustering to gather reviews that discuss similar privacy concerns, and employ summarization metrics to extract representative reviews to summarize each cluster. We apply our methods on 287M reviews for about 2M apps across the 29 cate-gories in Google Play to identify top privacy pain points in mobile apps. We identified approximately 440K privacy related reviews. We find that privacy related reviews occur in all 29 categories, with some issues arising across numerous app categories and other issues only surfacing in a small set of app categories. We show empirical evidence that confirms dominant privacy themes - concerns about apps requesting unnecessary permissions, collection of personal information, frustration with privacy controls, tracking and the selling of personal data. As far as we know, this is the first large scale analysis to confirm these findings based on hundreds of thousands of user inputs. We also observe some unexpected findings such as users warning each other not to install an app due to privacy issues, users uninstalling apps due to privacy reasons, as well as positive reviews that reward developers for privacy friendly apps. Finally we discuss the implications of our method and findings for developers and app stores.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794103","privacy;nlp;mobile apps;empirical","Privacy;Data privacy;Systematics;Pain;Ecosystems;Sociology;Mobile applications","","8","","80","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Utilizing Parallelism in Smart Contracts on Decentralized Blockchains by Taming Application-Inherent Conflicts","P. Garamvolgyi; Y. Liu; D. Zhou; F. Long; M. Wu","Shanghai Tree-Graph Blockchain Research Institute, Shanghai, China; Duke University, Durham, North Carolina, USA; Tsinghua University, Beijing, China; University of Toronto Toronto, Canada Shanghai Tree-Graph Blockchain Research Institute, Shanghai, China; Shanghai Tree-Graph Blockchain Research Institute, Shanghai, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2315","2326","Traditional public blockchain systems typically had very limited transaction throughput because of the bottleneck of the consensus protocol itself. With recent advances in consensus technology, the performance limit has been greatly lifted, typically to thousands of transactions per second. With this, transaction execution has become a new performance bottleneck. Exploiting parallelism in transaction execution is a clear and direct way to address this and to further increase transaction throughput. Although some recent literature introduced concurrency control mechanisms to execute smart contract transactions in parallel, the reported speedup that they can achieve is far from ideal. The main reason is that the proposed parallel execution mechanisms cannot effectively deal with the conflicts inherent in many blockchain applications. In this work, we thoroughly study the historical transaction exe-cution traces in Ethereum. We observe that application-inherent conflicts are the major factors that limit the exploitable parallelism during execution. We propose to use partitioned counters and spe-cial commutative instructions to break up the application conflict chains in order to maximize the potential speedup. When we eval-uated the maximum parallel speedup achievable, these techniques doubled this limit to an 18x overall speedup compared to serial execution, thus approaching the optimum. We also propose OCC-DA, an optimistic concurrency control scheduler with deterministic aborts, which makes it possible to use OCC scheduling in public blockchain settings.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793889","blockchain;distributed ledgers;smart contracts;parallel execution;optimistic concurrency;deterministic concurrency","Concurrent computing;Smart contracts;Parallel processing;Programming;Throughput;Concurrency control;Consensus protocol","","8","","33","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Evaluating and Improving Neural Program-Smoothing-based Fuzzing","M. Wu; L. Jiang; J. Xiang; Y. Zhang; G. Yang; H. Ma; S. Nie; S. Wu; H. Cui; L. Zhang","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; The University of Queensland, Brisbane, Australia; Tencent Security Keen Lab, Shanghai, China; Tencent Security Keen Lab, Shanghai, China; Tencent Security Keen Lab, Shanghai, China; The University of Hong Kong, Hong Kong, China; University of Illinois, Urbana-Champaign, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","847","858","Fuzzing nowadays has been commonly modeled as an optimization problem, e.g., maximizing code coverage under a given time budget via typical search-based solutions such as evolutionary algorithms. However, such solutions are widely argued to cause inefficient computing resource usage, i.e., inefficient mutations. To address this issue, two neural program-smoothing-based fuzzers, Neuzz and MTFuzz, have been recently proposed to approximate program branching behaviors via neural network models, which input byte sequences of a seed and output vectors representing program branching behaviors. Moreover, assuming that mutating the bytes with larger gradients can better explore branching behaviors, they develop strategies to mutate such bytes for generating new seeds as test cases. Meanwhile, although they have been shown to be effective in the original papers, they were only evaluated upon a limited dataset. In addition, it is still unclear how their key technical components and whether other factors can impact fuzzing performance. To further investigate neural program-smoothing-based fuzzing, we first construct a large-scale benchmark suite with a total of 28 popular open-source projects. Then, we extensively evaluate Neuzz and MTFuzz on such benchmarks. The evaluation results suggest that their edge coverage performance can be unstable. Moreover, neither neural network models nor mutation strategies can be consistently effective, and the power of their gradient-guidance mechanisms have been compromised. Inspired by such findings, we propose a simplistic technique, PreFuzz, which improves neural program-smoothing-based fuzzers with a resource-efficient edge selection mechanism to enhance their gradient guidance and a probabilistic byte selection mechanism to further boost mutation effectiveness. Our evaluation results indicate that PreFuzz can significantly increase the edge coverage of Neuzz/MTFuzz, and also reveal multiple practical guidelines to advance future research on neural program-smoothing-based fuzzing.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510089","National Natural Science Foundation of China(grant numbers:61902169); Shenzhen Peacock Plan(grant numbers:KQTD2016112514355531); National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794082","","Computational modeling;Neural networks;Fuzzing;Benchmark testing;Probabilistic logic;Search problems;Behavioral sciences","","8","","55","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Static Inference Meets Deep learning: A Hybrid Type Inference Approach for Python","Y. Peng; C. Gao; Z. Li; B. Gao; D. Lo; Q. Zhang; M. Lyu","The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Singapore Management University, Singapore; Georgia Institute of Technology, United States; The Chinese University of Hong Kong, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2019","2030","Type inference for dynamic programming languages such as Python is an important yet challenging task. Static type inference techniques can precisely infer variables with enough static constraints but are unable to handle variables with dynamic features. Deep learning (DL) based approaches are feature-agnostic, but they can-not guarantee the correctness of the predicted types. Their per-formance significantly depends on the quality of the training data (i.e., DL models perform poorly on some common types that rarely appear in the training dataset). It is interesting to note that the static and DL-based approaches offer complementary benefits. Un-fortunately, to our knowledge, precise type inference based on both static inference and neural predictions has not been exploited and remains an open challenge. In particular, it is hard to integrate DL models into the framework of rule-based static approaches. This paper fills the gap and proposes a hybrid type inference approach named Hityper based on both static inference and deep learning. Specifically, our key insight is to record type dependen-cies among variables in each function and encode the dependency information in type dependency graphs (TDGs). Based on TDGs, we can easily integrate type inference rules in the nodes to conduct static inference and type rejection rules to inspect the correctness of neural predictions. Hityper iteratively conducts static inference and DL-based prediction until the TDG is fully inferred. Experi-ments on two benchmark datasets show that Hityper outperforms state-of-the-art DL models by exactly matching 10% more human annotations. Hityper also achieves an increase of more than 30% on inferring rare types. Considering only the static part of Hityper, it infers 2× ~3× more types than existing static type inference tools. Moreover, Hityper successfully corrected seven wrong human an-notations in six GitHub projects, and two of them have already been approved by the repository owners.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510038","Research Grants Council of the Hong Kong Special Administrative Region, China(grant numbers:CUHK 14210920); National Natural Science Foundation of China(grant numbers:62002084); Shenzhen(grant numbers:GXWD20201230155427003-20200730101839009); United States National Science Foundation (NSF)(grant numbers:1917924,2114627); Defense Advanced Research Projects Agency (DARPA)(grant numbers:N66001-21-C-4024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794008","Type Inference;AI For SE;Static Analysis","Deep learning;Training;Training data;Static analysis;Predictive models;Dynamic programming;Task analysis","","7","","62","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Fuzzing Automatic Differentiation in Deep-Learning Libraries","C. Yang; Y. Deng; J. Yao; Y. Tu; H. Li; L. Zhang","University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; The Chinese University of Hong Kong, Shenzhen; Huazhong University of Science and Technology; University of Science and Technology of China; University of Illinois, Urbana-Champaign",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1174","1186","Deep learning (DL) has attracted wide attention and has been widely deployed in recent years. As a result, more and more research efforts have been dedicated to testing DL libraries and frameworks. However, existing work largely overlooked one crucial component of any DL system, automatic differentiation (AD), which is the basis for the recent development of DL. To this end, we propose ∇Fuzz, the first general and practical approach specifically targeting the critical AD component in DL libraries. Our key insight is that each DL library API can be abstracted into a function processing tensors/vectors, which can be differentially tested under various execution scenarios (for computing outputs/gradients with different implementations). We have implemented $\nabla \text{Fuzz}$ as a fully automated API-level fuzzer targeting AD in DL libraries, which utilizes differential testing on different execution scenarios to test both first-order and high-order gradients, and also includes automated filtering strategies to remove false positives caused by numerical instability. We have performed an extensive study on four of the most popular and actively-maintained DL libraries, PyTorch, TensorFlow, JAX, and OneFlow. The result shows that $\nabla \text{Fuzz}$ substantially outperforms state-of-the-art fuzzers in terms of both code coverage and bug detection. To date, $\nabla \text{Fuzz}$ has detected 173 bugs for the studied DL libraries, with 144 already confirmed by developers (117 of which are previously unknown bugs and 107 are related to AD). Remarkably, $\nabla \text{Fuzz}$ contributed 58.3% (7/12) of all high-priority AD bugs for PyTorch and JAX during a two-month period. None of the confirmed AD bugs were detected by existing fuzzers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00105","NSF(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172523","","Deep learning;Codes;Filtering;Computer bugs;Fuzzing;Libraries;Engines","","7","","68","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Fairneuron: Improving Deep Neural Network Fairness with Adversary Games on Selective Neurons","X. Gao; J. Zhai; S. Ma; C. Shen; Y. Chen; Q. Wang","Xi'an Jiaotong University, Xi'an, China; Rutgers University, United States; Rutgers University, United States; Xi'an Jiaotong University, Xi'an, China; Xi'an Jiaotong University, Xi'an, China; Wuhan University, Wuhan, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","921","933","With Deep Neural Network (DNN) being integrated into a growing number of critical systems with far-reaching impacts on society, there are increasing concerns on their ethical performance, such as fairness. Unfortunately, model fairness and accuracy in many cases are contradictory goals to optimize during model training. To solve this issue, there has been a number of works trying to improve model fairness by formalizing an adversarial game in the model level. This approach introduces an adversary that evaluates the fairness of a model besides its prediction accuracy on the main task, and performs joint-optimization to achieve a balanced result. In this paper, we noticed that when performing backward prop-agation based training, such contradictory phenomenon are also observable on individual neuron level. Based on this observation, we propose Fairneuron, a Dnn model automatic repairing tool, to mitigate fairness concerns and balance the accuracy-fairness trade-off without introducing another model. It works on detecting neurons with contradictory optimization directions from accuracy and fairness training goals, and achieving a trade-off by selective dropout. Comparing with state-of-the-art methods, our approach is lightweight, scaling to large models and more efficient. Our eval-uation on three datasets shows that Fairneuron can effectively improve all models' fairness while maintaining a stable utility.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510087","National Key R&D Program(grant numbers:2020YFB1406900); National Natural Science Foundation of China(grant numbers:U21B2018,62161160337,61822309,U20B2049,61773310,U1736205,61802166); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793993","fairness;path analysis;neural networks","Training;Deep learning;Neurons;Neural networks;Games;Predictive models;Search problems","","7","","73","","20 Jun 2022","","","IEEE","IEEE Conferences"
"One Adapter for All Programming Languages? Adapter Tuning for Code Search and Summarization","D. Wang; B. Chen; S. Li; W. Luo; S. Peng; W. Dong; X. Liao","National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; Hunan University, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","5","16","As pre-trained models automate many code intel-ligence tasks, a widely used paradigm is to fine-tune a model on the task dataset for each programming language. A recent study reported that multilingual fine-tuning benefits a range of tasks and models. However, we find that multilingual fine-tuning leads to performance degradation on recent models UniXcoder and CodeT5. To alleviate the potentially catastrophic forgetting issue in multilingual models, we fix all pre-trained model parameters, insert the parameter-efficient structure adapter, and fine-tune it. Updating only 0.6% of the overall parameters compared to full-model fine-tuning for each programming language, adapter tuning yields consistent improvements on code search and sum-marization tasks, achieving state-of-the-art results. In addition, we experimentally show its effectiveness in cross-lingual and low-resource scenarios. Multilingual fine-tuning with 200 samples per programming language approaches the results fine-tuned with the entire dataset on code summarization. Our experiments on three probing tasks show that adapter tuning significantly outperforms full-model fine-tuning and effectively overcomes catastrophic forgetting.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00013","National Natural Science Foundation of China(grant numbers:62032019,61872373,62272473); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172875","transfer learning;adapter;multilingual task","Degradation;Training;Adaptation models;Computer languages;Codes;Source coding;Transfer learning","","7","","38","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Control Parameters Considered Harmful: Detecting Range Specification Bugs in Drone Configuration Modules via Learning-Guided Search","R. Han; C. Yang; S. Ma; J. Ma; C. Sun; J. Li; E. Bertino","Xidian University, Xian, China; Xidian University, Xian, China; The University of New South Wales, Canberra, Sydney, Australia; Xidian University, Xian, China; Xidian University, Xian, China; Shanghai Jiao Tong University, Shanghai, China; Purdue University, West Lafayette, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","462","473","In order to support a variety of missions and deal with different flight environments, drone control programs typically provide configurable control parameters. However, such a flexibility introduces vulnerabilities. One such vulnerability, referred to as range specification bugs, has been recently identified. The vulnerability originates from the fact that even though each individual parameter receives a value in the recommended value range, certain combinations of parameter values may affect the drone physical stability. In this paper, we develop a novel learning-guided search system to find such combinations, that we refer to as incorrect configurations. Our system applies metaheuristic search algorithms mutating configurations to detect the configuration parameters that have values driving the drone to unstable physical states. To guide the mutations, our system leverages a machine learning based predictor as the fitness evaluator. Finally, by utilizing multi-objective optimization, our system returns the feasible ranges based on the mutation search results. Because in our system the mutations are guided by a predictor, evaluating the parameter configurations does not require realistic/simulation executions. Therefore, our system supports a comprehensive and yet efficient detection of incorrect configurations. We have carried out an experimental evaluation of our system. The evaluation results show that the system successfully reports potentially incorrect configurations, of which over 85% lead to actual unstable physical states.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510084","National Natural Science Foundation of China(grant numbers:62121001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794050","Drone security;configuration test;range specification bug;deep learning approximation","Machine learning algorithms;Computer bugs;Metaheuristics;Machine learning;Prediction algorithms;Genetics;Mobile handsets","","7","","38","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Unleashing the Power of Compiler Intermediate Representation to Enhance Neural Program Embeddings","Z. Li; P. Ma; H. Wang; S. Wang; Q. Tang; S. Nie; S. Wu","The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; Tencent Security Keen Lab, China; Tencent Security Keen Lab, China; Tencent Security Keen Lab, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2253","2265","Neural program embeddings have demonstrated considerable promise in a range of program analysis tasks, including clone identification, program repair, code completion, and program synthesis. However, most existing methods generate neural program embeddings di-rectly from the program source codes, by learning from features such as tokens, abstract syntax trees, and control flow graphs. This paper takes a fresh look at how to improve program embed-dings by leveraging compiler intermediate representation (IR). We first demonstrate simple yet highly effective methods for enhancing embedding quality by training embedding models alongside source code and LLVM IR generated by default optimization levels (e.g., -02). We then introduce IRGEN, a framework based on genetic algorithms (GA), to identify (near-)optimal sequences of optimization flags that can significantly improve embedding quality. We use IRGEN to find optimal sequences of LLVM optimization flags by performing GA on source code datasets. We then extend a popular code embedding model, CodeCMR, by adding a new objective based on triplet loss to enable a joint learning over source code and LLVM IR. We benchmark the quality of embedding using a rep-resentative downstream application, code clone detection. When CodeCMR was trained with source code and LLVM IRs optimized by findings of IRGEN, the embedding quality was significantly im-proved, outperforming the state-of-the-art model, CodeBERT, which was trained only with source code. Our augmented CodeCMR also outperformed CodeCMR trained over source code and IR optimized with default optimization levels. We investigate the properties of optimization flags that increase embedding quality, demonstrate IRGEN's generalization in boosting other embedding models, and establish IRGEN's use in settings with extremely limited training data. Our research and findings demonstrate that a straightforward addition to modern neural code embedding models can provide a highly effective enhancement.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510217","CCF-Tencent Open Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793906","program embedding;deep learing;compiler technique","Training;Codes;Program processors;Cloning;Training data;Syntactics;Task analysis","","7","","106","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Controlled Concurrency Testing via Periodical Scheduling","C. Wen; M. He; B. Wu; Z. Xu; S. Qin","CSSE, Shenzhen University, Shenzhen, China; SCEDT, Teesside University, UK; CSSE, Shenzhen University, Shenzhen, China; CSSE, Shenzhen University, Shenzhen, China; Huawei Hong Kong Research Center, Hong Kong, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","474","486","Controlled concurrency testing (CCT) techniques have been shown promising for concurrency bug detection. Their key insight is to control the order in which threads get executed, and attempt to explore the space of possible interleavings of a concurrent program to detect bugs. However, various challenges remain in current CCT techniques, rendering them ineffective and ad-hoc. In this paper, we propose a novel CCT technique Period. Unlike previous works, Period models the execution of concurrent programs as periodical execution, and systematically explores the space of possible inter-leavings, where the exploration is guided by periodical scheduling and influenced by previously tested interleavings. We have evaluated Period on 10 real-world CVEs and 36 widely-used benchmark programs, and our experimental results show that Period demonstrates superiority over other CCT techniques in both effectiveness and runtime overhead. Moreover, we have discovered 5 previously unknown concurrency bugs in real-world programs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510178","National Natural Science Foundation of China(grant numbers:61972260,61772347,61836005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793865","Concurrency Testing;Concurrency Bugs Detection;Multi-threaded Programs;Systematic Testing;Stateless Model Checking","Concurrent computing;Runtime;Computer bugs;Programming;Aerospace electronics;Model checking;Benchmark testing","","5","","81","","20 Jun 2022","","","IEEE","IEEE Conferences"
"EREBA: Black-box Energy Testing of Adaptive Neural Networks","M. Haque; Y. Yadlapalli; W. Yang; C. Liu",The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas; The University of Texas at Dallas,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","835","846","Recently, various Deep Neural Network (DNN) models have been proposed for environments like embedded systems with stringent energy constraints. The fundamental problem of determining the ro-bustness of a DNN with respect to its energy consumption (energy robustness) is relatively unexplored compared to accuracy-based ro-bustness. This work investigates the energy robustness of Adaptive Neural Networks (AdNNs), a type of energy-saving DNNs proposed for many energy-sensitive domains and have recently gained traction. We propose EREBA, the first black-box testing method for determining the energy robustness of an AdNN. EREBA explores and infers the relationship between inputs and the energy con-sumption of AdNN s to generate energy surging samples. Extensive implementation and evaluation using three state-of-the-art AdNNs demonstrate that test inputs generated by EREBA could degrade the performance of the system substantially. The test inputs gener-ated by EREBA can increase the energy consumption of AdNN s by 2,000% compared to the original inputs. Our results also show that test inputs generated via EREBA are valuable in detecting energy surging inputs.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793545","Green AI;AI Energy Testing;Adversarial Machine Learning","Deep learning;Energy consumption;Adaptation models;Adaptive systems;Embedded systems;Neural networks;Green products","","5","","44","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Morest: Model-based RESTful API Testing with Execution Feedback","Y. Liu; Y. Li; G. Deng; Y. Liu; R. Wan; R. Wu; D. Ji; S. Xu; M. Bao","Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Huawei Cloud Computing Technologies Co., Ltd, China; Huawei Cloud Computing Technologies Co., Ltd, China; Huawei Technologies Co., Ltd, China; Huawei Cloud Computing Technologies Co., Ltd, China; Huawei Cloud Computing Technologies Co., Ltd, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1406","1417","RESTful APIs are arguably the most popular endpoints for accessing Web services. Blackbox testing is one of the emerging techniques for ensuring the reliability of RESTful APIs. The major challenge in testing RESTful APIs is the need for correct sequences of API operation calls for in-depth testing. To build meaningful operation call sequences, researchers have proposed techniques to learn and utilize the API dependencies based on OpenAPI specifications. However, these techniques either lack the overall awareness of how all the APIs are connected or the flexibility of adaptively fixing the learned knowledge. In this paper, we propose Morest, a model-based RESTful API testing technique that builds and maintains a dynamically updating RESTful-service Property Graph (RPG) to model the behaviors of RESTful-services and guide the call sequence generation. We empirically evaluated Morest and the results demonstrate that Morest can successfully request an average of 152.66%-232.45% more API operations, cover 26.16%-103.24% more lines of code, and detect 40.64%-215.94% more bugs than state-of-the-art techniques. In total, we applied Morest to 6 real-world projects and found 44 bugs (13 of them cannot be detected by existing approaches). Specifically, 2 of the confirmed bugs are from Bitbucket, a famous code management service with more than 6 million users.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510133","National Research Foundation(grant numbers:NRF2018NCR-NCR005-0001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794107","RESTful service;model-based testing","Adaptation models;Codes;Web services;Computer bugs;Restful API;Behavioral sciences;Reliability","","5","","49","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Efficiency Matters: Speeding Up Automated Testing with GUI Rendering Inference","S. Feng; M. Xie; C. Chen","Monash University, Melbourne, Australia; Australian National University, Canberra, Australia; Monash University, Melbourne, Australia",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","906","918","Due to the importance of Android app quality assurance, many automated GUI testing tools have been developed. Although the test algorithms have been improved, the impact of GUI rendering has been overlooked. On the one hand, setting a long waiting time to execute events on fully rendered GUIs slows down the testing process. On the other hand, setting a short waiting time will cause the events to execute on partially rendered GUIs, which negatively affects the testing effectiveness. An optimal waiting time should strike a balance between effectiveness and efficiency. We propose AdaT, a lightweight image-based approach to dynamically adjust the inter-event time based on GUI rendering state. Given the real-time streaming on the GUI, AdaT presents a deep learning model to infer the rendering state, and synchronizes with the testing tool to schedule the next event when the GUI is fully rendered. The evaluations demonstrate the accuracy, efficiency, and effectiveness of our approach. We also integrate our approach with the existing automated testing tool to demonstrate the usefulness of AdaT in covering more activities and executing more events on fully rendered GUIs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00084","Monash FIT RSP fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172585","Efficient android GUI testing;GUI rendering;Machine Learning","Deep learning;Schedules;Quality assurance;Streaming media;Rendering (computer graphics);Real-time systems;Synchronization","","5","","87","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"JITfuzz: Coverage-guided Fuzzing for JVM Just-in-Time Compilers","M. Wu; M. Lu; H. Cui; J. Chen; Y. Zhang; L. Zhang","Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; The University of Hong Kong, Hong Kong, China; Tianjin University, Tianjin, China; Southern University of Science and Technology, Shenzhen, China; University of Illinois Urbana-Champaign, Champaign, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","56","68","As a widely-used platform to support various Java-bytecode-based applications, Java Virtual Machine (JVM) incurs severe performance loss caused by its real-time program interpretation mechanism. To tackle this issue, the Just-in- Time compiler (JIT) has been widely adopted to strengthen the efficacy of JVM. Therefore, how to effectively and efficiently detect JIT bugs becomes critical to ensure the correctness of JVM. In this paper, we propose a coverage-guided fuzzing framework, namely JITfuzz, to automatically detect JIT bugs. In particular, JITfuzz adopts a set of optimization-activating mutators to trigger the usage of typical JIT optimizations, e.g., function inlining and simplification. Meanwhile, given JIT optimizations are closely coupled with program control flows, JITfuzz also adopts mutators to enrich the control flows of target programs. Moreover, JITfuzz also proposes a mutator scheduler which iteratively schedules mutators according to the coverage updates to maximize the code coverage of JIT. To evaluate the effectiveness of JITfuzz, we conduct a set of experiments based on a benchmark suite with 16 popular JVM-based projects from GitHub. The experimental results suggest that JITfuzz outperforms the state-of-the-art mutation-based and generation-based JVM fuzzers by 27.9 % and 18.6 % respectively in terms of edge coverage on average. Furthermore, JITfuzz also successfully detects 36 previously unknown bugs (including 23 JIT bugs) and 27 bugs (including 18 JIT bugs) have been confirmed by the developers.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00017","National Natural Science Foundation of China(grant numbers:61902169); National Science Foundation(grant numbers:CCF-2131943,CCF-2141474); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172743","","Java;Schedules;Image edge detection;Computer bugs;Fuzzing;Benchmark testing;Virtual machining","","4","","95","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"GPTScan: Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis","Y. Sun; D. Wu; Y. Xue; H. Liu; H. Wang; Z. Xu; X. Xie; Y. Liu","Nanyang Technological University Singapore, Singapore; Nanyang Technological University Singapore, Singapore; MetaTrust Labs Singapore, Singapore; East China Normal University, Shanghai, China; Xi'an Jiaotong University, Xi'an, China; Nanyang Technological University Singapore, Singapore; Singapore Management University Singapore, Singapore; Nanyang Technological University Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2048","2060","Smart contracts are prone to various vulnerabilities, leading to substantial financial losses over time. Current analysis tools mainly target vulnerabilities with fixed control- or data-flow patterns, such as re-entrancy and integer overflow. However, a recent study on Web3 security bugs revealed that about 80% of these bugs cannot be audited by existing tools due to the lack of domain-specific property description and checking. Given recent advances in Large Language Models (LLMs), it is worth exploring how Generative Pre-training Transformer (GPT) could aid in detecting logic vulnerabilities. In this paper, we propose GPTScan, the first tool combining GPT with static analysis for smart contract logic vulnerability detection. Instead of relying solely on GPT to identify vulnerabilities, which can lead to high false positives and is limited by GPT's pre-trained knowledge, we utilize GPT as a versatile code understanding tool. By breaking down each logic vulnerability type into scenarios and properties, GPTScan matches candidate vulnerabilities with GPT. To enhance accuracy, GPTScan further instructs GPT to intelligently recognize key variables and statements, which are then validated by static confirmation. Evaluation on diverse datasets with around 400 contract projects and 3K Solidity files shows that GPTScan achieves high precision (over 90%) for token contracts and acceptable precision (57.14%) for large projects like Web3Bugs. It effectively detects ground-truth logic vulnerabilities with a recall of over 70%, including 9 new vulnerabilities missed by human auditors. GPTScan is fast and cost-effective, taking an average of 14.39 seconds and 0.01 USD to scan per thousand lines of Solidity code. Moreover, static confirmation helps GPTScan reduce two-thirds of false positives.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639117","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549149","","Codes;Accuracy;Smart contracts;Computer bugs;Static analysis;Transformers;Logic","","4","","66","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Two Sides of the Same Coin: Exploiting the Impact of Identifiers in Neural Code Comprehension","S. Gao; C. Gao; C. Wang; J. Sun; D. Lo; Y. Yu","School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Singapore Management University, Singapore; Singapore Management University, Singapore; National University of Defense Technology",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1933","1945","Previous studies have demonstrated that neural code comprehension models are vulnerable to identifier naming. By renaming as few as one identifier in the source code, the models would output completely irrelevant results, indicating that identifiers can be misleading for model prediction. However, identifiers are not completely detrimental to code comprehension, since the semantics of identifier names can be related to the program semantics. Well exploiting the two opposite impacts of identifiers is essential for enhancing the robustness and accuracy of neural code comprehension, and still remains under-explored. In this work, we propose to model the impact of identifiers from a novel causal perspective, and propose a counterfactual reasoning-based framework named CREAM. CREAM explicitly captures the misleading information of identifiers through multi-task learning in the training stage, and reduces the misleading impact by counterfactual inference in the inference stage. We evaluate CREAM on three popular neural code comprehension tasks, including function naming, defect detection and code classification. Experiment results show that CREAM not only significantly outperforms baselines in terms of robustness (e.g., +37.9% on the function naming task at F1 score), but also achieve improved results on the original datasets (e.g., +0.5% on the function naming task at F1 score).","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172869","","Training;Codes;Source coding;Semantics;Predictive models;Multitasking;Robustness","","4","","76","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Read It, Don't Watch It: Captioning Bug Recordings Automatically","S. Feng; M. Xie; Y. Xue; C. Chen",Monash University; Australian National University; University of Science and Technology of China; Monash University,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2349","2361","Screen recordings of mobile applications are easy to capture and include a wealth of information, making them a popular mechanism for users to inform developers of the problems encountered in the bug reports. However, watching the bug recordings and efficiently understanding the semantics of user actions can be time-consuming and tedious for developers. Inspired by the conception of the video subtitle in movie industry, we present a lightweight approach CAPdroid to caption bug recordings automatically. CAPdroid is a purely image-based and non-intrusive approach by using image processing and convolutional deep learning models to segment bug recordings, infer user action attributes, and generate subtitle descriptions. The automated experiments demonstrate the good performance of CAPdroid in inferring user actions from the recordings, and a user study confirms the usefulness of our generated step descriptions in assisting developers with bug replay.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172554","bug recording;video captioning;android app","Industries;Image segmentation;Computer bugs;Semantics;Natural languages;Motion pictures;Recording","","3","","85","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"R2Z2: Detecting Rendering Regressions in Web Browsers through Differential Fuzz Testing","S. Song; J. Hur; S. Kim; P. Rogers; B. Lee","Seoul National University, Seoul, South Korea; Seoul National University, Seoul, South Korea; Seoul National University, Seoul, South Korea; Google, Mountain View, CA, United States; Seoul National University, Seoul, South Korea",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1818","1829","A rendering regression is a bug introduced by a web browser where a web page no longer functions as users expect. Such rendering bugs critically harm the usability of web browsers as well as web applications. The unique aspect of rendering bugs is that they affect the presented visual appearance of web pages, but those web pages have no pre-defined correct appearance. Therefore, it is challenging to automatically detect errors in their appearance. In practice, web browser vendors rely on non-trivial and time-prohibitive manual analysis to detect and handle rendering regressions. This paper proposes R2Z2, an automated tool to find rendering regressions. R2Z2 uses the differential fuzz testing approach, which repeatedly compares the rendering results of two different versions of a browser while providing the same HTML as input. If the rendering results are different, R2Z2 further performs cross browser compatibility testing to check if the rendering difference is indeed a rendering regression. After identifying a rendering regression, R2Z2 will perform an in-depth analysis to aid in fixing the regression. Specifically, R2Z2 performs a delta-debugging-like analysis to pinpoint the exact browser source code commit causing the regression, as well as inspecting the rendering pipeline stages to pinpoint which pipeline stage is responsible. We implemented a prototype of R2Z2 particularly targeting the Chrome browser. So far, R2Z2 found 11 previously undiscovered rendering regressions in Chrome, all of which were confirmed by the Chrome developers. Importantly, in each case, R2Z2 correctly reported the culprit commit. Moreover, R2Z2 correctly pin-pointed the culprit rendering pipeline stage in all but one case.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510044","National Research Foundation (NRF) of Korea(grant numbers:NRF-2019R1C1C1006095); Seoul National University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794047","rendering regression;web-browser;differential testing","Visualization;Computer bugs;Pipelines;Web pages;Prototypes;Fuzzing;Rendering (computer graphics)","","3","","23","","20 Jun 2022","","","IEEE","IEEE Conferences"
"LogReducer: Identify and Reduce Log Hotspots in Kernel on the Fly","G. Yu; P. Chen; P. Li; T. Weng; H. Zheng; Y. Deng; Z. Zheng","Sun Yat-sen University, Tencent Inc.; Sun Yat-sen University; Tencent Inc.; Tencent Inc.; Tencent Inc.; Tencent Inc.; Sun Yat-sen University",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1763","1775","Modern systems generate a massive amount of logs to detect and diagnose system faults, which incurs expensive storage costs and runtime overhead. After investigating real-world production logs, we observe that most of the logging overhead is due to a small number of log templates, referred to as log hotspots. Therefore, we conduct a systematical study about log hotspots in an industrial system WeChat, which motivates us to identify log hotspots and reduce them on the fly. In this paper, we propose LogReducer, a non-intrusive and language-independent log reduction framework based on eBPF (Extended Berkeley Packet Filter), consisting of both online and offline processes. After two months of serving the offline process of LogReducer in WeChat, the log storage overhead has dropped from 19.7 PB per day to 12.0 PB (i.e., about a 39.08% decrease). Practical implementation and experimental evaluations in the test environment demonstrate that the online process of LogReducer can control the logging overhead of hotspots while preserving logging effectiveness. Moreover, the log hotspot handling time can be reduced from an average of 9 days in production to 10 minutes in the test with the help of LogReducer,","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172863","Log Hotspot;eBPF;Log Reduction;Log Parsing","Runtime;Costs;Social networking (online);Process control;Production;Message services;Kernel","","3","","60","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Learning Probabilistic Models for Static Analysis Alarms","H. Kim; M. Raghothaman; K. Heo","KAIST, Korea; University of Southern California, USA; KAIST, Korea",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1282","1293","We present BayeSmith, a general framework for automatically learning probabilistic models of static analysis alarms. Several prob-abilistic reasoning techniques have recently been proposed which incorporate external feedback on semantic facts and thereby reduce the user's alarm inspection burden. However, these approaches are fundamentally limited to models with pre-defined structure, and are therefore unable to learn or transfer knowledge regarding an analysis from one program to another. Furthermore, these probabilistic models often aggressively generalize from external feedback and falsely suppress real bugs. To address these problems, we propose BayeSmith that learns the structure and weights of the probabilistic model. Starting from an initial model and a set of training programs with bug labels, BayeSmith refines the model to effectively prioritize real bugs based on feedback. We evaluate the approach with two static analyses on a suite of C programs. We demonstrate that the learned models significantly improve the performance of three state-of-the-art probabilistic reasoning systems.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510098","National Research Foundation of Korea(NRF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794056","","Training;Analytical models;Computer bugs;Semantics;Static analysis;Inspection;Probabilistic logic","","3","","50","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Leveraging Feature Bias for Scalable Misprediction Explanation of Machine Learning Models","J. Gesi; X. Shen; Y. Geng; Q. Chen; I. Ahmed","Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1559","1570","Interpreting and debugging machine learning models is necessary to ensure the robustness of the machine learning models. Explaining mispredictions can help significantly in doing so. While recent works on misprediction explanation have proven promising in generating interpretable explanations for mispredictions, the state-of-the-art techniques “blindly” deduce misprediction explanation rules from all data features, which may not be scalable depending on the number of features. To alleviate this problem, we propose an efficient misprediction explanation technique named Bias Guided Misprediction Diagnoser (BGMD), which leverages two prior knowledge about data: a) data often exhibit highly-skewed feature distributions and b) trained models in many cases perform poorly on subdataset with under-represented features. Next, we propose a technique named MAPS (Mispredicted Area UPweight Sampling). MAPS increases the weights of subdataset during model retraining that belong to the group that is prone to be mispredicted because of containing under-represented features. Thus, MAPS make retrained model pay more attention to the under-represented features. Our empirical study shows that our proposed BGMD outperformed the state-of-the-art misprediction diagnoser and reduces diagnosis time by 92%. Furthermore, MAPS outperformed two state-of-the-art techniques on fixing the machine learning model's performance on mispredicted data without compromising performance on all data. All the research artifacts (i.e., tools, scripts, and data) of this study are available in the accompanying website [1].","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172677","machine learning;data imbalance;rule induction;misprediction explanation","Machine learning algorithms;Machine learning;Debugging;Predictive models;Prediction algorithms;Robustness;Data models","","3","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Lost in Translation: A Study of Bugs Introduced by Large Language Models While Translating Code","R. Pan; A. R. Ibrahimzada; R. Krishna; D. Sankar; L. P. Wassi; M. Merler; B. Sobolev; R. Pavuluri; S. Sinha; R. Jabbarvand","IBM Research, Yorktown Heights, NY, USA; University of Illinois Urbana-Champaign, Champaign, IL, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; IBM Research, Yorktown Heights, NY, USA; University of Illinois Urbana-Champaign, Champaign, IL, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","995","1007","Code translation aims to convert source code from one programming language (PL) to another. Given the promising abilities of large language models (LLMs) in code synthesis, researchers are exploring their potential to automate code translation. The prerequisite for advancing the state of LLM-based code translation is to understand their promises and limitations over existing techniques. To that end, we present a large-scale empirical study to investigate the ability of general LLMs and code LLMs for code translation across pairs of different languages, including C, C++, Go, Java, and Python. Our study, which involves the translation of 1,700 code samples from three benchmarks and two real-world projects, reveals that LLMs are yet to be reliably used to automate code translation-with correct translations ranging from 2.1% to 47.3% for the studied LLMs. Further manual investigation of unsuccessful translations identifies 15 categories of translation bugs. We also compare LLM-based code translation with traditional non-LLM-based approaches. Our analysis shows that these two classes of techniques have their own strengths and weaknesses. Finally, insights from our study suggest that providing more context to LLMs during translation can help them produce better results. To that end, we propose a prompt-crafting approach based on the symptoms of erroneous translations; this improves the performance of LLM-based code translation by 5.5% on average. Our study is the first of its kind, in terms of scale and breadth, that provides insights into the current limitations of LLMs in code translation and opportunities for improving them. Our dataset-consisting of 1,700 code samples in five PLs with 10K+ tests, 43K+ translated code, 1,748 manually labeled bugs, and 1,365 bug-fix pairs-can help drive research in this area.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548365","code translation;bug taxonomy;11m","Java;Codes;Source coding;Computer bugs;Manuals;C++ languages;Distance measurement","","2","","92","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Dataflow Analysis-Inspired Deep Learning for Efficient Vulnerability Detection","B. Steenhoek; H. Gao; W. Le","Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA; Iowa State University, Ames, Iowa, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","177","189","Deep learning-based vulnerability detection has shown great performance and, in some studies, outperformed static analysis tools. However, the highest-performing approaches use token-based transformer models, which are not the most efficient to capture code semantics required for vulnerability detection. Classical program analysis techniques such as dataflow analysis can detect many types of bugs based on their root causes. In this paper, we propose to combine such causal-based vulnerability detection algorithms with deep learning, aiming to achieve more efficient and effective vulnerability detection. Specifically, we designed DeepDFA, a dataflow analysis-inspired graph learning framework and an embedding technique that enables graph learning to simulate dataflow computation. We show that DeepDFA is both performant and efficient. DeepDFA outperformed all non-transformer baselines. It was trained in 9 minutes, 75x faster than the highest-performing baseline model. When using only 50+ vulnerable and several hundreds of total examples as training data, the model retained the same performance as 100% of the dataset. DeepDFA also generalized to real-world vulnerabilities in Dbgbench; it detected 8.7 out of 17 vulnerabilities on average across folds and was able to distinguish between patched and buggy versions, while the highest-performing baseline models did not detect any vulnerabilities. By combining DeepDFA with a large language model, we surpassed the state-of-the-art vulnerability detection performance on the Big-Vul dataset with 96.46 F1 score, 97.82 precision, and 95.14 recall. Our replication package is located at https://doi.org/10.6084/m9.figshare.21225413.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549585","vulnerability detection;deep learning;dataflow analysis;program analysis","Deep learning;Computational modeling;Semantics;Computer bugs;Training data;Static analysis;Transformers","","2","","56","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Compiler Test-Program Generation via Memoized Configuration Search","J. Chen; C. Suo; J. Jiang; P. Chen; X. Li","College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2035","2047","To ensure compilers' quality, compiler testing has received more and more attention, and test-program generation is the core task. In recent years, some approaches have been proposed to explore test configurations for generating more effective test programs, but they either are restricted by historical bugs or suffer from the cost-effectiveness issue. Here, we propose a novel test-program generation approach (called MCS) to further improving the performance of compiler testing. MCS conducts memoized search via multi-agent reinforcement learning (RL) for guiding the construction of effective test configurations based on the memoization for the explored test configurations during the on-the-fly compiler-testing process. During the process, the elaborate coordination among configuration options can be also well learned by multi-agent RL, which is required for generating bug-triggering test programs. Specifically, MCS considers the diversity among test configurations to efficiently explore the input space and the testing results under each explored configuration to learn which portions of space are more bug-triggering. Our extensive experiments on GCC and LLVM demonstrate the performance of MCS, significantly outperforming the state-of-the-art test-program generation approaches in bug detection. Also, MCS detects 16 new bugs on the latest trunk revisions of GCC and LLVM, and all of them have been confirmed or fixed by developers. MCS has been deployed by a global IT company (i.e., Huawei) for testing their in-house compiler, and detects 10 new bugs (covering all the 5 bugs detected by the compared approaches), all of which have been confirmed.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00172","National Natural Science Foundation of China(grant numbers:62002256,62232001,62202324); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172512","Compiler Testing;Test Program Generation;Reinforcement Learning;Configuration","Program processors;Atmospheric measurements;Computer bugs;Reinforcement learning;Companies;Particle measurements;Space exploration","","2","","71","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Ponziguard: Detecting Ponzi Schemes on Ethereum with Contract Runtime Behavior Graph (CRBG)","R. Liang; J. Chen; K. He; Y. Wu; G. Deng; R. Du; C. Wu","Wuhan University, China; Wuhan University, China; Wuhan University, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Wuhan University, China; Nanyang Technological University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","766","777","Ponzi schemes, a form of scam, have been discovered in Ethereum smart contracts in recent years, causing massive financial losses. Rule-based detection approaches rely on predefined rules with limited capabilities and domain knowledge dependency. Additionally, using static information like opcodes and transactions for machine learning models fails to effectively characterize the Ponzi contracts, resulting in poor reliability and interpretability. In this paper, we propose PonziGuard, an efficient Ponzi scheme detection approach based on contract runtime behavior. Inspired by the observation that a contract's runtime behavior is more effective in disguising Ponzi contracts from the innocent contracts, Ponzi-Guard establishes a comprehensive graph representation called contract runtime behavior graph (CRBG), to accurately depict the behavior of Ponzi contracts. Furthermore, it formulates the detection process as a graph classification task, enhancing its overall effectiveness. We conducted comparative experiments on a ground-truth dataset and applied PonziGuard to Ethereum Mainnet. The results show that PonziGuard outperforms the current state-of-the-art approaches and is also effective in open environments. Using PonziGuard, we have identified 805 Ponzi contracts on Ethereum Mainnet, which have resulted in an estimated economic loss of 281,700 Ether or approximately $500 million USD.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548971","Smart Contract;Ponzi Scheme;Flow Analysis;Graph Neural Net-works","Economics;Runtime;Biological system modeling;Smart contracts;Pressing;Machine learning;Reliability","","2","","47","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Safeguarding DeFi Smart Contracts Against Oracle Deviations","X. Deng; S. M. Beillahi; C. Minwalla; H. Du; A. Veneris; F. Long","University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; Bank of Canada, Ottawa, Canada; Bank of Canada, Ottawa, Canada; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2111","2122","This paper presents OVer, a framework designed to automatically analyze the behavior of decentralized finance (DeFi) protocols when subjected to a “skewed” oracle input. OVer firstly performs symbolic analysis on the given contract and constructs a model of constraints. Then, the framework leverages an SMT solver to identify parameters that allow its secure operation. Furthermore, guard statements may be generated for smart contracts that may use the oracle values, thus effectively preventing oracle manipulation attacks. Empirical results show that OVer can successfully analyze all 10 benchmarks collected, which encompass a diverse range of DeFi protocols. Additionally, this paper illustrates that current parameters utilized in the majority of benchmarks are inadequate to ensure safety when confronted with significant oracle deviations. It shows that existing ad-hoc control mechanisms such as introducing delays are often insufficient or even detrimental to protect the DeFi protocols against the oracle deviation in the real-world.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548838","Blockchain;Decentralized Finance;Smart Contracts;Oracle Deviation;Static Program Analysis;Code Summary;Parameter Optimization","Analytical models;Source coding;Smart contracts;Finance;Benchmark testing;Decentralized applications;Safety","","2","","53","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Columbus: Android App Testing Through Systematic Callback Exploration","P. Bose; D. Das; S. Vasan; S. Mariani; I. Grishchenko; A. Continella; A. Bianchi; C. Kruegel; G. Vigna","University of California, Santa Barbara; University of California, Santa Barbara; University of California, Santa Barbara; VMware, Inc.; University of California, Santa Barbara; University of Twente; Purdue University; University of California, Santa Barbara; University of California, Santa Barbara",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1381","1392","With the continuous rise in the popularity of Android mobile devices, automated testing of apps has become more important than ever. Android apps are event-driven programs. Unfortunately, generating all possible types of events by interacting with an app's interface is challenging for an automated testing approach. Callback-driven testing eliminates the need for event generation by directly invoking app callbacks. However, existing callback-driven testing techniques assume prior knowledge of Android callbacks, and they rely on a human expert, who is familiar with the Android API, to write stub code that prepares callback arguments before invocation. Since the Android API is very large and keeps evolving, prior techniques could only support a small fraction of callbacks present in the Android framework. In this work, we introduce Columbus, a callback-driven testing technique that employs two strategies to eliminate the need for human involvement: (i) it automatically identifies callbacks by simultaneously analyzing both the Android framework and the app under test; (ii) it uses a combination of under-constrained symbolic execution (primitive arguments), and type-guided dynamic heap introspection (object arguments) to generate valid and effective inputs. Lastly, Columbus integrates two novel feedback mechanisms-data dependency and crash-guidance- during testing to increase the likelihood of triggering crashes and maximizing coverage. In our evaluation, Columbus outperforms state-of-the-art model-driven, checkpoint-based, and callback-driven testing tools both in terms of crashes and coverage.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00121","DARPA(grant numbers:N66001-22-2-4037); NSF(grant numbers:2107101); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172528","Android;app testing;callback","Systematics;Codes;Computer bugs;Computer crashes;Object recognition;Smart phones;Testing","","2","","51","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"(Partial) Program Dependence Learning","A. Yadavally; T. N. Nguyen; W. Wang; S. Wang","Computer Science Department, The University of Texas at Dallas, Texas, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2501","2513","Code fragments from developer forums often migrate to applications due to the code reuse practice. Owing to the incomplete nature of such programs, analyzing them to early determine the presence of potential vulnerabilities is challenging. In this work, we introduce NeuralPDA, a neural network-based program dependence analysis tool for both complete and partial programs. Our tool efficiently incorporates intra-statement and inter-statement contextual features into statement representations, thereby modeling program dependence analysis as a statement-pair dependence decoding task. In the empirical evaluation, we report that NeuralPDA predicts the CFG and PDG edges in complete Java and C/C++ code with combined F-scores of 94.29% and 92.46%, respectively. The F-score values for partial Java and C/C++ code range from 94.29%-97.17% and 92.46%-96.01%, respectively. We also test the usefulness of the PDGs predicted by NeuralPDA (i.e., PDG*) on the downstream task of method-level vulnerability detection. We discover that the performance of the vulnerability detection tool utilizing PDG* is only 1.1% less than that utilizing the PDGs generated by a program analysis tool. We also report the detection of 14 real-world vulnerable code snippets from StackOverflow by a machine learning-based vulnerability detection tool that employs the PDGs predicted by NeuralPDA for these code snippets.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00209","US National Science Foundation (NSF)(grant numbers:CNS-2120386); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172603","neural partial program analysis;neural program dependence analysis;neural networks;deep learning","Java;Analytical models;Codes;Image edge detection;Neural networks;Decoding;Task analysis","","2","","55","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Semantic GUI Scene Learning and Video Alignment for Detecting Duplicate Video-based Bug Reports","Y. Yan; N. Cooper; O. Chaparro; K. Moran; D. Poshyvanyk","William & Mary, Williamsburg, Virginia, USA; William & Mary, Williamsburg, Virginia, USA; William & Mary, Williamsburg, Virginia, USA; University of Central Florida, Orlando, Florida, USA; William & Mary, Williamsburg, Virginia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2868","2880","Video-based bug reports are increasingly being used to document bugs for programs centered around a graphical user interface (GUI). However, developing automated techniques to manage video-based reports is challenging as it requires identifying and understanding often nuanced visual patterns that capture key information about a reported bug. In this paper, we aim to overcome these challenges by advancing the bug report management task of duplicate detection for video-based reports. To this end, we introduce a new approach, called JANUS, that adapts the scene-learning capabilities of vision transformers to capture subtle visual and textual patterns that manifest on app UI screens - which is key to differentiating between similar screens for accurate duplicate report detection. JANUS also makes use of a video alignment technique capable of adaptive weighting of video frames to account for typical bug manifestation patterns. In a comprehensive evaluation on a benchmark containing 7,290 duplicate detection tasks derived from 270 video-based bug reports from 90 Android app bugs, the best configuration of our approach achieves an overall mRR/mAP of 89.8%/84.7%, and for the large majority of duplicate detection tasks, outperforms prior work by ≈9% to a statistically significant degree. Finally, we qualitatively illustrate how the scene-learning capabilities provided by JANUS benefits its performance.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639163","NSF(grant numbers:CCF-2311469,CCF-2007246,CCF-1955853); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549397","Bug Reporting;GUI Learning;Duplicate Video Retrieval","Representation learning;Visualization;Computer bugs;Semantics;Benchmark testing;Transformers;Mobile applications","","2","","81","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"On the Applicability of Language Models to Block-Based Programs","E. Griebl; B. Fein; F. Obermüller; G. Fraser; R. Just","University of Passau, Passau, Germany; University of Passau, Passau, Germany; University of Passau, Passau, Germany; University of Passau, Passau, Germany; University of Washington, Seattle, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2374","2386","Block-based programming languages like Scratch are increasingly popular for programming education and end-user programming. Recent program analyses build on the insight that source code can be modelled using techniques from natural language processing. Many of the regularities of source code that support this approach are due to the syntactic overhead imposed by textual programming languages. This syntactic overhead, however, is precisely what block-based languages remove in order to simplify programming. Consequently, it is unclear how well this modelling approach performs on block-based programming languages. In this paper, we investigate the applicability of language models for the popular block-based programming language Scratch. We model Scratch programs using n-gram models, the most essential type of language model, and transformers, a popular deep learning model. Evaluation on the example tasks of code completion and bug finding confirm that blocks inhibit predictability, but the use of language models is nevertheless feasible. Our findings serve as foundation for improving tooling and analyses for block-based languages.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172831","Block-Based Programs;Scratch;Natural Language Model;Code Completion;Bugram","Computer languages;Analytical models;Codes;Source coding;Computational modeling;Predictive models;Transformers","","2","","46","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Compiling Parallel Symbolic Execution with Continuations","G. Wei; S. Jia; R. Gao; H. Deng; S. Tan; O. Bračevac; T. Rompf","Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of EECS, UC Berkeley, Purdue University, Berkeley, CA, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1316","1328","Symbolic execution is a powerful program analysis and testing technique. Symbolic execution engines are usually implemented as interpreters, and the induced interpretation over-head can dramatically inhibit performance. Alternatively, implementation choices based on instrumentation provide a limited ability to transform programs. However, the use of compilation and code generation techniques beyond simple instrumentation remains underexplored for engine construction, leaving potential performance gains untapped. In this paper, we show how to tap some of these gains using sophisticated compilation techniques: We present Gensym, an optimizing symbolic-execution compiler that generates symbolic code which explores paths and generates tests in parallel. The key insight of GensYmis to compile symbolic execution tasks into cooperative concurrency via continuation-passing style, which further enables efficient parallelism. The design and implementation of Gensym is based on partial evaluation and generative programming techniques, which make it high-level and performant at the same time. We compare the performance of Gensym against the prior symbolic-execution compiler LLSC and the state-of-the-art symbolic interpreter KLEE. The results show an average 4.6× speedup for sequential execution and 9.4× speedup for parallel execution on 20 benchmark programs.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00116","NSF(grant numbers:1553471,1564207,1918483,1910216); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172731","symbolic execution;compiler;code generation;metaprogramming;continuation","Concurrent computing;Codes;Instruments;Transforms;Programming;Performance gain;Parallel processing","","2","","68","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"REFTY: Refinement Types for Valid Deep Learning Models","Y. Gao; Z. Li; H. Lin; H. Zhang; M. Wu; M. Yang","Microsoft Research, China; Microsoft Research, China; Microsoft Research, China; The University of Newcastle, Australia; Shanghai Tree-Graph Blockchain Research Institute, China; Microsoft Research, China",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1843","1855","Deep learning has been increasingly adopted in many application areas. To construct valid deep learning models, developers must conform to certain computational constraints by carefully selecting appropriate neural architectures and hyperparameter values. For example, the kernel size hyperparameter of the 2D convolution operator cannot be overlarge to ensure that the height and width of the output tensor remain positive. Because model construction is largely manual and lacks necessary tooling support, it is possible to violate those constraints and raise type errors of deep learning models, causing either runtime exceptions or wrong output results. In this paper, we propose Refty, a refinement type-based tool for statically checking the validity of deep learning models ahead of job execution. Refty refines each type of deep learning operator with framework-independent logical formulae that describe the computational constraints on both tensors and hyperparameters. Given the neural architecture and hyperparameter domains of a model, Refty visits every operator, generates a set of constraints that the model should satisfy, and utilizes an SMT solver for solving the constraints. We have evaluated Refty on both individual operators and representative real-world models with various hyperparameter values under PyTorch and TensorFlow. We also compare it with an existing shape-checking tool. The experimental results show that Refty finds all the type errors and achieves 100% Precision and Recall, demonstrating its effectiveness.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510077","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794045","deep learning;validity checking;type error;refinement type","Deep learning;Tensors;Runtime;Convolution;Computational modeling;Computer architecture;Manuals","","2","","87","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Demystifying the Dependency Challenge in Kernel Fuzzing","Y. Hao; H. Zhang; G. Li; X. Du; Z. Qian; A. A. Sani","UC Riverside, Riverside, USA; Georgia Institute of Technology, Atlanta, USA; UC Riverside, Riverside, USA; UC Riverside, Riverside, USA; UC Riverside, Riverside, USA; UC Irvine, Irvine, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","659","671","Fuzz testing operating system kernels remains a daunting task to date. One known challenge is that much of the kernel code is locked under specific kernel states and current kernel fuzzers are not ef-fective in exploring such an enormous state space. We refer to this problem as the dependency challenge. Though there are some ef-forts trying to address the dependency challenge, the prevalence and categorization of dependencies have never been studied. Most prior work simply attempted to recover dependencies opportunisti-cally whenever they are relatively easy to recognize. In this paper, we undertake a substantial measurement study to systematically understand the real challenge behind dependencies. To our surprise, we show that even for well-fuzzed kernel modules, unresolved de-pendencies still account for 59% - 88% of the uncovered branches. Furthermore, we show that the dependency challenge is only a symptom rather than the root cause of failing to achieve more cov-erage. By distilling and summarizing our findings, we believe the research provides valuable guidance to future research in kernel fuzzing. Finally, we propose a number of novel research directions directly based on the insights gained from the measurement study.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793967","","Codes;Linux;Manuals;Fuzzing;Gain measurement;Kernel;Task analysis","","1","","36","CCBY","20 Jun 2022","","","IEEE","IEEE Conferences"
"Less is More? An Empirical Study on Configuration Issues in Python PyPI Ecosystem","Y. Peng; R. Hu; R. Wang; C. Gao; S. Li; M. R. Lyu","The Chinese University of Hong Kong, Hong Kong, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2494","2505","Python is the top popular programming language used in the open-source community, largely owing to the extensive support from diverse third-party libraries within the PyPI ecosystem. Nevertheless, the utilization of third-party libraries can potentially lead to conflicts in dependencies, prompting researchers to develop dependency conflict detectors. Moreover, endeavors have been made to automatically infer dependencies. These approaches focus on version-level checks and inference, based on the assumption that configurations of libraries in the PyPI ecosystem are correct. However, our study reveals that this assumption is not universally valid, and relying solely on version-level checks proves inadequate in ensuring compatible runtime environments. In this paper, we conduct an empirical study to comprehensively study the configuration issues in the PyPI ecosystem. Specifically, we propose PYCONF, a source-level detector, for detecting potential configuration issues. PYCONF employs three distinct checks, targeting the setup, packing, and usage stages of libraries, respectively. To evaluate the effectiveness of the current automatic dependency inference approaches, we build a benchmark called VLIBS, comprising library releases that pass all three checks of PYCONF. We identify 15 kinds of configuration issues and find that 183,864 library releases suffer from potential configuration issues. Remarkably, 68% of these issues can only be detected via the source-level check. Our experiment results show that the most advanced automatic dependency inference approach, PyEGo, can successfully infer dependencies for only 65% of library releases. The primary failures stem from dependency conflicts and the absence of required libraries in the generated configurations. Based on the empirical results, we derive six findings and draw two implications for open-source developers and future research in automatic dependency inference.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639077","National Natural Science Foundation of China(grant numbers:62002084); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548916","Configuration;PyPI;Python;Empirical Study","Runtime;Ecosystems;Detectors;Benchmark testing;Libraries;Python","","1","","45","","14 Jun 2024","","","IEEE","IEEE Conferences"
"S3C: Spatial Semantic Scene Coverage for Autonomous Vehicles","T. Woodlief; F. Toledo; S. Elbaum; M. B. Dwyer","University of Virginia, Charlottesville, VA, USA; University of Virginia, Charlottesville, VA, USA; University of Virginia, Charlottesville, VA, USA; University of Virginia, Charlottesville, VA, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1736","1748","Autonomous vehicles (AVs) must be able to operate in a wide range of scenarios including those in the long tail distribution that include rare but safety-critical events. The collection of sensor input and expected output datasets from such scenarios is crucial for the development and testing of such systems. Yet, approaches to quantify the extent to which a dataset covers test specifications that capture critical scenarios remain limited in their ability to discriminate between inputs that lead to distinct behaviors, and to render interpretations that are relevant to AV domain experts. To address this challenge, we introduce S3C, a framework that abstracts sensor inputs to coverage domains that account for the spatial semantics of a scene. The approach leverages scene graphs to produce a sensor-independent abstraction of the AV environment that is interpretable and discriminating. We provide an implementation of the approach and a study for camera-based autonomous vehicles operating in simulation. The findings show that S3C outperforms existing techniques in discriminating among classes of inputs that cause failures, and offers spatial interpretations that can explain to what extent a dataset covers a test specification. Further exploration of S3C with open datasets complements the study findings, revealing the potential and shortcomings of deploying the approach in the wild.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639178","National Science Foundation(grant numbers:2129824,2312487); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549477","coverage;scene graph;autonomous vehicles;perception","Training;Semantics;Transforms;Tail;Generators;Autonomous vehicles;Testing","","1","","55","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Language Models for Code Completion: A Practical Evaluation","M. Izadi; J. Katzy; T. van Dam; M. Otten; R. M. Popescu; A. van Deursen","Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands; Delft University of Technology, Delft, Netherlands",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","956","968","Transformer-based language models for automatic code completion have shown great promise so far, yet the evaluation of these models rarely uses real data. This study provides both quantitative and qualitative assessments of three public code language models when completing real-world code. We first developed an open-source IDE extension, Code4Me, for the online evaluation of the models. We collected real auto-completion usage data for over a year from more than 1200 users, resulting in over 600K valid completions. These models were then evaluated using six standard metrics across twelve programming languages. Next, we conducted a qualitative study of 1690 real-world completion requests to identify the reasons behind the poor model performance. A comparative analysis of the models' performance in online and offline settings was also performed, using benchmark synthetic datasets and two masking strategies. Our findings suggest that while developers utilize code completion across various languages, the best results are achieved for mainstream languages such as Python and Java. InCoder outper-formed the other models across all programming languages, high-lighting the significance of training data and objectives. Our study also revealed that offline evaluations do not accurately reflect real-world scenarios. Upon qualitative analysis of the models' predictions, we found that 66.3% of failures were due to models' limitations, 24.4% occurred due to inappropriate model usage in a development context, and 9.3% were valid requests that developers overwrote. Given these findings, we propose several strategies to overcome the current limitations. These include refining training objectives, improving resilience to typographical errors, adopting hybrid approaches, and enhancing implementations and usability.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548973","Automatic Code Completion;Transformers;Language Models;IDE;Evaluation;Open Source;InCoder;UniXcoder;CodeGPT","Training;Analytical models;Codes;Training data;Predictive models;Transformers;Data models","","1","","52","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"When to Say What: Learning to Find Condition-Message Inconsistencies","I. Bouzenia; M. Pradel","University of Stuttgart, Germany; University of Stuttgart, Germany",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","868","880","Programs often emit natural language messages, e.g., in logging statements or exceptions raised on unexpected paths. To be meaningful to users and developers, the message, i.e., what to say, must be consistent with the condition under which it gets triggered, i.e., when to say it. However, checking for inconsistencies between conditions and messages is challenging because the conditions are expressed in the logic of the programming language, while messages are informally expressed in natural language. This paper presents CMI-Finder, an approach for detecting condition-message inconsistencies. CMI-Finder is based on a neural model that takes a condition and a message as its input and then predicts whether the two are consistent. To address the problem of obtaining realistic, diverse, and large-scale training data, we present six techniques to generate large numbers of inconsistent examples to learn from automatically. Moreover, we describe and compare three neural models, which are based on binary classification, triplet loss, and fine-tuning, respectively. Our evaluation applies the approach to 300K condition-message statements extracted from 42 million lines of Python code. The best model achieves a precision of 78% at a recall of 72% on a dataset of past bug fixes. Applying the approach to the newest versions of popular open-source projects reveals 50 previously unknown bugs, 19 of which have been confirmed by the developers so far.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00081","European Research Council(grant numbers:851895); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172811","","Codes;Computer bugs;Natural languages;Training data;Predictive models;Data models;Python","","1","","56","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"SCTRANS: Constructing a Large Public Scenario Dataset for Simulation Testing of Autonomous Driving Systems","J. Dai; B. Gao; M. Luo; Z. Huang; Z. Li; Y. Zhang; M. Yang","Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","591","603","For the safety assessment of autonomous driving systems (ADS), simulation testing has become an important complementary technique to physical road testing. In essence, simulation testing is a scenario-driven approach, whose effectiveness is highly dependent on the quality of given simulation scenarios. Moreover, simulation scenarios should be encoded into well-formatted files, otherwise, ADS simulation platforms cannot take them as inputs. Without large public datasets of simulation scenario files, both industry and academic applications of ADS simulation testing are hindered. To fill this gap, we propose a transformation-based approach SCTRANS to construct simulation scenario files, utilizing existing traffic scenario datasets (i.e., naturalistic movement of road users recorded on public roads) as data sources. Specifically, we try to transform existing traffic scenario recording files into simulation scenario files that are compatible with the most advanced ADS simulation platforms, and this task is formalized as a Model Transformation Problem. Following this idea, we construct a dataset consisting of over 1,900 diverse simulation scenarios, each of which can be directly used to test the state-of-the-art ADSs (i.e., Apollo and Autoware) via high-fidelity simulators (i.e., Carla and LGSVL). To further demonstrate the utility of our dataset, we showcase that it can boost the collision-finding capability of existing simulation-based ADS fuzzers, helping identify about seven times more unique ADS-involved collisions within the same time period. By analyzing these collisions at the code level, we identify nine safety-critical bugs of Apollo and Autoware, each of which can be stably exploited to cause vehicle crashes. Till now, four of them have been confirmed.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623350","National Key Research and Development Program(grant numbers:2021YFB3101200); National Natural Science Foundation of China(grant numbers:62172105,62172104,62102091,62102093); Ministry of Industry and Information Technology of the People's Republic of China(grant numbers:TC220H079); Shanghai Rising-Star Program(grant numbers:210A1400700); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548123","simulation scenario;autonomous driving;model transformation","Roads;Soft sensors;Computer bugs;Transforms;Safety;Recording;Task analysis","","1","","96","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Are We There Yet? Unraveling the State-of-the-Art Smart Contract Fuzzers","S. Wu; Z. Li; L. Yan; W. Chen; M. Jiang; C. Wang; X. Luo; H. Zhou","The Hong Kong Polytechnic University, Hong Kong, China; The Hong Kong Polytechnic University, Hong Kong, China; The Hong Kong Polytechnic University, Hong Kong, China; The Hong Kong Polytechnic University, Hong Kong, China; The Hong Kong Polytechnic University, Hong Kong, China; Xi’ an Jiaotong University, Xi'an, China; The Hong Kong Polytechnic University, Hong Kong, China; The Hong Kong Polytechnic University, Hong Kong, China",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1560","1572","Given the growing importance of smart contracts in various applications, ensuring their security and reliability is critical. Fuzzing, an effective vulnerability detection technique, has recently been widely applied to smart contracts. Despite numerous studies, a systematic investigation of smart contract fuzzing techniques remains lacking. In this paper, we fill this gap by: 1) providing a comprehensive review of current research in contract fuzzing, and 2) conducting an in-depth empirical study to evaluate state-of-the-art contract fuzzers' usability. To guarantee a fair evaluation, we employ a carefully-labeled benchmark and introduce a set of pragmatic performance metrics, evaluating fuzzers from five complementary perspectives. Based on our findings, we provide direction for the future research and development of contract fuzzers.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639152","National Natural Science Foundation of China(grant numbers:62272379); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548588","Smart Contract;Fuzzing;Evaluation","Measurement;Systematics;Reviews;Smart contracts;Fuzzing;Benchmark testing;Security","","1","","111","","14 Jun 2024","","","IEEE","IEEE Conferences"
"PROMAL: Precise Window Transition Graphs for Android via Synergy of Program Analysis and Machine Learning","C. Liu; H. Wang; T. Liu; D. Gu; Y. Ma; H. Wang; X. Xiao",Case Western Reserve University; Case Western Reserve University; Monash University; Peking University; Peking University; Beijing University of Posts and Telecommunications; Case Western Reserve University,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1755","1767","Mobile apps have been an integral part in our daily life. As these apps become more complex, it is critical to provide automated analysis techniques to ensure the correctness, security, and performance of these apps. A key component for these automated analysis techniques is to create a graphical user interface (GUI) model of an app, i.e., a window transition graph (WTG), that models windows and transitions among the windows. While existing work has provided both static and dynamic analysis to build the WTG for an app, the constructed WTG misses many transitions or contains many infeasible transitions due to the coverage issues of dynamic analysis and over-approximation of the static analysis. We propose ProMal, a “tribrid” analysis that synergistically combines static analysis, dynamic analysis, and machine learning to construct a precise WTG. Specifically, ProMal first applies static analysis to build a static WTG, and then applies dynamic analysis to verify the transitions in the static WTG. For the unverified transitions, ProMal further provides machine learning techniques that leverage runtime information (i.e., screenshots, UI layouts, and text information) to predict whether they are feasible transitions. Our evaluations on 40 real-world apps demonstrate the superiority of ProMal in building WTGs over static analysis, dynamic analysis, and machine learning techniques when they are applied separately.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510037","National Science Foundation(grant numbers:CCF-2046953,CNS-2028748); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794097","mobile apps;window transition graph;static analysis;deep learning","Analytical models;Runtime;Buildings;Static analysis;Machine learning;Windows;Performance analysis","","1","","72","","20 Jun 2022","","","IEEE","IEEE Conferences"
"CERT: Finding Performance Issues in Database Systems Through the Lens of Cardinality Estimation","J. Ba; M. Rigger","National University of Singapore, Singapore; National University of Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1635","1647","Database Management Systems (DBMSs) process a given query by creating a query plan, which is subsequently executed, to compute the query's result. Deriving an efficient query plan is challenging, and both academia and industry have invested decades into researching query optimization. Despite this, DBMSs are prone to performance issues, where a DBMS produces an unexpectedly inefficient query plan that might lead to the slow execution of a query. Finding such issues is a longstanding problem and inherently difficult, because no ground truth information on an expected exe-cution time exists. In this work, we propose Cardinality Estimation Restriction Testing (CERT), a novel technique that finds performance issues through the lens of cardinality estimation. Given a query on a database, CERT derives a more restrictive query (e.g., by replacing a LEFT JOIN with an INNER JOIN), whose estimated number of rows should not exceed the estimated number of rows for the original query. CERT tests cardinality estimation specifically, because it was shown to be the most important part for query optimization; thus, we expect that finding and fixing cardinality-estimation issues might result in the highest performance gains. In addition, we found that other kinds of query optimization issues can be exposed by unexpected estimated cardinalities, which can also be found by CERT. CERT is a black-box technique that does not require access to the source code; DBMSs expose query plans via the EXPLAIN statement. CERT eschews executing queries, which is costly and prone to performance fluctuations. We evaluated CERT on three widely used and mature DBMSs, MySQL, TiDB, and CockroachDB. CERT found 13 unique issues, of which 2 issues were fixed and 9 confirmed by the developers. We expect that this new angle on finding performance bugs will help DBMS developers in improving DMBSs' performance.","1558-1225","979-8-4007-0217-4","","National Research Foundation, Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548542","Database;Performance Issue;Cardinality Estimation","Industries;Fluctuations;Query processing;Source coding;Computer bugs;Estimation;Performance gain","","","","68","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Supporting Web-Based API Searches in the IDE Using Signatures","N. C. Bradley; T. Fritz; R. Holmes","The University of British Columbia, Canada; University of Zurich, Switzerland; The University of British Columbia, Canada",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2295","2306","Developers frequently use the web to locate API examples that help them solve their programming tasks. While sites like Stack Overflow (SO) contain API examples embedded within their textual descriptions, developers cannot access this API knowledge directly. Instead they need to search for and browse results to select relevant SO posts and then read through individual posts to figure out which answers contain information about the APIs that are relevant to their task. This paper introduces an approach, called Scout, that automatically analyzes search results to extract API signature information. These signatures are used to group and rank examples and allow for a unique API-based presentation that reduces the amount of information the developer needs to consider when looking for API information on the web. This succinct representation enables Scout to be integrated fully within an IDE panel so that developers can search and view API examples without losing context on their development task. Scout also uses this integration to automatically augment queries with contextual information that tailors the developer's queries, and ranks the results according to the developer's needs. In an experiment with 40 developers, we found that Scout reduces the number of queries developers need to perform by 19% and allows them to solve almost half their tasks directly from the API-based representation, reducing the number of complete SO posts viewed by approximately 64%.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549139","API signatures;code search;controlled experiment","Information resources;Codes;Source coding;Search engines;Programming;Data mining;Task analysis","","","","50","","14 Jun 2024","","","IEEE","IEEE Conferences"
"A Framework for Inferring Properties of User-Defined Functions","X. Liu; J. Arulraj; A. Orso","Georgia Institute of Technology, Atlanta, Georgia, USA; Georgia Institute of Technology, Atlanta, Georgia, USA; Georgia Institute of Technology, Atlanta, Georgia, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1324","1334","User-defined functions (UDFs) are widely used to enhance the ca-pabilities of DBMSs. However, using UDFs comes with a significant performance penalty because DBMSs treat UDFs as black boxes, which hinders their ability to optimize queries that invoke such UDFs. To mitigate this problem, in this paper we present LAMBDA, a technique and framework for improving DBMSs' performance in the presence of UDFs. The core idea of LAMBDA is to statically infer properties of UDFs that facilitate UDF processing. Taking one such property as an example, if DBMSs know that a UDF is pure, that is it returns the same result given the same arguments, they can leverage a cache to avoid repetitive UDF invocations that have the same call arguments. We reframe the problem of analyzing UDF properties as a data flow problem. We tackle the data flow problem by building LAMBDA on top of an extensible abstract interpretation framework and developing an analysis model that is tailored for UDFs. Currently, LAMBDA supports inferring four properties from UDFs that are widely used across DBMSs. We evaluate LAMBDA on a benchmark that is derived from production query workloads and UDFs. Our evaluation results show that (1) LAMBDA conservatively and efficiently infers the considered UDF properties, and (2) inferring such properties improves UDF performance, with a time reduction ranging from 10% to 99%. In addition, when applied to 20 production UDFs, LAMBDA caught five instances in which developers provided incorrect UDF property annotations. We qualitatively compare LAMBDA against Froid, a state-of-the-art framework for improving UDF performance, and explain how LAMBDA can optimize UDFs that are not supported by Froid.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639147","NSF(grant numbers:CCF-0725202,IIS-1908984,IIS-2238431); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548342","UDF properties;DBMSs;static analysis","Analytical models;Annotations;Buildings;Production;Benchmark testing;Parallel processing;Distance measurement","","","","28","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"SmallRace: Static Race Detection for Dynamic Languages - A Case on Smalltalk","S. Cui; Y. Gao; R. Unterguggenberger; W. Pichler; S. Livingstone; J. Huang","Texas A&M University College Station, Texas; Texas A&M University College Station, Texas; Lam Research; Lam Research; Texas A&M University College Station, Texas; Texas A&M University College Station, Texas",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1136","1147","Smalltalk, one of the first object-oriented programming languages, has had a tremendous influence on the evolution of computer technology. Due to the simplicity and productivity provided by the language, Smalltalk is still in active use today by many companies with large legacy codebases and with new code written every day. A crucial problem in Smalltalk programming is the race condition. Like in any other parallel language, debugging race conditions is inherently challenging, but in Smalltalk, it is even more challenging due to its dynamic nature. Being a purely dynamically-typed language, Smalltalk allows assigning any object to any variable without type restrictions, and allows forking new threads to execute arbitrary anonymous code blocks passed as objects. In Smalltalk, race conditions can be introduced easily, but are difficult to prevent at runtime. We present SmallRace, a novel static race detection framework designed for multithreaded dynamic languages, with a focus on Smalltalk. A key component of SmallRace is SmallIR, a subset of LLVM IR, in which all variables are declared with the same type-a generic pointer 18✶. This allows SmallRace to design an effective interprocedural thread-sensitive pointer analysis to infer the concrete types of dynamic variables. SmallRace automatically translates Smalltalk source code into SmallIR, supports most of the modern Smalltalk syntax in Visual Works, and generates actionable race reports with detailed debugging information. Importantly, SmallRace has been used to analyze a production codebase in a large company with over a million lines of code, and it has found tens of complex race conditions in the production code.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172500","","Productivity;Visualization;Parallel languages;Codes;Instruction sets;Source coding;Debugging","","","","45","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Symbol-Specific Sparsification of Interprocedural Distributive Environment Problems","K. Karakaya; E. Bodden","Heinz Nixdorf Institute, Paderborn University, Paderborn, Germany; Heinz Nixdorf Institute, Paderborn University & Fraunhofer IEM, Paderborn, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1273","1284","Previous work has shown that one can often greatly speed up static analysis by computing data flows not for every edge in the program's control-flow graph but instead only along definition-use chains. This yields a so-called sparse static analysis. Recent work on Sparsedroid has shown that specifically taint analysis can be “sparsified” with extraordinary effectiveness because the taint state of one variable does not depend on those of others. This allows one to soundly omit more flow-function computations than in the general case. In this work, we now assess whether this result carries over to the more generic setting of so-called Interprocedural Distributive Envi-ronment (IDE) problems. Opposed to taint analysis, IDE comprises distributive problems with large or even infinitely broad domains, such as typestate analysis or linear constant propagation. Specif-ically, this paper presents Sparse IDE, a framework that realizes sparsification for any static analysis that fits the IDE framework. We implement Sparse IDE in SPARSEHEROS, as an extension to the popular Heros Ide solver, and evaluate its performance on real-world Java libraries by comparing it to the baseline IDE al-gorithm. To this end, we design, implement and evaluate a linear constant propagation analysis client on top of SPARSEHEROS. Our experiments show that, although IDE analyses can only be sparsi-fied with respect to symbols and not (numeric) values, Sparse IDE can nonetheless yield significantly lower runtimes and often also memory consumptions compared to the original IDE.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548489","static analysis;sparse analysis;IFDS;IDE;constant propagation","Java;Runtime;Symbols;Static analysis;Libraries","","","","41","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"REDriver: Runtime Enforcement for Autonomous Vehicles","Y. Sun; C. M. Poskitt; X. Zhang; J. Sun","Singapore Management University, Singapore; Singapore Management University, Singapore; Xidian University, China; Singapore Management University, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2171","2182","Autonomous driving systems (ADSs) integrate sensing, perception, drive control, and several other critical tasks in autonomous vehicles, motivating research into techniques for assessing their safety. While there are several approaches for testing and analysing them in high-fidelity simulators, ADSs may still encounter additional critical scenarios beyond those covered once they are deployed on real roads. An additional level of confidence can be established by monitoring and enforcing critical properties when the ADS is running. Existing work, however, is only able to monitor simple safety properties (e.g., avoidance of collisions) and is limited to blunt enforcement mechanisms such as hitting the emergency brakes. In this work, we propose REDriver, a general and modular approach to runtime enforcement, in which users can specify a broad range of properties (e.g., national traffic laws) in a specifi-cation language based on signal temporal logic (STL). REDriver monitors the planned trajectory of the ADS based on a quantitative semantics of STL, and uses a gradient-driven algorithm to repair the trajectory when a violation of the specification is likely. We implemented REDrive r for two versions of Apollo (i.e., a popular ADS), and subjected it to a benchmark of violations of Chinese traffic laws. The results show that REDri ver significantly improves Apollo's conformance to the specification with minimal overhead.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549259","Runtime Enforcement;Autonomous Driving;Autonomous Vehicles","Runtime;Roads;Semantics;Trajectory;Safety;Sensors;Task analysis","","","","50","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Scaling Code Pattern Inference with Interactive What-If Analysis","H. J. Kang; K. Wang; M. Kim","University of California, Los Angeles, USA; University of California, Los Angeles, USA; University of California, Los Angeles, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2893","2904","Programmers often have to search for similar code when detecting and fixing similar bugs. Prior active learning approaches take only instance-level feedback, i.e., positive and negative method instances. This limitation leads to increased labeling burden, when users try to control generality and specificity for a desired code pattern. We present a novel feedback-guided pattern inference approach, called SURF. To reduce users' labelling effort, it actively guides users in assessing the implication of having a particular feature choice in the constructed pattern, and incorporates direct feature-level feedback. The key insight behind SURF is that users can effectively select appropriate features with the aid of impact analysis. SURF provides hints on the global distribution of how each feature is consistent with already labelled positive and negative instances, and how selection of a new feature can yield additional matching instances. Its what-if-analysis contrasts how different feature choices can include (or exclude) more instances in the rest of the population. We performed a user study with 14 participants, designed with two-treatment factorial crossover. Participants were able to provide 30% more correct answers about different API usages in 20% less time. All participants found that what-if-analysis and impact analysis are useful for pattern refinement. 79% of the participants were able to produce the correct, expected pattern with SURF's feature-level guidance, as opposed to 43% of the participants when using the baseline with instance-level feedback only. SURF is the first approach to incorporate feature-level feedback with automated what-if analysis to empower users to control the generality (/ specificity) of a desired code pattern.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639193","National Science Foundation(grant numbers:2106838,1764077,1956322,2106404); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548674","active learning;code search patterns;API misuse;human feedback","Measurement;Codes;Sociology;Computer bugs;Skeleton;Labeling;Statistics","","","","49","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Finding XPath Bugs in XML Document Processors via Differential Testing","S. Li; M. Rigger","Southern University of Science and Technology, China; National University of Singapore, Singapore",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1787","1798","Extensible Markup Language (XML) is a widely used file format for data storage and transmission. Many XML processors support XPath, a query language that enables the extraction of elements from XML documents. These systems can be affected by logic bugs, which are bugs that cause the processor to return incorrect results. In order to tackle such bugs, we propose a new approach, which we realized as a system called XPress. As a test oracle, XPress relies on differential testing, which compares the results of multiple systems on the same test input, and identifies bugs through discrepancies in their outputs. As test inputs, XPress generates both XML documents and XPath queries. Aiming to generate meaningful queries that compute non-empty results, XPress selects a so-called targeted node to guide the XPath expression generation process. Using the targeted node, XPress generates XPath expressions that reference existing context related to the targeted node, such as its tag name and attributes, while also guaranteeing that a predicate evaluates to true before further expanding the query. We tested our approach on six mature XML processors, BaseX, eXist-DB, Saxon, PostgreSQL, libXML2, and a commercial database system. In total, we have found 27 unique bugs in these systems, of which 25 have been verified by the developers, and 20 of which have been fixed. XPress is efficient, as it finds 12 unique bugs in BaseX in 24 hours, which is 2× as fast as naive random generation. We expect that the effectiveness and simplicity of our approach will help to improve the robustness of many XML processors.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549336","XML processors;XPath generation;differential testing","Program processors;Computer bugs;XML;Memory;Robustness;Database systems;Database languages","","","","47","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Nuzzlebug: Debugging Block-based Programs in Scratch","A. Deiner; G. Fraser","University of Passau, Germany; University of Passau, Germany",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","241","253","While professional integrated programming environments support developers with advanced debugging functionality, block-based programming environments for young learners often provide no support for debugging at all, thus inhibiting debugging and preventing debugging education. In this paper we introduce NUZZLEBuG, an extension of the popular block-based programming environment Scratch that provides the missing debugging support. Nuzzlebug allows controlling the executions of Scratch programs with classical debugging functionality such as stepping and breakpoints, and it is an omniscient debugger that also allows reverse stepping. To support learners in deriving hypotheses that guide debugging, Nuz-ZLEBuG is an interrogative debugger that enables to ask questions about executions and provides answers explaining the behavior in question. In order to evaluate NUZZLEBuG, we survey the opinions of teachers, and study the effects on learners in terms of debugging effectiveness and efficiency. We find that teachers consider Nuzzlebug to be useful, and children can use it to debug faulty programs effectively. However, systematic debugging requires dedicated training, and even when Nuzzlebug can provide correct answers learners may require further help to comprehend faults and necessary fixes, thus calling for further research on improving debugging techniques and the information they provide.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3623331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549271","Debugging Tools;Omniscient Debugging;Interrogative Debugging;Scratch;Computer Science Education","Training;Surveys;Location awareness;Codes;Systematics;Source coding;Debugging","","","","66","","14 Jun 2024","","","IEEE","IEEE Conferences"
"CSCHECKER: Revisiting GDPR and CCPA Compliance of Cookie Banners on the Web","M. Zhang; W. Meng; Y. Zhou; K. Ren","The State Key Laboratory of Blockchain and Data Security, Zhejiang University; The Chinese University of Hong Kong; The State Key Laboratory of Blockchain and Data Security, Zhejiang University; The State Key Laboratory of Blockchain and Data Security, Zhejiang University",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2147","2158","Privacy regulations like GDPR and CCPA have greatly affected online advertising and tracking strategies. To comply with the regulations, websites need to display consent management UIs (i.e., cookie banners) implemented under the corresponding technical frameworks, allowing users to specify consents regarding their personal data processing. Although prior works have investigated the cookie banner compliance problems with GDPR, the technical specification has significantly changed. The compliance status under the latest framework remains unclear. There also lacks a systematic study of CCPA banner compliance. More importantly, most work have focused on detecting the regulation violations, whereas little is known about the possible culprits and causes. In this paper, we develop CSCHECKER, a browser-based tool that monitors and records consent strings on websites. We use CSCHECKER to analyze the GDPR and CCPA cookie banners, and reveal previously unknown compliance problems under both frame-works. We also discover and analyze possible miscreants leading to the violations, e.g., consent management providers that return wrong consent data. The comparison of the two frameworks inspires several suggestions about the design of cookie banners, the implementation of opt-out mechanisms, and the enforcement of user consent choices.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548105","Privacy Regulation;Compliance Analysis;GDPR;CCPA","Privacy;Systematics;Data processing;Regulation;Browsers;Advertising;Monitoring","","","","55","","14 Jun 2024","","","IEEE","IEEE Conferences"
"ExAIS: Executable AI Semantics","R. Schumi; J. Sun","Singapore Management University, Singapore; Singapore Management University, Singapore",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","859","870","Neural networks can be regarded as a new programming paradigm, i.e., instead of building ever-more complex programs through (often informal) logical reasoning in the programmers' mind, complex ‘AI’ systems are built by optimising generic neural network models with big data. In this new paradigm, AI frameworks such as Ten-sorFlow and PyTorch play a key role, which is as essential as the compiler for traditional programs. It is known that the lack of a proper semantics for programming languages (such as C), i.e., a correctness specification for compilers, has contributed to many problematic program behaviours and security issues. While it is in general hard to have a correctness specification for compilers due to the high complexity of programming languages and their rapid evolution, we have a unique opportunity to do it right this time for neural networks (which have a limited set of functions, and most of them have stable semantics). In this work, we report our effort on providing a correctness specification of neural net-work frameworks such as TensorFlow. We specify the semantics of almost all TensorFlow layers in the logical programming language Prolog. We demonstrate the usefulness of the semantics through two applications. One is a fuzzing engine for TensorFlow, which features a strong oracle and a systematic way of generating valid neural networks. The other is a model validation approach which enables consistent bug reporting for TensorFlow models.","1558-1225","978-1-4503-9221-1","10.1145/3510003.3510112","National Research Foundation, Singapore; National University of Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794011","AI frameworks;AI libraries;deep learning models;semantics;specification;test case generation;model validation;AI model generation","Deep learning;Computer languages;Program processors;Systematics;Semantics;Computer bugs;Neural networks","","","","45","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Object Graph Programming","A. Thimmaiah; L. Lampropoulos; C. J. Rossbach; M. Gligoric","The University of Texas at Austin, Austin, Texas, USA; University of Maryland, College Park, Maryland, USA; The University of Texas at Austin, Austin, Texas, USA; The University of Texas at Austin, Austin, Texas, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","216","228","We introduce Object Graph Programming (OGO), which enables reading and modifying an object graph (i.e., the entire state of the object heap) via declarative queries. OGO models the objects and their relations in the heap as an object graph thereby treating the heap as a graph database: each node in the graph is an object (e.g., an instance of a class or an instance of a metadata class) and each edge is a relation between objects (e.g., a field of one object references another object). We leverage Cypher, the most popular query language for graph databases, as OGO's query language. Unlike LINQ, which uses collections (e.g., List) as a source of data, OGO views the entire object graph as a single “collection”. OGO is ideal for querying collections (just like LINQ), introspecting the runtime system state (e.g., finding all instances of a given class or accessing fields via reflection), and writing assertions that have access to the entire program state. We prototyped OGO for Java in two ways: (a) by translating an object graph into a Neo4j database on which we run Cypher queries, and (b) by implementing our own in-memory graph query engine that directly queries the object heap. We used OGO to rewrite hundreds of statements in large open-source projects into OGO queries. We report our experience and performance of our prototypes.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548091","Object graph;graph database;query;Cypher","Ciphers;Java;Runtime;Databases;Prototypes;Writing;Reflection","","","","112","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Responsibility in Context: On Applicability of Slicing in Semantic Regression Analysis","S. Badihi; K. Ahmed; Y. Li; J. Rubin","University of British, Columbia, Canada; University of British, Columbia, Canada; Nanyang Technological University, Singapore; University of British, Columbia, Canada",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","563","575","Numerous program slicing approaches aim to help developers troubleshoot regression failures - one of the most time-consuming development tasks. The main idea behind these approaches is to identify a subset of interdependent program statements relevant to the failure, minimizing the amount of code developers need to inspect. Accuracy and reduction rate achieved by slicing are the key considerations toward their applicability in practice: inspecting only the statements in a slice should be faster and more efficient than inspecting the code in full. In this paper, we report on our experiment applying one of the most recent and accurate slicing approaches, dual slicing, to the task of troubleshooting regression failures. As subjects, we use projects from the popular Defects4J benchmark and a systematically-collected set of eight large, open-source client-library project pairs with at least one library upgrade failure, which we refer to as LibRench. The results of our experiments show that the produced slices, while effective in reducing the scope of manual inspection, are still very large to be comfortably analyzed by a human. When inspecting these slices, we observe that most statements in a slice deal with the propagation of information between changed code blocks; these statements are essential for obtaining the necessary context for the changes but are not responsible for the failure directly. Motivated by this insight, we propose a novel approach, implemented in a tool named INPRESS, for further reducing the size of a slice by accurately identifying and summarizing the propagation-related code blocks. Our evaluation of INPRESS shows that it is able to produce slices that are 76% shorter than the original ones (207 vs. 2,007 execution statements, on average), thus, reducing the amount of information developers need to inspect without losing the necessary contextual information.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172711","Program slicing;slice minimization;regression failures;case study","Codes;Semantics;Manuals;Benchmark testing;Inspection;Minimization;Libraries","","","","58","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Balancing Effectiveness and Flakiness of Non-Deterministic Machine Learning Tests","C. S. Xia; S. Dutta; S. Misailovic; D. Marinov; L. Zhang","University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1801","1813","Testing Machine Learning (ML) projects is challenging due to inherent non-determinism of various ML algorithms and the lack of reliable ways to compute reference results. Developers typically rely on their intuition when writing tests to check whether ML algorithms produce accurate results. However, this approach leads to conservative choices in selecting assertion bounds for comparing actual and expected results in test assertions. Because developers want to avoid false positive failures in tests, they often set the bounds to be too loose, potentially leading to missing critical bugs. We present FASER - the first systematic approach for balancing the trade-off between the fault-detection effectiveness and flakiness of non-deterministic tests by computing optimal assertion bounds. FASER frames this trade-off as an optimization problem between these competing objectives by varying the assertion bound. FASER leverages 1) statistical methods to estimate the flakiness rate, and 2) mutation testing to estimate the fault-detection effectiveness. We evaluate FASER on 87 non-deterministic tests collected from 22 popular ML projects. FASER finds that 23 out of 87 studied tests have conservative bounds and proposes tighter assertion bounds that maximizes the fault-detection effectiveness of the tests while limiting flakiness. We have sent 19 pull requests to developers, each fixing one test, out of which 14 pull requests have already been accepted.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00154","NSF(grant numbers:CCF-1763788); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172715","","Machine learning algorithms;Systematics;Limiting;Statistical analysis;Machine learning;Writing;Reliability","","","","105","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Attention! Your Copied Data is Under Monitoring: A Systematic Study of Clipboard Usage in Android Apps","Y. Chen; R. Tang; C. Zuo; X. Zhang; L. Xue; X. Luo; Q. Zhao",City University of Hong Kong; City University of Hong Kong; The Ohio State University; George Mason University; Sun Yat-Sen University; The Hong Kong Polytechnic University; City University of Hong Kong,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","753","765","Recently, clipboard usage has become prevalent in mobile apps allowing users to copy and paste text within the same app or across different apps. However, insufficient access control on the clipboard in the mobile operating systems exposes its contained data to high risks where one app can read the data copied in other apps and store it locally or even send it to remote servers. Unfortunately, the literature only has ad-hoc studies in this respect and lacks a comprehensive and systematic study of the entire mobile app ecosystem. To establish the missing links, this paper proposes an automated tool, ClipboardScope, that leverages the principled static program analysis to uncover the clipboard data usage in mobile apps at scale by defining a usage as a combination of two aspects, i.e., how the clipboard data is validated and where does it go. It defines four primary categories of clipboard data operation, namely spot-on, grand-slam, selective, and cherry-pick, based on the clipboard usage in an app. ClipboardScope is evaluated on 26,201 out of a total of 2.2 million mobile apps available on Google Play as of June 2022 that access and process the clipboard text. It identifies 23,948,848, 1,075, and 330 apps that are recognized as the four designated categories, respectively. In addition, we uncovered a prevalent programming habit of using the SharedPreferences object to store historical data, which can become an unnoticeable privacy leakage channel.","1558-1225","979-8-4007-0217-4","","National Natural Science Foundation(grant numbers:62372490); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549300","Program analysis;mobile security","Data privacy;Systematics;Operating systems;Ecosystems;Programming;Mobile applications;Internet","","","","64","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Are Your Requests Your True Needs? Checking Excessive Data Collection in VPA Apps","F. Xie; C. Yan; M. H. Meng; S. Teng; Y. Zhang; G. Bai","The University of Queensland, Brisbane, Australia; The University of Queensland, Brisbane, Australia; A*STAR, Institute for Infocomm Research, Singapore; The University of Queensland, Brisbane, Australia; Deakin University, Melbourne, Australia; The University of Queensland, Brisbane, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2530","2541","Virtual personal assistants (VPA) services encompass a large number of third-party applications (or apps) to enrich their function-alities. These apps have been well examined to scrutinize their data collection behaviors against their declared privacy policies. Nonetheless, it is often overlooked that most users tend to ignore privacy policies at the installation time. Dishonest developers thus can exploit this situation by embedding excessive declarations to cover their data collection behaviors during compliance auditing. In this work, we present Pico, a privacy inconsistency detector, which checks the VPA app's privacy compliance by analyzing (in)consistency between data requested and data essential for its functionality. Pico understands the app's functionality topics from its publicly available textual data, and leverages advanced GPT-based language models to address domain-specific challenges. Based on the counterparts with similar functionality, suspicious data collection can be detected through the lens of anomaly detection. We apply Pico to understand the status quo of data-functionality com-pliance among all 65,195 skills in the Alexa app store. Our study reveals that 21.7% of the analyzed skills exhibit suspicious data collection, including Top 10 popular Alexa skills that pose threats to 54,116 users. These findings should raise an alert to both developers and users, in the compliance with the purpose limitation principle in data regulations.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549439","Virtual Personal Assistant;privacy compliance;Alexa skills","Data privacy;Privacy;Virtual assistants;Semantics;Detectors;Data collection;Regulation","","","","43","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Precise Sparse Abstract Execution via Cross-Domain Interaction","X. Cheng; J. Wang; Y. Sui","University of New South Wales, Sydney, NSW, Australia; University of New South Wales, Sydney, NSW, Australia; University of New South Wales, Sydney, NSW, Australia",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1335","1346","Sparse static analysis offers a more scalable solution compared to its non-sparse counterpart. The basic idea is to first conduct a fast pointer analysis that over-approximates the value-flows and prop-agates the data-flow facts sparsely along only the pre-computed value-flows instead of all control flow points. Current sparse techniques focus on improving the scalability of the main analysis while maintaining its precision. However, their pointer analyses in both the offline and main phases are inherently imprecise because they rely solely on a single memory address domain without considering values from other domains like the interval domain. Consequently, this leads to conservative alias results, like array-insensitivity, which leaves substantial room for precision improve-ment of the main data-flow analysis. This paper presents CSA, a new Cross-domain Sparse Abstract execution that interweaves correlations between values across multiple abstract domains (e.g., memory address and interval domains). Unlike traditional sparse analysis without cross-domain interaction, CSA performs correlation tracking by establishing implications of values from one domain to another. This correlation tracking enables online bidirectional refinement: CSA refines spurious alias relations using interval domain information and also enhances the precision of interval analysis with refined alias results. This con-tributes to increasingly improved precision and scalability as the main analysis progresses. To improve the efficiency of correlation tracking, we propose an equivalent correlation tracking approach that groups (virtual) memory addresses with equivalent implication results to minimize redundant value joins and storage associated. We apply CSA on two common assertion-based checking clients, buffer overflow and null dereference detection. Experimental results show that CSA outperforms five open-source tools (INFER, Cppcheck, Ikos, Sparrow and KLEE) on ten large-scale projects. CSA finds 111 real bugs with 68.51% precision, detecting 46.05% more bugs than Infer and exhibiting 12.11% more precision rate than KLEE. CSA records 96.63% less false positives on real-world projects than the version without cross-domain interaction. CSA also exhibits an average speedup of 2.47× and an average memory reduction of 6.14× with equivalent correlation tracking.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549341","Abstract execution;sparse analysis;cross-domain interaction","Correlation;Scalability;Computer bugs;Memory management;Buffer overflows;Static analysis;NIST","","","","69","","14 Jun 2024","","","IEEE","IEEE Conferences"
"ECSTATIC: An Extensible Framework for Testing and Debugging Configurable Static Analysis","A. Mordahl; Z. Zhang; D. Soles; S. Wei","Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA; Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA; Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA; Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","550","562","Testing and debugging the implementation of static analysis is a challenging task, often involving significant manual effort from domain experts in a tedious and unprincipled process. In this work, we propose an approach that greatly improves the automation of this process for static analyzers with configuration options. At the core of our approach is the novel adaptation of the theoretical partial order relations that exist between these options to reason about the correctness of actual results from running the static analyzer with different configurations. This allows for automated testing of static analyzers with clearly defined oracles, followed by automated delta debugging, even in cases where ground truths are not defined over the input programs. To apply this approach to many static analysis tools, we design and implement ECSTATIC, an easy-to-extend, open-source framework. We have integrated four popular static analysis tools, SOOT, WALA, DOOP, and FlowDroid, into ECSTATIC. Our evaluation shows running ECSTATIC detects 74 partial order bugs in the four tools and produces reduced bug-inducing programs to assist debugging. We reported 42 bugs; in all cases where we received responses, the tool developers confirmed the reported tool behavior was unintended. So far, three bugs have been fixed and there are ongoing discussions to fix more.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00056","NSF(grant numbers:CCF-2047682,CCF-2008905); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172552","Program analysis;testing and debugging","Location awareness;Computer bugs;Debugging;Static analysis;Manuals;Benchmark testing;Fuzzing","","","","53","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"“I Tend to View Ads Almost Like a Pestilence”: On the Accessibility Implications of Mobile Ads for Blind Users","Z. He; S. F. Huq; S. Malek","University of California, Irvine, Irvine, California, USA; University of California, Irvine, Irvine, California, USA; University of California, Irvine, Irvine, California, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2432","2444","Ads are integral to the contemporary Android ecosystem, gener-ating revenue for free-to-use applications. However, injected as third-party content, ads are displayed on native apps in pervasive ways that affect easy navigation. Ads can prove more disruptive for blind users, who rely on screen readers for navigating an app. While the literature has looked into either the accessibility of web advertisements or the privacy and security implications of mobile ads, a research gap on the accessibility of mobile ads remains, which we aim to bridge. We conduct an empirical study analyzing 500 ad screens in Android apps to categorize and examine the accessi-bility issues therein. Additionally, we conduct 15 qualitative user interviews with blind Android users to better understand the impact of those accessibility issues, how users interact with ads and their preferences. Based on our findings, we discuss the design and practical strategies for developing accessible ads.","1558-1225","979-8-4007-0217-4","10.1145/3597503.3639228","National Science Foundation(grant numbers:2211790,2106306); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549414","Android;Accessibility;Advertisement;Screen Reader","Privacy;Navigation;Ecosystems;Switches;Motors;Libraries;Security","","","","75","CCBY","14 Jun 2024","","","IEEE","IEEE Conferences"
"Predicting performance via automated feature-interaction detection","N. Siegmund; S. S. Kolesnikov; C. Kästner; S. Apel; D. Batory; M. Rosenmüller; G. Saake","University of Magdeburg, Germany; University of Passau, Germany; Philipps Universitat Marburg, Germany; University of Passau, Germany; University of Texas, Austin, USA; University of Magdeburg, Germany; University of Magdeburg, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","167","177","Customizable programs and program families provide user-selectable features to allow users to tailor a program to an application scenario. Knowing in advance which feature selection yields the best performance is difficult because a direct measurement of all possible feature combinations is infeasible. Our work aims at predicting program performance based on selected features. However, when features interact, accurate predictions are challenging. An interaction occurs when a particular feature combination has an unexpected influence on performance. We present a method that automatically detects performance-relevant feature interactions to improve prediction accuracy. To this end, we propose three heuristics to reduce the number of measurements required to detect interactions. Our evaluation consists of six real-world case studies from varying domains (e.g., databases, encoding libraries, and web servers) using different configuration techniques (e.g., configuration files and preprocessor flags). Results show an average prediction accuracy of 95%.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227196","","Feature extraction;Accuracy;Educational institutions;Generators;Indexes;Encryption","","106","","41","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Recovering traceability links between an API and its learning resources","B. Dagenais; M. P. Robillard","School of Computer Science, McGill University, Montreal, QUE, Canada; School of Computer Science, McGill University, Montreal, QUE, Canada",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","47","57","Large frameworks and libraries require extensive developer learning resources, such as documentation and mailing lists, to be useful. Maintaining these learning resources is challenging partly because they are not explicitly linked to the frameworks' API, and changes in the API are not reflected in the learning resources. Automatically recovering traceability links between an API and learning resources is notoriously difficult due to the inherent ambiguity of unstructured natural language. Code elements mentioned in documents are rarely fully qualified, so readers need to understand the context in which a code element is mentioned. We propose a technique that identifies code-like terms in documents and links these terms to specific code elements in an API, such as methods. In an evaluation study with four open source systems, we found that our technique had an average recall and precision of 96%.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227207","","Context;Documentation;Libraries;Joining processes;Java;XML;HTML","","98","4","25","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Identifying Linux bug fixing patches","Y. Tian; J. Lawall; D. Lo","Singapore Management University, Singapore; INRIA/LIP6-Regal, France; Singapore Management University, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","386","396","In the evolution of an operating system there is a continuing tension between the need to develop and test new features, and the need to provide a stable and secure execution environment to users. A compromise, adopted by the developers of the Linux kernel, is to release new versions, including bug fixes and new features, frequently, while maintaining some older “longterm” versions. This strategy raises the problem of how to identify bug fixing patches that are submitted to the current version but should be applied to the longterm versions as well. The current approach is to rely on the individual subsystem maintainers to forward patches that seem relevant to the maintainers of the longterm kernels. The reactivity and diligence of the maintainers, however, varies, and thus many important patches could be missed by this approach. In this paper, we propose an approach that automatically identifies bug fixing patches based on the changes and commit messages recorded in code repositories. We compare our approach with the keyword-based approach for identifying bug-fixing patches used in the literature, in the context of the Linux kernel. The results show that our approach can achieve a 53.19% improvement in recall as compared to keyword-based approaches, with similar precision.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227176","","Linux;Kernel;Feature extraction;Data models;Support vector machines;Context;Data acquisition","","92","1","40","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"MagicFuzzer: Scalable deadlock detection for large-scale applications","Y. Cai; W. K. Chan","Department of Computer Science, City University of Hong Kong, Hong Kong, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","606","616","We present MagicFuzzer, a novel dynamic deadlock detection technique. Unlike existing techniques to locate potential deadlock cycles from an execution, it iteratively prunes lock dependencies that each has no incoming or outgoing edge. Combining with a novel thread-specific strategy, it dramatically shrinks the size of lock dependency set for cycle detection, improving the efficiency and scalability of such a detection significantly. In the real deadlock confirmation phase, it uses a new strategy to actively schedule threads of an execution against the whole set of potential deadlock cycles. We have implemented a prototype and evaluated it on large-scale C/C++ programs. The experimental results confirm that our technique is significantly more effective and efficient than existing techniques.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227156","deadlock detection;multithreaded programs","System recovery;Message systems;Classification algorithms;Image edge detection;Multicore processing;Monitoring;Instruction sets","","48","1","26","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Using dynamic analysis to discover polynomial and array invariants","T. Nguyen; D. Kapur; W. Weimer; S. Forrest","Computer Science, University of New Mexico, USA; Computer Science, University of New Mexico, USA; Computer Science, University of Virginia, USA; Computer Science, University of New Mexico, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","683","693","Dynamic invariant analysis identifies likely properties over variables from observed program traces. These properties can aid programmers in refactoring, documenting, and debugging tasks by making dynamic patterns visible statically. Two useful forms of invariants involve relations among polynomials over program variables and relations among array variables. Current dynamic analysis methods support such invariants in only very limited forms. We combine mathematical techniques that have not previously been applied to this problem, namely equation solving, polyhedra construction, and SMT solving, to bring new capabilities to dynamic invariant detection. Using these methods, we show how to find equalities and inequalities among nonlinear polynomials over program variables, and linear relations among array variables of multiple dimensions. Preliminary experiments on 24 mathematical algorithms and an implementation of AES encryption provide evidence that the approach is effective at finding these invariants.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227149","program analysis;dynamic analysis;invariant generation;nonlinear invariants;array invariants","Arrays;Polynomials;Performance analysis;Complexity theory;Educational institutions","","47","","34","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Ballerina: Automatic generation and clustering of efficient random unit tests for multithreaded code","A. Nistor; Q. Luo; M. Pradel; T. R. Gross; D. Marinov","Department of Computer Science, University of Illinois, Urbana-Champaign, USA; Department of Computer Science, University of Illinois, Urbana-Champaign, USA; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, ETH Zurich, Switzerland; Department of Computer Science, University of Illinois, Urbana-Champaign, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","727","737","Testing multithreaded code is hard and expensive. A multithreaded unit test creates two or more threads, each executing one or more methods on shared objects of the class under test. Such unit tests can be generated at random, but basic random generation produces tests that are either slow or do not trigger concurrency bugs. Worse, such tests have many false alarms, which require human effort to filter out. We present Ballerina, a novel technique for automated random generation of efficient multithreaded tests that effectively trigger concurrency bugs. Ballerina makes tests efficient by having only two threads, each executing a single, randomly selected method. Ballerina increases chances that such simple parallel code finds bugs by appending it to more complex, randomly generated sequential code. We also propose a clustering technique to reduce the manual effort in inspecting failures of automatically generated multithreaded tests. We evaluate Ballerina on 14 real-world bugs from six popular codebases: Groovy, JDK, JFreeChart, Apache Log4j, Apache Lucene, and Apache Pool. The experiments show that tests generated by Ballerina find bugs on average 2×-10× faster than basic random generation, and our clustering technique reduces the number of inspected failures on average 4×-8×. Using Ballerina, we found three previously unknown bugs, two of which were already confirmed and fixed.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227145","","Computer bugs;Instruction sets;Concurrent computing;Testing;Receivers;Inspection","","43","","50","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Slicing MATLAB Simulink models","R. Reicherdt; S. Glesner","Technische Universität Berlin, Germany; Technische Universität Berlin, Germany",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","551","561","MATLAB Simulink is the most widely used industrial tool for developing complex embedded systems in the automotive sector. The resulting Simulink models often consist of more than ten thousand blocks and a large number of hierarchy levels. To ensure the quality of such models, automated static analyses and slicing are necessary to cope with this complexity. In particular, static analyses are required that operate directly on the models. In this article, we present an approach for slicing Simulink Models using dependence graphs and demonstrate its efficiency using case studies from the automotive and avionics domain. With slicing, the complexity of a model can be reduced for a given point of interest by removing unrelated model elements, thus paving the way for subsequent static quality assurance methods.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227161","Slicing;Simulink;Dependence Analysis;MATLAB","Context;Context modeling;Data models;Analytical models;MATLAB;Switches;Embedded systems","","35","6","21","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Active code completion","C. Omar; Y. S. Yoon; T. D. LaToza; B. A. Myers","Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","859","869","Code completion menus have replaced standalone API browsers for most developers because they are more tightly integrated into the development workflow. Refinements to the code completion menu that incorporate additional sources of information have similarly been shown to be valuable, even relative to standalone counterparts offering similar functionality. In this paper, we describe active code completion, an architecture that allows library developers to introduce interactive and highly-specialized code generation interfaces, called palettes, directly into the editor. Using several empirical methods, we examine the contexts in which such a system could be useful, describe the design constraints governing the system architecture as well as particular code completion interfaces, and design one such system, named Graphite, for the Eclipse Java development environment. Using Graphite, we implement a palette for writing regular expressions as our primary example and conduct a small pilot study. In addition to showing the feasibility of this approach, it provides further evidence in support of the claim that integrating specialized code completion interfaces directly into the editor is valuable to professional developers.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227133","code completion;development environments","Image color analysis;Java;Syntactics;Computer architecture;Standards;Databases","","35","","24","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Maintaining invariant traceability through bidirectional transformations","Y. Yu; Y. Lin; Z. Hu; S. Hidaka; H. Kato; L. Montrieux","Department of Computing, Open University, Milton Keynes, UK; Department of Computer Science, University of Illinois, Urbana-Champaign, USA; National Institute of Information, Tokyo, Japan; National Institute of Information, Tokyo, Japan; National Institute of Information, Tokyo, Japan; Department of Computing, Open University, Milton Keynes, UK",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","540","550","Following the “convention over configuration” paradigm, model-driven development (MDD) generates code to implement the “default” behaviour that has been specified by a template separate from the input model, reducing the decision effort of developers. For flexibility, users of MDD are allowed to customise the model and the generated code in parallel. A synchronisation of changed model or code is maintained by reflecting them on the other end of the code generation, as long as the traceability is unchanged. However, such invariant traceability between corresponding model and code elements can be violated either when (a) users of MDD protect custom changes from the generated code, or when (b) developers of MDD change the template for generating the default behaviour. A mismatch between user and template code is inevitable as they evolve for their own purposes. In this paper, we propose a two-layered invariant traceability framework that reduces the number of mismatches through bidirectional transformations. On top of existing vertical (model↔code) synchronisations between a model and the template code, a horizontal (code↔code) synchronisation between user and template code is supported, aligning the changes in both directions. Our blinkit tool is evaluated using the data set available from the CVS repositories of a MDD project: Eclipse MDT/GMF.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227162","","Synchronization;Java;Computational modeling;Generators;Adaptation models;Educational institutions;Prototypes","","33","","36","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Automatic input rectification","F. Long; V. Ganesh; M. Carbin; S. Sidiroglou; M. Rinard","CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","80","90","We present a novel technique, automatic input rectification, and a prototype implementation, SOAP. SOAP learns a set of constraints characterizing typical inputs that an application is highly likely to process correctly. When given an atypical input that does not satisfy these constraints, SOAP automatically rectifies the input (i.e., changes the input so that it satisfies the learned constraints). The goal is to automatically convert potentially dangerous inputs into typical inputs that the program is highly likely to process correctly. Our experimental results show that, for a set of benchmark applications (Google Picasa, ImageMagick, VLC, Swfdec, and Dillo), this approach effectively converts malicious inputs (which successfully exploit vulnerabilities in the application) into benign inputs that the application processes correctly. Moreover, a manual code analysis shows that, if an input does satisfy the learned constraints, it is incapable of exploiting these vulnerabilities. We also present the results of a user study designed to evaluate the subjective perceptual quality of outputs from benign but atypical inputs that have been automatically rectified by SOAP to conform to the learned constraints. Specifically, we obtained benign inputs that violate learned constraints, used our input rectifier to obtain rectified inputs, then paid Amazon Mechanical Turk users to provide their subjective qualitative perception of the difference between the outputs from the original and rectified inputs. The results indicate that rectification can often preserve much, and in many cases all, of the desirable data in the original input.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227204","","Simple object access protocol;Monitoring;Training;Security;Engines;Videos;Safety","","25","1","38","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Debugger Canvas: Industrial experience with the code bubbles paradigm","R. DeLine; A. Bragdon; K. Rowan; J. Jacobsen; S. P. Reiss","Microsoft Research, Visual Studio Ultimate Microsoft Corporation, Redmond, WA, USA; Microsoft Research, Visual Studio Ultimate Microsoft Corporation, Redmond, WA, USA; Microsoft Research, Visual Studio Ultimate Microsoft Corporation, Redmond, WA, USA; Microsoft Research, Visual Studio Ultimate Microsoft Corporation, Redmond, WA, USA; Department of Computer Science, Brown University, Providence, RI, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1064","1073","At ICSE 2010, the Code Bubbles team from Brown University and the Code Canvas team from Microsoft Research presented similar ideas for new user experiences for an integrated development environment. Since then, the two teams formed a collaboration, along with the Microsoft Visual Studio team, to release Debugger Canvas, an industrial version of the Code Bubbles paradigm. With Debugger Canvas, a programmer debugs her code as a collection of code bubbles, annotated with call paths and variable values, on a two-dimensional pan-and-zoom surface. In this experience report, we describe new user interface ideas, describe the rationale behind our design choices, evaluate the performance overhead of the new design, and provide user feedback based on lab participants, post-release usage data, and a user survey and interviews. We conclude that the code bubbles paradigm does scale to existing customer code bases, is best implemented as a mode in the existing user experience rather than a replacement, and is most useful when the user has a long or complex call paths, a large or unfamiliar code base, or complex control patterns, like factories or dynamic linking.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227113","integrated development environments;user interfaces;human factors;experience report","Debugging;Visualization;Educational institutions;User interfaces;Testing;Navigation;Web servers","","20","1","19","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Static detection of resource contention problems in server-side scripts","Y. Zheng; X. Zhang","Department of Computer Science, Purdue University, USA; Department of Computer Science, Purdue University, USA",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","584","594","With modern multi-core architectures, web applications are usually configured to serve multiple requests simultaneously by spawning multiple instances. These instances may access the same external resources such as database tables and files. Such contentions may become severe during peak time, leading to violations of atomic business logic. In this paper, we propose a novel static analysis that detects atomicity violations of external operations for server side scripts. The analysis differs from traditional atomicity violation detection techniques by focusing on external resources instead of shared memory. It consists of three components. The first one is an interprocedural and path-sensitive resource identity analysis that determines whether multiple operations access the same external resource, which is critical to identifying contentions. The second component infers pairs of external operations that should be executed atomically. Finally, violations are detected by reasoning about serializability of interleaved atomic pairs. Experimental results show that the analysis is highly effective in detecting atomicity violations in real-world web apps.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227158","php;resource contention;static analysis;constraint solving","Servers;Databases;Encoding;Abstracts;Computational modeling;Context;Cognition","","15","1","37","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Inferring class level specifications for distributed systems","S. Kumar; S. -C. Khoo; A. Roychoudhury; D. Lo","National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; Singapore Management University, Singapore",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","914","924","Distributed systems often contain many behaviorally similar processes, which are conveniently grouped into classes. In system modeling, it is common to specify such systems by describing the class level behavior, instead of object level behavior. While there have been techniques that mine specifications of such distributed systems from their execution traces, these methods only mine object-level specifications involving concrete process objects. This leads to specifications which are large, hard to comprehend, and sensitive to simple changes in the system (such as the number of objects). In this paper, we develop a class level specification mining framework for distributed systems. A specification that describes interaction snippets between various processes in a distributed system forms a natural and intuitive way to document their behavior. Our mining method groups together such interactions between behaviorally similar processes, and presents a mined specification involving “symbolic” Message Sequence Charts. Our experiments indicate that our mined symbolic specifications are significantly smaller than mined concrete specifications, while at the same time achieving better precision and recall.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227128","Specification Mining;Distributed Systems","Concrete;History;Abstracts;Aggregates;Data mining;Context;Barium","","12","","39","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Methodology for migration of long running process instances in a global large scale BPM environment in Credit Suisse's SOA landscape","T. Ploom; S. Scheit; A. Glaser","Integration Architecture, Credit Suisse AG, Zurich, Switzerland; Workflow Competence Center, Credit Suisse AG, Zurich, Switzerland; Workflow Competence Center, Credit Suisse AG, Zurich, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","977","986","Research about process instance migration covers mainly changes in process models during the process evolution and their effects on the same runtime environment. But what if the runtime environment - a legacy Business Process Execution (BPE) platform - had to be replaced with a new solution? Several migration aspects must be taken into account. (1) Process models from the old BPE platform have to be converted to the target process definition language on the target BPE platform. (2) Existing Business Process Management (BPM) applications must be integrated via new BPE platform interfaces. (3) Process instances and process instance data state must be migrated. For each of these points an appropriate migration strategy must be chosen. This paper describes the migration methodology which was applied for the BPE platform renewal in Credit Suisse.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227123","migration of long running process instances;BPM application migration;workflow application migration;legacy workflow system replacement;business process execution platform;process definition model conversion","Business;Standards;Analytical models;History;Computer architecture;Data models;Banking","","1","","45","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Message from the General Co-Chairs International Conference on Software Engineering (ICSE) 2024","A. C. R. Paiva; R. Abreu","Faculty of Engineering, University of Porto, Portugal; Faculty of Engineering, University of Porto / Meta Platforms, Portugal, USA",2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","xxxvii","xl","Welcome to the 46th edition of the IEEE/ACM International Conference on Software Engineering - ICSE 2024, set against the vibrant backdrop of Lisbon, Portugal. Acting as General Co-Chairs for this prestigious conference has been our great privilege and an extraordinary journey. Lisbon, where tradition and innovation merge seamlessly, is a beacon for technological advancement and cultural heritage. Portugal's capital is renowned not only for its historic sites, sunny disposition, and welcoming atmosphere but also for its dynamic technological ecosystem and educational institutions at the forefront of software engineering research. With Lisbon's rich history, cuttingedge companies, and thriving start-up scene, we are thrilled to invite you to an event that promises to be a melting pot of ideas, fostering groundbreaking discussions and collaborations. Let the scenic views of the Tagus River - which you will be seeing from Centro Cultural de Belém meeting rooms - and the charming streets of Lisbon inspire you as we delve into the latest developments and challenges in software engineering. Welcome to ICSE 2024 in Lisbon - a conference that promises to be as memorable and impactful as the city itself.","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548336","","","","","","0","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Message from Program Chairs: International Conference on Software Engineering (ICSE) 2024","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","xli","xliv","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549328","","","","","","0","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Summary of the ICSE 2012 tutorials and technical briefings","A. Leitner; O. Nierstrasz","Google Zurich, Zurich, Switzerland; University of Bern, Bern, Switzerland",2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1654","1657","This year ICSE is offering a mix of half-day and full day tutorials in addition to shorter technical briefings in selected domains. Whereas tutorials cover a wide range of mature topics of both academic and practical interest, technical briefings are intended to provide a compact introduction to the state-of-the-art in an emerging area.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227212","","Tutorials;Software engineering;Software;Proposals;Multicore processing;Data mining;Ecosystems","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Message from the ICSE 2022 General Chair","M. B. Dwyer","Department of Computer Science, University of Virginia, USA",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xxix","xxx","On behalf of the ICSE 2022 organizing committee, I welcome you to the 44th ACM/IEEE International Conference on Software Engineering. In 2022 ICSE will be held as a hybrid conference with virtual and in-person events. Building on the success of ICSE's virtual offerings in 2020 and 2021, ICSE 2022's virtual program aims to provide a forum that is accessible to all members of the software engineering community and that promotes the ability of contributors to highlight their findings and engage the community in conversation. ICSE 2022's in-person events will be held in Pittsburgh, Pennsylvania, USA. This is the second time that ICSE will be held in Pittsburgh, but the city has transformed into a vibrant technology hub since it hosted the 11th ICSE in 1989 and this creates a great opportunity for ICSE participants to connect with local industry.","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793892","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the ICSE 2023 Program Co-Chairs","L. Pollock; M. Di Penta","University of Delaware, DE, USA; University of Sannio, Italy",2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","xl","xliii","Welcome to ICSE 2023! It is our great pleasure to introduce the program of the 45th IEEE/ACM International Conference on Software Engineering (ICSE 2023), which will be held in Melbourne, Australia, on May 14-20, 2023.","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172566","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Artifact Evaluation","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","lvii","lviii","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00008","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172820","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Title Page i","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1","1","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172533","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Message from the Journal-First Track Chairs","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xliv","xliv","","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793547","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Title Page iii","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1","1","","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793909","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Title Page iii","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1","1","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548959","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Title Page","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","1","1","","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794133","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Title Page","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","1","1","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548596","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Sponsors and Supporters","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xlvi","xlvi","","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794076","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the Workshop Chairs of ICSE 2022","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xlii","xlii","","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794039","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the ICSE 2022 Program Chairs","D. Damian; A. Zeller","University of Victoria, Canada; CISPA, Germany",2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xxxi","xxxii","What's new with ICSE 2022 ICSE 2022 is here! Oddly enough, a third year for ICSE papers to be written or reviewed during a global pandemic. Despite additional challenges, ICSE continued strong: another record submission number (691 papers in the technical track), and a largest ever ICSE Program Committee (almost 200 members). ICSE sets the record as being the flagship conference in Software Engineering.","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793861","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Message from the Chairs","",,2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","v","vii","Presents the welcome message from the conference proceedings.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227258","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Message from the ICSE 2023 General Chair","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","xxxvi","xxxix","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172791","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Organizing Committee","",,2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","ix","xv","Provides a listing of current committee members.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227257","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227257","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Conference sponsors","",,2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","xvi","xvii","The conference organizers greatly appreciate the support of the various corporate sponsors listed.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227256","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"[Front matter]","",,2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","i","ii","The following topics are dealt with: software engineering education; formal research demonstration; poster demonstration; informal demonstration; and ACM student research competition.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227260","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Title Page","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1","1","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172631","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Copyright","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","1","1","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172810","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Research Track Area Chairs","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","lvi","lvi","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548122","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Workshop Program Committee","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xliii","xliii","Workshop Program Committee.","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793938","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Most Influential Paper (MIP) Award","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","lix","lix","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172614","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Journal-First Program Committee","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xlv","xlv","Journal-First Program Committee.","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793997","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Additional Reviewers","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","lvii","lvii","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548476","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Other Track Committees","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","lvi","lvi","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00221","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172802","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"[Front and back cover]","",,2012 34th International Conference on Software Engineering (ICSE),"28 Jun 2012","2012","","","1","1","Presents the front and back covers of the proceedings record.","1558-1225","978-1-4673-1067-3","10.1109/ICSE.2012.6227016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6227016","","","","","","","IEEE","28 Jun 2012","","","IEEE","IEEE Conferences"
"Organizing Committee ICSE 2022","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","xxxiii","xli","","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793890","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Author Index","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","2643","2653","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172697","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Author Index","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","2943","2956","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548745","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Research Track Program Committee","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","xlv","lii","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548081","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Technical Track Program Committee","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","xliv","li","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172713","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Author Index","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","2453","2464","Author Index.","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794002","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Artifact Evaluation Committee","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","liii","lv","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10548752","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Additional Reviewers","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","liv","lv","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00222","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172513","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
"Table of Contents","",,2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE),"20 Jun 2022","2022","","","v","xxviii","Table of Contents.","1558-1225","978-1-4503-9221-1","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794019","","","","","","","","20 Jun 2022","","","IEEE","IEEE Conferences"
"Table of Contents","",,2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE),"14 Jun 2024","2024","","","v","xxxvi","","1558-1225","979-8-4007-0217-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549506","","","","","","","","14 Jun 2024","","","IEEE","IEEE Conferences"
"Table of Contents","",,2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE),"14 Jul 2023","2023","","","v","xxxvi","","1558-1225","978-1-6654-5701-9","10.1109/ICSE48619.2023.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172546","","","","","","","IEEE","14 Jul 2023","","","IEEE","IEEE Conferences"
